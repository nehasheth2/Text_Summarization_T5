,source,source_labels,rouge_scores,paper_id,target,cleaned_source,full_source_text,sent_count,avg_word_len,avg_sent_len
0,"['Mixed precision training (MPT) is becoming a practical technique to improve the speed and energy efficiency of training deep neural networks by leveraging the fast hardware support for IEEE half-precision floating point that is available in existing GPUs.', 'MPT is typically used in combination with a technique called loss scaling, that works by scaling up the loss value up before the start of backpropagation in order to minimize the impact of numerical underflow on training.', 'Unfortunately, existing methods make this loss scale value a hyperparameter that needs to be tuned per-model, and a single scale cannot be adapted to different layers at different training stages.', 'We introduce a loss scaling-based training method called adaptive loss scaling that makes MPT easier and more practical to use, by removing the need to tune a model-specific loss scale hyperparameter.', 'We achieve this by introducing layer-wise loss scale values which are automatically computed during training to deal with underflow more effectively than existing methods.', 'We present experimental results on a variety of networks and tasks that show our approach can shorten the time to convergence and improve accuracy, compared with using the existing state-of-the-art MPT and single-precision floating point.']","[0, 0, 0, 1, 0, 0]","[0.23999999463558197, 0.260869562625885, 0.19999998807907104, 0.380952388048172, 0.20512820780277252, 0.2978723347187042]",rJlnfaNYvB,"['We devise adaptive loss scaling to improve mixed precision training that surpass the state-of-the-art results.', 'Proposal for an adaptive loss scaling method during backpropagation for mix precision training where scale rate is decided automatically to reduce the underflow.', 'The authors propose a method to train models in FP16 precision that adopts a more elaborate way to minimize underflow in every layer simultaneously and automatically.']","['mixed precision training  mpt  becoming practical technique improve speed energy efficiency training deep neural network leveraging fast hardware support ieee halfprecision floating point available existing gpus ', 'mpt typically used combination technique called loss scaling  work scaling loss value start backpropagation order minimize impact numerical underflow training ', 'unfortunately  existing method make loss scale value hyperparameter need tuned permodel  single scale adapted different layer different training stage ', 'introduce loss scalingbased training method called adaptive loss scaling make mpt easier practical use  removing need tune modelspecific loss scale hyperparameter ', 'achieve introducing layerwise loss scale value automatically computed training deal underflow effectively existing method ', 'present experimental result variety network task show approach shorten time convergence improve accuracy  compared using existing stateoftheart mpt singleprecision floating point ']","Mixed precision training (MPT) is becoming a practical technique to improve the speed and energy efficiency of training deep neural networks by leveraging the fast hardware support for IEEE half-precision floating point that is available in existing GPUs., MPT is typically used in combination with a technique called loss scaling, that works by scaling up the loss value up before the start of backpropagation in order to minimize the impact of numerical underflow on training., Unfortunately, existing methods make this loss scale value a hyperparameter that needs to be tuned per-model, and a single scale cannot be adapted to different layers at different training stages., We introduce a loss scaling-based training method called adaptive loss scaling that makes MPT easier and more practical to use, by removing the need to tune a model-specific loss scale hyperparameter., We achieve this by introducing layer-wise loss scale values which are automatically computed during training to deal with underflow more effectively than existing methods., We present experimental results on a variety of networks and tasks that show our approach can shorten the time to convergence and improve accuracy, compared with using the existing state-of-the-art MPT and single-precision floating point.",11,5.574358974358974,17.727272727272727
1,"['Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities.', 'This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors.', 'We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks.', 'Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization.', 'We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.']","[0, 0, 1, 0, 0]","[0.05405404791235924, 0.2926829159259796, 0.9743589758872986, 0.19512194395065308, 0.11764705181121826]",rJVoEiCqKQ,"['We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.', 'A formulation to learn the distribution over unobservable permutation variables based on deep networks for the set prediction problem.']","['many realworld problem  eg  object detection  output naturally expressed set entity ', 'creates challenge traditional deep neural network naturally deal structured output vector  matrix tensor ', 'present novel approach learning predict set unknown permutation cardinality using deep neural network ', 'specifically  formulation incorporate permutation unobservable variable estimate distribution learning process using alternating optimization ', 'demonstrate validity new formulation two relevant vision problem  object detection  formulation outperforms stateoftheart detector faster rcnn yolo  complex captcha test  observe  surprisingly  set based network acquired ability mimicking arithmetic without rule coded ']","Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities., This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors., We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks., Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization., We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.",14,5.99236641221374,8.733333333333333
2,"['Foveation is an important part of human vision, and a number of deep networks have also used foveation.', 'However, there have been few systematic comparisons between foveating and non-foveating deep networks, and between different variable-resolution downsampling methods.', 'Here we define several such methods, and compare their performance on ImageNet recognition with a Densenet-121 network.', 'The best variable-resolution method slightly outperforms uniform downsampling.', 'Thus in our experiments, foveation does not substantially help or hinder object recognition in deep networks.']","[0, 0, 1, 0, 0]","[0.11764705181121826, 0.11764705181121826, 0.3529411852359772, 0.0, 0.1875]",rkldVXKU8H,['We compare object recognition performance on images that are downsampled uniformly and with three different foveation schemes.'],"['foveation important part human vision  number deep network also used foveation ', 'however  systematic comparison foveating nonfoveating deep network  different variableresolution downsampling method ', 'define several method  compare performance imagenet recognition densenet121 network ', 'best variableresolution method slightly outperforms uniform downsampling ', 'thus experiment  foveation substantially help hinder object recognition deep network ']","Foveation is an important part of human vision, and a number of deep networks have also used foveation., However, there have been few systematic comparisons between foveating and non-foveating deep networks, and between different variable-resolution downsampling methods., Here we define several such methods, and compare their performance on ImageNet recognition with a Densenet-121 network., The best variable-resolution method slightly outperforms uniform downsampling., Thus in our experiments, foveation does not substantially help or hinder object recognition in deep networks.",10,6.371794871794871,7.8
3,"['We explore the concept of co-design in the context of neural network verification.', 'Specifically, we aim to train deep neural networks that not only are robust to adversarial perturbations but also whose robustness can be verified more easily.', 'To this end, we identify two properties of network models - weight sparsity and so-called ReLU stability - that turn out to significantly impact the complexity of the corresponding verification task.', 'We demonstrate that improving weight sparsity alone already enables us to turn computationally intractable verification problems into tractable ones.', 'Then, improving ReLU stability leads to an additional 4-13x speedup in verification times.', 'An important feature of our methodology is its ""universality,"" in the sense that it can be used with a broad range of training procedures and verification approaches.\n']","[0, 1, 0, 0, 0, 0]","[0.1249999925494194, 0.4888888895511627, 0.20408162474632263, 0.14999999105930328, 0.05882352590560913, 0.1249999925494194]",BJfIVjAcKm,"['We develop methods to train deep neural models that are both robust to adversarial perturbations and whose robustness is significantly easier to verify.', 'The paper presents several ways to regularize plain ReLU networks to opimize the adversarial robustness, provable adversarial robustness, and the verification speed.', 'This paper proposes methods to train robust neural networks that can be verified faster, using pruning methods to encourage weight sparsity and regularization to encourage ReLU stability.']","['explore concept codesign context neural network verification ', 'specifically  aim train deep neural network robust adversarial perturbation also whose robustness verified easily ', 'end  identify two property network model  weight sparsity socalled relu stability  turn significantly impact complexity corresponding verification task ', 'demonstrate improving weight sparsity alone already enables u turn computationally intractable verification problem tractable one ', ' improving relu stability lead additional 413x speedup verification time ', 'important feature methodology  universality   sense used broad range training procedure verification approach ']","We explore the concept of co-design in the context of neural network verification., Specifically, we aim to train deep neural networks that not only are robust to adversarial perturbations but also whose robustness can be verified more easily., To this end, we identify two properties of network models - weight sparsity and so-called ReLU stability - that turn out to significantly impact the complexity of the corresponding verification task., We demonstrate that improving weight sparsity alone already enables us to turn computationally intractable verification problems into tractable ones., Then, improving ReLU stability leads to an additional 4-13x speedup in verification times., An important feature of our methodology is its ""universality,"" in the sense that it can be used with a broad range of training procedures and verification approaches.
",9,5.625,14.222222222222221
4,"['Batch Normalization (BatchNorm) has shown to be effective for improving and accelerating the training of deep neural networks.', 'However, recently it has been shown that it is also vulnerable to adversarial perturbations.', 'In this work, we aim to investigate the cause of adversarial vulnerability of the BatchNorm.', 'We hypothesize that the use of different normalization statistics during training and inference (mini-batch statistics for training and moving average of these values at inference) is the main cause of this adversarial vulnerability in the BatchNorm layer.', 'We empirically proved this by experiments on various neural network architectures and datasets.', 'Furthermore, we introduce Robust Normalization (RobustNorm) and experimentally show that it is not only resilient to adversarial perturbation but also inherit the benefits of BatchNorm.']","[0, 0, 1, 0, 0, 0]","[0.19999998807907104, 0.23999999463558197, 0.4000000059604645, 0.2380952388048172, 0.07999999821186066, 0.3243243098258972]",BJlEEaEFDS,"['Investigation of how BatchNorm causes adversarial vulnerability and how to avoid it. ', 'This paper addresses vulnerability to adversarial perturbations in BatchNorm, and proposes an alternative called RobustNorm, using min-max rescaling instead of normalization.', 'This paper investigates the reason behind the vulnerability of BatchNorm and proposes Robust Normalization, a normalization method that achieves significantly better results under a variety of attack methods.']","['batch normalization  batchnorm  shown effective improving accelerating training deep neural network ', 'however  recently shown also vulnerable adversarial perturbation ', 'work  aim investigate cause adversarial vulnerability batchnorm ', 'hypothesize use different normalization statistic training inference  minibatch statistic training moving average value inference  main cause adversarial vulnerability batchnorm layer ', 'empirically proved experiment various neural network architecture datasets ', 'furthermore  introduce robust normalization  robustnorm  experimentally show resilient adversarial perturbation also inherit benefit batchnorm ']","Batch Normalization (BatchNorm) has shown to be effective for improving and accelerating the training of deep neural networks., However, recently it has been shown that it is also vulnerable to adversarial perturbations., In this work, we aim to investigate the cause of adversarial vulnerability of the BatchNorm., We hypothesize that the use of different normalization statistics during training and inference (mini-batch statistics for training and moving average of these values at inference) is the main cause of this adversarial vulnerability in the BatchNorm layer., We empirically proved this by experiments on various neural network architectures and datasets., Furthermore, we introduce Robust Normalization (RobustNorm) and experimentally show that it is not only resilient to adversarial perturbation but also inherit the benefits of BatchNorm.",9,5.959016393442623,13.555555555555555
5,"['Electronic Health Records (EHR) comprise of longitudinal clinical observations portrayed with sparsity, irregularity, and high-dimensionality which become the major obstacles in drawing reliable downstream outcome.', 'Despite greatly numbers of imputation methods are being proposed to tackle these issues, most of the existing methods ignore correlated features or temporal dynamics and entirely put aside the uncertainty.', 'In particular, since the missing values estimates have the risk of being imprecise, it motivates us to pay attention to reliable and less certain information differently.', 'In this work, we propose a novel variational-recurrent imputation network (V-RIN), which unified imputation and prediction network, by taking into account the correlated features, temporal dynamics, and further utilizing the uncertainty to alleviate the risk of biased missing values estimates.', 'Specifically, we leverage the deep generative model to estimate the missing values based on the distribution among variables and a recurrent imputation network to exploit the temporal relations in conjunction with utilization of the uncertainty.', 'We validated the effectiveness of our proposed model with publicly available real-world EHR dataset, PhysioNet Challenge 2012, and compared the results with other state-of-the-art competing methods in the literature.']","[0, 0, 0, 1, 0, 0]","[0.11999999731779099, 0.307692289352417, 0.3265306055545807, 0.688524603843689, 0.3636363446712494, 0.11764705181121826]",ryg2wlSFwS,"['Our variational-recurrent imputation network (V-RIN) takes into account the correlated features, temporal dynamics, and further utilizes the uncertainty to alleviate the risk of biased missing values estimates.', 'A missing data imputation network to incorporate correlation, temporal relationships, and data uncertainty for the problem of data sparsity in EHRs, which yields higher AUC on mortality rate classification tasks.', 'The paper presented a method that combines VAE and uncertainty aware GRU for sequential missing data imputation and outcome prediction.']","['electronic health record  ehr  comprise longitudinal clinical observation portrayed sparsity  irregularity  highdimensionality become major obstacle drawing reliable downstream outcome ', 'despite greatly number imputation method proposed tackle issue  existing method ignore correlated feature temporal dynamic entirely put aside uncertainty ', 'particular  since missing value estimate risk imprecise  motivates u pay attention reliable le certain information differently ', 'work  propose novel variationalrecurrent imputation network  vrin   unified imputation prediction network  taking account correlated feature  temporal dynamic  utilizing uncertainty alleviate risk biased missing value estimate ', 'specifically  leverage deep generative model estimate missing value based distribution among variable recurrent imputation network exploit temporal relation conjunction utilization uncertainty ', 'validated effectiveness proposed model publicly available realworld ehr dataset  physionet challenge 2012  compared result stateoftheart competing method literature ']","Electronic Health Records (EHR) comprise of longitudinal clinical observations portrayed with sparsity, irregularity, and high-dimensionality which become the major obstacles in drawing reliable downstream outcome., Despite greatly numbers of imputation methods are being proposed to tackle these issues, most of the existing methods ignore correlated features or temporal dynamics and entirely put aside the uncertainty., In particular, since the missing values estimates have the risk of being imprecise, it motivates us to pay attention to reliable and less certain information differently., In this work, we propose a novel variational-recurrent imputation network (V-RIN), which unified imputation and prediction network, by taking into account the correlated features, temporal dynamics, and further utilizing the uncertainty to alleviate the risk of biased missing values estimates., Specifically, we leverage the deep generative model to estimate the missing values based on the distribution among variables and a recurrent imputation network to exploit the temporal relations in conjunction with utilization of the uncertainty., We validated the effectiveness of our proposed model with publicly available real-world EHR dataset, PhysioNet Challenge 2012, and compared the results with other state-of-the-art competing methods in the literature.",19,6.227027027027027,9.736842105263158
6,"['Despite the state-of-the-art accuracy of Deep Neural Networks (DNN) in various classification problems, their deployment onto resource constrained edge computing devices remains challenging due to their large size and complexity.', 'Several recent studies have reported remarkable results in reducing this complexity through quantization of DNN models.', 'However, these studies usually do not consider the changes in the loss function when performing quantization, nor do they take the different importances of DNN model parameters to the accuracy into account.', 'We address these issues in this paper by proposing a new method, called adaptive quantization, which simplifies a trained DNN model by finding a unique, optimal precision for each network parameter such that the increase in loss is minimized.', 'The optimization problem at the core of this method iteratively uses the loss function gradient to determine an error margin for each parameter and assigns it a precision accordingly.', 'Since this problem uses linear functions, it is computationally cheap and, as we will show, has a closed-form approximate solution.', 'Experiments on MNIST, CIFAR, and SVHN datasets showed that the proposed method can achieve near or better than state-of-the-art reduction in model size with similar error rates.', 'Furthermore, it can achieve compressions close to floating-point model compression methods without loss of accuracy.']","[0, 0, 0, 0, 0, 0, 1, 0]","[0.043478257954120636, 0.12121211737394333, 0.04444443807005882, 0.07692307233810425, 0.13333332538604736, 0.0, 0.13636362552642822, 0.0624999962747097]",SyOK1Sg0W,"['An adaptive method for fixed-point quantization of neural networks based on theoretical analysis rather than heuristics. ', 'Proposes a method for quantizing neural networks that allow weights to be quantized with different precision depending on their importance, taking into account the loss.', 'The paper proposes a technique for quantizing the weights of a neural network with bit-depth/precision varying on a per-parameter basis.']","['despite stateoftheart accuracy deep neural network  dnn  various classification problem  deployment onto resource constrained edge computing device remains challenging due large size complexity ', 'several recent study reported remarkable result reducing complexity quantization dnn model ', 'however  study usually consider change loss function performing quantization  take different importance dnn model parameter accuracy account ', 'address issue paper proposing new method  called adaptive quantization  simplifies trained dnn model finding unique  optimal precision network parameter increase loss minimized ', 'optimization problem core method iteratively us loss function gradient determine error margin parameter assigns precision accordingly ', 'since problem us linear function  computationally cheap  show  closedform approximate solution ', 'experiment mnist  cifar  svhn datasets showed proposed method achieve near better stateoftheart reduction model size similar error rate ', 'furthermore  achieve compression close floatingpoint model compression method without loss accuracy ']","Despite the state-of-the-art accuracy of Deep Neural Networks (DNN) in various classification problems, their deployment onto resource constrained edge computing devices remains challenging due to their large size and complexity., Several recent studies have reported remarkable results in reducing this complexity through quantization of DNN models., However, these studies usually do not consider the changes in the loss function when performing quantization, nor do they take the different importances of DNN model parameters to the accuracy into account., We address these issues in this paper by proposing a new method, called adaptive quantization, which simplifies a trained DNN model by finding a unique, optimal precision for each network parameter such that the increase in loss is minimized., The optimization problem at the core of this method iteratively uses the loss function gradient to determine an error margin for each parameter and assigns it a precision accordingly., Since this problem uses linear functions, it is computationally cheap and, as we will show, has a closed-form approximate solution., Experiments on MNIST, CIFAR, and SVHN datasets showed that the proposed method can achieve near or better than state-of-the-art reduction in model size with similar error rates., Furthermore, it can achieve compressions close to floating-point model compression methods without loss of accuracy.",20,5.725961538461538,10.4
7,"['We study the problem of learning permutation invariant representations that can capture containment relations.', 'We propose training a model on a novel task: predicting the size of the symmetric difference between pairs of multisets, sets which may contain multiple copies of the same object.', 'With motivation from fuzzy set theory, we formulate both multiset representations and how to predict symmetric difference sizes given these representations.', 'We model multiset elements as vectors on the standard simplex and multisets as the summations of such vectors, and we predict symmetric difference as the l1-distance between multiset representations.', 'We demonstrate that our representations more effectively predict the sizes of symmetric differences than DeepSets-based approaches with unconstrained object representations.', 'Furthermore, we demonstrate that the model learns meaningful representations, mapping objects of different classes to different standard basis vectors.']","[0, 0, 0, 1, 0, 0]","[0.19512194395065308, 0.38461539149284363, 0.3829787075519562, 0.47999998927116394, 0.30434781312942505, 0.2666666507720947]",H1eUz1rKPr,"['Based on fuzzy set theory, we propose a model that given only the sizes of symmetric differences between pairs of multisets, learns representations of such multisets and their elements.', 'This paper proposes a new task of set learning, predicting the size of the symmetric difference between multisets, and gives a method to solve the task based on fuzzy set theory.']","['study problem learning permutation invariant representation capture containment relation ', 'propose training model novel task  predicting size symmetric difference pair multisets  set may contain multiple copy object ', 'motivation fuzzy set theory  formulate multiset representation predict symmetric difference size given representation ', 'model multiset element vector standard simplex multisets summation vector  predict symmetric difference l1distance multiset representation ', 'demonstrate representation effectively predict size symmetric difference deepsetsbased approach unconstrained object representation ', 'furthermore  demonstrate model learns meaningful representation  mapping object different class different standard basis vector ']","We study the problem of learning permutation invariant representations that can capture containment relations., We propose training a model on a novel task: predicting the size of the symmetric difference between pairs of multisets, sets which may contain multiple copies of the same object., With motivation from fuzzy set theory, we formulate both multiset representations and how to predict symmetric difference sizes given these representations., We model multiset elements as vectors on the standard simplex and multisets as the summations of such vectors, and we predict symmetric difference as the l1-distance between multiset representations., We demonstrate that our representations more effectively predict the sizes of symmetric differences than DeepSets-based approaches with unconstrained object representations., Furthermore, we demonstrate that the model learns meaningful representations, mapping objects of different classes to different standard basis vectors.",11,6.285714285714286,12.090909090909092
8,"['It is important to collect credible training samples $(x,y)$ for building data-intensive learning systems (e.g., a deep learning system).', 'In the literature, there is a line of studies on eliciting distributional information from self-interested agents who hold a relevant information.  ', 'Asking people to report complex distribution $p(x)$, though theoretically viable, is challenging in practice.', 'This is primarily due to the heavy cognitive loads required for human agents to reason and report this high dimensional information.', 'Consider the example where we are interested in building an image classifier via first collecting a certain category of  high-dimensional image data.', 'While classical elicitation results apply to eliciting a complex and generative (and continuous) distribution $p(x)$ for this image data, we are interested in eliciting samples $x_i \\sim p(x)$ from agents.', 'This paper introduces a deep learning aided method to incentivize credible sample contributions from selfish and rational agents.', 'The challenge to do so is to design an incentive-compatible score function to score each reported sample to induce truthful reports, instead of an arbitrary or even adversarial one.', 'We show that with accurate estimation of a certain $f$-divergence function we are able to achieve approximate incentive compatibility in eliciting truthful samples.', 'We then present an efficient estimator with theoretical guarantee via studying the variational forms of $f$-divergence function.', 'Our work complements the literature of information elicitation via introducing the problem of \\emph{sample elicitation}.  We also show a connection between this sample elicitation problem and $f$-GAN, and how this connection can help reconstruct an estimator of the distribution based on collected samples.']","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.3333333432674408, 0.277777761220932, 0.06666666269302368, 0.1666666567325592, 0.05405404791235924, 0.2222222238779068, 0.6470588445663452, 0.04999999701976776, 0.1538461446762085, 0.0, 0.07999999821186066]",SkgQwpVYwH,"['This paper proposes a deep learning aided method to elicit credible samples from self-interested agents. ', 'The authors propose a sample elicitation framework for the problem of eliciting credible samples from agents for complex distributions, suggest that deep neural frameworks can be applied in this framework, and connect sample elicitation and f-GAN.', 'This paper studies the sample elicitation problem, proposing a deep learning approach that relies on the dual expression of the f-divergence which writes as a maximum over a set of functions t.']","['important collect credible training sample   x    building dataintensive learning system  eg  deep learning system  ', 'literature  line study eliciting distributional information selfinterested agent hold relevant information ', 'asking people report complex distribution  p  x    though theoretically viable  challenging practice ', 'primarily due heavy cognitive load required human agent reason report high dimensional information ', 'consider example interested building image classifier via first collecting certain category highdimensional image data ', 'classical elicitation result apply eliciting complex generative  continuous  distribution  p  x   image data  interested eliciting sample  xi sim p  x   agent ', 'paper introduces deep learning aided method incentivize credible sample contribution selfish rational agent ', 'challenge design incentivecompatible score function score reported sample induce truthful report  instead arbitrary even adversarial one ', 'show accurate estimation certain  f  divergence function able achieve approximate incentive compatibility eliciting truthful sample ', 'present efficient estimator theoretical guarantee via studying variational form  f  divergence function ', 'work complement literature information elicitation via introducing problem emph  sample elicitation   also show connection sample elicitation problem  f  gan  connection help reconstruct estimator distribution based collected sample ']","It is important to collect credible training samples $(x,y)$ for building data-intensive learning systems (e.g., a deep learning system)., In the literature, there is a line of studies on eliciting distributional information from self-interested agents who hold a relevant information.  , Asking people to report complex distribution $p(x)$, though theoretically viable, is challenging in practice., This is primarily due to the heavy cognitive loads required for human agents to reason and report this high dimensional information., Consider the example where we are interested in building an image classifier via first collecting a certain category of  high-dimensional image data., While classical elicitation results apply to eliciting a complex and generative (and continuous) distribution $p(x)$ for this image data, we are interested in eliciting samples $x_i \sim p(x)$ from agents., This paper introduces a deep learning aided method to incentivize credible sample contributions from selfish and rational agents., The challenge to do so is to design an incentive-compatible score function to score each reported sample to induce truthful reports, instead of an arbitrary or even adversarial one., We show that with accurate estimation of a certain $f$-divergence function we are able to achieve approximate incentive compatibility in eliciting truthful samples., We then present an efficient estimator with theoretical guarantee via studying the variational forms of $f$-divergence function., Our work complements the literature of information elicitation via introducing the problem of \emph{sample elicitation}.  We also show a connection between this sample elicitation problem and $f$-GAN, and how this connection can help reconstruct an estimator of the distribution based on collected samples.",18,5.957198443579767,13.526315789473685
9,"['The celebrated Sequence to Sequence learning (Seq2Seq) technique and its numerous variants achieve excellent performance on many tasks.', 'However, many machine learning tasks have inputs naturally represented as graphs; existing Seq2Seq models face a significant challenge in achieving accurate conversion from graph form to the appropriate sequence.', 'To address this challenge, we introduce a general end-to-end graph-to-sequence neural encoder-decoder architecture that maps an input graph to a sequence of vectors and uses an attention-based LSTM method to decode the target sequence from these vectors.', 'Our method first generates the node and graph embeddings using an improved graph-based neural network with a novel aggregation strategy to incorporate edge direction information in the node embeddings.', 'We further introduce an attention mechanism that aligns node embeddings and the decoding sequence to better cope with large graphs.', 'Experimental results on bAbI, Shortest Path, and Natural Language Generation tasks demonstrate that our model achieves state-of-the-art performance and significantly outperforms existing graph neural networks, Seq2Seq, and Tree2Seq models; using the proposed bi-directional node embedding aggregation strategy, the model can converge rapidly to the optimal performance.']","[1, 0, 0, 0, 0, 0]","[0.1599999964237213, 0.054054051637649536, 0.04999999701976776, 0.11764705181121826, 0.1428571343421936, 0.0416666641831398]",SkeXehR9t7,"['Graph to Sequence Learning with Attention-Based Neural Networks', 'A graph2seq architecture that combines a graph encoder mixing GGNN and GCN components with an attentional sequence encoder, and that shows improvements over baselines.', 'This work proposes an end-to-end graph encoder to sequence decoder models with an attention mechanism in between.']","['celebrated sequence sequence learning  seq2seq  technique numerous variant achieve excellent performance many task ', 'however  many machine learning task input naturally represented graph  existing seq2seq model face significant challenge achieving accurate conversion graph form appropriate sequence ', 'address challenge  introduce general endtoend graphtosequence neural encoderdecoder architecture map input graph sequence vector us attentionbased lstm method decode target sequence vector ', 'method first generates node graph embeddings using improved graphbased neural network novel aggregation strategy incorporate edge direction information node embeddings ', 'introduce attention mechanism aligns node embeddings decoding sequence better cope large graph ', 'experimental result babi  shortest path  natural language generation task demonstrate model achieves stateoftheart performance significantly outperforms existing graph neural network  seq2seq  tree2seq model  using proposed bidirectional node embedding aggregation strategy  model converge rapidly optimal performance ']","The celebrated Sequence to Sequence learning (Seq2Seq) technique and its numerous variants achieve excellent performance on many tasks., However, many machine learning tasks have inputs naturally represented as graphs; existing Seq2Seq models face a significant challenge in achieving accurate conversion from graph form to the appropriate sequence., To address this challenge, we introduce a general end-to-end graph-to-sequence neural encoder-decoder architecture that maps an input graph to a sequence of vectors and uses an attention-based LSTM method to decode the target sequence from these vectors., Our method first generates the node and graph embeddings using an improved graph-based neural network with a novel aggregation strategy to incorporate edge direction information in the node embeddings., We further introduce an attention mechanism that aligns node embeddings and the decoding sequence to better cope with large graphs., Experimental results on bAbI, Shortest Path, and Natural Language Generation tasks demonstrate that our model achieves state-of-the-art performance and significantly outperforms existing graph neural networks, Seq2Seq, and Tree2Seq models; using the proposed bi-directional node embedding aggregation strategy, the model can converge rapidly to the optimal performance.",13,6.268156424581005,13.76923076923077
10,"['We address the problem of learning to discover 3D parts for objects in unseen categories.', 'Being able to learn the geometry prior of parts and transfer this prior to unseen categories pose fundamental challenges on data-driven shape segmentation approaches.', 'Formulated as a contextual bandit problem, we propose a learning-based iterative grouping framework which learns a grouping policy to progressively merge small part proposals into bigger ones in a bottom-up fashion.', 'At the core of our approach is to restrict the local context for extracting part-level features, which encourages the generalizability to novel categories.', 'On a recently proposed large-scale fine-grained 3D part dataset, PartNet, we demonstrate that our method can transfer knowledge of parts learned from 3 training categories to 21 unseen testing categories without seeing any annotated samples.', 'Quantitative comparisons against four strong shape segmentation baselines show that we achieve the state-of-the-art performance.']","[0, 0, 1, 0, 0, 0]","[0.23529411852359772, 0.1463414579629898, 0.260869562625885, 0.10256409645080566, 0.11320754140615463, 0.11764705181121826]",rkl8dlHYvB,"['A zero-shot segmentation framework for 3D object part segmentation. Model the segmentation as a decision-making process and solve as a contextual bandit problem.', 'A method for segmenting 3D point clouds of objects into component parts, focused on generalizing part groupings to novel object categories unseen during training, that shows strong performance relative to baselines.', 'This paper proposes a method for part segmentation in object point clouds.']","['address problem learning discover 3d part object unseen category ', 'able learn geometry prior part transfer prior unseen category pose fundamental challenge datadriven shape segmentation approach ', 'formulated contextual bandit problem  propose learningbased iterative grouping framework learns grouping policy progressively merge small part proposal bigger one bottomup fashion ', 'core approach restrict local context extracting partlevel feature  encourages generalizability novel category ', 'recently proposed largescale finegrained 3d part dataset  partnet  demonstrate method transfer knowledge part learned 3 training category 21 unseen testing category without seeing annotated sample ', 'quantitative comparison four strong shape segmentation baseline show achieve stateoftheart performance ']","We address the problem of learning to discover 3D parts for objects in unseen categories., Being able to learn the geometry prior of parts and transfer this prior to unseen categories pose fundamental challenges on data-driven shape segmentation approaches., Formulated as a contextual bandit problem, we propose a learning-based iterative grouping framework which learns a grouping policy to progressively merge small part proposals into bigger ones in a bottom-up fashion., At the core of our approach is to restrict the local context for extracting part-level features, which encourages the generalizability to novel categories., On a recently proposed large-scale fine-grained 3D part dataset, PartNet, we demonstrate that our method can transfer knowledge of parts learned from 3 training categories to 21 unseen testing categories without seeing any annotated samples., Quantitative comparisons against four strong shape segmentation baselines show that we achieve the state-of-the-art performance.",10,5.965034965034965,14.3
11,"['This paper presents the ballistic graph neural network.', 'Ballistic graph neural network tackles the weight distribution from a transportation perspective and has many different properties comparing to the traditional graph neural network pipeline.', 'The ballistic graph neural network does not require to calculate any eigenvalue.', 'The filters propagate exponentially faster($\\sigma^2 \\sim T^2$) comparing to traditional graph neural network($\\sigma^2 \\sim T$).', 'We use a perturbed coin operator to perturb and optimize the diffusion rate.', 'Our results show that by selecting the diffusion speed, the network can reach a similar accuracy with fewer parameters.', 'We also show the perturbed filters act as better representations comparing to pure ballistic ones.', ""We provide a new perspective of training graph neural network, by adjusting the diffusion rate, the neural network's performance can be improved.""]","[0, 0, 0, 0, 0, 0, 0, 1]","[0.09090908616781235, 0.22857142984867096, 0.07692307233810425, 0.0714285671710968, 0.2222222238779068, 0.1249999925494194, 0.13793103396892548, 0.23529411852359772]",r1gV3nVKPS,"['A new perspective on how to collect the correlation between nodes based on diffusion properties.', 'A new diffusion operation for graph neural networks that does not require eigenvalue calculation and can propagate exponentially faster compared to traditional graph neural networks.', 'The paper proposes to cope with the speed of diffusion problem by introducing ballistic walk.']","['paper present ballistic graph neural network ', 'ballistic graph neural network tackle weight distribution transportation perspective many different property comparing traditional graph neural network pipeline ', 'ballistic graph neural network require calculate eigenvalue ', 'filter propagate exponentially faster   sigma2 sim t2   comparing traditional graph neural network   sigma2 sim   ', 'use perturbed coin operator perturb optimize diffusion rate ', 'result show selecting diffusion speed  network reach similar accuracy fewer parameter ', 'also show perturbed filter act better representation comparing pure ballistic one ', 'provide new perspective training graph neural network  adjusting diffusion rate  neural network performance improved ']","This paper presents the ballistic graph neural network., Ballistic graph neural network tackles the weight distribution from a transportation perspective and has many different properties comparing to the traditional graph neural network pipeline., The ballistic graph neural network does not require to calculate any eigenvalue., The filters propagate exponentially faster($\sigma^2 \sim T^2$) comparing to traditional graph neural network($\sigma^2 \sim T$)., We use a perturbed coin operator to perturb and optimize the diffusion rate., Our results show that by selecting the diffusion speed, the network can reach a similar accuracy with fewer parameters., We also show the perturbed filters act as better representations comparing to pure ballistic ones., We provide a new perspective of training graph neural network, by adjusting the diffusion rate, the neural network's performance can be improved.",11,5.953488372093023,11.727272727272727
12,"['In this paper, we propose a \\textit{weak supervision} framework for neural ranking tasks based on the data programming paradigm \\citep{Ratner2016}, which enables us to leverage multiple weak supervision signals from different sources.', 'Empirically, we consider two sources of weak supervision signals, unsupervised ranking functions and semantic feature similarities.', 'We train a BERT-based passage-ranking model (which achieves new state-of-the-art performances on two benchmark datasets with full supervision) in our weak supervision framework.', 'Without using ground-truth training labels, BERT-PR models outperform BM25 baseline by a large margin on all three datasets and even beat the previous state-of-the-art results with full supervision on two of datasets.']","[1, 0, 0, 0]","[0.48275861144065857, 0.2380952388048172, 0.40816324949264526, 0.2142857164144516]",S1ltj47xdE,"['We propose a weak supervision training pipeline based on the data programming framework for ranking tasks, in which we train a BERT-base ranking model and establish the new SOTA.', 'The authors propose a combination of BERT and the weak supervision framework to tackle the problem of passage ranking, obtaining results better than the fully supervised state-of-the-art.']","['paper  propose textit  weak supervision  framework neural ranking task based data programming paradigm citep  ratner2016   enables u leverage multiple weak supervision signal different source ', 'empirically  consider two source weak supervision signal  unsupervised ranking function semantic feature similarity ', 'train bertbased passageranking model  achieves new stateoftheart performance two benchmark datasets full supervision  weak supervision framework ', 'without using groundtruth training label  bertpr model outperform bm25 baseline large margin three datasets even beat previous stateoftheart result full supervision two datasets ']","In this paper, we propose a \textit{weak supervision} framework for neural ranking tasks based on the data programming paradigm \citep{Ratner2016}, which enables us to leverage multiple weak supervision signals from different sources., Empirically, we consider two sources of weak supervision signals, unsupervised ranking functions and semantic feature similarities., We train a BERT-based passage-ranking model (which achieves new state-of-the-art performances on two benchmark datasets with full supervision) in our weak supervision framework., Without using ground-truth training labels, BERT-PR models outperform BM25 baseline by a large margin on all three datasets and even beat the previous state-of-the-art results with full supervision on two of datasets.",9,6.359223300970874,11.444444444444445
13,"['We study the training process of Deep Neural Networks (DNNs) from the Fourier analysis perspective.', 'We demonstrate a very universal Frequency Principle (F-Principle) --- DNNs often fit target functions from low to high frequencies --- on high-dimensional benchmark datasets, such as MNIST/CIFAR10, and deep networks, such as VGG16.', 'This F-Principle of DNNs is opposite to the learning behavior of most conventional iterative numerical schemes (e.g., Jacobi method), which exhibits faster convergence for higher frequencies, for various scientific computing problems.', 'With a naive theory, we illustrate that this F-Principle results from the regularity of the commonly used activation functions.', 'The F-Principle implies an implicit bias that DNNs tend to fit training data by a low-frequency function.', 'This understanding provides an explanation of good generalization of DNNs on most real datasets and bad generalization of DNNs on parity function or randomized dataset.']","[0, 1, 0, 0, 0, 0]","[0.23529411852359772, 0.4000000059604645, 0.11764705181121826, 0.2631579041481018, 0.2702702581882477, 0.09999999403953552]",Skgb5h4KPH,"['In real problems, we found that DNNs often fit target functions from low to high frequencies during the training process.', 'This paper analyzes the loss of neural networks in the Fourier domain and finds that DNNs tend to learn low-frequency components before high-frequency ones.', 'The paper studies the training process of NNs through Fourier analysis, concluding that NNs learn low frequency components before high frequency components.']","['study training process deep neural network  dnns  fourier analysis perspective ', 'demonstrate universal frequency principle  fprinciple    dnns often fit target function low high frequency   highdimensional benchmark datasets  mnistcifar10  deep network  vgg16 ', 'fprinciple dnns opposite learning behavior conventional iterative numerical scheme  eg  jacobi method   exhibit faster convergence higher frequency  various scientific computing problem ', 'naive theory  illustrate fprinciple result regularity commonly used activation function ', 'fprinciple implies implicit bias dnns tend fit training data lowfrequency function ', 'understanding provides explanation good generalization dnns real datasets bad generalization dnns parity function randomized dataset ']","We study the training process of Deep Neural Networks (DNNs) from the Fourier analysis perspective., We demonstrate a very universal Frequency Principle (F-Principle) --- DNNs often fit target functions from low to high frequencies --- on high-dimensional benchmark datasets, such as MNIST/CIFAR10, and deep networks, such as VGG16., This F-Principle of DNNs is opposite to the learning behavior of most conventional iterative numerical schemes (e.g., Jacobi method), which exhibits faster convergence for higher frequencies, for various scientific computing problems., With a naive theory, we illustrate that this F-Principle results from the regularity of the commonly used activation functions., The F-Principle implies an implicit bias that DNNs tend to fit training data by a low-frequency function., This understanding provides an explanation of good generalization of DNNs on most real datasets and bad generalization of DNNs on parity function or randomized dataset.",13,5.878571428571429,10.76923076923077
14,"['The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties.', 'Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization.', 'In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph.', 'Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule.', 'We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines.']","[0, 1, 0, 0, 0]","[0.0, 0.23076923191547394, 0.0, 0.05714285373687744, 0.07407406717538834]",rJeeKTNKDB,"['We propose a multi-resolution, hierarchically coupled encoder-decoder for graph-to-graph translation.', 'A hierarchical graph-to-graph translation model to generate molecular graphs using chemical substructures as building blocks that is fully autoregressive and learns coherent multi-resolution representations, outperforming previous models.', 'The authors present a hierarchical graph-to-graph translation method for generating novel organic molecules.']","['problem accelerating drug discovery relies heavily automatic tool optimize precursor molecule afford better biochemical property ', 'work paper substantially extends prior stateoftheart graphtograph translation method molecular optimization ', 'particular  realize coherent multiresolution representation interweaving encoding substructure component atomlevel encoding original molecular graph ', 'moreover  graph decoder fully autoregressive  interleaf step adding new substructure process resolving attachment emerging molecule ', 'evaluate model multiple molecular optimization task show model significantly outperforms previous stateoftheart baseline ']","The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties., Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization., In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph., Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule., We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines.",8,6.5327102803738315,13.375
15,"['Equivariance is a nice property to have as it produces much more parameter efficient neural architectures and preserves the structure of the input through the feature mapping.', 'Even though some combinations of transformations might never appear (e.g. an upright face with a horizontal nose), current equivariant architectures consider the set of all possible transformations in a transformation group when learning feature representations.', 'Contrarily, the human visual system is able to attend to the set of relevant transformations occurring in the environment and utilizes this information to assist and improve object recognition.', 'Based on this observation, we modify conventional equivariant feature mappings such that they are able to attend to the set of co-occurring transformations in data and generalize this notion to act on groups consisting of multiple symmetries.', 'We show that our proposed co-attentive equivariant neural networks consistently outperform conventional rotation equivariant and rotation & reflection equivariant neural networks on rotated MNIST and CIFAR-10.']","[0, 0, 0, 1, 0]","[0.1463414579629898, 0.20408162474632263, 0.25, 0.3333333432674408, 0.2222222238779068]",r1g6ogrtDr,"['We utilize attention to restrict equivariant neural networks to the set or co-occurring transformations in data. ', ""This paper combines attention with group equivariance, specifically looking at the p4m group of rotations, translations, and flips, and derives a form of self-attention that doesn't destroy the equivariance property."", 'The authors propose a self-attention mechanism for rotation-equivariant neural nets that improves classification performance over regular rotation-equivariant nets.']","['equivariance nice property produce much parameter efficient neural architecture preserve structure input feature mapping ', 'even though combination transformation might never appear  eg  upright face horizontal nose   current equivariant architecture consider set possible transformation transformation group learning feature representation ', 'contrarily  human visual system able attend set relevant transformation occurring environment utilizes information assist improve object recognition ', 'based observation  modify conventional equivariant feature mapping able attend set cooccurring transformation data generalize notion act group consisting multiple symmetry ', 'show proposed coattentive equivariant neural network consistently outperform conventional rotation equivariant rotation  reflection equivariant neural network rotated mnist cifar10 ']","Equivariance is a nice property to have as it produces much more parameter efficient neural architectures and preserves the structure of the input through the feature mapping., Even though some combinations of transformations might never appear (e.g. an upright face with a horizontal nose), current equivariant architectures consider the set of all possible transformations in a transformation group when learning feature representations., Contrarily, the human visual system is able to attend to the set of relevant transformations occurring in the environment and utilizes this information to assist and improve object recognition., Based on this observation, we modify conventional equivariant feature mappings such that they are able to attend to the set of co-occurring transformations in data and generalize this notion to act on groups consisting of multiple symmetries., We show that our proposed co-attentive equivariant neural networks consistently outperform conventional rotation equivariant and rotation & reflection equivariant neural networks on rotated MNIST and CIFAR-10.",8,6.032467532467533,17.11111111111111
16,"['The fast generation and refinement of protein backbones would constitute a major advancement to current methodology for the design and development of de novo proteins.', 'In this study, we train Generative Adversarial Networks (GANs) to generate fixed-length full-atom protein backbones, with the goal of sampling from the distribution of realistic 3-D backbone fragments.', 'We represent protein structures by pairwise distances between all backbone atoms, and present a method for directly recovering and refining the corresponding backbone coordinates in a differentiable manner.', 'We show that interpolations in the latent space of the generator correspond to smooth deformations of the output backbones, and that test set structures not seen by the generator during training exist in its image.', 'Finally, we perform sequence design, relaxation, and ab initio folding of a subset of generated structures, and show that in some cases we can recover the generated folds after forward-folding.', 'Together, these results suggest a mechanism for fast protein structure refinement and folding using external energy functions.']","[0, 0, 0, 0, 1, 0]","[0.31372547149658203, 0.25925925374031067, 0.22641508281230927, 0.25, 0.5925925970077515, 0.13333332538604736]",SJxnVL8YOV,"['We train a GAN to generate and recover full-atom protein backbones , and we show that in select cases we can recover the generated proteins after sequence design and ab initio forward-folding.', 'A generative model for protein backbone which uses a GAN, autoencoder-like network, and refinement process, and a set of qualitative evaluations suggesting positive results.', 'This paper presents an end-to-end approach for generating protein backbones using generative adversarial networks.']","['fast generation refinement protein backbone would constitute major advancement current methodology design development de novo protein ', 'study  train generative adversarial network  gans  generate fixedlength fullatom protein backbone  goal sampling distribution realistic 3d backbone fragment ', 'represent protein structure pairwise distance backbone atom  present method directly recovering refining corresponding backbone coordinate differentiable manner ', 'show interpolation latent space generator correspond smooth deformation output backbone  test set structure seen generator training exist image ', 'finally  perform sequence design  relaxation  ab initio folding subset generated structure  show case recover generated fold forwardfolding ', 'together  result suggest mechanism fast protein structure refinement folding using external energy function ']","The fast generation and refinement of protein backbones would constitute a major advancement to current methodology for the design and development of de novo proteins., In this study, we train Generative Adversarial Networks (GANs) to generate fixed-length full-atom protein backbones, with the goal of sampling from the distribution of realistic 3-D backbone fragments., We represent protein structures by pairwise distances between all backbone atoms, and present a method for directly recovering and refining the corresponding backbone coordinates in a differentiable manner., We show that interpolations in the latent space of the generator correspond to smooth deformations of the output backbones, and that test set structures not seen by the generator during training exist in its image., Finally, we perform sequence design, relaxation, and ab initio folding of a subset of generated structures, and show that in some cases we can recover the generated folds after forward-folding., Together, these results suggest a mechanism for fast protein structure refinement and folding using external energy functions.",15,5.773006134969325,10.866666666666667
17,"['Few-Shot Learning (learning with limited labeled data) aims to overcome the limitations of traditional machine learning approaches which require thousands of labeled examples to train an effective model.', 'Considered as a hallmark of human intelligence, the community has recently witnessed several contributions on this topic, in particular through meta-learning, where a model learns how to learn an effective model for few-shot learning.', 'The main idea is to acquire prior knowledge from a set of training tasks, which is then used to perform (few-shot) test tasks.', 'Most existing work assumes that both training and test tasks are drawn from the same distribution, and a large amount of labeled data is available in the training tasks.', 'This is a very strong assumption which restricts the usage of meta-learning strategies in the real world where ample training tasks following the same distribution as test tasks may not be available.', 'In this paper, we propose a novel meta-learning paradigm wherein a few-shot learning model is learnt, which simultaneously overcomes domain shift between the train and test tasks via adversarial domain adaptation.', 'We demonstrate the efficacy the proposed method through extensive experiments.']","[0, 0, 0, 1, 0, 0, 0]","[0.15094339847564697, 0.09999999403953552, 0.16326530277729034, 0.4150943458080292, 0.21052631735801697, 0.17543859779834747, 0.054054051637649536]",ByGOuo0cYm,"['Meta Learning for Few Shot learning assumes that training tasks and test tasks are drawn from the same distribution. What do you do if they are not? Meta Learning with task-level Domain Adaptation!', 'This paper proposes a model combining unsupervised adversarial domain adaptation with prototypical networks that performs better than few-shot learning baselines on few-shot learning tasks with domain shift.', 'The authors proposed meta domain adaptation to address domain shift scenario in meta learning setup, demonstrating performance improvements in several experiments.']","['fewshot learning  learning limited labeled data  aim overcome limitation traditional machine learning approach require thousand labeled example train effective model ', 'considered hallmark human intelligence  community recently witnessed several contribution topic  particular metalearning  model learns learn effective model fewshot learning ', 'main idea acquire prior knowledge set training task  used perform  fewshot  test task ', 'existing work assumes training test task drawn distribution  large amount labeled data available training task ', 'strong assumption restricts usage metalearning strategy real world ample training task following distribution test task may available ', 'paper  propose novel metalearning paradigm wherein fewshot learning model learnt  simultaneously overcomes domain shift train test task via adversarial domain adaptation ', 'demonstrate efficacy proposed method extensive experiment ']","Few-Shot Learning (learning with limited labeled data) aims to overcome the limitations of traditional machine learning approaches which require thousands of labeled examples to train an effective model., Considered as a hallmark of human intelligence, the community has recently witnessed several contributions on this topic, in particular through meta-learning, where a model learns how to learn an effective model for few-shot learning., The main idea is to acquire prior knowledge from a set of training tasks, which is then used to perform (few-shot) test tasks., Most existing work assumes that both training and test tasks are drawn from the same distribution, and a large amount of labeled data is available in the training tasks., This is a very strong assumption which restricts the usage of meta-learning strategies in the real world where ample training tasks following the same distribution as test tasks may not be available., In this paper, we propose a novel meta-learning paradigm wherein a few-shot learning model is learnt, which simultaneously overcomes domain shift between the train and test tasks via adversarial domain adaptation., We demonstrate the efficacy the proposed method through extensive experiments.",14,5.53475935828877,13.357142857142858
18,"['Universal probabilistic programming systems (PPSs) provide a powerful framework for specifying rich and complex probabilistic models.', 'However, this expressiveness comes at the cost of substantially complicating the process of drawing inferences from the model.', 'In particular, inference can become challenging when the support of the model varies between executions.', 'Though general-purpose inference engines have been designed to operate in such settings, they are typically inefficient, often relying on proposing from the prior to make transitions.', 'To address this, we introduce a new inference framework: Divide, Conquer, and Combine (DCC).', 'DCC divides the program into separate straight-line sub-programs, each of which has a fixed support allowing more powerful inference algorithms to be run locally, before recombining their outputs in a principled fashion.', 'We show how DCC can be implemented as an automated and general-purpose PPS inference engine, and empirically confirm that it can provide substantial performance improvements over previous approaches.']","[0, 0, 0, 0, 1, 0, 0]","[0.1463414579629898, 0.09756097197532654, 0.19999998807907104, 0.11764705181121826, 0.3499999940395355, 0.17543859779834747, 0.19230768084526062]",Syx2tJnNtr,"['Divide, Conquer, and Combine is a new inference scheme that can be performed on the probabilistic programs with stochastic support, i.e. the very existence of variables is stochastic.']","['universal probabilistic programming system  ppss  provide powerful framework specifying rich complex probabilistic model ', 'however  expressiveness come cost substantially complicating process drawing inference model ', 'particular  inference become challenging support model varies execution ', 'though generalpurpose inference engine designed operate setting  typically inefficient  often relying proposing prior make transition ', 'address  introduce new inference framework  divide  conquer  combine  dcc  ', 'dcc divide program separate straightline subprogram  fixed support allowing powerful inference algorithm run locally  recombining output principled fashion ', 'show dcc implemented automated generalpurpose pps inference engine  empirically confirm provide substantial performance improvement previous approach ']","Universal probabilistic programming systems (PPSs) provide a powerful framework for specifying rich and complex probabilistic models., However, this expressiveness comes at the cost of substantially complicating the process of drawing inferences from the model., In particular, inference can become challenging when the support of the model varies between executions., Though general-purpose inference engines have been designed to operate in such settings, they are typically inefficient, often relying on proposing from the prior to make transitions., To address this, we introduce a new inference framework: Divide, Conquer, and Combine (DCC)., DCC divides the program into separate straight-line sub-programs, each of which has a fixed support allowing more powerful inference algorithms to be run locally, before recombining their outputs in a principled fashion., We show how DCC can be implemented as an automated and general-purpose PPS inference engine, and empirically confirm that it can provide substantial performance improvements over previous approaches.",17,6.073825503355705,8.764705882352942
19,"['Detecting communities or the modular structure of real-life networks (e.g. a social\n', 'network or a product purchase network) is an important task because the way a\n', 'network functions is often determined by its communities.\n', 'The traditional approaches to community detection involve modularity-based approaches,\n', 'which generally speaking, construct partitions based on heuristics that\n', 'seek to maximize the ratio of the edges within the partitions to those between\n', 'them.', 'Node embedding approaches, which represent each node in a graph as a\n', 'real-valued vector, transform the problem of community detection in a graph to\n', 'that of clustering a set of vectors.', 'Existing node embedding approaches are primarily\n', 'based on first initiating uniform random walks from each node to construct\n', 'a context of a node and then seeks to make the vector representation of\n', 'the node close to its context.', 'However, standard node embedding approaches do\n', 'not directly take into account the community structure of a network while constructing\n', 'the context around each node.', 'To alleviate this, we explore two different\n', 'threads of work.', 'First, we investigate the use of biased random walks (specifically,\n', 'maximum entropy based walks) to obtain more centrality preserving embedding\n', 'of nodes, which we hypothesize may lead to more effective clusters in the embedded\n', 'space.', 'Second, we propose a community structure aware node embedding\n', 'approach where we incorporate modularity-based partitioning heuristics into\n', 'the objective function of node embedding.', 'We demonstrate that our proposed approach\n', 'for community detection outperforms a number of modularity-based baselines\n', 'as well as K-means on a standard node-embedded vector space (specifically,\n', 'node2vec) on a wide range of real-life networks of different sizes and densities.']","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.23529411852359772, 0.11764705181121826, 0.06666666269302368, 0.13333332538604736, 0.13333332538604736, 0.1249999925494194, 0.25, 0.3636363446712494, 0.29629629850387573, 0.14814814925193787, 0.12121211737394333, 0.24242423474788666, 0.14814814925193787, 0.14814814925193787, 0.23529411852359772, 0.1538461446762085, 0.0, 0.0833333283662796, 0.12903225421905518, 0.19354838132858276, 0.34285715222358704, 0.2666666507720947, 0.0, 0.29629629850387573, 0.07407406717538834, 0.2666666507720947, 0.19354838132858276, 0.1818181723356247]",H1gQY64FwB,['A community preserving node embedding algorithm that results in more effective detection of communities with a clustering on the embedded space'],"['detecting community modular structure reallife network  eg  social', 'network product purchase network  important task way', 'network function often determined community ', 'traditional approach community detection involve modularitybased approach ', 'generally speaking  construct partition based heuristic', 'seek maximize ratio edge within partition', '', 'node embedding approach  represent node graph', 'realvalued vector  transform problem community detection graph', 'clustering set vector ', 'existing node embedding approach primarily', 'based first initiating uniform random walk node construct', 'context node seek make vector representation', 'node close context ', 'however  standard node embedding approach', 'directly take account community structure network constructing', 'context around node ', 'alleviate  explore two different', 'thread work ', 'first  investigate use biased random walk  specifically ', 'maximum entropy based walk  obtain centrality preserving embedding', 'node  hypothesize may lead effective cluster embedded', 'space ', 'second  propose community structure aware node embedding', 'approach incorporate modularitybased partitioning heuristic', 'objective function node embedding ', 'demonstrate proposed approach', 'community detection outperforms number modularitybased baseline', 'well kmeans standard nodeembedded vector space  specifically ', 'node2vec  wide range reallife network different size density ']","Detecting communities or the modular structure of real-life networks (e.g. a social
, network or a product purchase network) is an important task because the way a
, network functions is often determined by its communities.
, The traditional approaches to community detection involve modularity-based approaches,
, which generally speaking, construct partitions based on heuristics that
, seek to maximize the ratio of the edges within the partitions to those between
, them., Node embedding approaches, which represent each node in a graph as a
, real-valued vector, transform the problem of community detection in a graph to
, that of clustering a set of vectors., Existing node embedding approaches are primarily
, based on first initiating uniform random walks from each node to construct
, a context of a node and then seeks to make the vector representation of
, the node close to its context., However, standard node embedding approaches do
, not directly take into account the community structure of a network while constructing
, the context around each node., To alleviate this, we explore two different
, threads of work., First, we investigate the use of biased random walks (specifically,
, maximum entropy based walks) to obtain more centrality preserving embedding
, of nodes, which we hypothesize may lead to more effective clusters in the embedded
, space., Second, we propose a community structure aware node embedding
, approach where we incorporate modularity-based partitioning heuristics into
, the objective function of node embedding., We demonstrate that our proposed approach
, for community detection outperforms a number of modularity-based baselines
, as well as K-means on a standard node-embedded vector space (specifically,
, node2vec) on a wide range of real-life networks of different sizes and densities.",38,5.670411985018727,6.846153846153846
20,"[""A point cloud is an agile 3D representation, efficiently modeling an object's surface geometry."", 'However, these surface-centric properties also pose challenges on designing tools to recognize and synthesize point clouds.', 'This work presents a novel autoregressive model, PointGrow, which generates realistic point cloud samples from scratch or conditioned from given semantic contexts.', 'Our model operates recurrently, with each point sampled according to a conditional distribution given its previously-generated points.', 'Since point cloud object shapes are typically encoded by long-range interpoint dependencies, we augment our model with dedicated self-attention modules to capture these relations.', 'Extensive evaluation demonstrates that PointGrow achieves satisfying performance on both unconditional and conditional point cloud generation tasks, with respect to fidelity, diversity and semantic preservation.', 'Further, conditional PointGrow learns a smooth manifold of given images where 3D shape interpolation and arithmetic calculation can be performed inside.']","[0, 1, 0, 0, 0, 0, 0]","[0.08695651590824127, 0.1538461446762085, 0.12903225421905518, 0.14814814925193787, 0.11764705181121826, 0.05882352590560913, 0.0]",r1eWW2RqFX,"['An autoregressive deep learning model for generating diverse point clouds.', 'An approach for generating 3D shapes as point clouds which considers the lexicographic ordering of points according to coordinates and trains a model to predict points in order.', 'The paper introduces a generative model for point clouds using a pixel RNN-like auto-regressive model and an attention model to handle longer-range interactions.']","['point cloud agile 3d representation  efficiently modeling object surface geometry ', 'however  surfacecentric property also pose challenge designing tool recognize synthesize point cloud ', 'work present novel autoregressive model  pointgrow  generates realistic point cloud sample scratch conditioned given semantic context ', 'model operates recurrently  point sampled according conditional distribution given previouslygenerated point ', 'since point cloud object shape typically encoded longrange interpoint dependency  augment model dedicated selfattention module capture relation ', 'extensive evaluation demonstrates pointgrow achieves satisfying performance unconditional conditional point cloud generation task  respect fidelity  diversity semantic preservation ', ' conditional pointgrow learns smooth manifold given image 3d shape interpolation arithmetic calculation performed inside ']","A point cloud is an agile 3D representation, efficiently modeling an object's surface geometry., However, these surface-centric properties also pose challenges on designing tools to recognize and synthesize point clouds., This work presents a novel autoregressive model, PointGrow, which generates realistic point cloud samples from scratch or conditioned from given semantic contexts., Our model operates recurrently, with each point sampled according to a conditional distribution given its previously-generated points., Since point cloud object shapes are typically encoded by long-range interpoint dependencies, we augment our model with dedicated self-attention modules to capture these relations., Extensive evaluation demonstrates that PointGrow achieves satisfying performance on both unconditional and conditional point cloud generation tasks, with respect to fidelity, diversity and semantic preservation., Further, conditional PointGrow learns a smooth manifold of given images where 3D shape interpolation and arithmetic calculation can be performed inside.",16,6.589928057553957,8.6875
21,"['Reinforcement learning and evolutionary algorithms can be used to create sophisticated control solutions.', 'Unfortunately explaining how these solutions work can be difficult to due to their ""black box"" nature.', 'In addition, the time-extended nature of control algorithms often prevent direct applications of explainability techniques used for standard supervised learning algorithms.', 'This paper attempts to address explainability of blackbox control algorithms through six different techniques:', '1) Bayesian rule lists,', '2) Function analysis,', '3) Single time step integrated gradients,', '4) Grammar-based decision trees,', '5) Sensitivity analysis combined with temporal modeling with LSTMs, and', '6) Explanation templates.', 'These techniques are tested on a simple 2d domain, where a simulated rover attempts to navigate through obstacles to reach a goal.', 'For control, this rover uses an evolved multi-layer perception that maps an 8d field of obstacle and goal sensors to an action determining where it should go in the next time step.', 'Results show that some simple insights in explaining the neural network are possible, but that good explanations are difficult.']","[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.1428571343421936, 0.06666666269302368, 0.29411762952804565, 0.20689654350280762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23529411852359772, 0.08888888359069824, 0.1875]",Sklk4T3XcE,"['Describes a series of explainability techniques applied to a simple neural network controller used for navigation.', 'This paper provides insights and explanations for the problem of providing explanations for a multilayer perceptron used as an inverse controller for rover movement, and ideas on how to explain a black-box model.']","['reinforcement learning evolutionary algorithm used create sophisticated control solution ', 'unfortunately explaining solution work difficult due  black box  nature ', 'addition  timeextended nature control algorithm often prevent direct application explainability technique used standard supervised learning algorithm ', 'paper attempt address explainability blackbox control algorithm six different technique ', '1  bayesian rule list ', '2  function analysis ', '3  single time step integrated gradient ', '4  grammarbased decision tree ', '5  sensitivity analysis combined temporal modeling lstms ', '6  explanation template ', 'technique tested simple 2d domain  simulated rover attempt navigate obstacle reach goal ', 'control  rover us evolved multilayer perception map 8d field obstacle goal sensor action determining go next time step ', 'result show simple insight explaining neural network possible  good explanation difficult ']","Reinforcement learning and evolutionary algorithms can be used to create sophisticated control solutions., Unfortunately explaining how these solutions work can be difficult to due to their ""black box"" nature., In addition, the time-extended nature of control algorithms often prevent direct applications of explainability techniques used for standard supervised learning algorithms., This paper attempts to address explainability of blackbox control algorithms through six different techniques:, 1) Bayesian rule lists,, 2) Function analysis,, 3) Single time step integrated gradients,, 4) Grammar-based decision trees,, 5) Sensitivity analysis combined with temporal modeling with LSTMs, and, 6) Explanation templates., These techniques are tested on a simple 2d domain, where a simulated rover attempts to navigate through obstacles to reach a goal., For control, this rover uses an evolved multi-layer perception that maps an 8d field of obstacle and goal sensors to an action determining where it should go in the next time step., Results show that some simple insights in explaining the neural network are possible, but that good explanations are difficult.",18,5.868263473053892,9.277777777777779
22,"['The Vision-and-Language Navigation (VLN) task entails an agent following navigational instruction in photo-realistic unknown environments.', 'This challenging task demands that the agent be aware of which instruction was completed, which instruction is needed next, which way to go, and its navigation progress towards the goal.', 'In this paper, we introduce a self-monitoring agent with two complementary components: (1) visual-textual co-grounding module to locate the instruction completed in the past, the instruction required for the next action, and the next moving direction from surrounding images and (2) progress monitor to ensure the grounded instruction correctly reflects the navigation progress.', 'We test our self-monitoring agent on a standard benchmark and analyze our proposed approach through a series of ablation studies that elucidate the contributions of the primary components.', 'Using our proposed method, we set the new state of the art by a significant margin (8% absolute increase in success rate on the unseen test set).', 'Code is available at https://github.com/chihyaoma/selfmonitoring-agent.']","[1, 0, 0, 0, 0, 0]","[0.3199999928474426, 0.1666666567325592, 0.19607843458652496, 0.29411762952804565, 0.11428570747375488, 0.0]",r1GAsjC5Fm,"['We propose a self-monitoring agent for the Vision-and-Language Navigation task.', 'A method for vision+language navigation which tracks progress on the instruction using a progress monitor and a visual-textual co-grounding module, and performs well on standard benchmarks.', 'This paper describes a model for vision-and-language navigation with a panoramic visual attention and an auxillary progress monitoring loss, giving state-of-the-art results.']","['visionandlanguage navigation  vln  task entail agent following navigational instruction photorealistic unknown environment ', 'challenging task demand agent aware instruction completed  instruction needed next  way go  navigation progress towards goal ', 'paper  introduce selfmonitoring agent two complementary component   1  visualtextual cogrounding module locate instruction completed past  instruction required next action  next moving direction surrounding image  2  progress monitor ensure grounded instruction correctly reflects navigation progress ', 'test selfmonitoring agent standard benchmark analyze proposed approach series ablation study elucidate contribution primary component ', 'using proposed method  set new state art significant margin  8  absolute increase success rate unseen test set  ', 'code available http  githubcomchihyaomaselfmonitoringagent ']","The Vision-and-Language Navigation (VLN) task entails an agent following navigational instruction in photo-realistic unknown environments., This challenging task demands that the agent be aware of which instruction was completed, which instruction is needed next, which way to go, and its navigation progress towards the goal., In this paper, we introduce a self-monitoring agent with two complementary components: (1) visual-textual co-grounding module to locate the instruction completed in the past, the instruction required for the next action, and the next moving direction from surrounding images and (2) progress monitor to ensure the grounded instruction correctly reflects the navigation progress., We test our self-monitoring agent on a standard benchmark and analyze our proposed approach through a series of ablation studies that elucidate the contributions of the primary components., Using our proposed method, we set the new state of the art by a significant margin (8% absolute increase in success rate on the unseen test set)., Code is available at https://github.com/chihyaoma/selfmonitoring-agent.",13,5.993670886075949,12.153846153846153
23,"['Environments in Reinforcement Learning (RL) are usually only partially observable.', 'To address this problem, a possible solution is to provide the agent with information about past  observations.', 'While common methods represent this history using a Recurrent Neural Network (RNN), in this paper we propose an alternative representation which is based on the record of the past events observed in a given episode.', 'Inspired by the human memory, these events describe only important changes in the environment and, in our approach, are automatically discovered using self-supervision.\n ', 'We evaluate our history representation method using two challenging RL benchmarks: some games of the Atari-57 suite and the 3D environment Obstacle Tower.', 'Using these benchmarks we show the advantage of our solution with respect to common RNN-based approaches.']","[0, 1, 0, 0, 0, 0]","[0.09999999403953552, 0.2222222238779068, 0.19512194395065308, 0.1249999925494194, 0.1875, 0.1538461446762085]",H1eVlgHKPr,"['event discovery to represent the history for the agent in RL', 'The authors study the problem of RL under partially observed settings, and propose a solution that uses a FFNN but provides a history representation, outperforming PPO.', 'This paper proposes a new way to represent past history as input to an RL agent, showing to perform better than PPO and an RNN variant of PPO.']","['environment reinforcement learning  rl  usually partially observable ', 'address problem  possible solution provide agent information past observation ', 'common method represent history using recurrent neural network  rnn   paper propose alternative representation based record past event observed given episode ', 'inspired human memory  event describe important change environment  approach  automatically discovered using selfsupervision ', 'evaluate history representation method using two challenging rl benchmark  game atari57 suite 3d environment obstacle tower ', 'using benchmark show advantage solution respect common rnnbased approach ']","Environments in Reinforcement Learning (RL) are usually only partially observable., To address this problem, a possible solution is to provide the agent with information about past  observations., While common methods represent this history using a Recurrent Neural Network (RNN), in this paper we propose an alternative representation which is based on the record of the past events observed in a given episode., Inspired by the human memory, these events describe only important changes in the environment and, in our approach, are automatically discovered using self-supervision.
 , We evaluate our history representation method using two challenging RL benchmarks: some games of the Atari-57 suite and the 3D environment Obstacle Tower., Using these benchmarks we show the advantage of our solution with respect to common RNN-based approaches.",11,5.733870967741935,11.272727272727273
24,"['The unconditional generation of high fidelity images is a longstanding benchmark\n', 'for testing the performance of image decoders.', 'Autoregressive image models\n', 'have been able to generate small images unconditionally, but the extension of\n', 'these methods to large images where fidelity can be more readily assessed has\n', 'remained an open problem.', 'Among the major challenges are the capacity to encode\n', 'the vast previous context and the sheer difficulty of learning a distribution that\n', 'preserves both global semantic coherence and exactness of detail.', 'To address the\n', 'former challenge, we propose the Subscale Pixel Network (SPN), a conditional\n', 'decoder architecture that generates an image as a sequence of image slices of equal\n', 'size.', 'The SPN compactly captures image-wide spatial dependencies and requires a\n', 'fraction of the memory and the computation.', 'To address the latter challenge, we\n', 'propose to use multidimensional upscaling to grow an image in both size and depth\n', 'via intermediate stages corresponding to distinct SPNs.', 'We evaluate SPNs on the\n', 'unconditional generation of CelebAHQ of size 256 and of ImageNet from size 32\n', 'to 128.', 'We achieve state-of-the-art likelihood results in multiple settings, set up\n', 'new benchmark results in previously unexplored settings and are able to generate\n', 'very high fidelity large scale samples on the basis of both datasets.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.27272728085517883, 0.0, 0.1428571343421936, 0.17391303181648254, 0.25, 0.0, 0.0, 0.08695651590824127, 0.0, 0.0, 0.0, 0.08695651590824127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1249999925494194, 0.0, 0.0952380895614624, 0.08695651590824127, 0.17391303181648254]",HylzTiC5Km,"['We show that autoregressive models can generate high fidelity images. ', 'An architecture utilizing decoder, size-upscaling decoder, and depth-upscaling decoder components to tackle the problem of learning long-range dependencies in images in order to obtain high fidelity images.', 'This paper addresses the problem of generation to high fidelity images, successfully showing convincing Imagenet samples with 128x128 resolution for a likelihood density model.']","['unconditional generation high fidelity image longstanding benchmark', 'testing performance image decoder ', 'autoregressive image model', 'able generate small image unconditionally  extension', 'method large image fidelity readily assessed', 'remained open problem ', 'among major challenge capacity encode', 'vast previous context sheer difficulty learning distribution', 'preserve global semantic coherence exactness detail ', 'address', 'former challenge  propose subscale pixel network  spn   conditional', 'decoder architecture generates image sequence image slice equal', 'size ', 'spn compactly capture imagewide spatial dependency requires', 'fraction memory computation ', 'address latter challenge ', 'propose use multidimensional upscaling grow image size depth', 'via intermediate stage corresponding distinct spns ', 'evaluate spns', 'unconditional generation celebahq size 256 imagenet size 32', '128 ', 'achieve stateoftheart likelihood result multiple setting  set', 'new benchmark result previously unexplored setting able generate', 'high fidelity large scale sample basis datasets ']","The unconditional generation of high fidelity images is a longstanding benchmark
, for testing the performance of image decoders., Autoregressive image models
, have been able to generate small images unconditionally, but the extension of
, these methods to large images where fidelity can be more readily assessed has
, remained an open problem., Among the major challenges are the capacity to encode
, the vast previous context and the sheer difficulty of learning a distribution that
, preserves both global semantic coherence and exactness of detail., To address the
, former challenge, we propose the Subscale Pixel Network (SPN), a conditional
, decoder architecture that generates an image as a sequence of image slices of equal
, size., The SPN compactly captures image-wide spatial dependencies and requires a
, fraction of the memory and the computation., To address the latter challenge, we
, propose to use multidimensional upscaling to grow an image in both size and depth
, via intermediate stages corresponding to distinct SPNs., We evaluate SPNs on the
, unconditional generation of CelebAHQ of size 256 and of ImageNet from size 32
, to 128., We achieve state-of-the-art likelihood results in multiple settings, set up
, new benchmark results in previously unexplored settings and are able to generate
, very high fidelity large scale samples on the basis of both datasets.",29,5.475961538461538,7.172413793103448
25,"['Real-world dynamical systems often consist of multiple stochastic subsystems that interact with each other.', 'Modeling and forecasting the behavior of such dynamics are generally not easy, due to the inherent hardness in understanding the complicated interactions and evolutions of their constituents.', 'This paper introduces the relational state-space model (R-SSM), a sequential hierarchical latent variable model that makes use of graph neural networks (GNNs) to simulate the joint state transitions of multiple correlated objects.', 'By letting GNNs cooperate with SSM, R-SSM provides a flexible way to incorporate relational information into the modeling of multi-object dynamics.', 'We further suggest augmenting the model with normalizing flows instantiated for vertex-indexed random variables and propose two auxiliary contrastive objectives to facilitate the learning.', 'The utility of R-SSM is empirically evaluated on synthetic and real time series datasets.']","[0, 0, 1, 0, 0, 0]","[0.060606054961681366, 0.1904761791229248, 0.5, 0.09999999403953552, 0.0952380895614624, 0.060606054961681366]",B1lGU64tDr,"['A deep hierarchical state-space model in which the state transitions of correlated objects are coordinated by graph neural networks.', 'A hierarchical latent variable model of sequential dynamic processes of multiple objects when each object exhibits significant stochasticity.', 'The paper presents a relational state-space model that simulates the joint state transitions of correlated objects which are hierarchically coordinated in a graph structure.']","['realworld dynamical system often consist multiple stochastic subsystem interact ', 'modeling forecasting behavior dynamic generally easy  due inherent hardness understanding complicated interaction evolution constituent ', 'paper introduces relational statespace model  rssm   sequential hierarchical latent variable model make use graph neural network  gnns  simulate joint state transition multiple correlated object ', 'letting gnns cooperate ssm  rssm provides flexible way incorporate relational information modeling multiobject dynamic ', 'suggest augmenting model normalizing flow instantiated vertexindexed random variable propose two auxiliary contrastive objective facilitate learning ', 'utility rssm empirically evaluated synthetic real time series datasets ']","Real-world dynamical systems often consist of multiple stochastic subsystems that interact with each other., Modeling and forecasting the behavior of such dynamics are generally not easy, due to the inherent hardness in understanding the complicated interactions and evolutions of their constituents., This paper introduces the relational state-space model (R-SSM), a sequential hierarchical latent variable model that makes use of graph neural networks (GNNs) to simulate the joint state transitions of multiple correlated objects., By letting GNNs cooperate with SSM, R-SSM provides a flexible way to incorporate relational information into the modeling of multi-object dynamics., We further suggest augmenting the model with normalizing flows instantiated for vertex-indexed random variables and propose two auxiliary contrastive objectives to facilitate the learning., The utility of R-SSM is empirically evaluated on synthetic and real time series datasets.",9,6.234848484848484,14.666666666666666
26,"['Natural language is hierarchically structured: smaller units (e.g., phrases) are nested within larger units (e.g., clauses).', 'When a larger constituent ends, all of the smaller constituents that are nested within it must also be closed.', 'While the standard LSTM architecture allows different neurons to track information at different time scales, it does not have an explicit bias towards modeling a hierarchy of constituents.', 'This paper proposes to add such inductive bias by ordering the neurons; a vector of master input and forget gates ensures that when a given neuron is updated, all the neurons that follow it in the ordering are also updated.', 'Our novel recurrent architecture, ordered neurons LSTM (ON-LSTM), achieves good performance on four different tasks: language modeling, unsupervised parsing, targeted syntactic evaluation, and logical inference.']","[0, 0, 0, 1, 0]","[0.0, 0.12121211737394333, 0.09756097197532654, 0.20408162474632263, 0.05128204822540283]",B1l6qiR5F7,"['We introduce a new inductive bias that integrates tree structures in recurrent neural networks.', 'This paper proposes ON-LSTM, a new RNN unit that integrates the latent tree structure into recurrent models and that has good results on language modeling, unsupervised parsing, targeted syntactic evaluation, and logical inference.']","['natural language hierarchically structured  smaller unit  eg  phrase  nested within larger unit  eg  clause  ', 'larger constituent end  smaller constituent nested within must also closed ', 'standard lstm architecture allows different neuron track information different time scale  explicit bias towards modeling hierarchy constituent ', 'paper proposes add inductive bias ordering neuron  vector master input forget gate ensures given neuron updated  neuron follow ordering also updated ', 'novel recurrent architecture  ordered neuron lstm  onlstm   achieves good performance four different task  language modeling  unsupervised parsing  targeted syntactic evaluation  logical inference ']","Natural language is hierarchically structured: smaller units (e.g., phrases) are nested within larger units (e.g., clauses)., When a larger constituent ends, all of the smaller constituents that are nested within it must also be closed., While the standard LSTM architecture allows different neurons to track information at different time scales, it does not have an explicit bias towards modeling a hierarchy of constituents., This paper proposes to add such inductive bias by ordering the neurons; a vector of master input and forget gates ensures that when a given neuron is updated, all the neurons that follow it in the ordering are also updated., Our novel recurrent architecture, ordered neurons LSTM (ON-LSTM), achieves good performance on four different tasks: language modeling, unsupervised parsing, targeted syntactic evaluation, and logical inference.",15,5.6484375,8.533333333333333
27,"['Skip connections made the training of very deep networks possible and have become an indispensable component in a variety of neural architectures.', 'A completely satisfactory explanation for their success remains elusive.', 'Here, we present a novel explanation for the benefits of skip connections in training very deep networks.', 'The difficulty of training deep networks is partly due to the singularities caused by the non-identifiability of the model.', 'Several such singularities have been identified in previous works:', '(i) overlap singularities caused by the permutation symmetry of nodes in a given layer,', '(ii) elimination singularities corresponding to the elimination, i.e. consistent deactivation, of nodes,', '(iii) singularities generated by the linear dependence of the nodes.', 'These singularities cause degenerate manifolds in the loss landscape that slow down learning.', 'We argue that skip connections eliminate these singularities by breaking the permutation symmetry of nodes, by reducing the possibility of node elimination and by making the nodes less linearly dependent.', 'Moreover, for typical initializations, skip connections move the network away from the ""ghosts"" of these singularities and sculpt the landscape around them to alleviate the learning slow-down.', 'These hypotheses are supported by evidence from simplified models, as well as from experiments with deep networks trained on real-world datasets.']","[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.24390242993831635, 0.0, 0.3243243098258972, 0.3333333432674408, 0.06896550953388214, 0.23529411852359772, 0.12121211737394333, 0.20689654350280762, 0.3636363446712494, 0.2666666507720947, 0.27272728085517883, 0.1538461446762085]",HkwBEMWCZ,"['Degenerate manifolds arising from the non-identifiability of the model slow down learning in deep networks; skip connections help by breaking degeneracies.', 'The authors show that elimination singularities and overlap singularities impede learning in deep neural networks, and demonstrate that skip connections can reduce the prevalence of these singularities, speeding up learning.', 'Paper examines the use of skip connections in deep networks as a way of alleviating singularities in the Hessian matrix during training.']","['skip connection made training deep network possible become indispensable component variety neural architecture ', 'completely satisfactory explanation success remains elusive ', ' present novel explanation benefit skip connection training deep network ', 'difficulty training deep network partly due singularity caused nonidentifiability model ', 'several singularity identified previous work ', '  overlap singularity caused permutation symmetry node given layer ', ' ii  elimination singularity corresponding elimination  ie  consistent deactivation  node ', ' iii  singularity generated linear dependence node ', 'singularity cause degenerate manifold loss landscape slow learning ', 'argue skip connection eliminate singularity breaking permutation symmetry node  reducing possibility node elimination making node le linearly dependent ', 'moreover  typical initialization  skip connection move network away  ghost  singularity sculpt landscape around alleviate learning slowdown ', 'hypothesis supported evidence simplified model  well experiment deep network trained realworld datasets ']","Skip connections made the training of very deep networks possible and have become an indispensable component in a variety of neural architectures., A completely satisfactory explanation for their success remains elusive., Here, we present a novel explanation for the benefits of skip connections in training very deep networks., The difficulty of training deep networks is partly due to the singularities caused by the non-identifiability of the model., Several such singularities have been identified in previous works:, (i) overlap singularities caused by the permutation symmetry of nodes in a given layer,, (ii) elimination singularities corresponding to the elimination, i.e. consistent deactivation, of nodes,, (iii) singularities generated by the linear dependence of the nodes., These singularities cause degenerate manifolds in the loss landscape that slow down learning., We argue that skip connections eliminate these singularities by breaking the permutation symmetry of nodes, by reducing the possibility of node elimination and by making the nodes less linearly dependent., Moreover, for typical initializations, skip connections move the network away from the ""ghosts"" of these singularities and sculpt the landscape around them to alleviate the learning slow-down., These hypotheses are supported by evidence from simplified models, as well as from experiments with deep networks trained on real-world datasets.",19,5.945812807881773,10.15
28,"['Representation learning is a central challenge across a range of machine learning areas.', 'In reinforcement learning, effective and functional representations have the potential to tremendously accelerate learning progress and solve more challenging problems.', 'Most prior work on representation learning has focused on generative approaches, learning representations that capture all the underlying factors of variation in the observation space in a more disentangled or well-ordered manner.', 'In this paper, we instead aim to learn functionally salient representations: representations that are not necessarily complete in terms of capturing all factors of variation in the observation space, but rather aim to capture those factors of variation that are important for decision making -- that are ""actionable"".', 'These representations are aware of the dynamics of the environment, and capture only the elements of the observation that are necessary for decision making rather than all factors of variation, eliminating the need for explicit reconstruction.', 'We show how these learned representations can be useful to improve exploration for sparse reward problems, to enable long horizon hierarchical reinforcement learning, and as a state representation for learning policies for downstream tasks.', 'We evaluate our method on a number of simulated environments, and compare it to prior methods for representation learning, exploration, and hierarchical reinforcement learning.']","[0, 0, 0, 0, 1, 0, 0]","[0.0, 0.0714285671710968, 0.1621621549129486, 0.17391304671764374, 0.277777761220932, 0.14999999105930328, 0.0624999962747097]",Hye9lnCct7,"['Learning state representations which capture factors necessary for control', 'An approach to representation learning in the context of reinforcement learning that distinguishes two stages functionally in terms of the actions that are needed to reach them.', 'The paper presents a method to learn representations where proximity in euclidean distance represents states that are achieved by similar policies.']","['representation learning central challenge across range machine learning area ', 'reinforcement learning  effective functional representation potential tremendously accelerate learning progress solve challenging problem ', 'prior work representation learning focused generative approach  learning representation capture underlying factor variation observation space disentangled wellordered manner ', 'paper  instead aim learn functionally salient representation  representation necessarily complete term capturing factor variation observation space  rather aim capture factor variation important decision making   actionable  ', 'representation aware dynamic environment  capture element observation necessary decision making rather factor variation  eliminating need explicit reconstruction ', 'show learned representation useful improve exploration sparse reward problem  enable long horizon hierarchical reinforcement learning  state representation learning policy downstream task ', 'evaluate method number simulated environment  compare prior method representation learning  exploration  hierarchical reinforcement learning ']","Representation learning is a central challenge across a range of machine learning areas., In reinforcement learning, effective and functional representations have the potential to tremendously accelerate learning progress and solve more challenging problems., Most prior work on representation learning has focused on generative approaches, learning representations that capture all the underlying factors of variation in the observation space in a more disentangled or well-ordered manner., In this paper, we instead aim to learn functionally salient representations: representations that are not necessarily complete in terms of capturing all factors of variation in the observation space, but rather aim to capture those factors of variation that are important for decision making -- that are ""actionable""., These representations are aware of the dynamics of the environment, and capture only the elements of the observation that are necessary for decision making rather than all factors of variation, eliminating the need for explicit reconstruction., We show how these learned representations can be useful to improve exploration for sparse reward problems, to enable long horizon hierarchical reinforcement learning, and as a state representation for learning policies for downstream tasks., We evaluate our method on a number of simulated environments, and compare it to prior methods for representation learning, exploration, and hierarchical reinforcement learning.",18,6.043478260869565,11.5
29,"['We explore the behavior of a standard convolutional neural net in a setting that introduces classification tasks sequentially and requires the net to master new tasks while preserving mastery of previously learned tasks.  ', 'This setting corresponds to that which human learners face as they acquire domain expertise, for example, as an individual reads a textbook chapter-by-chapter.', 'Through simulations involving sequences of 10 related tasks, we find reason for optimism that nets will scale well as they advance from having a single skill to becoming domain experts.', 'We observed two key phenomena.', 'First, forward facilitation---the accelerated learning of task n+1 having learned n previous tasks---grows with n. Second, backward interference---the forgetting of the n previous tasks when learning task n+1---diminishes with n.  Forward facilitation is the goal of research on metalearning, and reduced backward interference is the goal of research on ameliorating catastrophic forgetting.', 'We find that both of these goals are attained simply through broader exposure to a domain.']","[1, 0, 0, 0, 0, 0]","[0.52173912525177, 0.14999999105930328, 0.1666666567325592, 0.08695651590824127, 0.1538461446762085, 0.1764705777168274]",Bygi-YNNC4,['We study the behavior of a CNN as it masters new tasks while preserving mastery for previously learned tasks'],"['explore behavior standard convolutional neural net setting introduces classification task sequentially requires net master new task preserving mastery previously learned task ', 'setting corresponds human learner face acquire domain expertise  example  individual read textbook chapterbychapter ', 'simulation involving sequence 10 related task  find reason optimism net scale well advance single skill becoming domain expert ', 'observed two key phenomenon ', 'first  forward facilitation  accelerated learning task n1 learned n previous task  grows n second  backward interference  forgetting n previous task learning task n1  diminishes n forward facilitation goal research metalearning  reduced backward interference goal research ameliorating catastrophic forgetting ', 'find goal attained simply broader exposure domain ']","We explore the behavior of a standard convolutional neural net in a setting that introduces classification tasks sequentially and requires the net to master new tasks while preserving mastery of previously learned tasks.  , This setting corresponds to that which human learners face as they acquire domain expertise, for example, as an individual reads a textbook chapter-by-chapter., Through simulations involving sequences of 10 related tasks, we find reason for optimism that nets will scale well as they advance from having a single skill to becoming domain experts., We observed two key phenomena., First, forward facilitation---the accelerated learning of task n+1 having learned n previous tasks---grows with n. Second, backward interference---the forgetting of the n previous tasks when learning task n+1---diminishes with n.  Forward facilitation is the goal of research on metalearning, and reduced backward interference is the goal of research on ameliorating catastrophic forgetting., We find that both of these goals are attained simply through broader exposure to a domain.",12,5.754716981132075,13.25
30,"['We demonstrate a low effort method that unsupervisedly constructs task-optimized embeddings from existing word embeddings to gain performance on a supervised end-task.', 'This avoids additional labeling or building more complex model architectures by instead providing specialized embeddings better fit for the end-task(s).', 'Furthermore, the method can be used to roughly estimate whether a specific kind of end-task(s) can be learned form, or is represented in, a given unlabeled dataset, e.g. using publicly available probing tasks.', 'We evaluate our method for diverse word embedding probing tasks and by size of embedding training corpus -- i.e. to explore its use in reduced (pretraining-resource) settings.']","[1, 0, 0, 0]","[0.23255813121795654, 0.09302324801683426, 0.07407406717538834, 0.11999999731779099]",rylTa8uvQ4,"['Morty refits pretrained word embeddings to either: (a) improve overall embedding performance (for Multi-task settings) or improve Single-task performance, while requiring only minimal effort.']","['demonstrate low effort method unsupervisedly construct taskoptimized embeddings existing word embeddings gain performance supervised endtask ', 'avoids additional labeling building complex model architecture instead providing specialized embeddings better fit endtask   ', 'furthermore  method used roughly estimate whether specific kind endtask   learned form  represented  given unlabeled dataset  eg  using publicly available probing task ', 'evaluate method diverse word embedding probing task size embedding training corpus  ie  explore use reduced  pretrainingresource  setting ']","We demonstrate a low effort method that unsupervisedly constructs task-optimized embeddings from existing word embeddings to gain performance on a supervised end-task., This avoids additional labeling or building more complex model architectures by instead providing specialized embeddings better fit for the end-task(s)., Furthermore, the method can be used to roughly estimate whether a specific kind of end-task(s) can be learned form, or is represented in, a given unlabeled dataset, e.g. using publicly available probing tasks., We evaluate our method for diverse word embedding probing tasks and by size of embedding training corpus -- i.e. to explore its use in reduced (pretraining-resource) settings.",8,5.892156862745098,10.2
31,"['Data augmentation is commonly used to encode invariances in learning methods.', 'However, this process is often performed in an inefficient manner, as artificial examples are created by applying a number of transformations to all points in the training set.', 'The resulting explosion of the dataset size can be an issue in terms of storage and training costs, as well as in selecting and tuning the optimal set of transformations to apply.', 'In this work, we demonstrate that it is possible to significantly reduce the number of data points included in data augmentation while realizing the same accuracy and invariance benefits of augmenting the entire dataset.', 'We propose a novel set of subsampling policies, based on model influence and loss, that can achieve a 90% reduction in augmentation set size while maintaining the accuracy gains of standard data augmentation.']","[0, 1, 0, 0, 0]","[0.1904761791229248, 0.21621620655059814, 0.1666666567325592, 0.20000000298023224, 0.05128204822540283]",Byxpfh0cFm,"['Selectively augmenting difficult to classify points results in efficient training.', 'The authors study the problem of identifying subsampling strategies for data augmentation and propose strategies based on model influence and loss as well as empirical benchmarking of the proposed methods.', 'The authors propose to use influence or loss-based methods to select a subset of points to use in augmenting data sets for training models where the loss is additive over data points.']","['data augmentation commonly used encode invariance learning method ', 'however  process often performed inefficient manner  artificial example created applying number transformation point training set ', 'resulting explosion dataset size issue term storage training cost  well selecting tuning optimal set transformation apply ', 'work  demonstrate possible significantly reduce number data point included data augmentation realizing accuracy invariance benefit augmenting entire dataset ', 'propose novel set subsampling policy  based model influence loss  achieve 90  reduction augmentation set size maintaining accuracy gain standard data augmentation ']","Data augmentation is commonly used to encode invariances in learning methods., However, this process is often performed in an inefficient manner, as artificial examples are created by applying a number of transformations to all points in the training set., The resulting explosion of the dataset size can be an issue in terms of storage and training costs, as well as in selecting and tuning the optimal set of transformations to apply., In this work, we demonstrate that it is possible to significantly reduce the number of data points included in data augmentation while realizing the same accuracy and invariance benefits of augmenting the entire dataset., We propose a novel set of subsampling policies, based on model influence and loss, that can achieve a 90% reduction in augmentation set size while maintaining the accuracy gains of standard data augmentation.",11,5.22463768115942,12.545454545454545
32,"['Over the last few years exciting work in deep generative models has produced models able to suggest new organic molecules by generating strings, trees, and graphs representing their structure.', 'While such models are able to generate molecules with desirable properties, their utility in practice is limited due to the difficulty in knowing how to synthesize these molecules.', 'We therefore propose a new molecule generation model, mirroring a more realistic real-world process, where reactants are selected and combined to form more complex molecules.', 'More specifically, our generative model proposes a bag of initial reactants (selected from a pool of commercially-available molecules) and uses a reaction model to predict how they react together to generate new molecules.', 'Modeling the entire process of constructing a molecule during generation offers a number of advantages.', 'First, we show that such a model has the ability to generate a wide, diverse set of valid and unique molecules due to the useful inductive biases of modeling reactions.', 'Second, modeling synthesis routes rather than final molecules offers practical advantages to chemists who are not only interested in new molecules but also suggestions on stable and safe synthetic routes.', 'Third, we demonstrate the capabilities of our model to also solve one-step retrosynthesis problems, predicting a set of reactants that can produce a target product.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.1666666567325592, 0.09090908616781235, 0.09302324801683426, 0.2083333283662796, 0.060606054961681366, 0.17391303181648254, 0.0416666604578495, 0.1395348757505417]",BJlQEILY_N,"['A deep generative model for organic molecules that first generates reactant building blocks before combining these using a reaction predictor.', 'A molecular generative model that generates molecules via a two-step process that provides synthesis routes of the generated molecules, allowing users to examine the synthetic accessibility of generated compounds.']","['last year exciting work deep generative model produced model able suggest new organic molecule generating string  tree  graph representing structure ', 'model able generate molecule desirable property  utility practice limited due difficulty knowing synthesize molecule ', 'therefore propose new molecule generation model  mirroring realistic realworld process  reactant selected combined form complex molecule ', 'specifically  generative model proposes bag initial reactant  selected pool commerciallyavailable molecule  us reaction model predict react together generate new molecule ', 'modeling entire process constructing molecule generation offer number advantage ', 'first  show model ability generate wide  diverse set valid unique molecule due useful inductive bias modeling reaction ', 'second  modeling synthesis route rather final molecule offer practical advantage chemist interested new molecule also suggestion stable safe synthetic route ', 'third  demonstrate capability model also solve onestep retrosynthesis problem  predicting set reactant produce target product ']","Over the last few years exciting work in deep generative models has produced models able to suggest new organic molecules by generating strings, trees, and graphs representing their structure., While such models are able to generate molecules with desirable properties, their utility in practice is limited due to the difficulty in knowing how to synthesize these molecules., We therefore propose a new molecule generation model, mirroring a more realistic real-world process, where reactants are selected and combined to form more complex molecules., More specifically, our generative model proposes a bag of initial reactants (selected from a pool of commercially-available molecules) and uses a reaction model to predict how they react together to generate new molecules., Modeling the entire process of constructing a molecule during generation offers a number of advantages., First, we show that such a model has the ability to generate a wide, diverse set of valid and unique molecules due to the useful inductive biases of modeling reactions., Second, modeling synthesis routes rather than final molecules offers practical advantages to chemists who are not only interested in new molecules but also suggestions on stable and safe synthetic routes., Third, we demonstrate the capabilities of our model to also solve one-step retrosynthesis problems, predicting a set of reactants that can produce a target product.",19,5.530232558139535,11.31578947368421
33,"['Deep neural networks are complex non-linear models used as predictive analytics tool and have demonstrated state-of-the-art performance on many classification tasks.  ', 'However, they have no inherent capability to recognize when their predictions might go wrong.', 'There have been several efforts in the recent past to detect natural errors i.e.  misclassified inputs but these mechanisms pose additional energy requirements.  ', 'To address this issue, we present a novel post-hoc framework to detect natural errors in an energy efficient way.  ', 'We achieve this by appending relevant features based linear classifiers per class referred as Relevant features based Auxiliary Cells (RACs).   ', 'The proposed technique makes use of the consensus between RACs appended at few selected hidden layers to distinguish the correctly classified inputs from misclassified inputs.', 'The combined confidence of RACs is utilized to determine if classification should terminate at an early stage.', 'We demonstrate the effectiveness of our technique on various image classification datasets such as CIFAR10, CIFAR100 and Tiny-ImageNet.', 'Our results show that for CIFAR100 dataset trained on VGG16 network, RACs can detect 46% of the misclassified examples along with 12% reduction in energy compared to the baseline network while 69% of the examples are correctly classified.\n']","[0, 0, 0, 0, 0, 0, 0, 1, 0]","[0.1111111044883728, 0.0, 0.10256409645080566, 0.11764705181121826, 0.0, 0.1621621549129486, 0.06451612710952759, 0.1875, 0.16326530277729034]",BJgedkStDS,"['Improve the robustness and energy efficiency of a deep neural network using the hidden representations.', 'This paper aims to reduce the misclassifications of deep neural networks in an energy efficient way by adding Relevant feature based Auxiliary Cells after one or more hidden layers to decide whether to end classification early.']","['deep neural network complex nonlinear model used predictive analytics tool demonstrated stateoftheart performance many classification task ', 'however  inherent capability recognize prediction might go wrong ', 'several effort recent past detect natural error ie  misclassified input mechanism pose additional energy requirement ', 'address issue  present novel posthoc framework detect natural error energy efficient way ', 'achieve appending relevant feature based linear classifier per class referred relevant feature based auxiliary cell  racs  ', 'proposed technique make use consensus racs appended selected hidden layer distinguish correctly classified input misclassified input ', 'combined confidence racs utilized determine classification terminate early stage ', 'demonstrate effectiveness technique various image classification datasets cifar10  cifar100 tinyimagenet ', 'result show cifar100 dataset trained vgg16 network  racs detect 46  misclassified example along 12  reduction energy compared baseline network 69  example correctly classified ']","Deep neural networks are complex non-linear models used as predictive analytics tool and have demonstrated state-of-the-art performance on many classification tasks.  , However, they have no inherent capability to recognize when their predictions might go wrong., There have been several efforts in the recent past to detect natural errors i.e.  misclassified inputs but these mechanisms pose additional energy requirements.  , To address this issue, we present a novel post-hoc framework to detect natural errors in an energy efficient way.  , We achieve this by appending relevant features based linear classifiers per class referred as Relevant features based Auxiliary Cells (RACs).   , The proposed technique makes use of the consensus between RACs appended at few selected hidden layers to distinguish the correctly classified inputs from misclassified inputs., The combined confidence of RACs is utilized to determine if classification should terminate at an early stage., We demonstrate the effectiveness of our technique on various image classification datasets such as CIFAR10, CIFAR100 and Tiny-ImageNet., Our results show that for CIFAR100 dataset trained on VGG16 network, RACs can detect 46% of the misclassified examples along with 12% reduction in energy compared to the baseline network while 69% of the examples are correctly classified.
",13,5.841025641025641,13.928571428571429
34,"['Many methods have been developed to represent knowledge graph data, which implicitly exploit low-rank latent structure in the data to encode known information and enable unknown facts to be inferred.', 'To predict whether a relationship holds between entities, their embeddings are typically compared in the latent space following a relation-specific mapping.', 'Whilst link prediction has steadily improved, the latent structure, and hence why such models capture semantic information, remains unexplained.', 'We build on recent theoretical interpretation of word embeddings as a basis to consider an explicit structure for representations of relations between entities.', 'For identifiable relation types, we are able to predict properties and justify the relative performance of leading knowledge graph representation methods, including their often overlooked ability to make independent predictions.']","[0, 0, 0, 0, 1]","[0.20000000298023224, 0.1249999925494194, 0.06451612710952759, 0.23529411852359772, 0.24390242993831635]",SygcSlHFvS,"['Understanding the structure of knowledge graph representation using insight from word embeddings.', ""This paper attempts to understand the latent structure underlying knowledge graph embedding methods, and demonstrates that a model's ability to represent a relation type depends on the model architecture's limitations with respect to relation conditions."", ""This paper proposes a detailed study on the explainability of link prediction (LP) models by utilizing a recent interpretation of word embeddings to provide a better understanding of LPs' model performance.""]","['many method developed represent knowledge graph data  implicitly exploit lowrank latent structure data encode known information enable unknown fact inferred ', 'predict whether relationship hold entity  embeddings typically compared latent space following relationspecific mapping ', 'whilst link prediction steadily improved  latent structure  hence model capture semantic information  remains unexplained ', 'build recent theoretical interpretation word embeddings basis consider explicit structure representation relation entity ', 'identifiable relation type  able predict property justify relative performance leading knowledge graph representation method  including often overlooked ability make independent prediction ']","Many methods have been developed to represent knowledge graph data, which implicitly exploit low-rank latent structure in the data to encode known information and enable unknown facts to be inferred., To predict whether a relationship holds between entities, their embeddings are typically compared in the latent space following a relation-specific mapping., Whilst link prediction has steadily improved, the latent structure, and hence why such models capture semantic information, remains unexplained., We build on recent theoretical interpretation of word embeddings as a basis to consider an explicit structure for representations of relations between entities., For identifiable relation types, we are able to predict properties and justify the relative performance of leading knowledge graph representation methods, including their often overlooked ability to make independent predictions.",12,6.195121951219512,10.25
35,"['Many real-world applications involve multivariate, geo-tagged time series data: at each location, multiple sensors record corresponding measurements.', 'For example, air quality monitoring system records PM2.5, CO, etc.', 'The resulting time-series data often has missing values due to device outages or communication errors.', 'In order to impute the missing values, state-of-the-art methods are built on Recurrent Neural Networks (RNN), which process each time stamp sequentially, prohibiting the direct modeling of the relationship between distant time stamps.', 'Recently, the self-attention mechanism has been proposed for sequence modeling tasks such as machine translation, significantly outperforming RNN because the relationship between each two time stamps can be modeled explicitly.', 'In this paper, we are the first to adapt the self-attention mechanism for multivariate, geo-tagged time series data.', 'In order to jointly capture the self-attention across different dimensions (i.e. time, location and sensor measurements) while keep the size of attention maps reasonable, we propose a novel approach called Cross-Dimensional Self-Attention (CDSA) to process each dimension sequentially, yet in an order-independent manner.', 'On three real-world datasets, including one our newly collected NYC-traffic dataset, extensive experiments demonstrate the superiority of our approach compared to state-of-the-art methods for both imputation and forecasting tasks. \n']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.29629629850387573, 0.0, 0.0, 0.04999999701976776, 0.20512820780277252, 0.5185185074806213, 0.07692307233810425, 0.10256409645080566]",SJxRKT4Fwr,"['A novel self-attention mechanism for multivariate, geo-tagged time series imputation.', 'This paper proposes the problem of applying the transformer network to spatiotemporal data in a compuationally efficient way, and investigates ways of implementing 3D attention.', 'This paper empirically studies the effectiveness of transformer models for time series data imputation across dimensions of the input.']","['many realworld application involve multivariate  geotagged time series data  location  multiple sensor record corresponding measurement ', 'example  air quality monitoring system record pm25  co  etc ', 'resulting timeseries data often missing value due device outage communication error ', 'order impute missing value  stateoftheart method built recurrent neural network  rnn   process time stamp sequentially  prohibiting direct modeling relationship distant time stamp ', 'recently  selfattention mechanism proposed sequence modeling task machine translation  significantly outperforming rnn relationship two time stamp modeled explicitly ', 'paper  first adapt selfattention mechanism multivariate  geotagged time series data ', 'order jointly capture selfattention across different dimension  ie  time  location sensor measurement  keep size attention map reasonable  propose novel approach called crossdimensional selfattention  cdsa  process dimension sequentially  yet orderindependent manner ', 'three realworld datasets  including one newly collected nyctraffic dataset  extensive experiment demonstrate superiority approach compared stateoftheart method imputation forecasting task ']","Many real-world applications involve multivariate, geo-tagged time series data: at each location, multiple sensors record corresponding measurements., For example, air quality monitoring system records PM2.5, CO, etc., The resulting time-series data often has missing values due to device outages or communication errors., In order to impute the missing values, state-of-the-art methods are built on Recurrent Neural Networks (RNN), which process each time stamp sequentially, prohibiting the direct modeling of the relationship between distant time stamps., Recently, the self-attention mechanism has been proposed for sequence modeling tasks such as machine translation, significantly outperforming RNN because the relationship between each two time stamps can be modeled explicitly., In this paper, we are the first to adapt the self-attention mechanism for multivariate, geo-tagged time series data., In order to jointly capture the self-attention across different dimensions (i.e. time, location and sensor measurements) while keep the size of attention maps reasonable, we propose a novel approach called Cross-Dimensional Self-Attention (CDSA) to process each dimension sequentially, yet in an order-independent manner., On three real-world datasets, including one our newly collected NYC-traffic dataset, extensive experiments demonstrate the superiority of our approach compared to state-of-the-art methods for both imputation and forecasting tasks. 
",25,6.358974358974359,7.5
36,"['The conversion of scanned documents to digital forms is performed using an Optical Character Recognition (OCR) software.', 'This work focuses on improving the quality of scanned documents in order to improve the OCR output.', 'We create an end-to-end document enhancement pipeline which takes in a set of noisy documents and produces clean ones.', 'Deep neural network based denoising auto-encoders are trained to improve the OCR quality.', 'We train a blind model that works on different noise levels of scanned text documents.', 'Results are shown for blurring and watermark noise removal from noisy scanned documents.']","[0, 0, 0, 0, 0, 1]","[0.0416666604578495, 0.08510638028383255, 0.19999998807907104, 0.09090908616781235, 0.1304347813129425, 0.22727271914482117]",S1Mnzp9qLB,"['We designed and tested a REDNET (ResNet Encoder-Decoder) with 8 skip connections to remove noise from documents, including blurring and watermarks, resulting in a high performance deep network for document image cleanup. ']","['conversion scanned document digital form performed using optical character recognition  ocr  software ', 'work focus improving quality scanned document order improve ocr output ', 'create endtoend document enhancement pipeline take set noisy document produce clean one ', 'deep neural network based denoising autoencoders trained improve ocr quality ', 'train blind model work different noise level scanned text document ', 'result shown blurring watermark noise removal noisy scanned document ']","The conversion of scanned documents to digital forms is performed using an Optical Character Recognition (OCR) software., This work focuses on improving the quality of scanned documents in order to improve the OCR output., We create an end-to-end document enhancement pipeline which takes in a set of noisy documents and produces clean ones., Deep neural network based denoising auto-encoders are trained to improve the OCR quality., We train a blind model that works on different noise levels of scanned text documents., Results are shown for blurring and watermark noise removal from noisy scanned documents.",6,5.446808510638298,15.666666666666666
37,"['The existence of adversarial examples, or intentional mis-predictions constructed from small changes to correctly predicted examples, is one of the most significant challenges in neural network research today.', 'Ironically, many new defenses are based on a simple observation - the adversarial inputs themselves are not robust and small perturbations to the attacking input often recover the desired prediction.', 'While the intuition is somewhat clear, a detailed understanding of this phenomenon is missing from the research literature.', 'This paper presents a comprehensive experimental analysis of when and why perturbation defenses work and potential mechanisms that could explain their effectiveness (or ineffectiveness) in different settings.']","[0, 1, 0, 0]","[0.1599999964237213, 0.23529411852359772, 0.14999999105930328, 0.19999998807907104]",rkePU0VYDr,"['We identify a family of defense techniques and show that both deterministic lossy compression and randomized perturbations to the input lead to similar gains in robustness.', ""This paper discusses ways of destabilizing a given adversarial attack, what makes adversarial images non-robust, and if it's possible for attackers to use a universal model of perturbations to make their adversarial examples robust against such perturbations."", 'The paper studies the robustness of adversarial attacks to transformations of their input.']","['existence adversarial example  intentional mispredictions constructed small change correctly predicted example  one significant challenge neural network research today ', 'ironically  many new defense based simple observation  adversarial input robust small perturbation attacking input often recover desired prediction ', 'intuition somewhat clear  detailed understanding phenomenon missing research literature ', 'paper present comprehensive experimental analysis perturbation defense work potential mechanism could explain effectiveness  ineffectiveness  different setting ']","The existence of adversarial examples, or intentional mis-predictions constructed from small changes to correctly predicted examples, is one of the most significant challenges in neural network research today., Ironically, many new defenses are based on a simple observation - the adversarial inputs themselves are not robust and small perturbations to the attacking input often recover the desired prediction., While the intuition is somewhat clear, a detailed understanding of this phenomenon is missing from the research literature., This paper presents a comprehensive experimental analysis of when and why perturbation defenses work and potential mechanisms that could explain their effectiveness (or ineffectiveness) in different settings.",8,6.174757281553398,12.875
38,"['There is no consensus yet on the question whether adaptive gradient methods like Adam are easier to use than non-adaptive optimization methods like SGD.', 'In this work, we fill in the important, yet ambiguous concept of ease-of-use by defining an optimizers tunability:  How easy is it to find good hyperparameter configurations using automatic random hyperparameter search?', 'We propose a practical and universal quantitative measure for optimizer tunability that can form the basis for a fair optimizer benchmark.  ', 'Evaluating a variety of optimizers on an extensive set of standard datasets and architectures, we find  that Adam is the most tunable for the majority of problems, especially with a low budget for hyperparameter tuning.']","[0, 0, 0, 1]","[0.1666666567325592, 0.17777776718139648, 0.3030303120613098, 0.3181818127632141]",H1gEP6NFwr,"['We provide a method to benchmark optimizers that is cognizant to the hyperparameter tuning process.', 'Introduction of a novel metric to capture the tunability of an optimizer, and a comprehensive empirical comparison of deep learning optimizers under different amounts of hyper-parameter tuning. ', ""This paper introduces a simple measure of tunability that allows to compare optimizers under resource constraints, finding that tuning Adam optimizers' learning rate is easiest to find well-performing hyperparameter configurations.""]","['consensus yet question whether adaptive gradient method like adam easier use nonadaptive optimization method like sgd ', 'work  fill important  yet ambiguous concept  easeofuse  defining optimizer  tunability  easy find good hyperparameter configuration using automatic random hyperparameter search ', 'propose practical universal quantitative measure optimizer tunability form basis fair optimizer benchmark ', 'evaluating variety optimizers extensive set standard datasets architecture  find adam tunable majority problem  especially low budget hyperparameter tuning ']","There is no consensus yet on the question whether adaptive gradient methods like Adam are easier to use than non-adaptive optimization methods like SGD., In this work, we fill in the important, yet ambiguous concept of ease-of-use by defining an optimizers tunability:  How easy is it to find good hyperparameter configurations using automatic random hyperparameter search?, We propose a practical and universal quantitative measure for optimizer tunability that can form the basis for a fair optimizer benchmark.  , Evaluating a variety of optimizers on an extensive set of standard datasets and architectures, we find  that Adam is the most tunable for the majority of problems, especially with a low budget for hyperparameter tuning.",8,5.508928571428571,14.0
39,"['The phase problem in diffraction physics is one of the oldest inverse problems in all of science.', 'The central difficulty that any approach to solving this inverse problem must overcome is that half of the information, namely the phase of the diffracted beam, is always missing.', 'In the context of electron microscopy, the phase problem is generally non-linear and solutions provided by phase-retrieval techniques are known to be poor approximations to the physics of electrons interacting with matter.', 'Here, we show that a semi-supervised learning approach can effectively solve the phase problem in electron microscopy/scattering.', 'In particular, we introduce a new Deep Neural Network (DNN), Y-net, which simultaneously learns a reconstruction algorithm via supervised training in addition to learning a physics-based regularization via unsupervised training.', 'We demonstrate that this constrained, semi-supervised approach is an order of magnitude more data-efficient and accurate than the same model trained in a purely supervised fashion.', ""In addition, the architecture of the Y-net model provides for a straightforward evaluation of the consistency of the model's prediction during inference and is generally applicable to the phase problem in other settings.""]","[0, 0, 0, 1, 0, 0, 0]","[0.3125, 0.24390242993831635, 0.2666666507720947, 0.4117647111415863, 0.1860465109348297, 0.2790697515010834, 0.3181818127632141]",Bygi2739Lr,['We introduce a semi-supervised deep neural network to approximate the solution of the phase problem in electron microscopy'],"['phase problem diffraction physic one oldest inverse problem science ', 'central difficulty approach solving inverse problem must overcome half information  namely phase diffracted beam  always missing ', 'context electron microscopy  phase problem generally nonlinear solution provided phaseretrieval technique known poor approximation physic electron interacting matter ', ' show semisupervised learning approach effectively solve phase problem electron microscopyscattering ', 'particular  introduce new deep neural network  dnn   ynet  simultaneously learns reconstruction algorithm via supervised training addition learning physicsbased regularization via unsupervised training ', 'demonstrate constrained  semisupervised approach order magnitude dataefficient accurate model trained purely supervised fashion ', 'addition  architecture ynet model provides straightforward evaluation consistency model prediction inference generally applicable phase problem setting ']","The phase problem in diffraction physics is one of the oldest inverse problems in all of science., The central difficulty that any approach to solving this inverse problem must overcome is that half of the information, namely the phase of the diffracted beam, is always missing., In the context of electron microscopy, the phase problem is generally non-linear and solutions provided by phase-retrieval techniques are known to be poor approximations to the physics of electrons interacting with matter., Here, we show that a semi-supervised learning approach can effectively solve the phase problem in electron microscopy/scattering., In particular, we introduce a new Deep Neural Network (DNN), Y-net, which simultaneously learns a reconstruction algorithm via supervised training in addition to learning a physics-based regularization via unsupervised training., We demonstrate that this constrained, semi-supervised approach is an order of magnitude more data-efficient and accurate than the same model trained in a purely supervised fashion., In addition, the architecture of the Y-net model provides for a straightforward evaluation of the consistency of the model's prediction during inference and is generally applicable to the phase problem in other settings.",16,5.809782608695652,11.5
40,"['Word embeddings extract semantic features of words from large datasets of text.\n', 'Most embedding methods rely on a log-bilinear model to predict the occurrence\n', 'of a word in a context of other words.', 'Here we propose word2net, a method that\n', 'replaces their linear parametrization with neural networks.', 'For each term in the\n', 'vocabulary, word2net posits a neural network that takes the context as input and\n', 'outputs a probability of occurrence.', 'Further, word2net can use the hierarchical\n', 'organization of its word networks to incorporate additional meta-data, such as\n', 'syntactic features, into the embedding model.', 'For example, we show how to share\n', 'parameters across word networks to develop an embedding model that includes\n', 'part-of-speech information.', 'We study word2net with two datasets, a collection\n', 'of Wikipedia articles and a corpus of U.S. Senate speeches.', 'Quantitatively, we\n', 'found that word2net outperforms popular embedding methods on predicting held-\n', 'out words and that sharing parameters based on part of speech further boosts\n', 'performance.', 'Qualitatively, word2net learns interpretable semantic representations\n', 'and, compared to vector-based methods, better incorporates syntactic information.']","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.23529411852359772, 0.11764705181121826, 0.20689654350280762, 0.20689654350280762, 0.06896551698446274, 0.0, 0.22857142984867096, 0.14814814925193787, 0.1428571343421936, 0.12121211737394333, 0.0714285671710968, 0.06896551698446274, 0.12121211737394333, 0.06666666269302368, 0.1249999925494194, 0.0624999962747097, 0.17142856121063232, 0.1428571343421936, 0.25806450843811035]",SkJd_y-Cb,"['Word2net is a novel method for learning neural network representations of words that can use syntactic information to learn better semantic features.', 'This paper extends SGNS with an architectural change from a bag-of-words model to a feedforward model, and contributes a new form of regularization by tying a subset of layers between different associated networks.', 'A method to use non-linear combination of context vectors for learning vector representation of words, where the main idea is to replace each word embedding by a neural network.']","['word embeddings extract semantic feature word large datasets text ', 'embedding method rely logbilinear model predict occurrence', 'word context word ', 'propose word2net  method', 'replaces linear parametrization neural network ', 'term', 'vocabulary  word2net posit neural network take context input', 'output probability occurrence ', ' word2net use hierarchical', 'organization word network incorporate additional metadata ', 'syntactic feature  embedding model ', 'example  show share', 'parameter across word network develop embedding model includes', 'partofspeech information ', 'study word2net two datasets  collection', 'wikipedia article corpus u senate speech ', 'quantitatively ', 'found word2net outperforms popular embedding method predicting held', 'word sharing parameter based part speech boost', 'performance ', 'qualitatively  word2net learns interpretable semantic representation', ' compared vectorbased method  better incorporates syntactic information ']","Word embeddings extract semantic features of words from large datasets of text.
, Most embedding methods rely on a log-bilinear model to predict the occurrence
, of a word in a context of other words., Here we propose word2net, a method that
, replaces their linear parametrization with neural networks., For each term in the
, vocabulary, word2net posits a neural network that takes the context as input and
, outputs a probability of occurrence., Further, word2net can use the hierarchical
, organization of its word networks to incorporate additional meta-data, such as
, syntactic features, into the embedding model., For example, we show how to share
, parameters across word networks to develop an embedding model that includes
, part-of-speech information., We study word2net with two datasets, a collection
, of Wikipedia articles and a corpus of U.S. Senate speeches., Quantitatively, we
, found that word2net outperforms popular embedding methods on predicting held-
, out words and that sharing parameters based on part of speech further boosts
, performance., Qualitatively, word2net learns interpretable semantic representations
, and, compared to vector-based methods, better incorporates syntactic information.",33,5.8604651162790695,5.212121212121212
41,"['A key goal in neuroscience is to understand brain mechanisms of cognitive functions.', 'An emerging approach is to study brain states dynamics using functional magnetic resonance imaging (fMRI).', 'So far in the literature, brain states have typically been studied using 30 seconds of fMRI data or more, and it is unclear to which extent brain states can be reliably identified from very short time series.', 'In this project, we applied graph convolutional networks (GCN) to decode brain activity over short time windows in a task fMRI dataset, i.e. associate a given window of fMRI time series with the task used.', 'Starting with a populational brain graph with nodes defined by a parcellation of cerebral cortex and the adjacent matrix extracted from functional connectome, GCN takes a short series of fMRI volumes as input, generates high-level domain-specific graph representations, and then predicts the corresponding cognitive state.', 'We investigated the performance of this GCN ""cognitive state annotation"" in the Human Connectome Project (HCP) database, which features 21 different experimental conditions spanning seven major cognitive domains, and high temporal resolution task fMRI data.', 'Using a 10-second window, the 21 cognitive states were identified with an excellent average test accuracy of 89% (chance level 4.8%).', 'As the HCP task battery was designed to selectively activate a wide range of specialized functional networks, we anticipate the GCN annotation to be applicable as a base model for other transfer learning applications, for instance, adapting to new task domains.']","[0, 0, 0, 0, 0, 0, 1, 0]","[0.05714285373687744, 0.0, 0.14035087823867798, 0.2222222238779068, 0.19999998807907104, 0.25, 0.40909090638160706, 0.21052631735801697]",HJenmmF8Ir,"['Using a 10s window of fMRI signals, our GCN model identified 21 different task conditions from HCP dataset with a test accuracy of 89%.']","['key goal neuroscience understand brain mechanism cognitive function ', 'emerging approach study  brain state  dynamic using functional magnetic resonance imaging  fmri  ', 'far literature  brain state typically studied using 30 second fmri data  unclear extent brain state reliably identified short time series ', 'project  applied graph convolutional network  gcn  decode brain activity short time window task fmri dataset  ie  associate given window fmri time series task used ', 'starting populational brain graph node defined parcellation cerebral cortex adjacent matrix extracted functional connectome  gcn take short series fmri volume input  generates highlevel domainspecific graph representation  predicts corresponding cognitive state ', 'investigated performance gcn  cognitive state annotation  human connectome project  hcp  database  feature 21 different experimental condition spanning seven major cognitive domain  high temporal resolution task fmri data ', 'using 10second window  21 cognitive state identified excellent average test accuracy 89   chance level 48   ', 'hcp task battery designed selectively activate wide range specialized functional network  anticipate gcn annotation applicable base model transfer learning application  instance  adapting new task domain ']","A key goal in neuroscience is to understand brain mechanisms of cognitive functions., An emerging approach is to study brain states dynamics using functional magnetic resonance imaging (fMRI)., So far in the literature, brain states have typically been studied using 30 seconds of fMRI data or more, and it is unclear to which extent brain states can be reliably identified from very short time series., In this project, we applied graph convolutional networks (GCN) to decode brain activity over short time windows in a task fMRI dataset, i.e. associate a given window of fMRI time series with the task used., Starting with a populational brain graph with nodes defined by a parcellation of cerebral cortex and the adjacent matrix extracted from functional connectome, GCN takes a short series of fMRI volumes as input, generates high-level domain-specific graph representations, and then predicts the corresponding cognitive state., We investigated the performance of this GCN ""cognitive state annotation"" in the Human Connectome Project (HCP) database, which features 21 different experimental conditions spanning seven major cognitive domains, and high temporal resolution task fMRI data., Using a 10-second window, the 21 cognitive states were identified with an excellent average test accuracy of 89% (chance level 4.8%)., As the HCP task battery was designed to selectively activate a wide range of specialized functional networks, we anticipate the GCN annotation to be applicable as a base model for other transfer learning applications, for instance, adapting to new task domains.",21,5.5,11.0
42,"['Modern deep neural networks (DNNs) require high memory consumption and large computational loads.  ', 'In order to deploy DNN algorithms efficiently on edge or mobile devices, a series of DNN compression algorithms have been explored, including the line of works on factorization methods.', 'Factorization methods approximate the weight matrix of a DNN layer with multiplication of two or multiple low-rank matrices.', 'However, it is hard to measure the ranks of DNN layers during the training process.', 'Previous works mainly induce low-rank through implicit approximations or via costly singular value decomposition (SVD) process on every training step.', 'The former approach usually induces a high accuracy loss while the latter prevents DNN factorization from efficiently reaching a high compression rate.', ""In this work, we propose SVD training, which first applies SVD to decompose DNN's layers and then performs training on the full-rank decomposed weights."", 'To improve the training quality and convergence, we add orthogonality regularization to the singular vectors, which ensure the valid form of SVD and avoid gradient vanishing/exploding.', 'Low-rank is encouraged by applying sparsity-inducing regularizers on the singular values of each layer.', 'Singular value pruning is applied at the end to reach a low-rank model.', 'We empirically show that SVD training can significantly reduce the rank of DNN layers and achieve higher reduction on computation load under the same accuracy, comparing to not only previous factorization methods but also state-of-the-art filter pruning methods.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.2666666507720947, 0.0, 0.12121211737394333, 0.06666666269302368, 0.2222222238779068, 0.0, 0.1538461446762085, 0.20512819290161133, 0.13333332538604736, 0.06896550953388214, 0.11538460850715637]",SJeNA6EtDB,"['Efficiently inducing low-rank deep neural networks via SVD training with sparse singular values and orthogonal singular vectors.', 'This paper introduces an approach to network compression by encouraging the weight matrix in each layer to have a low rank and explicitly factorizing the weight matrices into an SVD-like factorization for treatment as new parameters.', 'Proposal to parametrize each layer of a deep neural network, before training, with a low-rank matrix decomposition, accordingly replace convolutions with two consecutive convolutions, and then train the decomposed method.']","['modern deep neural network  dnns  require high memory consumption large computational load ', 'order deploy dnn algorithm efficiently edge mobile device  series dnn compression algorithm explored  including line work factorization method ', 'factorization method approximate weight matrix dnn layer multiplication two multiple lowrank matrix ', 'however  hard measure rank dnn layer training process ', 'previous work mainly induce lowrank implicit approximation via costly singular value decomposition  svd  process every training step ', 'former approach usually induces high accuracy loss latter prevents dnn factorization efficiently reaching high compression rate ', 'work  propose svd training  first applies svd decompose dnn layer performs training fullrank decomposed weight ', 'improve training quality convergence  add orthogonality regularization singular vector  ensure valid form svd avoid gradient vanishingexploding ', 'lowrank encouraged applying sparsityinducing regularizers singular value layer ', 'singular value pruning applied end reach lowrank model ', 'empirically show svd training significantly reduce rank dnn layer achieve higher reduction computation load accuracy  comparing previous factorization method also stateoftheart filter pruning method ']","Modern deep neural networks (DNNs) require high memory consumption and large computational loads.  , In order to deploy DNN algorithms efficiently on edge or mobile devices, a series of DNN compression algorithms have been explored, including the line of works on factorization methods., Factorization methods approximate the weight matrix of a DNN layer with multiplication of two or multiple low-rank matrices., However, it is hard to measure the ranks of DNN layers during the training process., Previous works mainly induce low-rank through implicit approximations or via costly singular value decomposition (SVD) process on every training step., The former approach usually induces a high accuracy loss while the latter prevents DNN factorization from efficiently reaching a high compression rate., In this work, we propose SVD training, which first applies SVD to decompose DNN's layers and then performs training on the full-rank decomposed weights., To improve the training quality and convergence, we add orthogonality regularization to the singular vectors, which ensure the valid form of SVD and avoid gradient vanishing/exploding., Low-rank is encouraged by applying sparsity-inducing regularizers on the singular values of each layer., Singular value pruning is applied at the end to reach a low-rank model., We empirically show that SVD training can significantly reduce the rank of DNN layers and achieve higher reduction on computation load under the same accuracy, comparing to not only previous factorization methods but also state-of-the-art filter pruning methods.",19,5.745689655172414,12.210526315789474
43,"['The recent rise in popularity of few-shot learning algorithms has enabled models to quickly adapt to new tasks based on only a few training samples.', 'Previous few-shot learning works have mainly focused on classification and reinforcement learning. \n', 'In this paper, we propose a few-shot meta-learning system that focuses exclusively on regression tasks.', 'Our model is based on the idea that the degree of freedom of the unknown function can be significantly reduced if it is represented as a linear combination of a set of appropriate basis functions.', 'This enables a few labelled samples to approximate the function.', 'We design a Feature Extractor network to encode basis functions for a task distribution, and a  Weights Generator to generate the weight vector for a novel task.', 'We show that our model outperforms the current state of the art meta-learning methods in various regression tasks.']","[0, 0, 1, 0, 0, 0, 0]","[0.21621620655059814, 0.1599999964237213, 0.4285714328289032, 0.19512194395065308, 0.08695651590824127, 0.1764705777168274, 0.3333333432674408]",r1ldYi9rOV,"['We propose a few-shot learning model that is tailored specifically for regression tasks', 'This paper proposes a novel shot-learning method for small sample regression problems.', 'A method that learns a regression model with a few samples and outperforms other methods.']","['recent rise popularity fewshot learning algorithm enabled model quickly adapt new task based training sample ', 'previous fewshot learning work mainly focused classification reinforcement learning ', 'paper  propose fewshot metalearning system focus exclusively regression task ', 'model based idea degree freedom unknown function significantly reduced represented linear combination set appropriate basis function ', 'enables labelled sample approximate function ', 'design feature extractor network encode basis function task distribution  weight generator generate weight vector novel task ', 'show model outperforms current state art metalearning method various regression task ']","The recent rise in popularity of few-shot learning algorithms has enabled models to quickly adapt to new tasks based on only a few training samples., Previous few-shot learning works have mainly focused on classification and reinforcement learning. 
, In this paper, we propose a few-shot meta-learning system that focuses exclusively on regression tasks., Our model is based on the idea that the degree of freedom of the unknown function can be significantly reduced if it is represented as a linear combination of a set of appropriate basis functions., This enables a few labelled samples to approximate the function., We design a Feature Extractor network to encode basis functions for a task distribution, and a  Weights Generator to generate the weight vector for a novel task., We show that our model outperforms the current state of the art meta-learning methods in various regression tasks.",9,5.253521126760563,15.777777777777779
44,"['Most classification and segmentation datasets assume a closed-world scenario in which predictions are expressed as distribution over a predetermined set of visual classes.', 'However, such assumption implies unavoidable and often unnoticeable failures in presence of out-of-distribution (OOD) input.', 'These failures are bound to happen in most real-life applications since current visual ontologies are far from being comprehensive.', 'We propose to address this issue by discriminative detection \n', 'of OOD pixels in input data.', 'Different from recent approaches, we avoid to bring any decisions by only observing the training dataset of the primary model trained to solve the desired computer vision task.', 'Instead, we train a dedicated OOD model\n', 'which discriminates the primary training set from a much larger ""background"" dataset which approximates the variety of the visual world.', 'We perform our experiments on high resolution natural images in a dense prediction setup.', 'We use several road driving datasets as our training distribution, while we approximate the background distribution with the ILSVRC dataset.', 'We evaluate our approach on WildDash test, which is currently the only public test dataset with out-of-distribution images.\n', 'The obtained results show that the proposed approach succeeds to identify out-of-distribution pixels while outperforming previous work by a wide margin.']","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]","[0.1764705777168274, 0.14814814925193787, 0.06666666269302368, 0.0952380895614624, 0.2222222238779068, 0.0, 0.10526315122842789, 0.06896550953388214, 0.23076923191547394, 0.06451612710952759, 0.19354838132858276, 0.24242423474788666]",H1x1noAqKX,"['We present a novel approach for detecting out-of-distribution pixels in semantic segmentation.', 'This paper addresses out-of-distribution detection for helping the segmentation process, and proposes an approach of training a binary classifier that distinguishes image patches from a known set of classes from those of an unknown.', 'This paper aims to detect out-of-distribution pixels for semantic segmentation, and this work utilizes data from other domains to detect undetermined classes to model uncertainty better.']","['classification segmentation datasets assume closedworld scenario prediction expressed distribution predetermined set visual class ', 'however  assumption implies unavoidable often unnoticeable failure presence outofdistribution  ood  input ', 'failure bound happen reallife application since current visual ontology far comprehensive ', 'propose address issue discriminative detection', 'ood pixel input data ', 'different recent approach  avoid bring decision observing training dataset primary model trained solve desired computer vision task ', 'instead  train dedicated ood model', 'discriminates primary training set much larger  background  dataset approximates variety visual world ', 'perform experiment high resolution natural image dense prediction setup ', 'use several road driving datasets training distribution  approximate background distribution ilsvrc dataset ', 'evaluate approach wilddash test  currently public test dataset outofdistribution image ', 'obtained result show proposed approach succeeds identify outofdistribution pixel outperforming previous work wide margin ']","Most classification and segmentation datasets assume a closed-world scenario in which predictions are expressed as distribution over a predetermined set of visual classes., However, such assumption implies unavoidable and often unnoticeable failures in presence of out-of-distribution (OOD) input., These failures are bound to happen in most real-life applications since current visual ontologies are far from being comprehensive., We propose to address this issue by discriminative detection 
, of OOD pixels in input data., Different from recent approaches, we avoid to bring any decisions by only observing the training dataset of the primary model trained to solve the desired computer vision task., Instead, we train a dedicated OOD model
, which discriminates the primary training set from a much larger ""background"" dataset which approximates the variety of the visual world., We perform our experiments on high resolution natural images in a dense prediction setup., We use several road driving datasets as our training distribution, while we approximate the background distribution with the ILSVRC dataset., We evaluate our approach on WildDash test, which is currently the only public test dataset with out-of-distribution images.
, The obtained results show that the proposed approach succeeds to identify out-of-distribution pixels while outperforming previous work by a wide margin.",17,5.88,11.764705882352942
45,"['Network quantization is one of the most hardware friendly techniques to enable the deployment of convolutional neural networks (CNNs) on low-power mobile devices.', 'Recent network quantization techniques quantize each weight kernel in a convolutional layer independently for higher inference accuracy, since the weight kernels in a layer exhibit different variances and hence have different amounts of redundancy.', 'The quantization bitwidth or bit number (QBN) directly decides the inference accuracy, latency, energy and hardware overhead.', 'To effectively reduce the redundancy and accelerate CNN inferences, various weight kernels should be quantized with different QBNs.', 'However, prior works use only one QBN to quantize each convolutional layer or the entire CNN, because the design space of searching a QBN for each weight kernel is too large.', 'The hand-crafted heuristic of the kernel-wise QBN search is so sophisticated that domain experts can obtain only sub-optimal results.', 'It is difficult for even deep reinforcement learning (DRL) DDPG-based agents to find a kernel-wise QBN configuration that can achieve reasonable inference accuracy.', 'In this paper, we propose a hierarchical-DRL-based kernel-wise network quantization technique, AutoQ, to automatically search a QBN for each weight kernel, and choose another QBN for each activation layer.', 'Compared to the models quantized by the state-of-the-art DRL-based schemes, on average, the same models quantized by AutoQ reduce the inference latency by 54.06%, and decrease the inference energy consumption by 50.69%, while achieving the same inference accuracy.']","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.05405404791235924, 0.04444443807005882, 0.060606054961681366, 0.11764705181121826, 0.0, 0.0, 0.0, 0.04878048226237297, 0.04651162400841713]",rygfnn4twS,"['Accurate, Fast and Automated Kernel-Wise Neural Network Quantization with Mixed Precision using Hierarchical Deep Reinforcement Learning', 'A method for quantizing neural network weights and activations that uses deep reinforcement learning to select bitwidth for individual kernels in a layer and that achieves better performance, or latency, than prior approaches.', 'This paper proposes to automatically search quantization schemes for each kernel in the neural network, using hierarchial RL to guide the search. ']","['network quantization one hardware friendly technique enable deployment convolutional neural network  cnns  lowpower mobile device ', 'recent network quantization technique quantize weight kernel convolutional layer independently higher inference accuracy  since weight kernel layer exhibit different variance hence different amount redundancy ', 'quantization bitwidth bit number  qbn  directly decides inference accuracy  latency  energy hardware overhead ', 'effectively reduce redundancy accelerate cnn inference  various weight kernel quantized different qbns ', 'however  prior work use one qbn quantize convolutional layer entire cnn  design space searching qbn weight kernel large ', 'handcrafted heuristic kernelwise qbn search sophisticated domain expert obtain suboptimal result ', 'difficult even deep reinforcement learning  drl  ddpgbased agent find kernelwise qbn configuration achieve reasonable inference accuracy ', 'paper  propose hierarchicaldrlbased kernelwise network quantization technique  autoq  automatically search qbn weight kernel  choose another qbn activation layer ', 'compared model quantized stateoftheart drlbased scheme  average  model quantized autoq reduce inference latency 5406   decrease inference energy consumption 5069   achieving inference accuracy ']","Network quantization is one of the most hardware friendly techniques to enable the deployment of convolutional neural networks (CNNs) on low-power mobile devices., Recent network quantization techniques quantize each weight kernel in a convolutional layer independently for higher inference accuracy, since the weight kernels in a layer exhibit different variances and hence have different amounts of redundancy., The quantization bitwidth or bit number (QBN) directly decides the inference accuracy, latency, energy and hardware overhead., To effectively reduce the redundancy and accelerate CNN inferences, various weight kernels should be quantized with different QBNs., However, prior works use only one QBN to quantize each convolutional layer or the entire CNN, because the design space of searching a QBN for each weight kernel is too large., The hand-crafted heuristic of the kernel-wise QBN search is so sophisticated that domain experts can obtain only sub-optimal results., It is difficult for even deep reinforcement learning (DRL) DDPG-based agents to find a kernel-wise QBN configuration that can achieve reasonable inference accuracy., In this paper, we propose a hierarchical-DRL-based kernel-wise network quantization technique, AutoQ, to automatically search a QBN for each weight kernel, and choose another QBN for each activation layer., Compared to the models quantized by the state-of-the-art DRL-based schemes, on average, the same models quantized by AutoQ reduce the inference latency by 54.06%, and decrease the inference energy consumption by 50.69%, while achieving the same inference accuracy.",23,5.900862068965517,10.08695652173913
46,"['Recent visual analytics systems make use of multiple machine learning models to better fit the data as opposed to traditional single, pre-defined model systems.', 'However, while multi-model visual analytic systems can be effective, their added complexity poses usability concerns, as users are required to interact with the parameters of multiple models.', 'Further, the advent of various model algorithms and associated hyperparameters creates an exhaustive model space to sample models from.', 'This poses complexity to navigate this model space to find the right model for the data and the task.', 'In this paper, we present Gaggle, a multi-model visual analytic system that enables users to interactively navigate the model space.', 'Further translating user interactions into inferences, Gaggle simplifies working with multiple models by automatically finding the best model from the high-dimensional model space to support various user tasks.', 'Through a qualitative user study, we show how our approach helps users to find a best model for a classification and ranking task.', 'The study results confirm that Gaggle is intuitive and easy to use, supporting interactive model space navigation and automated model selection without requiring any technical expertise from users.']","[0, 0, 0, 0, 1, 0, 0, 0]","[0.14999999105930328, 0.17777776718139648, 0.277777761220932, 0.3636363446712494, 0.5263158082962036, 0.1860465109348297, 0.3589743673801422, 0.27272728085517883]",KyMw0p9rWL,"['Gaggle, an interactive visual analytic system to help users interactively navigate model space for classification and ranking tasks.', 'A new visual analytic system which aims to enable non-expert users to interactively navigate a model space by using a demonstration-based approach.', 'A visual analytics system that helps novice analysts navigate model space in performing classification and ranking tasks.']","['recent visual analytics system make use multiple machine learning model better fit data opposed traditional single  predefined model system ', 'however  multimodel visual analytic system effective  added complexity pose usability concern  user required interact parameter multiple model ', ' advent various model algorithm associated hyperparameters creates exhaustive model space sample model ', 'pose complexity navigate model space find right model data task ', 'paper  present gaggle  multimodel visual analytic system enables user interactively navigate model space ', 'translating user interaction inference  gaggle simplifies working multiple model automatically finding best model highdimensional model space support various user task ', 'qualitative user study  show approach help user find best model classification ranking task ', 'study result confirm gaggle intuitive easy use  supporting interactive model space navigation automated model selection without requiring technical expertise user ']","Recent visual analytics systems make use of multiple machine learning models to better fit the data as opposed to traditional single, pre-defined model systems., However, while multi-model visual analytic systems can be effective, their added complexity poses usability concerns, as users are required to interact with the parameters of multiple models., Further, the advent of various model algorithms and associated hyperparameters creates an exhaustive model space to sample models from., This poses complexity to navigate this model space to find the right model for the data and the task., In this paper, we present Gaggle, a multi-model visual analytic system that enables users to interactively navigate the model space., Further translating user interactions into inferences, Gaggle simplifies working with multiple models by automatically finding the best model from the high-dimensional model space to support various user tasks., Through a qualitative user study, we show how our approach helps users to find a best model for a classification and ranking task., The study results confirm that Gaggle is intuitive and easy to use, supporting interactive model space navigation and automated model selection without requiring any technical expertise from users.",18,5.670212765957447,10.444444444444445
47,"['Chinese text classification has received more and more attention today.', 'However, the problem of Chinese text representation still hinders the improvement of Chinese text classification, especially the polyphone and the homophone in social media.', 'To cope with it effectively, we propose a new structure, the Extractor, based on attention mechanisms and design novel attention networks named Extractor-attention network (EAN).', 'Unlike most of previous works, EAN uses a combination of a word encoder and a Pinyin character encoder instead of a single encoder.', 'It improves the capability of Chinese text representation.', 'Moreover, compared with the hybrid encoder methods, EAN has more complex combination architecture and more reducing parameters structures.', 'Thus, EAN can take advantage of a large amount of information that comes from multi-inputs and alleviates efficiency issues.', 'The proposed model achieves the state of the art results on 5 large datasets for Chinese text classification.']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.21621620655059814, 0.43478259444236755, 0.307692289352417, 0.1818181723356247, 0.277777761220932, 0.17777776718139648, 0.1304347813129425, 0.17777776718139648]",H1xtU6VtwH,"['We propose a novel attention networks with the hybird encoder to solve the text representation issue of Chinese text classification, especially the language phenomena about pronunciations such as the polyphone and the homophone.', 'This paper proposes an attention-based model consisting of the word encoder and Pinyin encoder for the Chinese text classification task, and extends the architecture for the Pinyin character encoder.', 'Proposal for an attention network where both word and pinyin are considered for Chinese representation, with improved results shown in several datasets for text classification.']","['chinese text classification received attention today ', 'however  problem chinese text representation still hinders improvement chinese text classification  especially polyphone homophone social medium ', 'cope effectively  propose new structure  extractor  based attention mechanism design novel attention network named extractorattention network  ean  ', 'unlike previous work  ean us combination word encoder pinyin character encoder instead single encoder ', 'improves capability chinese text representation ', 'moreover  compared hybrid encoder method  ean complex combination architecture reducing parameter structure ', 'thus  ean take advantage large amount information come multiinputs alleviates efficiency issue ', 'proposed model achieves state art result 5 large datasets chinese text classification ']","Chinese text classification has received more and more attention today., However, the problem of Chinese text representation still hinders the improvement of Chinese text classification, especially the polyphone and the homophone in social media., To cope with it effectively, we propose a new structure, the Extractor, based on attention mechanisms and design novel attention networks named Extractor-attention network (EAN)., Unlike most of previous works, EAN uses a combination of a word encoder and a Pinyin character encoder instead of a single encoder., It improves the capability of Chinese text representation., Moreover, compared with the hybrid encoder methods, EAN has more complex combination architecture and more reducing parameters structures., Thus, EAN can take advantage of a large amount of information that comes from multi-inputs and alleviates efficiency issues., The proposed model achieves the state of the art results on 5 large datasets for Chinese text classification.",17,5.76551724137931,8.529411764705882
48,"['Recent advances in learning from demonstrations (LfD) with deep neural networks have enabled learning complex robot skills that involve high dimensional perception such as raw image inputs. \n', 'LfD algorithms generally assume learning from single task demonstrations.', 'In practice, however, it is more efficient for a teacher to demonstrate a multitude of tasks without careful task set up, labeling, and engineering.', 'Unfortunately in such cases, traditional imitation learning techniques fail to represent the multi-modal nature of the data, and often result in sub-optimal behavior.', 'In this paper we present an LfD approach for learning multiple modes of behavior from visual data.', 'Our approach is based on a stochastic deep neural network (SNN), which represents the underlying intention in the demonstration as a stochastic activation in the network.', 'We present an efficient algorithm for training SNNs, and for learning with vision inputs, we also propose an architecture that associates the intention with a stochastic attention module.\n', 'We demonstrate our method on real robot visual object reaching tasks, and show that\n', 'it can reliably learn the multiple behavior modes in the demonstration data.', 'Video results are available at https://vimeo.com/240212286/fd401241b9.']","[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]","[0.25, 0.27272728085517883, 0.0, 0.1764705777168274, 0.13333332538604736, 0.24242423474788666, 0.20512820780277252, 0.0, 0.0, 0.0]",Hk3ddfWRW,"['multi-modal imitation learning from unstructured demonstrations using stochastic neural network modeling intention. ', 'A new sampling-based approach for inference in latent variable models that applies to multi-modal imitation learning and works better than deterministic neural networks and stochastic neural networks for a real visual robotics task.', 'This paper shows how to learn several modalities using imitation learning from visual data using stochastic Neural Networks, and a method for learning from demonstrations where several modalities of the same task are given.']","['recent advance learning demonstration  lfd  deep neural network enabled learning complex robot skill involve high dimensional perception raw image input ', 'lfd algorithm generally assume learning single task demonstration ', 'practice  however  efficient teacher demonstrate multitude task without careful task set  labeling  engineering ', 'unfortunately case  traditional imitation learning technique fail represent multimodal nature data  often result suboptimal behavior ', 'paper present lfd approach learning multiple mode behavior visual data ', 'approach based stochastic deep neural network  snn   represents underlying intention demonstration stochastic activation network ', 'present efficient algorithm training snns  learning vision input  also propose architecture associate intention stochastic attention module ', 'demonstrate method real robot visual object reaching task  show', 'reliably learn multiple behavior mode demonstration data ', 'video result available http  vimeocom240212286fd401241b9 ']","Recent advances in learning from demonstrations (LfD) with deep neural networks have enabled learning complex robot skills that involve high dimensional perception such as raw image inputs. 
, LfD algorithms generally assume learning from single task demonstrations., In practice, however, it is more efficient for a teacher to demonstrate a multitude of tasks without careful task set up, labeling, and engineering., Unfortunately in such cases, traditional imitation learning techniques fail to represent the multi-modal nature of the data, and often result in sub-optimal behavior., In this paper we present an LfD approach for learning multiple modes of behavior from visual data., Our approach is based on a stochastic deep neural network (SNN), which represents the underlying intention in the demonstration as a stochastic activation in the network., We present an efficient algorithm for training SNNs, and for learning with vision inputs, we also propose an architecture that associates the intention with a stochastic attention module.
, We demonstrate our method on real robot visual object reaching tasks, and show that
, it can reliably learn the multiple behavior modes in the demonstration data., Video results are available at https://vimeo.com/240212286/fd401241b9.",20,5.774193548387097,9.3
49,"['The interpretability of neural networks has become crucial for their applications in real world with respect to the reliability and trustworthiness.', 'Existing explanation generation methods usually provide important features by scoring their individual contributions to the model prediction and ignore the interactions between features, which eventually provide a bag-of-words representation as explanation.', 'In natural language processing, this type of explanations is challenging for human user to understand the meaning of an explanation and draw the connection between explanation and model prediction, especially for long texts.', 'In this work, we focus on detecting the interactions between features, and propose a novel approach to build a hierarchy of explanations based on feature interactions.', 'The proposed method is evaluated with three neural classifiers, LSTM, CNN, and BERT, on two benchmark text classification datasets.', 'The generated explanations are assessed by both automatic evaluation measurements and human evaluators.', 'Experiments show the effectiveness of the proposed method in providing explanations that are both faithful to models, and understandable to humans.']","[0, 0, 0, 1, 0, 0, 0]","[0.11428570747375488, 0.1428571343421936, 0.1428571343421936, 0.37837836146354675, 0.12121211737394333, 0.14814814925193787, 0.12121211737394333]",S1xD6xHKDr,"['A novel approach to construct hierarchical explanations for text classification by detecting feature interactions.', 'A novel method for providing explanations for predicitions made by text classifiers that outperforms baselines on word level importance scores, and a new metric, cohesion loss, to evaluate span-level importance.', 'An interpretation method based on feature interactions and feature importance score as compared to independent feature contributions.']","['interpretability neural network become crucial application real world respect reliability trustworthiness ', 'existing explanation generation method usually provide important feature scoring individual contribution model prediction ignore interaction feature  eventually provide bagofwords representation explanation ', 'natural language processing  type explanation challenging human user understand meaning explanation draw connection explanation model prediction  especially long text ', 'work  focus detecting interaction feature  propose novel approach build hierarchy explanation based feature interaction ', 'proposed method evaluated three neural classifier  lstm  cnn  bert  two benchmark text classification datasets ', 'generated explanation assessed automatic evaluation measurement human evaluator ', 'experiment show effectiveness proposed method providing explanation faithful model  understandable human ']","The interpretability of neural networks has become crucial for their applications in real world with respect to the reliability and trustworthiness., Existing explanation generation methods usually provide important features by scoring their individual contributions to the model prediction and ignore the interactions between features, which eventually provide a bag-of-words representation as explanation., In natural language processing, this type of explanations is challenging for human user to understand the meaning of an explanation and draw the connection between explanation and model prediction, especially for long texts., In this work, we focus on detecting the interactions between features, and propose a novel approach to build a hierarchy of explanations based on feature interactions., The proposed method is evaluated with three neural classifiers, LSTM, CNN, and BERT, on two benchmark text classification datasets., The generated explanations are assessed by both automatic evaluation measurements and human evaluators., Experiments show the effectiveness of the proposed method in providing explanations that are both faithful to models, and understandable to humans.",17,6.158536585365853,9.647058823529411
50,"['Making deep convolutional neural networks more accurate typically comes at the cost of increased computational and memory resources.', 'In this paper, we reduce this cost by exploiting the fact that the importance of features computed by convolutional layers is highly input-dependent, and propose feature boosting and suppression (FBS), a new method to predictively amplify salient convolutional channels and skip unimportant ones at run-time.', 'FBS introduces small auxiliary connections to existing convolutional layers.', 'In contrast to channel pruning methods which permanently remove channels, it preserves the full network structures and accelerates convolution by dynamically skipping unimportant input and output channels.', 'FBS-augmented networks are trained with conventional stochastic gradient descent, making it readily available for many state-of-the-art CNNs.', 'We compare FBS to a range of existing channel pruning and dynamic execution schemes and demonstrate large improvements on ImageNet classification.', 'Experiments show that FBS can respectively provide 5 and 2 savings in compute on VGG-16 and ResNet-18, both with less than 0.6% top-5 accuracy loss.']","[0, 1, 0, 0, 0, 0, 0]","[0.12121211737394333, 0.25925925374031067, 0.1666666567325592, 0.19512194395065308, 0.0, 0.11428570747375488, 0.09999999403953552]",BJxh2j0qYm,"['We make convolutional layers run faster by dynamically boosting and suppressing channels in feature computation.', 'A feature boosting and suppression method for dynamic channel pruning that predicts the importance of each channel and then uses an affine function to amplify/suppress channel importance.', 'Proposal for a channel pruning method for dynamically selecting channels during testing.']","['making deep convolutional neural network accurate typically come cost increased computational memory resource ', 'paper  reduce cost exploiting fact importance feature computed convolutional layer highly inputdependent  propose feature boosting suppression  fbs   new method predictively amplify salient convolutional channel skip unimportant one runtime ', 'fbs introduces small auxiliary connection existing convolutional layer ', 'contrast channel pruning method permanently remove channel  preserve full network structure accelerates convolution dynamically skipping unimportant input output channel ', 'fbsaugmented network trained conventional stochastic gradient descent  making readily available many stateoftheart cnns ', 'compare fbs range existing channel pruning dynamic execution scheme demonstrate large improvement imagenet classification ', 'experiment show fbs respectively provide 5 2 saving compute vgg16 resnet18  le 06  top5 accuracy loss ']","Making deep convolutional neural networks more accurate typically comes at the cost of increased computational and memory resources., In this paper, we reduce this cost by exploiting the fact that the importance of features computed by convolutional layers is highly input-dependent, and propose feature boosting and suppression (FBS), a new method to predictively amplify salient convolutional channels and skip unimportant ones at run-time., FBS introduces small auxiliary connections to existing convolutional layers., In contrast to channel pruning methods which permanently remove channels, it preserves the full network structures and accelerates convolution by dynamically skipping unimportant input and output channels., FBS-augmented networks are trained with conventional stochastic gradient descent, making it readily available for many state-of-the-art CNNs., We compare FBS to a range of existing channel pruning and dynamic execution schemes and demonstrate large improvements on ImageNet classification., Experiments show that FBS can respectively provide 5 and 2 savings in compute on VGG-16 and ResNet-18, both with less than 0.6% top-5 accuracy loss.",13,6.154320987654321,12.461538461538462
51,"['We propose a novel way of reducing the number of parameters in the storage-hungry fully connected layers of a neural network by using pre-defined sparsity, where the majority of connections are absent prior to starting training.', 'Our results indicate that convolutional neural networks can operate without any loss of accuracy at less than 0.5% classification layer connection density, or less than 5% overall network connection density.', 'We also investigate the effects of pre-defining the sparsity of networks with only fully connected layers.', ""Based on our sparsifying technique, we introduce the `scatter' metric to characterize the quality of a particular connection pattern."", 'As proof of concept, we show results on CIFAR, MNIST and a new dataset on classifying Morse code symbols, which highlights some interesting trends and limits of sparse connection patterns.']","[0, 1, 0, 0, 0]","[0.0952380895614624, 0.1538461446762085, 0.07692307233810425, 0.06666666269302368, 0.05128204822540283]",BJgPCveAW,"['Neural networks can be pre-defined to have sparse connectivity without performance degradation.', 'This paper examines sparse connection patterns in upper layers of convolutional image classification networks, and introduces heuristics for distributing connections among windows/groups and a measure called scatter to construct connectivity masks.', 'Proposal to reduce the number of parameters learned by a deep network by setting up sparse connection weights in classiication layers, and introduction of a concept of ""scatter.""']","['propose novel way reducing number parameter storagehungry fully connected layer neural network using predefined sparsity  majority connection absent prior starting training ', 'result indicate convolutional neural network operate without loss accuracy le 05  classification layer connection density  le 5  overall network connection density ', 'also investigate effect predefining sparsity network fully connected layer ', 'based sparsifying technique  introduce  scatter  metric characterize quality particular connection pattern ', 'proof concept  show result cifar  mnist new dataset classifying morse code symbol  highlight interesting trend limit sparse connection pattern ']","We propose a novel way of reducing the number of parameters in the storage-hungry fully connected layers of a neural network by using pre-defined sparsity, where the majority of connections are absent prior to starting training., Our results indicate that convolutional neural networks can operate without any loss of accuracy at less than 0.5% classification layer connection density, or less than 5% overall network connection density., We also investigate the effects of pre-defining the sparsity of networks with only fully connected layers., Based on our sparsifying technique, we introduce the `scatter' metric to characterize the quality of a particular connection pattern., As proof of concept, we show results on CIFAR, MNIST and a new dataset on classifying Morse code symbols, which highlights some interesting trends and limits of sparse connection patterns.",11,5.572519083969466,11.909090909090908
52,"['Deep neural networks are vulnerable to adversarial examples, which becomes one of the most important problems in the development of deep learning.', 'While a lot of efforts have been made in recent years, it is of great significance to perform correct and complete evaluations of the adversarial attack and defense algorithms.', 'In this paper, we establish a comprehensive, rigorous, and coherent benchmark to evaluate adversarial robustness on image classification tasks.', 'After briefly reviewing plenty of representative attack and defense methods, we perform large-scale experiments with two robustness curves as the fair-minded evaluation criteria to fully understand the performance of these methods.', 'Based on the evaluation results, we draw several important findings and provide insights for future research.']","[0, 0, 1, 0, 0]","[0.277777761220932, 0.2380952388048172, 0.5714285373687744, 0.17777776718139648, 0.1249999925494194]",BygWBRNtvH,"['We provide a comprehensive, rigorous, and coherent benchmark to evaluate adversarial robustness of deep learning models.', 'This paper presents an evaluation of different kinds of classification models under various adversarial attack methods.', 'A large-scale empirical study comparing different adversarial attack and defense techniques, and use of accuracy vs. perturbation budget and accuracy vs. attack strength curves to evaluate attacks and defenses.']","['deep neural network vulnerable adversarial example  becomes one important problem development deep learning ', 'lot effort made recent year  great significance perform correct complete evaluation adversarial attack defense algorithm ', 'paper  establish comprehensive  rigorous  coherent benchmark evaluate adversarial robustness image classification task ', 'briefly reviewing plenty representative attack defense method  perform largescale experiment two robustness curve fairminded evaluation criterion fully understand performance method ', 'based evaluation result  draw several important finding provide insight future research ']","Deep neural networks are vulnerable to adversarial examples, which becomes one of the most important problems in the development of deep learning., While a lot of efforts have been made in recent years, it is of great significance to perform correct and complete evaluations of the adversarial attack and defense algorithms., In this paper, we establish a comprehensive, rigorous, and coherent benchmark to evaluate adversarial robustness on image classification tasks., After briefly reviewing plenty of representative attack and defense methods, we perform large-scale experiments with two robustness curves as the fair-minded evaluation criteria to fully understand the performance of these methods., Based on the evaluation results, we draw several important findings and provide insights for future research.",12,5.863247863247863,9.75
53,"['We propose a modification to traditional Artificial Neural Networks (ANNs), which provides the ANNs with new aptitudes motivated by biological neurons.  ', 'Biological neurons work far beyond linearly summing up synaptic inputs and then transforming the integrated information.  ', 'A biological neuron change firing modes accordingly to peripheral factors (e.g., neuromodulators) as well as intrinsic ones.  ', 'Our modification connects a new type of ANN nodes, which mimic the function of biological neuromodulators and are termed modulators, to enable other traditional ANN nodes to adjust their activation sensitivities in run-time based on their input patterns.  ', 'In this manner, we enable the slope of the activation function to be context dependent.  ', 'This modification produces statistically significant improvements in comparison with traditional ANN nodes in the context of Convolutional Neural Networks and Long Short-Term Memory networks.']","[1, 0, 0, 0, 0, 0]","[0.5909090638160706, 0.10256409645080566, 0.04878048226237297, 0.31578946113586426, 0.4864864945411682, 0.31111109256744385]",rylWVnR5YQ,"['We propose a modification to traditional Artificial Neural Networks motivated by the biology of neurons to enable the shape of the activation function to be context dependent.', 'A method to scale the activations of a layer of neurons in an ANN depending on inputs to that layer that reports improvements above the baselines.', 'Introduction of an architectural change for basic neurons in a neural network, and the idea to multiply neuron linear combination output by a modulator prior to feeding it into the activation function.']","['propose modification traditional artificial neural network  anns   provides anns new aptitude motivated biological neuron ', 'biological neuron work far beyond linearly summing synaptic input transforming integrated information ', 'biological neuron change firing mode accordingly peripheral factor  eg  neuromodulators  well intrinsic one ', 'modification connects new type ann node  mimic function biological neuromodulators termed modulators  enable traditional ann node adjust activation sensitivity runtime based input pattern ', 'manner  enable slope activation function context dependent ', 'modification produce statistically significant improvement comparison traditional ann node context convolutional neural network long shortterm memory network ']","We propose a modification to traditional Artificial Neural Networks (ANNs), which provides the ANNs with new aptitudes motivated by biological neurons.  , Biological neurons work far beyond linearly summing up synaptic inputs and then transforming the integrated information.  , A biological neuron change firing modes accordingly to peripheral factors (e.g., neuromodulators) as well as intrinsic ones.  , Our modification connects a new type of ANN nodes, which mimic the function of biological neuromodulators and are termed modulators, to enable other traditional ANN nodes to adjust their activation sensitivities in run-time based on their input patterns.  , In this manner, we enable the slope of the activation function to be context dependent.  , This modification produces statistically significant improvements in comparison with traditional ANN nodes in the context of Convolutional Neural Networks and Long Short-Term Memory networks.",11,6.083969465648855,11.909090909090908
54,"['In this work, we study how the large-scale pretrain-finetune framework changes the behavior of a neural language generator.', 'We focus on the transformer encoder-decoder model for the open-domain dialogue response generation task.', 'We find that after standard fine-tuning, the model forgets important language generation skills acquired during large-scale pre-training.', 'We demonstrate the forgetting phenomenon through a detailed behavior analysis from the perspectives of context sensitivity and knowledge transfer.', 'Adopting the concept of data mixing, we propose an intuitive fine-tuning strategy named ""mix-review\'\'.', 'We find that mix-review effectively regularize the fine-tuning process, and the forgetting problem is largely alleviated.', 'Finally, we discuss interesting behavior of the resulting dialogue model and its implications.\n']","[0, 0, 0, 0, 0, 1, 0]","[0.11428570747375488, 0.12903225421905518, 0.11428570747375488, 0.277777761220932, 0.3125, 0.42424240708351135, 0.1875]",r1lUE04YPB,"['We identify the forgetting problem in fine-tuning of pre-trained NLG models, and propose the mix-review strategy to address it.', 'This paper analyzes the forgetting problem in the pretraining-finetuning framework from the perspective of context sensitivity and knowledge transfer, and proposes a fine-tuning strategy which outperforms the weight decay method.', 'Study of the forgetting problem in the pretrain-finetune framework, specifically in dialogue response generation tasks, and proposal of a mix-review strategy to alleviate the forgetting issue.']","['work  study largescale pretrainfinetune framework change behavior neural language generator ', 'focus transformer encoderdecoder model opendomain dialogue response generation task ', 'find standard finetuning  model forgets important language generation skill acquired largescale pretraining ', 'demonstrate forgetting phenomenon detailed behavior analysis perspective context sensitivity knowledge transfer ', 'adopting concept data mixing  propose intuitive finetuning strategy named  mixreview  ', 'find mixreview effectively regularize finetuning process  forgetting problem largely alleviated ', 'finally  discus interesting behavior resulting dialogue model implication ']","In this work, we study how the large-scale pretrain-finetune framework changes the behavior of a neural language generator., We focus on the transformer encoder-decoder model for the open-domain dialogue response generation task., We find that after standard fine-tuning, the model forgets important language generation skills acquired during large-scale pre-training., We demonstrate the forgetting phenomenon through a detailed behavior analysis from the perspectives of context sensitivity and knowledge transfer., Adopting the concept of data mixing, we propose an intuitive fine-tuning strategy named ""mix-review''., We find that mix-review effectively regularize the fine-tuning process, and the forgetting problem is largely alleviated., Finally, we discuss interesting behavior of the resulting dialogue model and its implications.
",12,6.468468468468468,9.25
55,"['Combining domain knowledge models with neural models has been challenging.  ', 'End-to-end trained neural models often perform better (lower Mean Square Error) than domain knowledge models or domain/neural combinations, and the combination is inefficient to train.  ', 'In this paper, we demonstrate that by composing domain models with machine learning models, by using extrapolative testing sets, and invoking decorrelation objective functions, we create models which can predict more complex systems.', 'The models are interpretable, extrapolative, data-efficient, and capture predictable but complex non-stochastic behavior such as unmodeled degrees of freedom and systemic measurement noise.  ', 'We apply this improved modeling paradigm to several simulated systems and an actual physical system in the context of system identification.   ', 'Several ways of composing domain models with neural models are examined for time series, boosting, bagging, and auto-encoding on various systems of varying complexity and non-linearity.  ', 'Although this work is preliminary, we show that the ability to combine models is a very promising direction for neural modeling.']","[0, 0, 1, 0, 0, 0, 0]","[0.0, 0.04651162400841713, 0.2083333283662796, 0.1463414579629898, 0.20512819290161133, 0.1428571343421936, 0.052631575614213943]",rygfC0VKPS,"['Improved modeling of complex systems uses hybrid neural/domain model composition, new decorrelation loss functions and extrapolative test sets ', 'This paper conducts experiments to compare the extrapolative predictions of various hybrid models which compose physical models, neural networks and stochastic models, and tackles the challenge of unmodeled dynamics being a bottleneck.', 'This paper presents approaches for combining neural network with non-NN models to predict behavior of complex physical systems.']","['combining domain knowledge model neural model challenging ', 'endtoend trained neural model often perform better  lower mean square error  domain knowledge model domainneural combination  combination inefficient train ', 'paper  demonstrate composing domain model machine learning model  using extrapolative testing set  invoking decorrelation objective function  create model predict complex system ', 'model interpretable  extrapolative  dataefficient  capture predictable complex nonstochastic behavior unmodeled degree freedom systemic measurement noise ', 'apply improved modeling paradigm several simulated system actual physical system context system identification ', 'several way composing domain model neural model examined time series  boosting  bagging  autoencoding various system varying complexity nonlinearity ', 'although work preliminary  show ability combine model promising direction neural modeling ']","Combining domain knowledge models with neural models has been challenging.  , End-to-end trained neural models often perform better (lower Mean Square Error) than domain knowledge models or domain/neural combinations, and the combination is inefficient to train.  , In this paper, we demonstrate that by composing domain models with machine learning models, by using extrapolative testing sets, and invoking decorrelation objective functions, we create models which can predict more complex systems., The models are interpretable, extrapolative, data-efficient, and capture predictable but complex non-stochastic behavior such as unmodeled degrees of freedom and systemic measurement noise.  , We apply this improved modeling paradigm to several simulated systems and an actual physical system in the context of system identification.   , Several ways of composing domain models with neural models are examined for time series, boosting, bagging, and auto-encoding on various systems of varying complexity and non-linearity.  , Although this work is preliminary, we show that the ability to combine models is a very promising direction for neural modeling.",19,6.09433962264151,8.368421052631579
56,"['Humans can learn task-agnostic priors from interactive experience and utilize the priors for novel tasks without any finetuning.', 'In this paper, we propose Scoring-Aggregating-Planning (SAP), a framework that can learn task-agnostic semantics and dynamics priors from arbitrary quality interactions as well as the corresponding sparse rewards and then plan on unseen tasks in zero-shot condition.', 'The framework finds a neural score function for local regional state and action pairs that can be aggregated to approximate the quality of a full trajectory; moreover, a dynamics model that is learned with self-supervision can be incorporated for planning.', 'Many of previous works that leverage interactive data for policy learning either need massive on-policy environmental interactions or assume access to expert data while we can achieve a similar goal with pure off-policy imperfect data.', 'Instantiating our framework results in a generalizable policy to unseen tasks.', 'Experiments demonstrate that the proposed method can outperform baseline methods on a wide range of applications including gridworld, robotics tasks and video games.']","[0, 1, 0, 0, 0, 0]","[0.24390242993831635, 0.37288135290145874, 0.17241378128528595, 0.14035087823867798, 0.2857142686843872, 0.12765957415103912]",HyeuP2EtDB,"['We learn dense scores and dynamics model as priors from exploration data and use them to induce a good policy in new tasks in zero-shot condition.', 'This paper discusses zero shot generalization into new environments, and proposes an approach with results on Grid-World, Super Mario Bros, and 3D Robotics.', 'A method aiming to learn task-agnostic priors for zero-shot generalization, with the idea to employ a modeling approach on top of the model-based RL framework.']","['human learn taskagnostic prior interactive experience utilize prior novel task without finetuning ', 'paper  propose scoringaggregatingplanning  sap   framework learn taskagnostic semantics dynamic prior arbitrary quality interaction well corresponding sparse reward plan unseen task zeroshot condition ', 'framework find neural score function local regional state action pair aggregated approximate quality full trajectory  moreover  dynamic model learned selfsupervision incorporated planning ', 'many previous work leverage interactive data policy learning either need massive onpolicy environmental interaction assume access expert data achieve similar goal pure offpolicy imperfect data ', 'instantiating framework result generalizable policy unseen task ', 'experiment demonstrate proposed method outperform baseline method wide range application including gridworld  robotics task video game ']","Humans can learn task-agnostic priors from interactive experience and utilize the priors for novel tasks without any finetuning., In this paper, we propose Scoring-Aggregating-Planning (SAP), a framework that can learn task-agnostic semantics and dynamics priors from arbitrary quality interactions as well as the corresponding sparse rewards and then plan on unseen tasks in zero-shot condition., The framework finds a neural score function for local regional state and action pairs that can be aggregated to approximate the quality of a full trajectory; moreover, a dynamics model that is learned with self-supervision can be incorporated for planning., Many of previous works that leverage interactive data for policy learning either need massive on-policy environmental interactions or assume access to expert data while we can achieve a similar goal with pure off-policy imperfect data., Instantiating our framework results in a generalizable policy to unseen tasks., Experiments demonstrate that the proposed method can outperform baseline methods on a wide range of applications including gridworld, robotics tasks and video games.",10,5.890243902439025,16.4
57,"['Particle-based inference algorithm is a promising method to efficiently generate samples for an intractable target distribution by iteratively updating a set of particles.', 'As a noticeable example, Stein variational gradient descent (SVGD) provides a deterministic and computationally efficient update, but it is known to underestimate the variance in high dimensions, the mechanism of which is poorly understood.', ""In this work we explore a connection between SVGD and MMD-based inference algorithm via Stein's lemma."", 'By comparing the two update rules, we identify the source of bias in SVGD as a combination of high variance and deterministic bias, and empirically demonstrate that the removal of either factors leads to accurate estimation of the variance.', 'In addition, for learning high-dimensional Gaussian target, we analytically derive the converged variance for both algorithms, and confirm that only SVGD suffers from the ""curse of dimensionality"".']","[0, 0, 0, 1, 0]","[0.060606054961681366, 0.2380952388048172, 0.07407406717538834, 0.2857142686843872, 0.2222222238779068]",Byg9KJn4Fr,['Analyze the underlying mechanisms of variance collapse of SVGD in high dimensions.'],"['particlebased inference algorithm promising method efficiently generate sample intractable target distribution iteratively updating set particle ', 'noticeable example  stein variational gradient descent  svgd  provides deterministic computationally efficient update  known underestimate variance high dimension  mechanism poorly understood ', 'work explore connection svgd mmdbased inference algorithm via stein lemma ', 'comparing two update rule  identify source bias svgd combination high variance deterministic bias  empirically demonstrate removal either factor lead accurate estimation variance ', 'addition  learning highdimensional gaussian target  analytically derive converged variance algorithm  confirm svgd suffers  curse dimensionality  ']","Particle-based inference algorithm is a promising method to efficiently generate samples for an intractable target distribution by iteratively updating a set of particles., As a noticeable example, Stein variational gradient descent (SVGD) provides a deterministic and computationally efficient update, but it is known to underestimate the variance in high dimensions, the mechanism of which is poorly understood., In this work we explore a connection between SVGD and MMD-based inference algorithm via Stein's lemma., By comparing the two update rules, we identify the source of bias in SVGD as a combination of high variance and deterministic bias, and empirically demonstrate that the removal of either factors leads to accurate estimation of the variance., In addition, for learning high-dimensional Gaussian target, we analytically derive the converged variance for both algorithms, and confirm that only SVGD suffers from the ""curse of dimensionality"".",13,5.81294964028777,10.692307692307692
58,"['We describe an approach to understand the peculiar and counterintuitive generalization properties of deep neural networks.  ', 'The approach involves going beyond worst-case theoretical capacity control frameworks that have been popular in machine learning in recent years to revisit old ideas in the statistical mechanics of neural networks.  ', 'Within this approach, we present a prototypical Very Simple Deep Learning (VSDL) model, whose behavior is controlled by two control parameters, one describing an effective amount of data, or load, on the network (that decreases when noise is added to the input), and one with an effective temperature interpretation (that increases when algorithms are early stopped).  ', 'Using this model, we describe how a very simple application of ideas from the statistical mechanics theory of generalization provides a strong qualitative description of recently-observed empirical results regarding the inability of deep neural networks not to overfit training data, discontinuous learning and sharp transitions in the generalization properties of learning algorithms, etc.']","[0, 1, 0, 0]","[0.13333332538604736, 0.1860465109348297, 0.0634920597076416, 0.17543859779834747]",SkPoRg10b,"['Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior', 'The authors suggest that statistical mechanics ideas will help to understand generalization properties of deep neural networks, and give an approach that provides strong qualitative descriptions of empirical results regarding deep neural networks and learning algorithms.', 'A set of ideas related to theoretical understanding generalization properties of multilayer neural networks, and a qualitative analogy between behaviours in deep learning and results from quantitative statistical physics analysis of single and two-layer neural networks.']","['describe approach understand peculiar counterintuitive generalization property deep neural network ', 'approach involves going beyond worstcase theoretical capacity control framework popular machine learning recent year revisit old idea statistical mechanic neural network ', 'within approach  present prototypical simple deep learning  vsdl  model  whose behavior controlled two control parameter  one describing effective amount data  load  network  decrease noise added input   one effective temperature interpretation  increase algorithm early stopped  ', 'using model  describe simple application idea statistical mechanic theory generalization provides strong qualitative description recentlyobserved empirical result regarding inability deep neural network overfit training data  discontinuous learning sharp transition generalization property learning algorithm  etc ']","We describe an approach to understand the peculiar and counterintuitive generalization properties of deep neural networks.  , The approach involves going beyond worst-case theoretical capacity control frameworks that have been popular in machine learning in recent years to revisit old ideas in the statistical mechanics of neural networks.  , Within this approach, we present a prototypical Very Simple Deep Learning (VSDL) model, whose behavior is controlled by two control parameters, one describing an effective amount of data, or load, on the network (that decreases when noise is added to the input), and one with an effective temperature interpretation (that increases when algorithms are early stopped).  , Using this model, we describe how a very simple application of ideas from the statistical mechanics theory of generalization provides a strong qualitative description of recently-observed empirical results regarding the inability of deep neural networks not to overfit training data, discontinuous learning and sharp transitions in the generalization properties of learning algorithms, etc.",13,5.9743589743589745,12.0
59,"['Computations for the softmax function in neural network models are expensive when the number of output classes is large.', 'This can become a significant issue in both training and inference for such models.', 'In this paper, we present Doubly Sparse Softmax (DS-Softmax), Sparse Mixture of Sparse of Sparse Experts, to improve the efficiency for softmax inference.', 'During training, our method learns a two-level class hierarchy by dividing entire output class space into several partially overlapping experts.', 'Each expert is responsible for a learned subset of the output class space and each output class only belongs to a small number of those experts.', 'During inference, our method quickly locates the most probable expert to compute small-scale softmax.', 'Our method is learning-based and requires no knowledge of the output class partition space a priori.', 'We empirically evaluate our method on several real-world tasks and demonstrate that we can achieve significant computation reductions without loss of performance.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.20512819290161133, 0.11428570747375488, 0.44999998807907104, 0.14999999105930328, 0.1860465109348297, 0.17142856121063232, 0.10810810327529907, 0.09302324801683426]",rJl2E3AcF7,"['We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. ', 'This paper proposes a fast approximation to the softmax computation when the number of classes is very large.', 'This paper proposes a sparse mixture of sparse experts that learns a two-level class hierarchy for efficient softmax inference.']","['computation softmax function neural network model expensive number output class large ', 'become significant issue training inference model ', 'paper  present doubly sparse softmax  dssoftmax   sparse mixture sparse sparse expert  improve efficiency softmax inference ', 'training  method learns twolevel class hierarchy dividing entire output class space several partially overlapping expert ', 'expert responsible learned subset output class space output class belongs small number expert ', 'inference  method quickly locates probable expert compute smallscale softmax ', 'method learningbased requires knowledge output class partition space priori ', 'empirically evaluate method several realworld task demonstrate achieve significant computation reduction without loss performance ']","Computations for the softmax function in neural network models are expensive when the number of output classes is large., This can become a significant issue in both training and inference for such models., In this paper, we present Doubly Sparse Softmax (DS-Softmax), Sparse Mixture of Sparse of Sparse Experts, to improve the efficiency for softmax inference., During training, our method learns a two-level class hierarchy by dividing entire output class space into several partially overlapping experts., Each expert is responsible for a learned subset of the output class space and each output class only belongs to a small number of those experts., During inference, our method quickly locates the most probable expert to compute small-scale softmax., Our method is learning-based and requires no knowledge of the output class partition space a priori., We empirically evaluate our method on several real-world tasks and demonstrate that we can achieve significant computation reductions without loss of performance.",13,5.564935064935065,11.846153846153847
60,"['Supervised machine learning models for high-value computer vision applications such as medical image classification often require large datasets labeled by domain experts, which are slow to collect, expensive to maintain, and static with respect to changes in the data distribution.', 'In this context, we assess the utility of observational supervision, where we take advantage of passively-collected signals such as eye tracking or gaze data, to reduce the amount of hand-labeled data needed for model training.', 'Specifically, we leverage gaze information to directly supervise a visual attention layer by penalizing disagreement between the spatial regions the human labeler looked at the longest and those that most heavily influence model output.', 'We present evidence that constraining the model in this way can reduce the number of labeled examples required to achieve a given performance level by as much as 50%, and that gaze information is most helpful on more difficult tasks.']","[0, 1, 0, 0]","[0.14814814925193787, 0.3404255211353302, 0.0833333283662796, 0.22641508281230927]",r1gPtjcH_N,"['We explore using passively collected eye-tracking data to reduce the amount of labeled data needed during training.', 'A method to use gaze information to reduce the sample complexity of a model and the needed labeling effort to get a target performance, with improved results in middle-sized samples and harder tasks.', ""A method to incorporate gaze signals into standard CNNs for image classification, adding a loss function term based in the difference between the model's Class Activation Map and the map constructed from eye tracking information.""]","['supervised machine learning model highvalue computer vision application medical image classification often require large datasets labeled domain expert  slow collect  expensive maintain  static respect change data distribution ', 'context  ass utility observational supervision  take advantage passivelycollected signal eye tracking  gaze  data  reduce amount handlabeled data needed model training ', 'specifically  leverage gaze information directly supervise visual attention layer penalizing disagreement spatial region human labeler looked longest heavily influence model output ', 'present evidence constraining model way reduce number labeled example required achieve given performance level much 50   gaze information helpful difficult task ']","Supervised machine learning models for high-value computer vision applications such as medical image classification often require large datasets labeled by domain experts, which are slow to collect, expensive to maintain, and static with respect to changes in the data distribution., In this context, we assess the utility of observational supervision, where we take advantage of passively-collected signals such as eye tracking or gaze data, to reduce the amount of hand-labeled data needed for model training., Specifically, we leverage gaze information to directly supervise a visual attention layer by penalizing disagreement between the spatial regions the human labeler looked at the longest and those that most heavily influence model output., We present evidence that constraining the model in this way can reduce the number of labeled examples required to achieve a given performance level by as much as 50%, and that gaze information is most helpful on more difficult tasks.",12,5.550335570469799,12.416666666666666
61,"['We study the robustness to symmetric label noise of GNNs training procedures.', 'By combining the nonlinear neural message-passing models (e.g. Graph Isomorphism Networks, GraphSAGE, etc.) with loss correction methods, we present a noise-tolerant approach for the graph classification task.', 'Our experiments show that test accuracy can be improved under the artificial symmetric noisy setting.']","[0, 1, 0]","[0.23076923191547394, 0.2380952388048172, 0.0]",r1xOmNmxuN,"['We apply loss correction to graph neural networks to train a more robust to noise model.', 'This paper introduces loss correction for Graph Neural Networks to deal with symmetric graph label noise, focused on a graph classification task.', 'This paper proposes the use of a noise correction loss in the context of graph neural networks to deal with noisy labels.']","['study robustness symmetric label noise gnns training procedure ', 'combining nonlinear neural messagepassing model  eg  graph isomorphism network  graphsage  etc   loss correction method  present noisetolerant approach graph classification task ', 'experiment show test accuracy improved artificial symmetric noisy setting ']","We study the robustness to symmetric label noise of GNNs training procedures., By combining the nonlinear neural message-passing models (e.g. Graph Isomorphism Networks, GraphSAGE, etc.) with loss correction methods, we present a noise-tolerant approach for the graph classification task., Our experiments show that test accuracy can be improved under the artificial symmetric noisy setting.",6,6.166666666666667,6.75
62,"['Through many recent advances in graph representation learning, performance achieved on tasks involving graph-structured data has substantially increased in recent years---mostly on tasks involving node-level predictions.', 'The setup of prediction tasks over entire graphs (such as property prediction for a molecule, or side-effect prediction for a drug), however, proves to be more challenging, as the algorithm must combine evidence about several structurally relevant patches of the graph into a single prediction.\n', 'Most prior work attempts to predict these graph-level properties while considering only one graph at a time---not allowing the learner to directly leverage structural similarities and motifs across graphs.', 'Here we propose a setup in which a graph neural network receives pairs of graphs at once, and extend it with a co-attentional layer that allows node representations to easily exchange structural information across them.', 'We first show that such a setup provides natural benefits on a pairwise graph classification task (drug-drug interaction prediction), and then expand to a more generic graph regression setup: enhancing predictions over QM9, a standard molecular prediction benchmark.', 'Our setup is flexible, powerful and makes no assumptions about the underlying dataset properties, beyond anticipating the existence of multiple training graphs.']","[0, 0, 0, 0, 1, 0]","[0.11764705181121826, 0.11999999731779099, 0.1463414579629898, 0.17391304671764374, 0.25531914830207825, 0.11764705181121826]",BJeRykBKDH,"['We use graph co-attention in a paired graph training system for graph classification and regression.', 'This paper injects a multi-head co-attention mechanism in GCN that allows one drug to attend to another drug during drug side effect prediction.', 'A method to extend graph-based learning with a co-attentional layer, which outperforms other previous ones on a pairwise graph classification task.']","['many recent advance graph representation learning  performance achieved task involving graphstructured data substantially increased recent year  mostly task involving nodelevel prediction ', 'setup prediction task entire graph  property prediction molecule  sideeffect prediction drug   however  prof challenging  algorithm must combine evidence several structurally relevant patch graph single prediction ', 'prior work attempt predict graphlevel property considering one graph time  allowing learner directly leverage structural similarity motif across graph ', 'propose setup graph neural network receives pair graph  extend coattentional layer allows node representation easily exchange structural information across ', 'first show setup provides natural benefit pairwise graph classification task  drugdrug interaction prediction   expand generic graph regression setup  enhancing prediction qm9  standard molecular prediction benchmark ', 'setup flexible  powerful make assumption underlying dataset property  beyond anticipating existence multiple training graph ']","Through many recent advances in graph representation learning, performance achieved on tasks involving graph-structured data has substantially increased in recent years---mostly on tasks involving node-level predictions., The setup of prediction tasks over entire graphs (such as property prediction for a molecule, or side-effect prediction for a drug), however, proves to be more challenging, as the algorithm must combine evidence about several structurally relevant patches of the graph into a single prediction.
, Most prior work attempts to predict these graph-level properties while considering only one graph at a time---not allowing the learner to directly leverage structural similarities and motifs across graphs., Here we propose a setup in which a graph neural network receives pairs of graphs at once, and extend it with a co-attentional layer that allows node representations to easily exchange structural information across them., We first show that such a setup provides natural benefits on a pairwise graph classification task (drug-drug interaction prediction), and then expand to a more generic graph regression setup: enhancing predictions over QM9, a standard molecular prediction benchmark., Our setup is flexible, powerful and makes no assumptions about the underlying dataset properties, beyond anticipating the existence of multiple training graphs.",16,5.9743589743589745,12.1875
63,"['In this paper we study image captioning as a conditional GAN training, proposing both a context-aware LSTM captioner and co-attentive discriminator, which enforces semantic alignment between images and captions.', 'We investigate the viability of two discrete GAN training methods: Self-critical Sequence Training (SCST) and Gumbel Straight-Through (ST) and demonstrate that SCST shows more stable gradient behavior and improved results over Gumbel ST.']","[1, 0]","[0.2790697515010834, 0.17391303181648254]",rkepX8LFuE,"['Image captioning as a conditional GAN training with novel architectures, also study two discrete GAN training methods. ', 'An improved GAN model for image captioning that proposes a context-aware LSTM captioner, introduces a stronger co-attentive discriminator with better performance, and uses SCST for GAN training.']","['paper study image captioning conditional gan training  proposing contextaware lstm captioner coattentive discriminator  enforces semantic alignment image caption ', 'investigate viability two discrete gan training method  selfcritical sequence training  scst  gumbel straightthrough  st  demonstrate scst show stable gradient behavior improved result gumbel st ']","In this paper we study image captioning as a conditional GAN training, proposing both a context-aware LSTM captioner and co-attentive discriminator, which enforces semantic alignment between images and captions., We investigate the viability of two discrete GAN training methods: Self-critical Sequence Training (SCST) and Gumbel Straight-Through (ST) and demonstrate that SCST shows more stable gradient behavior and improved results over Gumbel ST.",4,6.225806451612903,15.5
64,"['We present Newtonian Monte Carlo (NMC), a method to improve Markov Chain Monte Carlo (MCMC) convergence by analyzing the first and second order gradients of the target density to determine a suitable proposal density at each point.', 'Existing first order gradient-based methods suffer from the problem of determining an appropriate step size.', 'Too small a step size and it will take a large number of steps to converge, while a very large step size will cause it to overshoot the high density region.', 'NMC is similar to the Newton-Raphson update in optimization where the second order gradient is used to automatically scale the step size in each dimension.', 'However, our objective is not to find a maxima but instead to find a parameterized density that can best match the local curvature of the target density.  ', 'This parameterized density is then used as a single-site Metropolis-Hastings proposal.\n\n', ""As a further improvement on first order methods, we show that random variables with constrained supports don't need to be transformed before taking a gradient step."", 'NMC directly matches constrained random variables to a proposal density with the same support thus keeping the curvature of the target density intact.\n\n', 'We demonstrate the efficiency of NMC on a number of different domains.', 'For statistical models where the prior is conjugate to the likelihood, our method recovers the posterior quite trivially in one step.', 'However, we also show results on fairly large non-conjugate models, where NMC performs better than adaptive first order methods such as NUTS or other inexact scalable inference methods such as Stochastic Variational Inference or bootstrapping.\n']","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.13636362552642822, 0.2142857164144516, 0.1666666567325592, 0.12121211737394333, 0.2222222238779068, 0.0, 0.052631575614213943, 0.23529411852359772, 0.1666666567325592, 0.1249999925494194, 0.08888888359069824]",SklKcJ3EFH,['Exploit curvature to make MCMC methods converge faster than state of the art.'],"['present newtonian monte carlo  nmc   method improve markov chain monte carlo  mcmc  convergence analyzing first second order gradient target density determine suitable proposal density point ', 'existing first order gradientbased method suffer problem determining appropriate step size ', 'small step size take large number step converge  large step size cause overshoot high density region ', 'nmc similar newtonraphson update optimization second order gradient used automatically scale step size dimension ', 'however  objective find maximum instead find parameterized density best match local curvature target density ', 'parameterized density used singlesite metropolishastings proposal ', 'improvement first order method  show random variable constrained support nt need transformed taking gradient step ', 'nmc directly match constrained random variable proposal density support thus keeping curvature target density intact ', 'demonstrate efficiency nmc number different domain ', 'statistical model prior conjugate likelihood  method recovers posterior quite trivially one step ', 'however  also show result fairly large nonconjugate model  nmc performs better adaptive first order method nut inexact scalable inference method stochastic variational inference bootstrapping ']","We present Newtonian Monte Carlo (NMC), a method to improve Markov Chain Monte Carlo (MCMC) convergence by analyzing the first and second order gradients of the target density to determine a suitable proposal density at each point., Existing first order gradient-based methods suffer from the problem of determining an appropriate step size., Too small a step size and it will take a large number of steps to converge, while a very large step size will cause it to overshoot the high density region., NMC is similar to the Newton-Raphson update in optimization where the second order gradient is used to automatically scale the step size in each dimension., However, our objective is not to find a maxima but instead to find a parameterized density that can best match the local curvature of the target density.  , This parameterized density is then used as a single-site Metropolis-Hastings proposal.

, As a further improvement on first order methods, we show that random variables with constrained supports don't need to be transformed before taking a gradient step., NMC directly matches constrained random variables to a proposal density with the same support thus keeping the curvature of the target density intact.

, We demonstrate the efficiency of NMC on a number of different domains., For statistical models where the prior is conjugate to the likelihood, our method recovers the posterior quite trivially in one step., However, we also show results on fairly large non-conjugate models, where NMC performs better than adaptive first order methods such as NUTS or other inexact scalable inference methods such as Stochastic Variational Inference or bootstrapping.
",18,5.285171102661597,14.61111111111111
65,"['Neural Tangents is a library designed to enable research into infinite-width neural networks.', 'It provides a high-level API for specifying complex and hierarchical neural network architectures.', 'These networks can then be trained and evaluated either at finite-width as usual or in their infinite-width limit.', 'Infinite-width networks can be trained analytically using exact Bayesian inference or using gradient descent via the Neural Tangent Kernel.', 'Additionally, Neural Tangents provides tools to study gradient descent training dynamics of wide but finite networks in either function space or weight space. \n\n', 'The entire library runs out-of-the-box on CPU, GPU, or TPU.', 'All computations can be automatically distributed over multiple accelerators with near-linear scaling in the number of devices.', ' \n\nNeural Tangents is available', 'at\nhttps://www.github.com/google/neural-tangents\n\n', 'We also provide an accompanying interactive Colab notebook at\n', 'https://colab.sandbox.google.com/github/google/neural-tangents/blob/master/notebooks/neural_tangents_cookbook.ipynb']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.2222222238779068, 0.2222222238779068, 0.08695651590824127, 0.08695651590824127, 0.0714285671710968, 0.0, 0.0, 0.0, 0.0]",rkxi9J3VKS,['Keras for infinite neural networks.'],"['neural tangent library designed enable research infinitewidth neural network ', 'provides highlevel api specifying complex hierarchical neural network architecture ', 'network trained evaluated either finitewidth usual infinitewidth limit ', 'infinitewidth network trained analytically using exact bayesian inference using gradient descent via neural tangent kernel ', 'additionally  neural tangent provides tool study gradient descent training dynamic wide finite network either function space weight space ', 'entire library run outofthebox cpu  gpu  tpu ', 'computation automatically distributed multiple accelerator nearlinear scaling number device ', 'neural tangent available', 'http  wwwgithubcomgoogleneuraltangents', 'also provide accompanying interactive colab notebook', 'http  colabsandboxgooglecomgithubgoogleneuraltangentsblobmasternotebooksneuraltangentscookbookipynb']","Neural Tangents is a library designed to enable research into infinite-width neural networks., It provides a high-level API for specifying complex and hierarchical neural network architectures., These networks can then be trained and evaluated either at finite-width as usual or in their infinite-width limit., Infinite-width networks can be trained analytically using exact Bayesian inference or using gradient descent via the Neural Tangent Kernel., Additionally, Neural Tangents provides tools to study gradient descent training dynamics of wide but finite networks in either function space or weight space. 

, The entire library runs out-of-the-box on CPU, GPU, or TPU., All computations can be automatically distributed over multiple accelerators with near-linear scaling in the number of devices.,  

Neural Tangents is available, at
https://www.github.com/google/neural-tangents

, We also provide an accompanying interactive Colab notebook at
, https://colab.sandbox.google.com/github/google/neural-tangents/blob/master/notebooks/neural_tangents_cookbook.ipynb",14,7.124031007751938,9.214285714285714
66,"['Deep neural networks have achieved great success in classication tasks during the last years.', 'However, one major problem to the path towards articial intelligence is the inability of neural networks to accurately detect samples from novel class distributions and therefore, most of the existent classication algorithms assume that all classes are known prior to the training stage.', 'In this work, we propose a methodology for training a neural network that allows it to efciently detect out-of-distribution (OOD) examples without compromising much of its classication accuracy on the test examples from known classes.', 'Based on the Outlier Exposure (OE) technique, we propose a novel loss function that achieves state-of-the-art results in out-of-distribution detection with OE both on image and text classication tasks.', 'Additionally, the way this method was constructed makes it suitable for training any classication algorithm that is based on Maximum Likelihood methods.']","[0, 0, 0, 1, 0]","[0.1621621549129486, 0.13333332538604736, 0.2142857164144516, 0.8627451062202454, 0.13333332538604736]",Hyez1CVYvr,"['We propose a novel loss function that achieves state-of-the-art results in out-of-distribution detection with Outlier Exposure both on image and text classication tasks.', 'This paper tackles the problems of out-of-distribution detection and model calibration by adapting the loss function of the Outlier Exposure technique, with results demonstrating increased performance over OE on vision and text benchmarks and improved model calibration.', 'Proposal for a new loss function to train the network with Outlier Exposure which leads to better OOD detection compared to simple loss functions using KL divergence.']","['deep neural network achieved great success classication task last year ', 'however  one major problem path towards articial intelligence inability neural network accurately detect sample novel class distribution therefore  existent classication algorithm assume class known prior training stage ', 'work  propose methodology training neural network allows efciently detect outofdistribution  ood  example without compromising much classication accuracy test example known class ', 'based outlier exposure  oe  technique  propose novel loss function achieves stateoftheart result outofdistribution detection oe image text classication task ', 'additionally  way method constructed make suitable training classication algorithm based maximum likelihood method ']","Deep neural networks have achieved great success in classication tasks during the last years., However, one major problem to the path towards articial intelligence is the inability of neural networks to accurately detect samples from novel class distributions and therefore, most of the existent classication algorithms assume that all classes are known prior to the training stage., In this work, we propose a methodology for training a neural network that allows it to efciently detect out-of-distribution (OOD) examples without compromising much of its classication accuracy on the test examples from known classes., Based on the Outlier Exposure (OE) technique, we propose a novel loss function that achieves state-of-the-art results in out-of-distribution detection with OE both on image and text classication tasks., Additionally, the way this method was constructed makes it suitable for training any classication algorithm that is based on Maximum Likelihood methods.",10,5.811188811188811,14.3
67,"['Navigation is crucial for animal behavior and is assumed to require an internal representation of the external environment, termed a cognitive map.', 'The precise form of this representation is often considered to be a metric representation of space.', 'An internal representation, however, is judged by its contribution to performance on a given task, and may thus vary between different types of navigation tasks.', 'Here we train a recurrent neural network that controls an agent performing several navigation tasks in a simple environment.', ""To focus on internal representations, we split learning into a task-agnostic pre-training stage that modifies internal connectivity and a task-specific Q learning stage that controls the network's output."", 'We show that pre-training shapes the attractor landscape of the networks, leading to either a continuous attractor, discrete attractors or a disordered state.', 'These structures induce bias onto the Q-Learning phase, leading to a performance pattern across the tasks corresponding to metric and topological regularities.', 'Our results show that, in recurrent networks, inductive bias takes the form of attractor landscapes -- which can be shaped by pre-training and analyzed using dynamical systems methods.', 'Furthermore, we demonstrate that non-metric representations are useful for navigation tasks.  ']","[0, 0, 0, 0, 0, 0, 0, 1, 0]","[0.10526315122842789, 0.06451612710952759, 0.1904761791229248, 0.11428570747375488, 0.09999999403953552, 0.10526315122842789, 0.1621621549129486, 0.31111109256744385, 0.20689654350280762]",Byx4NkrtDS,"[""Task agnostic pre-training can shape RNN's attractor landscape, and form diverse inductive bias for different navigation tasks   "", 'This paper studies the internal representations of recurrent neural networks trained on navigation tasks, and finds that RNNs pre-trained to use path integration contain 2D continuous attractors while RNNs pre-trained for landmark memory contain discrete attractors.', 'This paper explores how pre-training recurrent networks on different navigational objectives confers different benefits for solving downstream tasks, and shows how different pretraining manifests as different dynamical structures in the networks after pre-training.']","['navigation crucial animal behavior assumed require internal representation external environment  termed cognitive map ', 'precise form representation often considered metric representation space ', 'internal representation  however  judged contribution performance given task  may thus vary different type navigation task ', 'train recurrent neural network control agent performing several navigation task simple environment ', 'focus internal representation  split learning taskagnostic pretraining stage modifies internal connectivity taskspecific q learning stage control network output ', 'show pretraining shape attractor landscape network  leading either continuous attractor  discrete attractor disordered state ', 'structure induce bias onto qlearning phase  leading performance pattern across task corresponding metric topological regularity ', 'result show  recurrent network  inductive bias take form attractor landscape  shaped pretraining analyzed using dynamical system method ', 'furthermore  demonstrate nonmetric representation useful navigation task ']","Navigation is crucial for animal behavior and is assumed to require an internal representation of the external environment, termed a cognitive map., The precise form of this representation is often considered to be a metric representation of space., An internal representation, however, is judged by its contribution to performance on a given task, and may thus vary between different types of navigation tasks., Here we train a recurrent neural network that controls an agent performing several navigation tasks in a simple environment., To focus on internal representations, we split learning into a task-agnostic pre-training stage that modifies internal connectivity and a task-specific Q learning stage that controls the network's output., We show that pre-training shapes the attractor landscape of the networks, leading to either a continuous attractor, discrete attractors or a disordered state., These structures induce bias onto the Q-Learning phase, leading to a performance pattern across the tasks corresponding to metric and topological regularities., Our results show that, in recurrent networks, inductive bias takes the form of attractor landscapes -- which can be shaped by pre-training and analyzed using dynamical systems methods., Furthermore, we demonstrate that non-metric representations are useful for navigation tasks.  ",20,5.835051546391752,9.7
68,"['Formal verification of machine learning models has attracted attention recently, and significant progress has been made on proving simple properties like robustness to small perturbations of the input features.', 'In this context, it has also been observed that folding the verification procedure into training makes it easier to train verifiably robust models.', 'In this paper, we extend the applicability of verified training by extending it to (1) recurrent neural network architectures and (2) complex specifications that go beyond simple adversarial robustness, particularly specifications that capture temporal properties like requiring that a robot periodically visits a charging station or that a language model always produces sentences of bounded length.', 'Experiments show that while models trained using standard training often violate desired specifications, our verified training method produces models that both perform well (in terms of test error or reward) and can be shown to be provably consistent with specifications.']","[1, 0, 0, 0]","[0.054054051637649536, 0.0, 0.03389830142259598, 0.043478257954120636]",BklC2RNKDS,"['Neural Network Verification for Temporal Properties and Sequence Generation Models', 'This paper extends interval bound propagation to recurrent computation and auto-regressive models, introduces and extends Signal Temporal Logic for specifying temporal contraints, and provides proof that STL with bound propagation can ensure neural models conform to temporal specification.', 'A way to train time-series regressors verifiably with respect to a set of rules defined by signal temporal logic, and work in deriving bound propagation rules for the STL language.']","['formal verification machine learning model attracted attention recently  significant progress made proving simple property like robustness small perturbation input feature ', 'context  also observed folding verification procedure training make easier train verifiably robust model ', 'paper  extend applicability verified training extending  1  recurrent neural network architecture  2  complex specification go beyond simple adversarial robustness  particularly specification capture temporal property like requiring robot periodically visit charging station language model always produce sentence bounded length ', 'experiment show model trained using standard training often violate desired specification  verified training method produce model perform well  term test error reward  shown provably consistent specification ']","Formal verification of machine learning models has attracted attention recently, and significant progress has been made on proving simple properties like robustness to small perturbations of the input features., In this context, it has also been observed that folding the verification procedure into training makes it easier to train verifiably robust models., In this paper, we extend the applicability of verified training by extending it to (1) recurrent neural network architectures and (2) complex specifications that go beyond simple adversarial robustness, particularly specifications that capture temporal properties like requiring that a robot periodically visits a charging station or that a language model always produces sentences of bounded length., Experiments show that while models trained using standard training often violate desired specifications, our verified training method produces models that both perform well (in terms of test error or reward) and can be shown to be provably consistent with specifications.",9,5.9391891891891895,16.444444444444443
69,"['Neural Network (NN) has achieved state-of-the-art performances in many tasks within image, speech, and text domains.', 'Such great success is mainly due to special structure design to fit the particular data patterns, such as CNN capturing spatial locality and RNN modeling sequential dependency.', 'Essentially, these specific NNs achieve good performance by leveraging the prior knowledge over corresponding domain data.', 'Nevertheless, there are many applications with all kinds of tabular data in other domains.', 'Since there are no shared patterns among these diverse tabular data, it is hard to design specific structures to fit them all.', 'Without careful architecture design based on domain knowledge, it is quite challenging for NN to reach satisfactory performance in these tabular data domains.', 'To fill the gap of NN in tabular data learning, we propose a universal neural network solution, called TabNN, to derive effective NN architectures for tabular data in all kinds of tasks automatically.', 'Specifically, the design of TabNN follows two principles: \\emph{to explicitly leverages expressive feature combinations} and \\emph{to reduce model complexity}.', 'Since GBDT has empirically proven its strength in modeling tabular data, we use GBDT to power the implementation of TabNN.', 'Comprehensive experimental analysis on a variety of tabular datasets demonstrate that TabNN can achieve much better performance than many baseline solutions.']","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.0, 0.0952380895614624, 0.0624999962747097, 0.13333332538604736, 0.10810810327529907, 0.25641024112701416, 0.6363636255264282, 0.0, 0.11428570747375488, 0.10810810327529907]",r1eJssCqY7,"['We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.', 'A new Neural Network training procedure, designed for tabular data, that seeks to leverage feature clusters extracted from GBDTs.', 'Proposal for a hybrid machine learning algorithm using Gradient Boosted Decision Trees and Deep Neural Networks, with intended research direction on tabular data.']","['neural network  nn  achieved stateoftheart performance many task within image  speech  text domain ', 'great success mainly due special structure design fit particular data pattern  cnn capturing spatial locality rnn modeling sequential dependency ', 'essentially  specific nns achieve good performance leveraging prior knowledge corresponding domain data ', 'nevertheless  many application kind tabular data domain ', 'since shared pattern among diverse tabular data  hard design specific structure fit ', 'without careful architecture design based domain knowledge  quite challenging nn reach satisfactory performance tabular data domain ', 'fill gap nn tabular data learning  propose universal neural network solution  called tabnn  derive effective nn architecture tabular data kind task automatically ', 'specifically  design tabnn follows two principle  emph  explicitly leverage expressive feature combination  emph  reduce model complexity  ', 'since gbdt empirically proven strength modeling tabular data  use gbdt power implementation tabnn ', 'comprehensive experimental analysis variety tabular datasets demonstrate tabnn achieve much better performance many baseline solution ']","Neural Network (NN) has achieved state-of-the-art performances in many tasks within image, speech, and text domains., Such great success is mainly due to special structure design to fit the particular data patterns, such as CNN capturing spatial locality and RNN modeling sequential dependency., Essentially, these specific NNs achieve good performance by leveraging the prior knowledge over corresponding domain data., Nevertheless, there are many applications with all kinds of tabular data in other domains., Since there are no shared patterns among these diverse tabular data, it is hard to design specific structures to fit them all., Without careful architecture design based on domain knowledge, it is quite challenging for NN to reach satisfactory performance in these tabular data domains., To fill the gap of NN in tabular data learning, we propose a universal neural network solution, called TabNN, to derive effective NN architectures for tabular data in all kinds of tasks automatically., Specifically, the design of TabNN follows two principles: \emph{to explicitly leverages expressive feature combinations} and \emph{to reduce model complexity}., Since GBDT has empirically proven its strength in modeling tabular data, we use GBDT to power the implementation of TabNN., Comprehensive experimental analysis on a variety of tabular datasets demonstrate that TabNN can achieve much better performance than many baseline solutions.",22,5.748815165876778,9.590909090909092
70,"['Knowledge Bases (KBs) are becoming increasingly large, sparse and probabilistic.', 'These KBs are typically used to perform query inferences and rule mining.', 'But their efficacy is only as high as their completeness.', 'Efficiently utilizing incomplete KBs remains a major challenge as the current KB completion techniques either do not take into account the inherent uncertainty associated with each KB tuple or do not scale to large KBs.\n\n', 'Probabilistic rule learning not only considers the probability of every KB tuple but also tackles the problem of KB completion in an explainable way.', 'For any given probabilistic KB, it learns probabilistic first-order rules from its relations to identify interesting patterns.', 'But, the current probabilistic rule learning techniques perform grounding to do probabilistic inference for evaluation of candidate rules.', 'It does not scale well to large KBs as the time complexity of inference using grounding is exponential over the size of the KB.', 'In this paper, we present SafeLearner -- a scalable solution to probabilistic KB completion that performs probabilistic rule learning using lifted probabilistic inference -- as faster approach instead of grounding. \n\n', 'We compared SafeLearner to the state-of-the-art probabilistic rule learner ProbFOIL+ and to its deterministic contemporary AMIE+ on standard probabilistic KBs of NELL (Never-Ending Language Learner) and Yago.', 'Our results demonstrate that SafeLearner scales as good as AMIE+ when learning simple rules and is also significantly faster than ProbFOIL+.']","[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.0, 0.0, 0.0, 0.0, 0.0714285671710968, 0.0, 0.0, 0.0714285671710968, 0.05714285373687744, 0.0, 0.0]",HkyI-5667,"['Probabilistic Rule Learning system using Lifted Inference', 'A model for probabilistic rule learning to automate the completion of probabilistic databases that uses AMIE+ and lifted inference to help computational efficiency.']","['knowledge base  kb  becoming increasingly large  sparse probabilistic ', 'kb typically used perform query inference rule mining ', 'efficacy high completeness ', 'efficiently utilizing incomplete kb remains major challenge current kb completion technique either take account inherent uncertainty associated kb tuple scale large kb ', 'probabilistic rule learning considers probability every kb tuple also tackle problem kb completion explainable way ', 'given probabilistic kb  learns probabilistic firstorder rule relation identify interesting pattern ', ' current probabilistic rule learning technique perform grounding probabilistic inference evaluation candidate rule ', 'scale well large kb time complexity inference using grounding exponential size kb ', 'paper  present safelearner  scalable solution probabilistic kb completion performs probabilistic rule learning using lifted probabilistic inference  faster approach instead grounding ', 'compared safelearner stateoftheart probabilistic rule learner probfoil deterministic contemporary amie standard probabilistic kb nell  neverending language learner  yago ', 'result demonstrate safelearner scale good amie learning simple rule also significantly faster probfoil ']","Knowledge Bases (KBs) are becoming increasingly large, sparse and probabilistic., These KBs are typically used to perform query inferences and rule mining., But their efficacy is only as high as their completeness., Efficiently utilizing incomplete KBs remains a major challenge as the current KB completion techniques either do not take into account the inherent uncertainty associated with each KB tuple or do not scale to large KBs.

, Probabilistic rule learning not only considers the probability of every KB tuple but also tackles the problem of KB completion in an explainable way., For any given probabilistic KB, it learns probabilistic first-order rules from its relations to identify interesting patterns., But, the current probabilistic rule learning techniques perform grounding to do probabilistic inference for evaluation of candidate rules., It does not scale well to large KBs as the time complexity of inference using grounding is exponential over the size of the KB., In this paper, we present SafeLearner -- a scalable solution to probabilistic KB completion that performs probabilistic rule learning using lifted probabilistic inference -- as faster approach instead of grounding. 

, We compared SafeLearner to the state-of-the-art probabilistic rule learner ProbFOIL+ and to its deterministic contemporary AMIE+ on standard probabilistic KBs of NELL (Never-Ending Language Learner) and Yago., Our results demonstrate that SafeLearner scales as good as AMIE+ when learning simple rules and is also significantly faster than ProbFOIL+.",15,5.745614035087719,15.2
71,"['Recent efforts in Dialogue State Tracking (DST) for task-oriented dialogues have progressed toward open-vocabulary or generation-based approaches where the models can generate slot value candidates from the dialogue history itself.', 'These approaches have shown good performance gain, especially in complicated dialogue domains with dynamic slot values.', 'However, they fall short in two aspects: (1) they do not allow models to explicitly learn signals across domains and slots to detect potential dependencies among \\textit{(domain, slot)} pairs; and (2) existing models follow auto-regressive approaches which incur high time cost when the dialogue evolves over multiple domains and multiple turns.', 'In this paper, we propose a novel framework of Non-Autoregressive Dialog State Tracking (NADST) which can factor in potential dependencies among domains and slots to optimize the models towards better prediction of dialogue states as a complete set rather than separate slots.', 'In particular, the non-autoregressive nature of our method not only enables decoding in parallel to significantly reduce the latency of DST for real-time dialogue response generation, but also detect dependencies among slots at token level in addition to slot and domain level.', 'Our empirical results show that our model achieves the state-of-the-art joint accuracy across all domains on the MultiWOZ 2.1 corpus, and the latency of our model is an order of magnitude lower than the previous state of the art as the dialogue history extends over time.']","[0, 0, 0, 0, 0, 1]","[0.16949151456356049, 0.0, 0.05405404791235924, 0.17391303181648254, 0.17910447716712952, 0.3235293924808502]",H1e_cC4twS,"['We propose the first non-autoregressive neural model for Dialogue State Tracking (DST), achieving the SOTA accuracy (49.04%) on MultiWOZ2.1 benchmark, and reducing inference latency by an order of magnitude.', 'A new model for the DST task that reduces inference time complexity with a non-autoregressive decoder, obtains competitive DST accuracy, and shows improvements over other baselines.', 'Proposal for a model that is capable of tracking dialogue states in a non-recursive fashion.']","['recent effort dialogue state tracking  dst  taskoriented dialogue progressed toward openvocabulary generationbased approach model generate slot value candidate dialogue history ', 'approach shown good performance gain  especially complicated dialogue domain dynamic slot value ', 'however  fall short two aspect   1  allow model explicitly learn signal across domain slot detect potential dependency among textit   domain  slot   pair   2  existing model follow autoregressive approach incur high time cost dialogue evolves multiple domain multiple turn ', 'paper  propose novel framework nonautoregressive dialog state tracking  nadst  factor potential dependency among domain slot optimize model towards better prediction dialogue state complete set rather separate slot ', 'particular  nonautoregressive nature method enables decoding parallel significantly reduce latency dst realtime dialogue response generation  also detect dependency among slot token level addition slot domain level ', 'empirical result show model achieves stateoftheart joint accuracy across domain multiwoz 21 corpus  latency model order magnitude lower previous state art dialogue history extends time ']","Recent efforts in Dialogue State Tracking (DST) for task-oriented dialogues have progressed toward open-vocabulary or generation-based approaches where the models can generate slot value candidates from the dialogue history itself., These approaches have shown good performance gain, especially in complicated dialogue domains with dynamic slot values., However, they fall short in two aspects: (1) they do not allow models to explicitly learn signals across domains and slots to detect potential dependencies among \textit{(domain, slot)} pairs; and (2) existing models follow auto-regressive approaches which incur high time cost when the dialogue evolves over multiple domains and multiple turns., In this paper, we propose a novel framework of Non-Autoregressive Dialog State Tracking (NADST) which can factor in potential dependencies among domains and slots to optimize the models towards better prediction of dialogue states as a complete set rather than separate slots., In particular, the non-autoregressive nature of our method not only enables decoding in parallel to significantly reduce the latency of DST for real-time dialogue response generation, but also detect dependencies among slots at token level in addition to slot and domain level., Our empirical results show that our model achieves the state-of-the-art joint accuracy across all domains on the MultiWOZ 2.1 corpus, and the latency of our model is an order of magnitude lower than the previous state of the art as the dialogue history extends over time.",13,5.687224669603524,17.46153846153846
72,"['The 3D-zoom operation is the positive translation of the camera in the Z-axis, perpendicular to the image plane.', 'In contrast, the optical zoom changes the focal length and the digital zoom is used to enlarge a certain region of an image to the original image size.', 'In this paper, we are the first to formulate an unsupervised 3D-zoom learning problem where images with an arbitrary zoom factor can be generated from a given single image.', 'An unsupervised framework is convenient, as it is a challenging task to obtain a 3D-zoom dataset of natural scenes due to the need for special equipment to ensure camera movement is restricted to the Z-axis.', 'Besides, the objects in the scenes should not move when being captured, which hinders the construction of a large dataset of outdoor scenes.', 'We present a novel unsupervised framework to learn how to generate arbitrarily 3D-zoomed versions of a single image, not requiring a 3D-zoom ground truth, called the Deep 3D-Zoom Net.', 'The Deep 3D-Zoom Net incorporates the following features:', '(i) transfer learning from a pre-trained disparity estimation network via a back re-projection reconstruction loss;', '(ii) a fully convolutional network architecture that models depth-image-based rendering (DIBR), taking into account high-frequency details without the need for estimating the intermediate disparity; and', '(iii) incorporating a discriminator network that acts as a no-reference penalty for unnaturally rendered areas.', 'Even though there is no baseline to fairly compare our results, our method outperforms previous novel view synthesis research in terms of realistic appearance on large camera baselines.', 'We performed extensive experiments to verify the effectiveness of our method on the KITTI and Cityscapes datasets.']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.07692307233810425, 0.060606054961681366, 0.05128204822540283, 0.05128204822540283, 0.0, 0.1621621549129486, 0.10526315122842789, 0.07999999821186066, 0.11428570747375488, 0.07999999821186066, 0.10526315122842789, 0.07407406717538834]",HylohJrKPS,"['A novel network architecture to perform Deep 3D Zoom or close-ups.', 'A method for creating a ""zoomed image"" for a given input image,and a novel back re-projection reconstruction loss that allows the network to learn underlying 3D structure and maintain a natural appearance.', 'An algorithm for synthesizing 3D-zoom behavior when the camera is moving forward, a network structure incorporating disparity estimation in a GANs framework to synthesize novel views, and a proposed new computer vision task.']","['3dzoom operation positive translation camera zaxis  perpendicular image plane ', 'contrast  optical zoom change focal length digital zoom used enlarge certain region image original image size ', 'paper  first formulate unsupervised 3dzoom learning problem image arbitrary zoom factor generated given single image ', 'unsupervised framework convenient  challenging task obtain 3dzoom dataset natural scene due need special equipment ensure camera movement restricted zaxis ', 'besides  object scene move captured  hinders construction large dataset outdoor scene ', 'present novel unsupervised framework learn generate arbitrarily 3dzoomed version single image  requiring 3dzoom ground truth  called deep 3dzoom net ', 'deep 3dzoom net incorporates following feature ', '  transfer learning pretrained disparity estimation network via back reprojection reconstruction loss ', ' ii  fully convolutional network architecture model depthimagebased rendering  dibr   taking account highfrequency detail without need estimating intermediate disparity ', ' iii  incorporating discriminator network act noreference penalty unnaturally rendered area ', 'even though baseline fairly compare result  method outperforms previous novel view synthesis research term realistic appearance large camera baseline ', 'performed extensive experiment verify effectiveness method kitti cityscape datasets ']","The 3D-zoom operation is the positive translation of the camera in the Z-axis, perpendicular to the image plane., In contrast, the optical zoom changes the focal length and the digital zoom is used to enlarge a certain region of an image to the original image size., In this paper, we are the first to formulate an unsupervised 3D-zoom learning problem where images with an arbitrary zoom factor can be generated from a given single image., An unsupervised framework is convenient, as it is a challenging task to obtain a 3D-zoom dataset of natural scenes due to the need for special equipment to ensure camera movement is restricted to the Z-axis., Besides, the objects in the scenes should not move when being captured, which hinders the construction of a large dataset of outdoor scenes., We present a novel unsupervised framework to learn how to generate arbitrarily 3D-zoomed versions of a single image, not requiring a 3D-zoom ground truth, called the Deep 3D-Zoom Net., The Deep 3D-Zoom Net incorporates the following features:, (i) transfer learning from a pre-trained disparity estimation network via a back re-projection reconstruction loss;, (ii) a fully convolutional network architecture that models depth-image-based rendering (DIBR), taking into account high-frequency details without the need for estimating the intermediate disparity; and, (iii) incorporating a discriminator network that acts as a no-reference penalty for unnaturally rendered areas., Even though there is no baseline to fairly compare our results, our method outperforms previous novel view synthesis research in terms of realistic appearance on large camera baselines., We performed extensive experiments to verify the effectiveness of our method on the KITTI and Cityscapes datasets.",22,5.485185185185185,12.272727272727273
73,"['The universal approximation theorem, in one of its most general versions, says that if we consider only continuous activation functions , then a standard feedforward neural network with one hidden layer is able to approximate any continuous multivariate function f to any given approximation threshold , if and only if  is non-polynomial.', 'In this paper, we give a direct algebraic proof of the theorem.', 'Furthermore we shall explicitly quantify the number of hidden units required for approximation.', 'Specifically, if X in R^n is compact, then a neural network with n input units, m output units, and a single hidden layer with {n+d choose d} hidden units (independent of m and ), can uniformly approximate any polynomial function f:X -> R^m whose total degree is at most d for each of its m coordinate functions.', 'In the general case that f is any continuous function, we show there exists some N in O(^{-n}) (independent of m), such that N hidden units would suffice to approximate f.', 'We also show that this uniform approximation property (UAP) still holds even under seemingly strong conditions imposed on the weights.', 'We highlight several consequences:', '(i) For any  > 0, the UAP still holds if we restrict all non-bias weights w in the last layer to satisfy |w| < .', '(ii) There exists some >0 (depending only on f and ), such that the UAP still holds if we restrict all non-bias weights w in the first layer to satisfy |w|>.', '(iii) If the non-bias weights in the first layer are *fixed* and randomly chosen from a suitable range, then the UAP holds with probability 1.']","[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]","[0.1071428507566452, 0.3333333134651184, 0.23999999463558197, 0.03333333134651184, 0.09999999403953552, 0.1249999925494194, 0.0, 0.0555555522441864, 0.0476190447807312, 0.05714285373687744]",rkevSgrtPr,"['A quantitative refinement of the universal approximation theorem via an algebraic approach.', 'The authors derive the universal approximation property proofs algebraically and assert that the results are general to other kinds of neural networks and similar learners.', ""A new proof of Leshno's version of the universal approximation property for neural networks, and new insights into the universal approximation property.""]","['universal approximation theorem  one general version  say consider continuous activation function   standard feedforward neural network one hidden layer able approximate continuous multivariate function f given approximation threshold    nonpolynomial ', 'paper  give direct algebraic proof theorem ', 'furthermore shall explicitly quantify number hidden unit required approximation ', 'specifically  x rn compact  neural network n input unit  output unit  single hidden layer  nd choose  hidden unit  independent    uniformly approximate polynomial function f  x   rm whose total degree coordinate function ', 'general case f continuous function  show exists n    n    independent   n hidden unit would suffice approximate f ', 'also show uniform approximation property  uap  still hold even seemingly strong condition imposed weight ', 'highlight several consequence ', '    0  uap still hold restrict nonbias weight w last layer satisfy w   ', ' ii  exists   0  depending f    uap still hold restrict nonbias weight w first layer satisfy w   ', ' iii  nonbias weight first layer  fixed  randomly chosen suitable range  uap hold probability 1 ']","The universal approximation theorem, in one of its most general versions, says that if we consider only continuous activation functions , then a standard feedforward neural network with one hidden layer is able to approximate any continuous multivariate function f to any given approximation threshold , if and only if  is non-polynomial., In this paper, we give a direct algebraic proof of the theorem., Furthermore we shall explicitly quantify the number of hidden units required for approximation., Specifically, if X in R^n is compact, then a neural network with n input units, m output units, and a single hidden layer with {n+d choose d} hidden units (independent of m and ), can uniformly approximate any polynomial function f:X -> R^m whose total degree is at most d for each of its m coordinate functions., In the general case that f is any continuous function, we show there exists some N in O(^{-n}) (independent of m), such that N hidden units would suffice to approximate f., We also show that this uniform approximation property (UAP) still holds even under seemingly strong conditions imposed on the weights., We highlight several consequences:, (i) For any  > 0, the UAP still holds if we restrict all non-bias weights w in the last layer to satisfy |w| < ., (ii) There exists some >0 (depending only on f and ), such that the UAP still holds if we restrict all non-bias weights w in the first layer to satisfy |w|>., (iii) If the non-bias weights in the first layer are *fixed* and randomly chosen from a suitable range, then the UAP holds with probability 1.",25,4.7463235294117645,10.88
74,"['In this paper, we design a generic framework for learning a robust text classification model that achieves accuracy comparable to standard full models under test-time\n', 'budget constraints.', 'We take a different approach from existing methods and learn to dynamically delete a large fraction of unimportant words by a low-complexity selector such that the high-complexity classifier only needs to process a small fraction of important words.', 'In addition, we propose a new data aggregation method to train the classifier, allowing it to make accurate predictions even on fragmented sequence of words.', 'Our end-to-end method achieves state-of-the-art performance while its computational complexity scales linearly with the small fraction of important words in the whole corpus.', 'Besides, a single deep neural network classifier trained by our framework can be dynamically tuned to different budget levels at inference time.']","[0, 0, 1, 0, 0, 0]","[0.21739129722118378, 0.22641508281230927, 0.260869562625885, 0.13636362552642822, 0.09090908616781235]",H1xLsjAqtX,"['Modular framework for document classification and data aggregation technique for making the framework robust to various distortion, and noise and focus only on the important words. ', 'The authors consider training a RNN-based text classification where there is a resource restriction on test-time prediction, and provide an approach using a masking mechanism to reduce words/phrases/sentences used in prediction followed by a classifier to handle those components.']","['paper  design generic framework learning robust text classification model achieves accuracy comparable standard full model testtime', 'budget constraint ', 'take different approach existing method learn dynamically delete large fraction unimportant word lowcomplexity selector highcomplexity classifier need process small fraction important word ', 'addition  propose new data aggregation method train classifier  allowing make accurate prediction even fragmented sequence word ', 'endtoend method achieves stateoftheart performance computational complexity scale linearly small fraction important word whole corpus ', 'besides  single deep neural network classifier trained framework dynamically tuned different budget level inference time ']","In this paper, we design a generic framework for learning a robust text classification model that achieves accuracy comparable to standard full models under test-time
, budget constraints., We take a different approach from existing methods and learn to dynamically delete a large fraction of unimportant words by a low-complexity selector such that the high-complexity classifier only needs to process a small fraction of important words., In addition, we propose a new data aggregation method to train the classifier, allowing it to make accurate predictions even on fragmented sequence of words., Our end-to-end method achieves state-of-the-art performance while its computational complexity scales linearly with the small fraction of important words in the whole corpus., Besides, a single deep neural network classifier trained by our framework can be dynamically tuned to different budget levels at inference time.",10,5.7481481481481485,13.5
75,"['Differentiable architecture search (DARTS) provided a fast solution in finding effective network architectures, but suffered from large memory and computing overheads in jointly training a super-net and searching for an optimal architecture.', 'In this paper, we present a novel approach, namely  Partially-Connected DARTS, by sampling a small part of super-net to reduce the redundancy in exploring the network space, thereby performing a more efficient search without comprising the performance.', 'In particular, we perform operation search in a subset of channels while bypassing the held out part in a shortcut.', 'This strategy may suffer from an undesired inconsistency on selecting the edges of super-net caused by sampling different channels.', 'We solve it by introducing  edge normalization, which adds a new set of edge-level hyper-parameters to reduce uncertainty in search.', 'Thanks to the reduced memory cost, PC-DARTS can be trained with a larger batch size and, consequently, enjoy both faster speed and higher training stability.', 'Experiment results demonstrate the effectiveness of the proposed method.', 'Specifically, we achieve an error rate of 2.57% on CIFAR10 within merely 0.1 GPU-days for architecture search, and a state-of-the-art top-1 error rate of 24.2% on ImageNet (under the mobile setting) within 3.8 GPU-days for search.', 'Our code has been made available at https://www.dropbox.com/sh/on9lg3rpx1r6dkf/AABG5mt0sMHjnEJyoRnLEYW4a?dl=0', '.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.19512194395065308, 0.1304347813129425, 0.12903225421905518, 0.0, 0.1818181723356247, 0.10526315122842789, 0.0, 0.1304347813129425, 0.0]",BJlS634tPr,"['Allowing partial channel connection in super-networks to regularize and accelerate differentiable architecture search', 'An extension of the neural architecture search method DARTS that addresses its shortcoming of immense memory cost by using a random subset of channels and a method to normalize edges.', 'This paper proposes to improve DARTS in terms of training efficiency, from large memory and computing overheads, and proposes a partially-connected DARTS with partial channel connection and edge normalization.']","['differentiable architecture search  dart  provided fast solution finding effective network architecture  suffered large memory computing overhead jointly training supernet searching optimal architecture ', 'paper  present novel approach  namely partiallyconnected dart  sampling small part supernet reduce redundancy exploring network space  thereby performing efficient search without comprising performance ', 'particular  perform operation search subset channel bypassing held part shortcut ', 'strategy may suffer undesired inconsistency selecting edge supernet caused sampling different channel ', 'solve introducing edge normalization  add new set edgelevel hyperparameters reduce uncertainty search ', 'thanks reduced memory cost  pcdarts trained larger batch size  consequently  enjoy faster speed higher training stability ', 'experiment result demonstrate effectiveness proposed method ', 'specifically  achieve error rate 257  cifar10 within merely 01 gpudays architecture search  stateoftheart top1 error rate 242  imagenet  mobile setting  within 38 gpudays search ', 'code made available http  wwwdropboxcomshon9lg3rpx1r6dkfaabg5mt0smhjnejyornleyw4a  dl0', '']","Differentiable architecture search (DARTS) provided a fast solution in finding effective network architectures, but suffered from large memory and computing overheads in jointly training a super-net and searching for an optimal architecture., In this paper, we present a novel approach, namely  Partially-Connected DARTS, by sampling a small part of super-net to reduce the redundancy in exploring the network space, thereby performing a more efficient search without comprising the performance., In particular, we perform operation search in a subset of channels while bypassing the held out part in a shortcut., This strategy may suffer from an undesired inconsistency on selecting the edges of super-net caused by sampling different channels., We solve it by introducing  edge normalization, which adds a new set of edge-level hyper-parameters to reduce uncertainty in search., Thanks to the reduced memory cost, PC-DARTS can be trained with a larger batch size and, consequently, enjoy both faster speed and higher training stability., Experiment results demonstrate the effectiveness of the proposed method., Specifically, we achieve an error rate of 2.57% on CIFAR10 within merely 0.1 GPU-days for architecture search, and a state-of-the-art top-1 error rate of 24.2% on ImageNet (under the mobile setting) within 3.8 GPU-days for search., Our code has been made available at https://www.dropbox.com/sh/on9lg3rpx1r6dkf/AABG5mt0sMHjnEJyoRnLEYW4a?dl=0, .",22,5.93719806763285,9.409090909090908
76,"['Dialogue research tends to distinguish between chit-chat and goal-oriented tasks.', 'While the former is arguably more naturalistic and has a wider use of language, the latter has clearer metrics and a more straightforward learning signal.', 'Humans effortlessly combine the two, and engage in chit-chat for example with the goal of exchanging information or eliciting a specific response.', 'Here, we bridge the divide between these two domains in the setting of a rich multi-player text-based fantasy environment where agents and humans engage in both actions and dialogue.', 'Specifically, we train a goal-oriented model with reinforcement learning via self-play against an imitation-learned chit-chat model with two new approaches: the policy either learns to pick a topic or learns to pick an utterance given the top-k utterances.', 'We show that both models outperform a strong inverse model baseline and can converse naturally with their dialogue partner in order to achieve goals.']","[0, 0, 0, 0, 0, 1]","[0.25, 0.1904761791229248, 0.2790697515010834, 0.2916666567325592, 0.19230768084526062, 0.3478260934352875]",BJxRrlBFwB,"['Agents interact (speak, act) and can achieve goals in a rich world with diverse language, bridging the gap between chit-chat and goal-oriented dialogue.', 'This paper studies a multiagent dialog task in which the learning agent aims to generate natural language actions that elicit a particular action from the other agent, and shows RL-agents can achieve higher task completion levels than imitation learning baselines.', 'This paper explores the goal-oriented dialogue setting with reinforcement learning in a Fantasy Text Adventure Game and observes that the RL approaches outperform supervised learning models.']","['dialogue research tends distinguish chitchat goaloriented task ', 'former arguably naturalistic wider use language  latter clearer metric straightforward learning signal ', 'human effortlessly combine two  engage chitchat example goal exchanging information eliciting specific response ', ' bridge divide two domain setting rich multiplayer textbased fantasy environment agent human engage action dialogue ', 'specifically  train goaloriented model reinforcement learning via selfplay imitationlearned chitchat model two new approach  policy either learns pick topic learns pick utterance given topk utterance ', 'show model outperform strong inverse model baseline converse naturally dialogue partner order achieve goal ']","Dialogue research tends to distinguish between chit-chat and goal-oriented tasks., While the former is arguably more naturalistic and has a wider use of language, the latter has clearer metrics and a more straightforward learning signal., Humans effortlessly combine the two, and engage in chit-chat for example with the goal of exchanging information or eliciting a specific response., Here, we bridge the divide between these two domains in the setting of a rich multi-player text-based fantasy environment where agents and humans engage in both actions and dialogue., Specifically, we train a goal-oriented model with reinforcement learning via self-play against an imitation-learned chit-chat model with two new approaches: the policy either learns to pick a topic or learns to pick an utterance given the top-k utterances., We show that both models outperform a strong inverse model baseline and can converse naturally with their dialogue partner in order to achieve goals.",10,5.554054054054054,14.8
77,"['We consider off-policy policy evaluation when the trajectory data are generated by multiple behavior policies.', 'Recent work has shown the key role played by the state or state-action stationary distribution corrections in the infinite horizon context for off-policy policy evaluation.', 'We propose estimated mixture policy (EMP), a novel class of partially policy-agnostic methods to accurately estimate those quantities.', 'With careful analysis, we show that EMP gives rise to estimates with reduced variance for estimating the state stationary distribution correction while it also offers a useful induction bias for estimating the state-action stationary distribution correction.', 'In extensive experiments with both continuous and discrete environments, we demonstrate that our algorithm offers significantly improved accuracy compared to the state-of-the-art methods.']","[1, 0, 0, 0, 0]","[0.3125, 0.19999998807907104, 0.17142856121063232, 0.08510638028383255, 0.04999999329447746]",rkgU1gHtvr,"['A new partially policy-agnostic method for infinite-horizon off-policy policy evalution with multiple known or unknown behavior policies.', 'An estimated mixture policy which takes ideas from off-policy policy evaluation infinite horizon estimators and regression importance sampling for importance weight, and extends them to many policies and unknown policies.', 'An algorithm to solve infinite horizon off policy evaluation with multiple behavior policies by estimating a mixed policy under regression, and theoretical proof that an estimated policy ratio can reduce variance.']","['consider offpolicy policy evaluation trajectory data generated multiple behavior policy ', 'recent work shown key role played state stateaction stationary distribution correction infinite horizon context offpolicy policy evaluation ', 'propose estimated mixture policy  emp   novel class partially policyagnostic method accurately estimate quantity ', 'careful analysis  show emp give rise estimate reduced variance estimating state stationary distribution correction also offer useful induction bias estimating stateaction stationary distribution correction ', 'extensive experiment continuous discrete environment  demonstrate algorithm offer significantly improved accuracy compared stateoftheart method ']","We consider off-policy policy evaluation when the trajectory data are generated by multiple behavior policies., Recent work has shown the key role played by the state or state-action stationary distribution corrections in the infinite horizon context for off-policy policy evaluation., We propose estimated mixture policy (EMP), a novel class of partially policy-agnostic methods to accurately estimate those quantities., With careful analysis, we show that EMP gives rise to estimates with reduced variance for estimating the state stationary distribution correction while it also offers a useful induction bias for estimating the state-action stationary distribution correction., In extensive experiments with both continuous and discrete environments, we demonstrate that our algorithm offers significantly improved accuracy compared to the state-of-the-art methods.",8,6.3760683760683765,14.625
78,"['We introduce a more efficient neural architecture for amortized inference, which combines continuous and conditional normalizing flows using a principled choice of structure.', 'Our gradient flow derives its sparsity pattern from the minimally faithful inverse of its underlying graphical model.', 'We find that this factorization reduces the necessary numbers both of parameters in the neural network and of adaptive integration steps in the ODE solver.', 'Consequently, the throughput at training time and inference time is increased, without decreasing performance in comparison to unconstrained flows.', 'By expressing the structural inversion and the flow construction as compilation passes of a probabilistic programming language, we demonstrate their applicability to the stochastic inversion of realistic models such as convolutional neural networks (CNN).']","[1, 0, 0, 0, 0]","[0.9777777791023254, 0.10256409645080566, 0.1818181723356247, 0.09756097197532654, 0.1538461446762085]",BJlhYknNFS,"['We introduce a more efficient neural architecture for amortized inference, which combines continuous and conditional normalizing flows using a principled choice of sparsity structure.']","['introduce efficient neural architecture amortized inference  combine continuous conditional normalizing flow using principled choice structure ', 'gradient flow derives sparsity pattern minimally faithful inverse underlying graphical model ', 'find factorization reduces necessary number parameter neural network adaptive integration step ode solver ', 'consequently  throughput training time inference time increased  without decreasing performance comparison unconstrained flow ', 'expressing structural inversion flow construction compilation pass probabilistic programming language  demonstrate applicability stochastic inversion realistic model convolutional neural network  cnn  ']","We introduce a more efficient neural architecture for amortized inference, which combines continuous and conditional normalizing flows using a principled choice of structure., Our gradient flow derives its sparsity pattern from the minimally faithful inverse of its underlying graphical model., We find that this factorization reduces the necessary numbers both of parameters in the neural network and of adaptive integration steps in the ODE solver., Consequently, the throughput at training time and inference time is increased, without decreasing performance in comparison to unconstrained flows., By expressing the structural inversion and the flow construction as compilation passes of a probabilistic programming language, we demonstrate their applicability to the stochastic inversion of realistic models such as convolutional neural networks (CNN).",9,6.194915254237288,13.11111111111111
79,"['We present a neural architecture search algorithm to construct compact reinforcement learning (RL) policies, by combining ENAS and ES in a highly scalable and intuitive way.', 'By defining the combinatorial search space of NAS to be the set of different edge-partitionings (colorings) into same-weight classes, we represent compact architectures via efficient learned edge-partitionings.', 'For several RL tasks, we manage to learn colorings translating to effective policies parameterized by as few as 17 weight parameters, providing >90 % compression over vanilla policies and 6x compression over state-of-the-art compact policies based on Toeplitz matrices, while still maintaining good reward.', 'We believe that our work is one of the first attempts to propose a rigorous approach to training structured neural network architectures for RL problems that are of interest especially in mobile robotics with limited storage and computational resources.']","[1, 0, 0, 0]","[0.3478260934352875, 0.04347825422883034, 0.19999998807907104, 0.3448275923728943]",S1gKkpNKwH,"['We show that ENAS with ES-optimization in RL is highly scalable, and use it to compactify neural network policies by weight sharing.', 'The authors construct reinforcement learning policies with very few parameters by compressing a feed-forward neural network, forcing it to share weights, and using a reinforcement learning method to learn the mapping of shared weights.', 'This paper combines ideas from ENAS and ES methods for optimisation, and introduces the chromatic network architecture, which partitions weights of the RL network into tied sub-groups.']","['present neural architecture search algorithm construct compact reinforcement learning  rl  policy  combining enas e highly scalable intuitive way ', 'defining combinatorial search space na set different edgepartitionings  coloring  sameweight class  represent compact architecture via efficient learned edgepartitionings ', 'several rl task  manage learn coloring translating effective policy parameterized 17 weight parameter  providing  90  compression vanilla policy 6x compression stateoftheart compact policy based toeplitz matrix  still maintaining good reward ', 'believe work one first attempt propose rigorous approach training structured neural network architecture rl problem interest especially mobile robotics limited storage computational resource ']","We present a neural architecture search algorithm to construct compact reinforcement learning (RL) policies, by combining ENAS and ES in a highly scalable and intuitive way., By defining the combinatorial search space of NAS to be the set of different edge-partitionings (colorings) into same-weight classes, we represent compact architectures via efficient learned edge-partitionings., For several RL tasks, we manage to learn colorings translating to effective policies parameterized by as few as 17 weight parameters, providing >90 % compression over vanilla policies and 6x compression over state-of-the-art compact policies based on Toeplitz matrices, while still maintaining good reward., We believe that our work is one of the first attempts to propose a rigorous approach to training structured neural network architectures for RL problems that are of interest especially in mobile robotics with limited storage and computational resources.",9,5.919117647058823,15.11111111111111
80,"['Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets.', 'Typically anomaly detection is treated as an unsupervised learning problem.', 'In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous.', 'Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples.', 'Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific.', 'In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection.', 'Using an information-theoretic perspective on anomaly detection, we derive a loss motivated by the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution.', 'We demonstrate in extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.1621621549129486, 0.13793103396892548, 0.11999999731779099, 0.1538461446762085, 0.29411762952804565, 0.4571428596973419, 0.21276594698429108, 0.24137930572032928]",HkgH0TEYwH,"['We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.', 'A new method to find anomaly data, when some labeled anomalies are given, that applies information theory-derived loss based on normal data usuallly having lower entropy than abnormal data.', 'Proposal for an abnormal detection framework under settings where unlabeled data, labeled positive data, and labeled negative data are available, and proposal to approach semi-supervised AD from an information theoretic perspective.']","['deep approach anomaly detection recently shown promising result shallow method large complex datasets ', 'typically anomaly detection treated unsupervised learning problem ', 'practice however  one may  addition large set unlabeled sample  access small pool labeled sample  eg  subset verified domain expert normal anomalous ', 'semisupervised approach anomaly detection aim utilize labeled sample  proposed method limited merely including labeled normal sample ', 'method take advantage labeled anomaly  existing deep approach domainspecific ', 'work present deep sad  endtoend deep methodology general semisupervised anomaly detection ', 'using informationtheoretic perspective anomaly detection  derive loss motivated idea entropy latent distribution normal data lower entropy anomalous distribution ', 'demonstrate extensive experiment mnist  fashionmnist  cifar10  along anomaly detection benchmark datasets  method par outperforms shallow  hybrid  deep competitor  yielding appreciable performance improvement even provided little labeled data ']","Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets., Typically anomaly detection is treated as an unsupervised learning problem., In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous., Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples., Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific., In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection., Using an information-theoretic perspective on anomaly detection, we derive a loss motivated by the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution., We demonstrate in extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.",21,5.839378238341969,8.772727272727273
81,"['To analyze deep ReLU network, we adopt a student-teacher setting in which an over-parameterized student network learns from the output of a fixed teacher network of the same depth, with Stochastic Gradient Descent (SGD).', 'Our contributions are two-fold.', 'First, we prove that when the gradient is zero (or bounded above by a small constant) at every data point in training, a situation called  \\emph{interpolation setting}, there exists many-to-one \\emph{alignment} between student and teacher nodes in the lowest layer under mild conditions.', 'This suggests that generalization in unseen dataset is achievable, even the same condition often leads to zero training error.', 'Second, analysis of noisy recovery and training dynamics in 2-layer network shows that strong teacher nodes (with large fan-out weights) are learned first and subtle teacher nodes are left unlearned until late stage of training.', 'As a result, it could take a long time to converge into these small-gradient critical points.', 'Our analysis shows that over-parameterization plays two roles: (1) it is a necessary condition for alignment to happen at the critical points, and (2) in training dynamics, it helps student nodes cover more teacher nodes with fewer iterations.', 'Both improve generalization.', 'Experiments justify our finding.']","[1, 0, 0, 0, 0, 0, 0, 0, 0]","[0.2857142686843872, 0.0, 0.10169491171836853, 0.21052631735801697, 0.25, 0.11764705181121826, 0.1818181723356247, 0.0, 0.0]",HJgcw0Etwr,"['This paper analyzes training dynamics and critical points of training deep ReLU network via SGD in the teacher-student setting. ', 'Study of over-parametrization in student-teacher multilayer ReLU networks, a theoretical part about SGD critical points for the teacher-student setting, and a heuristic and empirical part on dynamics of the SDG algorithm as a function of teacher networks.']","['analyze deep relu network  adopt studentteacher setting overparameterized student network learns output fixed teacher network depth  stochastic gradient descent  sgd  ', 'contribution twofold ', 'first  prove gradient zero  bounded small constant  every data point training  situation called emph  interpolation setting   exists manytoone emph  alignment  student teacher node lowest layer mild condition ', 'suggests generalization unseen dataset achievable  even condition often lead zero training error ', 'second  analysis noisy recovery training dynamic 2layer network show strong teacher node  large fanout weight  learned first subtle teacher node left unlearned late stage training ', 'result  could take long time converge smallgradient critical point ', 'analysis show overparameterization play two role   1  necessary condition alignment happen critical point   2  training dynamic  help student node cover teacher node fewer iteration ', 'improve generalization ', 'experiment justify finding ']","To analyze deep ReLU network, we adopt a student-teacher setting in which an over-parameterized student network learns from the output of a fixed teacher network of the same depth, with Stochastic Gradient Descent (SGD)., Our contributions are two-fold., First, we prove that when the gradient is zero (or bounded above by a small constant) at every data point in training, a situation called  \emph{interpolation setting}, there exists many-to-one \emph{alignment} between student and teacher nodes in the lowest layer under mild conditions., This suggests that generalization in unseen dataset is achievable, even the same condition often leads to zero training error., Second, analysis of noisy recovery and training dynamics in 2-layer network shows that strong teacher nodes (with large fan-out weights) are learned first and subtle teacher nodes are left unlearned until late stage of training., As a result, it could take a long time to converge into these small-gradient critical points., Our analysis shows that over-parameterization plays two roles: (1) it is a necessary condition for alignment to happen at the critical points, and (2) in training dynamics, it helps student nodes cover more teacher nodes with fewer iterations., Both improve generalization., Experiments justify our finding.",19,5.561224489795919,10.31578947368421
82,"['We study the convergence of gradient descent (GD) and stochastic gradient descent (SGD) for training $L$-hidden-layer linear residual networks (ResNets).', 'We prove that for training deep residual networks with certain linear transformations at input and output layers, which are fixed throughout training, both GD and SGD with zero initialization on all hidden weights can converge to the global minimum of the training loss.', 'Moreover, when specializing to appropriate Gaussian random linear transformations, GD and SGD provably optimize wide enough deep linear ResNets.', 'Compared with the global convergence result of GD for training standard deep linear networks \\citep{du2019width}, our condition on the neural network width is sharper by a factor of $O(\\kappa L)$, where $\\kappa$ denotes the condition number of the covariance matrix of the training data.', 'In addition, for the first time we establish the global convergence of SGD for training deep linear ResNets and prove a linear convergence rate when the global minimum is $0$.']","[0, 1, 0, 0, 0]","[0.307692289352417, 0.5, 0.3589743673801422, 0.3571428656578064, 0.4444444477558136]",HJxEhREKDH,"['Under certain condition on the input and output linear transformations, both GD and SGD can achieve global convergence for training deep linear ResNets.', 'The authors study the convergence of gradient descent in training deep linear residual networks, and establish a global convergence of GD/SGD and linear convergence rates of SG/SGD.', 'Study of convergence properties of GD and SGD on deep linear resnets, and proof that under certain conditions on the input and output transformations and with zero initialization, GD and SGD converges to global minima.']","['study convergence gradient descent  gd  stochastic gradient descent  sgd  training  l  hiddenlayer linear residual network  resnets  ', 'prove training deep residual network certain linear transformation input output layer  fixed throughout training  gd sgd zero initialization hidden weight converge global minimum training loss ', 'moreover  specializing appropriate gaussian random linear transformation  gd sgd provably optimize wide enough deep linear resnets ', 'compared global convergence result gd training standard deep linear network citep  du2019width   condition neural network width sharper factor   kappa l     kappa  denotes condition number covariance matrix training data ', 'addition  first time establish global convergence sgd training deep linear resnets prove linear convergence rate global minimum  0  ']","We study the convergence of gradient descent (GD) and stochastic gradient descent (SGD) for training $L$-hidden-layer linear residual networks (ResNets)., We prove that for training deep residual networks with certain linear transformations at input and output layers, which are fixed throughout training, both GD and SGD with zero initialization on all hidden weights can converge to the global minimum of the training loss., Moreover, when specializing to appropriate Gaussian random linear transformations, GD and SGD provably optimize wide enough deep linear ResNets., Compared with the global convergence result of GD for training standard deep linear networks \citep{du2019width}, our condition on the neural network width is sharper by a factor of $O(\kappa L)$, where $\kappa$ denotes the condition number of the covariance matrix of the training data., In addition, for the first time we establish the global convergence of SGD for training deep linear ResNets and prove a linear convergence rate when the global minimum is $0$.",12,5.583333333333333,13.0
83,"['In this paper, we empirically investigate the training journey of deep neural networks relative to fully trained shallow machine learning models.', 'We observe that the deep neural networks (DNNs) train by learning to correctly classify shallow-learnable examples in the early epochs before learning the harder examples.', 'We build on this observation this to suggest a way for partitioning the dataset into hard and easy subsets that can be used for improving the overall training process.', 'Incidentally, we also found evidence of a subset of intriguing examples across all the datasets we considered, that were shallow learnable but not deep-learnable.', 'In order to aid reproducibility, we also duly release our code for this work at https://github.com/karttikeya/Shallow_to_Deep/']","[0, 0, 1, 0, 0]","[0.21739129722118378, 0.30434781312942505, 0.31372547149658203, 0.1702127605676651, 0.0952380895614624]",HkxHv4rn24,['We analyze the training process for Deep Networks and show that they start from rapidly learning shallow classifiable examples and slowly generalize to harder data points.'],"['paper  empirically investigate training journey deep neural network relative fully trained shallow machine learning model ', 'observe deep neural network  dnns  train learning correctly classify shallowlearnable example early epoch learning harder example ', 'build observation suggest way partitioning dataset hard easy subset used improving overall training process ', 'incidentally  also found evidence subset intriguing example across datasets considered  shallow learnable deeplearnable ', 'order aid reproducibility  also duly release code work http  githubcomkarttikeyashallowtodeep']","In this paper, we empirically investigate the training journey of deep neural networks relative to fully trained shallow machine learning models., We observe that the deep neural networks (DNNs) train by learning to correctly classify shallow-learnable examples in the early epochs before learning the harder examples., We build on this observation this to suggest a way for partitioning the dataset into hard and easy subsets that can be used for improving the overall training process., Incidentally, we also found evidence of a subset of intriguing examples across all the datasets we considered, that were shallow learnable but not deep-learnable., In order to aid reproducibility, we also duly release our code for this work at https://github.com/karttikeya/Shallow_to_Deep/",9,5.71304347826087,12.777777777777779
84,"['While much recent work has targeted learning deep discrete latent variable models with variational inference, this setting remains challenging, and it is often necessary to make use of potentially high-variance gradient estimators in optimizing the ELBO.', ""As an alternative, we propose to optimize a non-ELBO objective derived from the Bethe free energy approximation to an MRF's partition function."", 'This objective gives rise to a saddle-point learning problem, which we train inference networks to approximately optimize.', 'The derived objective requires no sampling, and can be efficiently computed for many MRFs of interest.', 'We evaluate the proposed approach in learning high-order neural HMMs on text, and find that it often outperforms other approximate inference schemes in terms of true held-out log likelihood.', 'At the same time, we find that all the approximate inference-based approaches to learning high-order neural HMMs we consider underperform learning with exact inference by a significant margin.']","[0, 1, 0, 0, 0, 0]","[0.19230768084526062, 0.5, 0.1875, 0.1875, 0.045454539358615875, 0.1463414579629898]",ByeMHULt_N,"['Learning deep latent variable MRFs with a saddle-point objective derived from the Bethe partition function approximation.', 'A method for learning deep latent-variable MRF with an optimization objective that utilizes Bethe free energy, that also solves the underlying constraints of Bethe free energy optimizations.', 'An objective for learning latent variable MRFs based on Bethe free energy and amortized inference, different from optimizing the standard ELBO.']","['much recent work targeted learning deep discrete latent variable model variational inference  setting remains challenging  often necessary make use potentially highvariance gradient estimator optimizing elbo ', 'alternative  propose optimize nonelbo objective derived bethe free energy approximation mrf partition function ', 'objective give rise saddlepoint learning problem  train inference network approximately optimize ', 'derived objective requires sampling  efficiently computed many mrfs interest ', 'evaluate proposed approach learning highorder neural hmms text  find often outperforms approximate inference scheme term true heldout log likelihood ', 'time  find approximate inferencebased approach learning highorder neural hmms consider underperform learning exact inference significant margin ']","While much recent work has targeted learning deep discrete latent variable models with variational inference, this setting remains challenging, and it is often necessary to make use of potentially high-variance gradient estimators in optimizing the ELBO., As an alternative, we propose to optimize a non-ELBO objective derived from the Bethe free energy approximation to an MRF's partition function., This objective gives rise to a saddle-point learning problem, which we train inference networks to approximately optimize., The derived objective requires no sampling, and can be efficiently computed for many MRFs of interest., We evaluate the proposed approach in learning high-order neural HMMs on text, and find that it often outperforms other approximate inference schemes in terms of true held-out log likelihood., At the same time, we find that all the approximate inference-based approaches to learning high-order neural HMMs we consider underperform learning with exact inference by a significant margin.",13,5.77027027027027,11.384615384615385
85,"['In an explanation generation problem, an agent needs to identify and explain the reasons for its decisions to another agent.', 'Existing work in this area is mostly confined to planning-based systems that use automated planning approaches to solve the problem.', 'In this paper, we approach this problem from a new perspective, where we propose a general logic-based framework for explanation generation.', 'In particular, given a knowledge base $KB_1$ that entails a formula $\\phi$ and a second knowledge base $KB_2$ that does not entail $\\phi$, we seek to identify an explanation $\\epsilon$ that is a subset of $KB_1$ such that the union of $KB_2$ and $\\epsilon$ entails $\\phi$.', 'We define two types of explanations, model- and proof-theoretic explanations, and use cost functions to reflect preferences between explanations.', 'Further, we present our algorithm implemented for propositional logic that compute such explanations and empirically evaluate it in random knowledge bases and a planning domain.']","[0, 0, 1, 0, 0, 0]","[0.23999999463558197, 0.0, 0.38461539149284363, 0.05128204822540283, 0.0, 0.0624999962747097]",rJxiXT2XcV,"['A general framework for explanation generation using Logic.', 'This paper researches explanation generation from a KR point of view and conducts experiments measuring explanation size and runtime on random formulas and formulas from a Blocksworld instance.', 'This paper provides a perspective on explanations between two knowledge bases, and runs parallel to work on model reconciliation in planning literature.']","['explanation generation problem  agent need identify explain reason decision another agent ', 'existing work area mostly confined planningbased system use automated planning approach solve problem ', 'paper  approach problem new perspective  propose general logicbased framework explanation generation ', 'particular  given knowledge base  kb1  entail formula  phi  second knowledge base  kb2  entail  phi   seek identify explanation  epsilon  subset  kb1  union  kb2   epsilon  entail  phi  ', 'define two type explanation  model prooftheoretic explanation  use cost function reflect preference explanation ', ' present algorithm implemented propositional logic compute explanation empirically evaluate random knowledge base planning domain ']","In an explanation generation problem, an agent needs to identify and explain the reasons for its decisions to another agent., Existing work in this area is mostly confined to planning-based systems that use automated planning approaches to solve the problem., In this paper, we approach this problem from a new perspective, where we propose a general logic-based framework for explanation generation., In particular, given a knowledge base $KB_1$ that entails a formula $\phi$ and a second knowledge base $KB_2$ that does not entail $\phi$, we seek to identify an explanation $\epsilon$ that is a subset of $KB_1$ such that the union of $KB_2$ and $\epsilon$ entails $\phi$., We define two types of explanations, model- and proof-theoretic explanations, and use cost functions to reflect preferences between explanations., Further, we present our algorithm implemented for propositional logic that compute such explanations and empirically evaluate it in random knowledge bases and a planning domain.",14,5.543046357615894,10.785714285714286
86,"['Recent theoretical work has demonstrated that deep neural networks have superior performance over shallow networks, but their training is more difficult, e.g., they suffer from the vanishing gradient problem.', 'This problem can be typically resolved by the rectified linear unit (ReLU) activation.', 'However, here we show that even for such activation, deep and narrow neural networks (NNs) will converge to erroneous mean or median states of the target function depending on the loss with high probability.', 'Deep and narrow NNs are encountered in solving partial differential equations with high-order derivatives.', 'We demonstrate this collapse of such NNs both numerically and theoretically, and provide estimates of the probability of collapse.', 'We also construct a diagram of a safe region for designing NNs that avoid the collapse to erroneous states.', 'Finally, we examine different ways of initialization and normalization that may avoid the collapse problem.', 'Asymmetric initializations may reduce the probability of collapse but do not totally eliminate it.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.1111111044883728, 0.0555555522441864, 0.7857142686843872, 0.21621620655059814, 0.21052631735801697, 0.24390242993831635, 0.15789473056793213, 0.1621621549129486]",r1MSBjA9Ym,"['Deep and narrow neural networks will converge to erroneous mean or median states of the target function depending on the loss with high probability.', 'This paper studies failure modes of deep and narrow networks, focusing on as small as possible models for which the undesired behavior occurs.', 'This paper shows that the training of deep ReLU neural networks will converge to a constant classifier with high probability over random initialization if hidden layer widths are too small.']","['recent theoretical work demonstrated deep neural network superior performance shallow network  training difficult  eg  suffer vanishing gradient problem ', 'problem typically resolved rectified linear unit  relu  activation ', 'however  show even activation  deep narrow neural network  nns  converge erroneous mean median state target function depending loss high probability ', 'deep narrow nns encountered solving partial differential equation highorder derivative ', 'demonstrate collapse nns numerically theoretically  provide estimate probability collapse ', 'also construct diagram safe region designing nns avoid collapse erroneous state ', 'finally  examine different way initialization normalization may avoid collapse problem ', 'asymmetric initialization may reduce probability collapse totally eliminate ']","Recent theoretical work has demonstrated that deep neural networks have superior performance over shallow networks, but their training is more difficult, e.g., they suffer from the vanishing gradient problem., This problem can be typically resolved by the rectified linear unit (ReLU) activation., However, here we show that even for such activation, deep and narrow neural networks (NNs) will converge to erroneous mean or median states of the target function depending on the loss with high probability., Deep and narrow NNs are encountered in solving partial differential equations with high-order derivatives., We demonstrate this collapse of such NNs both numerically and theoretically, and provide estimates of the probability of collapse., We also construct a diagram of a safe region for designing NNs that avoid the collapse to erroneous states., Finally, we examine different ways of initialization and normalization that may avoid the collapse problem., Asymmetric initializations may reduce the probability of collapse but do not totally eliminate it.",15,5.687898089171974,10.466666666666667
87,"[""We study adversarial robustness of neural networks from a margin maximization perspective, where margins are defined as the distances from inputs to a classifier's decision boundary.\n"", 'Our study shows that maximizing margins can be achieved by minimizing the adversarial loss on the decision boundary at the ""shortest successful perturbation"", demonstrating a close connection between adversarial losses and the margins.', 'We propose Max-Margin Adversarial (MMA) training to directly maximize the margins to achieve adversarial robustness. \n', 'Instead of adversarial training with a fixed $\\epsilon$, MMA offers an improvement by enabling adaptive selection of the ""correct"" $\\epsilon$ as the margin individually for each datapoint.', 'In addition, we rigorously analyze adversarial training with the perspective of margin maximization, and provide an alternative interpretation for adversarial training, maximizing either a lower or an upper bound of the margins.', ""Our experiments empirically confirm our theory and demonstrate MMA training's efficacy on the MNIST and CIFAR10 datasets w.r.t. $\\ell_\\infty$ and $\\ell_2$ robustness.""]","[0, 0, 1, 0, 0, 0]","[0.31372547149658203, 0.14814814925193787, 0.4390243887901306, 0.3529411852359772, 0.25925925374031067, 0.1249999925494194]",HkeryxBtPB,"['We propose MMA training to directly maximize input space margin in order to improve adversarial robustness primarily by removing the requirement of specifying a fixed distortion bound.', 'An adaptive margin-based adversarial training approach to train robust DNNs, by maximizing the shortest margin of inputs to the decision boundary, that makes adversarial training with large perturbation possible.', 'A method for robust learning against adversarial attacks where the input space margin is directly maximized and a softmax variant of the max-margin is introduced.']","['study adversarial robustness neural network margin maximization perspective  margin defined distance input classifier decision boundary ', 'study show maximizing margin achieved minimizing adversarial loss decision boundary  shortest successful perturbation   demonstrating close connection adversarial loss margin ', 'propose maxmargin adversarial  mma  training directly maximize margin achieve adversarial robustness ', 'instead adversarial training fixed  epsilon   mma offer improvement enabling adaptive selection  correct   epsilon  margin individually datapoint ', 'addition  rigorously analyze adversarial training perspective margin maximization  provide alternative interpretation adversarial training  maximizing either lower upper bound margin ', 'experiment empirically confirm theory demonstrate mma training efficacy mnist cifar10 datasets wrt   ellinfty   ell2  robustness ']","We study adversarial robustness of neural networks from a margin maximization perspective, where margins are defined as the distances from inputs to a classifier's decision boundary.
, Our study shows that maximizing margins can be achieved by minimizing the adversarial loss on the decision boundary at the ""shortest successful perturbation"", demonstrating a close connection between adversarial losses and the margins., We propose Max-Margin Adversarial (MMA) training to directly maximize the margins to achieve adversarial robustness. 
, Instead of adversarial training with a fixed $\epsilon$, MMA offers an improvement by enabling adaptive selection of the ""correct"" $\epsilon$ as the margin individually for each datapoint., In addition, we rigorously analyze adversarial training with the perspective of margin maximization, and provide an alternative interpretation for adversarial training, maximizing either a lower or an upper bound of the margins., Our experiments empirically confirm our theory and demonstrate MMA training's efficacy on the MNIST and CIFAR10 datasets w.r.t. $\ell_\infty$ and $\ell_2$ robustness.",12,6.193548387096774,11.923076923076923
88,"['Many anomaly detection methods exist that perform well on low-dimensional problems however there is a notable lack of effective methods for high-dimensional spaces, such as images.', 'Inspired by recent successes in deep learning we propose a novel approach to anomaly detection using generative adversarial networks.', 'Given a sample under consideration, our method is based on searching for a good representation of that sample in the latent space of the generator; if such a representation is not found, the sample is deemed anomalous.  ', 'We achieve state-of-the-art performance on standard image benchmark datasets and visual inspection of the most anomalous samples reveals that our method does indeed return anomalies.']","[0, 0, 1, 0]","[0.1860465109348297, 0.2702702581882477, 0.3913043439388275, 0.1395348757505417]",S1EfylZ0Z,"[""We propose a method for anomaly detection with GANs by searching the generator's latent space for good sample representations."", 'The authors propose using GAN for anomaly detection, a gradient-descent based method to iteratively update latent representations, and a novel parameter update to the generators.', ""A GAN based approach to doing anomaly detection for image data where the generator's latent space is explored to find a representation for a test image.""]","['many anomaly detection method exist perform well lowdimensional problem however notable lack effective method highdimensional space  image ', 'inspired recent success deep learning propose novel approach anomaly detection using generative adversarial network ', 'given sample consideration  method based searching good representation sample latent space generator  representation found  sample deemed anomalous ', 'achieve stateoftheart performance standard image benchmark datasets visual inspection anomalous sample reveals method indeed return anomaly ']","Many anomaly detection methods exist that perform well on low-dimensional problems however there is a notable lack of effective methods for high-dimensional spaces, such as images., Inspired by recent successes in deep learning we propose a novel approach to anomaly detection using generative adversarial networks., Given a sample under consideration, our method is based on searching for a good representation of that sample in the latent space of the generator; if such a representation is not found, the sample is deemed anomalous.  , We achieve state-of-the-art performance on standard image benchmark datasets and visual inspection of the most anomalous samples reveals that our method does indeed return anomalies.",7,5.672897196261682,15.285714285714286
89,"['Variational inference (VI) and Markov chain Monte Carlo (MCMC) are approximate posterior inference algorithms that are often said to have complementary strengths, with VI being fast but biased and MCMC being slower but asymptotically unbiased.', 'In this paper, we analyze gradient-based MCMC and VI procedures and find theoretical and empirical evidence that these procedures are not as different as one might think.', 'In particular, a close examination of the Fokker-Planck equation that governs the Langevin dynamics (LD) MCMC procedure reveals that LD implicitly follows a gradient flow that corresponds to a variational inference procedure based on optimizing a nonparametric normalizing flow.', 'This result suggests that the transient bias of LD (due to too few warmup steps) may track that of VI (due to too few optimization steps), up to differences due to VIs parameterization and asymptotic bias.', 'Empirically, we find that the transient biases of these algorithms (and momentum-accelerated versions) do evolve similarly.', 'This suggests that practitioners with a limited time budget may get more accurate results by running an MCMC procedure (even if its far from burned in) than a VI procedure, as long as the variance of the MCMC estimator can be dealt with (e.g., by running many parallel chains).']","[0, 1, 0, 0, 0, 0]","[0.18518517911434174, 0.25531914830207825, 0.2181818187236786, 0.19607841968536377, 0.25, 0.1764705777168274]",HJggcy2NFS,"['The transient behavior of gradient-based MCMC and variational inference algorithms is more similar than one might think, calling into question the claim that variational inference is faster than MCMC.']","['variational inference  vi  markov chain monte carlo  mcmc  approximate posterior inference algorithm often said complementary strength  vi fast biased mcmc slower asymptotically unbiased ', 'paper  analyze gradientbased mcmc vi procedure find theoretical empirical evidence procedure different one might think ', 'particular  close examination fokkerplanck equation governs langevin dynamic  ld  mcmc procedure reveals ld implicitly follows gradient flow corresponds variational inference procedure based optimizing nonparametric normalizing flow ', 'result suggests transient bias ld  due warmup step  may track vi  due optimization step   difference due vi  parameterization asymptotic bias ', 'empirically  find transient bias algorithm  momentumaccelerated version  evolve similarly ', 'suggests practitioner limited time budget may get accurate result running mcmc procedure  even  far burned  vi procedure  long variance mcmc estimator dealt  eg  running many parallel chain  ']","Variational inference (VI) and Markov chain Monte Carlo (MCMC) are approximate posterior inference algorithms that are often said to have complementary strengths, with VI being fast but biased and MCMC being slower but asymptotically unbiased., In this paper, we analyze gradient-based MCMC and VI procedures and find theoretical and empirical evidence that these procedures are not as different as one might think., In particular, a close examination of the Fokker-Planck equation that governs the Langevin dynamics (LD) MCMC procedure reveals that LD implicitly follows a gradient flow that corresponds to a variational inference procedure based on optimizing a nonparametric normalizing flow., This result suggests that the transient bias of LD (due to too few warmup steps) may track that of VI (due to too few optimization steps), up to differences due to VIs parameterization and asymptotic bias., Empirically, we find that the transient biases of these algorithms (and momentum-accelerated versions) do evolve similarly., This suggests that practitioners with a limited time budget may get more accurate results by running an MCMC procedure (even if its far from burned in) than a VI procedure, as long as the variance of the MCMC estimator can be dealt with (e.g., by running many parallel chains).",13,5.420792079207921,15.538461538461538
90,"['Graph Convolutional Networks (GCNs) have recently been shown to be quite successful in modeling graph-structured data.', 'However, the primary focus has been on handling simple undirected graphs.', 'Multi-relational graphs are a more general and prevalent form of graphs where each edge has a label and direction associated with it.', 'Most of the existing approaches to handle such graphs suffer from over-parameterization and are restricted to learning representations of nodes only.', 'In this paper, we propose CompGCN, a novel Graph Convolutional framework which jointly embeds both nodes and relations in a relational graph.', 'CompGCN leverages a variety of entity-relation composition operations from Knowledge Graph Embedding techniques and scales with the number of relations.', 'It also generalizes several of the existing multi-relational GCN methods.', 'We evaluate our proposed method on multiple tasks such as node classification, link prediction, and graph classification, and achieve demonstrably superior results.', 'We make the source code of CompGCN available to foster reproducible research.']","[0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.1666666567325592, 0.10526315122842789, 0.07407406717538834, 0.07407406717538834, 0.20689654350280762, 0.07407406717538834, 0.1111111044883728, 0.0, 0.0]",BylA_C4tPr,"['A Composition-based Graph Convolutional framework for multi-relational graphs.', 'The authors develop GCN on multi-relational graphs and propose CompGCN, which leverages insights from knowledge graph embeddings and learns node and relation representations to alleviate the problem of over-parameterization.', 'This paper introduces a GCN framework for multi-relational graphs and generalizes several existing approaches to Knowledge Graph embedding into one framework.']","['graph convolutional network  gcns  recently shown quite successful modeling graphstructured data ', 'however  primary focus handling simple undirected graph ', 'multirelational graph general prevalent form graph edge label direction associated ', 'existing approach handle graph suffer overparameterization restricted learning representation node ', 'paper  propose compgcn  novel graph convolutional framework jointly embeds node relation relational graph ', 'compgcn leverage variety entityrelation composition operation knowledge graph embedding technique scale number relation ', 'also generalizes several existing multirelational gcn method ', 'evaluate proposed method multiple task node classification  link prediction  graph classification  achieve demonstrably superior result ', 'make source code compgcn available foster reproducible research ']","Graph Convolutional Networks (GCNs) have recently been shown to be quite successful in modeling graph-structured data., However, the primary focus has been on handling simple undirected graphs., Multi-relational graphs are a more general and prevalent form of graphs where each edge has a label and direction associated with it., Most of the existing approaches to handle such graphs suffer from over-parameterization and are restricted to learning representations of nodes only., In this paper, we propose CompGCN, a novel Graph Convolutional framework which jointly embeds both nodes and relations in a relational graph., CompGCN leverages a variety of entity-relation composition operations from Knowledge Graph Embedding techniques and scales with the number of relations., It also generalizes several of the existing multi-relational GCN methods., We evaluate our proposed method on multiple tasks such as node classification, link prediction, and graph classification, and achieve demonstrably superior results., We make the source code of CompGCN available to foster reproducible research.",15,5.9423076923076925,10.4
91,"['State-of-the-art neural machine translation methods employ massive amounts of parameters.', 'Drastically reducing computational costs of such methods without affecting performance has been up to this point unsolved.', 'In this work, we propose a quantization strategy tailored to the Transformer architecture.', 'We evaluate our method on the WMT14 EN-FR and WMT14 EN-DE translation tasks and achieve state-of-the-art quantization results for the Transformer, obtaining no loss in BLEU scores compared to the non-quantized baseline.', 'We further compress the Transformer by showing that, once the model is trained, a good portion of the nodes in the encoder can be removed without causing any loss in BLEU.']","[0, 0, 0, 1, 0]","[0.07999999821186066, 0.0624999962747097, 0.2142857164144516, 0.2790697515010834, 0.1904761791229248]",B1eYGkBKDB,"['We fully quantize the Transformer to 8-bit and improve translation quality compared to the full precision model.', 'An 8-bit quantization method to quantize the machine translation model Transformer, proposing to use uniform min-max quantization during inference and bucketing weigts before quantization to reduce quantization error.', 'A method for reducing the required memory space by a quantization technique, focused on reducing it for Transformer architecture.']","['stateoftheart neural machine translation method employ massive amount parameter ', 'drastically reducing computational cost method without affecting performance point unsolved ', 'work  propose quantization strategy tailored transformer architecture ', 'evaluate method wmt14 enfr wmt14 ende translation task achieve stateoftheart quantization result transformer  obtaining loss bleu score compared nonquantized baseline ', 'compress transformer showing  model trained  good portion node encoder removed without causing loss bleu ']","State-of-the-art neural machine translation methods employ massive amounts of parameters., Drastically reducing computational costs of such methods without affecting performance has been up to this point unsolved., In this work, we propose a quantization strategy tailored to the Transformer architecture., We evaluate our method on the WMT14 EN-FR and WMT14 EN-DE translation tasks and achieve state-of-the-art quantization results for the Transformer, obtaining no loss in BLEU scores compared to the non-quantized baseline., We further compress the Transformer by showing that, once the model is trained, a good portion of the nodes in the encoder can be removed without causing any loss in BLEU.",9,5.718446601941747,11.444444444444445
92,"['Gradient-based meta-learning techniques are both widely applicable and proficient at solving challenging few-shot learning and fast adaptation problems.', 'However, they have practical difficulties when operating on high-dimensional parameter spaces in extreme low-data regimes.', 'We show that it is possible to bypass these limitations by learning a data-dependent latent generative representation of model parameters, and performing gradient-based meta-learning in this low-dimensional latent space.', 'The resulting approach, latent embedding optimization (LEO), decouples the gradient-based adaptation procedure from the underlying high-dimensional space of model parameters.', 'Our evaluation shows that LEO can achieve state-of-the-art performance on the competitive miniImageNet and tieredImageNet few-shot classification tasks.', 'Further analysis indicates LEO is able to capture uncertainty in the data, and can perform adaptation more effectively by optimizing in latent space.']","[0, 0, 0, 0, 1, 0]","[0.09999999403953552, 0.052631575614213943, 0.15686273574829102, 0.0952380895614624, 0.4390243887901306, 0.13333332538604736]",BJgklhAcK7,"['Latent Embedding Optimization (LEO) is a novel gradient-based meta-learner with state-of-the-art performance on the challenging 5-way 1-shot and 5-shot miniImageNet and tieredImageNet classification tasks.', 'A new meta-learning framework that learns data-dependent latent space, performs fast adaptation in the latent space, is effective for few-shot learning, has task-dependent initialization for adaptation, and works well for multimodal task distribution.', 'This paper proposes a latent embedding optimization method for meta-learning, and claims the contribution is to decouple optimization-based meta-learning techniques from high-dimensional space of model parameters.']","['gradientbased metalearning technique widely applicable proficient solving challenging fewshot learning fast adaptation problem ', 'however  practical difficulty operating highdimensional parameter space extreme lowdata regime ', 'show possible bypass limitation learning datadependent latent generative representation model parameter  performing gradientbased metalearning lowdimensional latent space ', 'resulting approach  latent embedding optimization  leo   decouples gradientbased adaptation procedure underlying highdimensional space model parameter ', 'evaluation show leo achieve stateoftheart performance competitive miniimagenet tieredimagenet fewshot classification task ', 'analysis indicates leo able capture uncertainty data  perform adaptation effectively optimizing latent space ']","Gradient-based meta-learning techniques are both widely applicable and proficient at solving challenging few-shot learning and fast adaptation problems., However, they have practical difficulties when operating on high-dimensional parameter spaces in extreme low-data regimes., We show that it is possible to bypass these limitations by learning a data-dependent latent generative representation of model parameters, and performing gradient-based meta-learning in this low-dimensional latent space., The resulting approach, latent embedding optimization (LEO), decouples the gradient-based adaptation procedure from the underlying high-dimensional space of model parameters., Our evaluation shows that LEO can achieve state-of-the-art performance on the competitive miniImageNet and tieredImageNet few-shot classification tasks., Further analysis indicates LEO is able to capture uncertainty in the data, and can perform adaptation more effectively by optimizing in latent space.",11,6.8861788617886175,11.181818181818182
93,"['We introduce an approach for augmenting model-free deep reinforcement learning agents with a mechanism for relational reasoning over structured representations, which improves performance, learning efficiency, generalization, and interpretability.', 'Our architecture encodes an image as a set of vectors, and applies an iterative message-passing procedure to discover and reason about relevant entities and relations in a scene.', 'In six of seven StarCraft II Learning Environment mini-games, our agent achieved state-of-the-art performance, and surpassed human grandmaster-level on four.', ""In a novel navigation and planning task, our agent's performance and learning efficiency far exceeded non-relational baselines, it was able to generalize to more complex scenes than it had experienced during training."", ""Moreover, when we examined its learned internal representations, they reflected important structure about the problem and the agent's intentions."", 'The main contribution of this work is to introduce techniques for representing and reasoning about states in model-free deep reinforcement learning agents via relational inductive biases.', 'Our experiments show this approach can offer advantages in efficiency, generalization, and interpretability, and can scale up to meet some of the most challenging test environments in modern artificial intelligence.']","[0, 0, 0, 0, 0, 1, 0]","[0.21052631735801697, 0.0555555522441864, 0.0, 0.04878048226237297, 0.0, 0.3684210479259491, 0.05128204822540283]",HkxaFoC9KQ,"['Relational inductive biases improve out-of-distribution generalization capacities in model-free reinforcement learning agents', 'A shared relational network architecture for parameterizing the actor and critic network, focused on distributed advantage actor-critic algorithms, that enhances model-free deep reinforcement techniques with relational knowledge about the environment so agents can learn interpretable state representations.', 'A quantitative and qualitative analysis and evaluation of the self-attention mechanism combined with relation network in the context of model-free RL.']","['introduce approach augmenting modelfree deep reinforcement learning agent mechanism relational reasoning structured representation  improves performance  learning efficiency  generalization  interpretability ', 'architecture encodes image set vector  applies iterative messagepassing procedure discover reason relevant entity relation scene ', 'six seven starcraft ii learning environment minigames  agent achieved stateoftheart performance  surpassed human grandmasterlevel four ', 'novel navigation planning task  agent performance learning efficiency far exceeded nonrelational baseline  able generalize complex scene experienced training ', 'moreover  examined learned internal representation  reflected important structure problem agent intention ', 'main contribution work introduce technique representing reasoning state modelfree deep reinforcement learning agent via relational inductive bias ', 'experiment show approach offer advantage efficiency  generalization  interpretability  scale meet challenging test environment modern artificial intelligence ']","We introduce an approach for augmenting model-free deep reinforcement learning agents with a mechanism for relational reasoning over structured representations, which improves performance, learning efficiency, generalization, and interpretability., Our architecture encodes an image as a set of vectors, and applies an iterative message-passing procedure to discover and reason about relevant entities and relations in a scene., In six of seven StarCraft II Learning Environment mini-games, our agent achieved state-of-the-art performance, and surpassed human grandmaster-level on four., In a novel navigation and planning task, our agent's performance and learning efficiency far exceeded non-relational baselines, it was able to generalize to more complex scenes than it had experienced during training., Moreover, when we examined its learned internal representations, they reflected important structure about the problem and the agent's intentions., The main contribution of this work is to introduce techniques for representing and reasoning about states in model-free deep reinforcement learning agents via relational inductive biases., Our experiments show this approach can offer advantages in efficiency, generalization, and interpretability, and can scale up to meet some of the most challenging test environments in modern artificial intelligence.",21,6.316939890710382,8.714285714285714
94,"['Image translation between two domains is a class of problems aiming to learn mapping from an input image in the source domain to an output image in the target domain.', 'It has been applied to numerous applications, such as data augmentation, domain adaptation, and unsupervised training.', 'When paired training data is not accessible, image translation becomes an ill-posed problem.', 'We constrain the problem with the assumption that the translated image needs to be perceptually similar to the original image and also appears to be drawn from the new domain, and propose a simple yet effective image translation model consisting of a single generator trained with a self-regularization term and an adversarial term.', 'We further notice that existing image translation techniques are agnostic to the subjects of interest and often introduce unwanted changes or artifacts to the input.', 'Thus we propose to add an attention module to predict an attention map to guide the image translation process.', 'The module learns to attend to key parts of the image while keeping everything else unaltered, essentially avoiding undesired artifacts or changes.', 'The predicted attention map also opens door to applications such as unsupervised segmentation and saliency detection.', 'Extensive experiments and evaluations show that our model while being simpler, achieves significantly better performance than existing image translation methods.']","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.1621621549129486, 0.13793103396892548, 0.1538461446762085, 0.31372547149658203, 0.2222222238779068, 0.2142857164144516, 0.05882352590560913, 0.27586206793785095, 0.24242423474788666]",rygypo0qtm,['We propose a simple generative model for unsupervised image translation and saliency detection.'],"['image translation two domain class problem aiming learn mapping input image source domain output image target domain ', 'applied numerous application  data augmentation  domain adaptation  unsupervised training ', 'paired training data accessible  image translation becomes illposed problem ', 'constrain problem assumption translated image need perceptually similar original image also appears drawn new domain  propose simple yet effective image translation model consisting single generator trained selfregularization term adversarial term ', 'notice existing image translation technique agnostic subject interest often introduce unwanted change artifact input ', 'thus propose add attention module predict attention map guide image translation process ', 'module learns attend key part image keeping everything else unaltered  essentially avoiding undesired artifact change ', 'predicted attention map also open door application unsupervised segmentation saliency detection ', 'extensive experiment evaluation show model simpler  achieves significantly better performance existing image translation method ']","Image translation between two domains is a class of problems aiming to learn mapping from an input image in the source domain to an output image in the target domain., It has been applied to numerous applications, such as data augmentation, domain adaptation, and unsupervised training., When paired training data is not accessible, image translation becomes an ill-posed problem., We constrain the problem with the assumption that the translated image needs to be perceptually similar to the original image and also appears to be drawn from the new domain, and propose a simple yet effective image translation model consisting of a single generator trained with a self-regularization term and an adversarial term., We further notice that existing image translation techniques are agnostic to the subjects of interest and often introduce unwanted changes or artifacts to the input., Thus we propose to add an attention module to predict an attention map to guide the image translation process., The module learns to attend to key parts of the image while keeping everything else unaltered, essentially avoiding undesired artifacts or changes., The predicted attention map also opens door to applications such as unsupervised segmentation and saliency detection., Extensive experiments and evaluations show that our model while being simpler, achieves significantly better performance than existing image translation methods.",16,5.588785046728972,13.375
95,"['Building deep neural networks to control autonomous agents which have to interact in real-time with the physical world, such as robots or automotive vehicles, requires a seamless integration of time into a networks architecture.', 'The central question of this work is, how the temporal nature of reality should be reflected in the execution of a deep neural network and its components.', 'Most artificial deep neural networks are partitioned into a directed graph of connected modules or layers and the layers themselves consist of elemental building blocks, such as single units.', 'For most deep neural networks, all units of a layer are processed synchronously and in parallel, but layers themselves are processed in a sequential manner.', 'In contrast, all elements of a biological neural network are processed in parallel.', 'In this paper, we define a class of networks between these two extreme cases.', 'These networks are executed in a streaming or synchronous layerwise-parallel manner, unlocking the layers of such networks for parallel processing.', 'Compared to the standard layerwise-sequential deep networks, these new layerwise-parallel networks show a fundamentally different temporal behavior and flow of information, especially for networks with skip or recurrent connections.', 'We argue that layerwise-parallel deep networks are better suited for future challenges of deep neural network design, such as large functional modularized and/or recurrent architectures as well as networks allocating different network capacities dependent on current stimulus and/or task complexity.', 'We layout basic properties and discuss major challenges for layerwise-parallel networks.', 'Additionally, we provide a toolbox to design, train, evaluate, and online-interact with layerwise-parallel networks.']","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]","[0.3333333134651184, 0.23076923191547394, 0.2545454502105713, 0.36734694242477417, 0.19512194395065308, 0.2380952388048172, 0.25531914830207825, 0.3571428656578064, 0.22580644488334656, 0.20512820780277252, 0.4761904776096344]",SkfNU2e0Z,"['We define a concept of layerwise model-parallel deep neural networks, for which layers operate in parallel, and provide a toolbox to design, train, evaluate, and on-line interact with these networks.', 'A GPU-accelerated toolbox for parallel neuron updating, written in Theano, that supports different update orders in recurrent networks and networks with connections that skip layers. ', 'A new toolbox for deep neural networks learning and evaluation, and proposal for a paradigm switch from layerwise-sequential networks to layer-wise parallel networks.']","['building deep neural network control autonomous agent interact realtime physical world  robot automotive vehicle  requires seamless integration time network  architecture ', 'central question work  temporal nature reality reflected execution deep neural network component ', 'artificial deep neural network partitioned directed graph connected module layer layer consist elemental building block  single unit ', 'deep neural network  unit layer processed synchronously parallel  layer processed sequential manner ', 'contrast  element biological neural network processed parallel ', 'paper  define class network two extreme case ', 'network executed streaming synchronous layerwiseparallel manner  unlocking layer network parallel processing ', 'compared standard layerwisesequential deep network  new layerwiseparallel network show fundamentally different temporal behavior flow information  especially network skip recurrent connection ', 'argue layerwiseparallel deep network better suited future challenge deep neural network design  large functional modularized andor recurrent architecture well network allocating different network capacity dependent current stimulus andor task complexity ', 'layout basic property discus major challenge layerwiseparallel network ', 'additionally  provide toolbox design  train  evaluate  onlineinteract layerwiseparallel network ']","Building deep neural networks to control autonomous agents which have to interact in real-time with the physical world, such as robots or automotive vehicles, requires a seamless integration of time into a networks architecture., The central question of this work is, how the temporal nature of reality should be reflected in the execution of a deep neural network and its components., Most artificial deep neural networks are partitioned into a directed graph of connected modules or layers and the layers themselves consist of elemental building blocks, such as single units., For most deep neural networks, all units of a layer are processed synchronously and in parallel, but layers themselves are processed in a sequential manner., In contrast, all elements of a biological neural network are processed in parallel., In this paper, we define a class of networks between these two extreme cases., These networks are executed in a streaming or synchronous layerwise-parallel manner, unlocking the layers of such networks for parallel processing., Compared to the standard layerwise-sequential deep networks, these new layerwise-parallel networks show a fundamentally different temporal behavior and flow of information, especially for networks with skip or recurrent connections., We argue that layerwise-parallel deep networks are better suited for future challenges of deep neural network design, such as large functional modularized and/or recurrent architectures as well as networks allocating different network capacities dependent on current stimulus and/or task complexity., We layout basic properties and discuss major challenges for layerwise-parallel networks., Additionally, we provide a toolbox to design, train, evaluate, and online-interact with layerwise-parallel networks.",27,5.90234375,9.481481481481481
96,"['Deep neural networks are known to be vulnerable to adversarial perturbations.', 'In this paper, we bridge adversarial robustness of neural nets with Lyapunov stability of dynamical systems.', ""From this viewpoint, training neural nets is equivalent to finding an optimal control of the discrete dynamical system, which allows one to utilize methods of successive approximations, an optimal control algorithm based on Pontryagin's maximum principle, to train neural nets."", 'This decoupled training method allows us to add constraints to the optimization, which makes the deep model more robust.', 'The constrained optimization problem can be formulated as a semi-definite programming problem and hence can be solved efficiently.', ""Experiments show that our method effectively improves deep model's adversarial robustness.""]","[0, 1, 0, 0, 0, 0]","[0.17391303181648254, 0.5714285373687744, 0.13333332538604736, 0.13333332538604736, 0.0, 0.3333333432674408]",BklVA2NYvH,"['An adversarial defense method bridging robustness of deep neural nets with Lyapunov stability', 'The authors formulate training NNs as finding an optimal controller for a discrete dynamical system, allowing them to use method of successive approximations to train a NN in a way to be more robust to adversarial attacks.', 'This paper uses the theoretical view of a neural network as a discretized ODE to develop a robust control theory aimed at training the network while enforcing robustness.']","['deep neural network known vulnerable adversarial perturbation ', 'paper  bridge adversarial robustness neural net lyapunov stability dynamical system ', 'viewpoint  training neural net equivalent finding optimal control discrete dynamical system  allows one utilize method successive approximation  optimal control algorithm based pontryagin maximum principle  train neural net ', 'decoupled training method allows u add constraint optimization  make deep model robust ', 'constrained optimization problem formulated semidefinite programming problem hence solved efficiently ', 'experiment show method effectively improves deep model adversarial robustness ']","Deep neural networks are known to be vulnerable to adversarial perturbations., In this paper, we bridge adversarial robustness of neural nets with Lyapunov stability of dynamical systems., From this viewpoint, training neural nets is equivalent to finding an optimal control of the discrete dynamical system, which allows one to utilize methods of successive approximations, an optimal control algorithm based on Pontryagin's maximum principle, to train neural nets., This decoupled training method allows us to add constraints to the optimization, which makes the deep model more robust., The constrained optimization problem can be formulated as a semi-definite programming problem and hence can be solved efficiently., Experiments show that our method effectively improves deep model's adversarial robustness.",12,5.973913043478261,9.583333333333334
97,"['In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs.', 'We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field.', 'However, practically, we find that the degrees DrGCNs help vary severely on different datasets.', 'We revisit the problem and develop a new measure K to quantify the effect.', 'This measure guides when we should use dimensional reweighting in GCNs and how much it can help.', 'Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs.', 'The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants.', 'Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches.', 'Significant improvements can also be observed on a large scale industrial dataset.']","[0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.1818181723356247, 0.3333333134651184, 0.06451612710952759, 0.19999998807907104, 0.05882352590560913, 0.13793103396892548, 0.11428570747375488, 0.04444443807005882, 0.06896550953388214]",SJeLO34KwS,"['We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.', 'A method, known as DrGCN, for reweighting the different dimensions of the node representations in graph convolutional networks by reducing variance between dimensions.']","['paper  propose method named dimensional reweighting graph convolutional network  drgcns   tackle problem variance dimensional information node representation gcns ', 'prove drgcns reduce variance node representation connecting problem theory mean field ', 'however  practically  find degree drgcns help vary severely different datasets ', 'revisit problem develop new measure k quantify effect ', 'measure guide use dimensional reweighting gcns much help ', 'moreover  offer insight explain improvement obtained proposed drgcns ', 'dimensional reweighting block lightweighted highly flexible built gcn variant ', 'carefully designed experiment  including several fix duplicate  information leak  wrong label wellknown node classification benchmark datasets  demonstrate superior performance drgcns existing stateoftheart approach ', 'significant improvement also observed large scale industrial dataset ']","In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs., We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field., However, practically, we find that the degrees DrGCNs help vary severely on different datasets., We revisit the problem and develop a new measure K to quantify the effect., This measure guides when we should use dimensional reweighting in GCNs and how much it can help., Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs., The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants., Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches., Significant improvements can also be observed on a large scale industrial dataset.",18,5.684210526315789,9.5
98,"['Knowledge-grounded dialogue is a task of generating an informative response based on both discourse context and external knowledge.', 'As we focus on better modeling the knowledge selection in the multi-turn knowledge-grounded dialogue, we propose a sequential latent variable model as the first approach to this matter.', 'The model named sequential knowledge transformer (SKT) can keep track of the prior and posterior distribution over knowledge; as a result, it can not only reduce the ambiguity caused from the diversity in knowledge selection of conversation but also better leverage the response information for proper choice of knowledge.', 'Our experimental results show that the proposed model improves the knowledge selection accuracy and subsequently the performance of utterance generation.', 'We achieve the new state-of-the-art performance on Wizard of Wikipedia (Dinan et al., 2019) as one of the most large-scale and challenging benchmarks.', 'We further validate the effectiveness of our model over existing conversation methods in another knowledge-based dialogue Holl-E dataset (Moghe et al., 2018).']","[0, 1, 0, 0, 0, 0]","[0.25, 0.5454545617103577, 0.28169015049934387, 0.2916666567325592, 0.307692289352417, 0.18867923319339752]",Hke0K1HKwr,"['Our approach is the first attempt to leverage a sequential latent variable model for knowledge selection in the multi-turn knowledge-grounded dialogue. It achieves the new state-of-the-art performance on Wizard of Wikipedia benchmark.', 'A sequential latent variable model for knowledge selection in dialogue generation that extends the posterior attention model to the latent knowledge selection problem and achieves higher performances than previous state-of-the-art models.', 'A novel architecture for selecting knowledge-grounded multi-turn dialogue that yields state of the art on relevant benchmarks datasets, and scores higher in human evaluations.']","['knowledgegrounded dialogue task generating informative response based discourse context external knowledge ', 'focus better modeling knowledge selection multiturn knowledgegrounded dialogue  propose sequential latent variable model first approach matter ', 'model named sequential knowledge transformer  skt  keep track prior posterior distribution knowledge  result  reduce ambiguity caused diversity knowledge selection conversation also better leverage response information proper choice knowledge ', 'experimental result show proposed model improves knowledge selection accuracy subsequently performance utterance generation ', 'achieve new stateoftheart performance wizard wikipedia  dinan et al  2019  one largescale challenging benchmark ', 'validate effectiveness model existing conversation method another knowledgebased dialogue holle dataset  moghe et al  2018  ']","Knowledge-grounded dialogue is a task of generating an informative response based on both discourse context and external knowledge., As we focus on better modeling the knowledge selection in the multi-turn knowledge-grounded dialogue, we propose a sequential latent variable model as the first approach to this matter., The model named sequential knowledge transformer (SKT) can keep track of the prior and posterior distribution over knowledge; as a result, it can not only reduce the ambiguity caused from the diversity in knowledge selection of conversation but also better leverage the response information for proper choice of knowledge., Our experimental results show that the proposed model improves the knowledge selection accuracy and subsequently the performance of utterance generation., We achieve the new state-of-the-art performance on Wizard of Wikipedia (Dinan et al., 2019) as one of the most large-scale and challenging benchmarks., We further validate the effectiveness of our model over existing conversation methods in another knowledge-based dialogue Holl-E dataset (Moghe et al., 2018).",10,5.88125,16.0
99,"['Meta-learning, or learning-to-learn, has proven to be a successful strategy in attacking problems in supervised learning and reinforcement learning that involve small amounts of data.', 'State-of-the-art solutions involve learning an initialization and/or learning algorithm using a set of training episodes so that the meta learner can generalize to an evaluation episode quickly.', 'These methods perform well but often lack good quantification of uncertainty, which can be vital to real-world applications when data is lacking.', 'We propose a meta-learning method which efficiently amortizes hierarchical variational inference across tasks, learning a prior distribution over neural network weights so that a few steps of Bayes by Backprop will produce a good task-specific approximate posterior.', 'We show that our method produces good uncertainty estimates on contextual bandit and few-shot learning benchmarks.']","[0, 0, 0, 1, 0]","[0.05405404791235924, 0.1538461446762085, 0.0555555522441864, 0.5, 0.13333332538604736]",rkgpy3C5tX,"['We propose a meta-learning method which efficiently amortizes hierarchical variational inference across training episodes.', 'An adaptation to MAML-type models that accounts for posterior uncertainty in task specific latent variables by employing variational inference for task-specific parameters in a hierarchical Bayesian view of MAML.', 'The authors consider meta-learning to learn a prior over neural network weights, done via amortized variational inference.']","['metalearning  learningtolearn  proven successful strategy attacking problem supervised learning reinforcement learning involve small amount data ', 'stateoftheart solution involve learning initialization andor learning algorithm using set training episode meta learner generalize evaluation episode quickly ', 'method perform well often lack good quantification uncertainty  vital realworld application data lacking ', 'propose metalearning method efficiently amortizes hierarchical variational inference across task  learning prior distribution neural network weight step bayes backprop produce good taskspecific approximate posterior ', 'show method produce good uncertainty estimate contextual bandit fewshot learning benchmark ']","Meta-learning, or learning-to-learn, has proven to be a successful strategy in attacking problems in supervised learning and reinforcement learning that involve small amounts of data., State-of-the-art solutions involve learning an initialization and/or learning algorithm using a set of training episodes so that the meta learner can generalize to an evaluation episode quickly., These methods perform well but often lack good quantification of uncertainty, which can be vital to real-world applications when data is lacking., We propose a meta-learning method which efficiently amortizes hierarchical variational inference across tasks, learning a prior distribution over neural network weights so that a few steps of Bayes by Backprop will produce a good task-specific approximate posterior., We show that our method produces good uncertainty estimates on contextual bandit and few-shot learning benchmarks.",9,6.110236220472441,14.11111111111111
100,"['  Often we wish to transfer representational knowledge from one neural network to another.', 'Examples include distilling a large network into a smaller one, transferring knowledge from one sensory modality to a second, or ensembling a collection of models into a single estimator.', 'Knowledge distillation, the standard approach to these problems, minimizes the KL divergence between the probabilistic outputs of a teacher and student network.', 'We demonstrate that this objective ignores important structural knowledge of the teacher network.', ""This motivates an alternative objective by which we train a student to capture significantly more information in the teacher's representation of the data."", 'We formulate this objective as contrastive learning.', 'Experiments demonstrate that our resulting new objective outperforms knowledge distillation on a variety of knowledge transfer tasks, including single model compression, ensemble distillation, and cross-modal transfer.', 'When combined with knowledge distillation, our method sets a state of the art in many transfer tasks, sometimes even outperforming the teacher network.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.0, 0.0, 0.2666666507720947, 0.08695651590824127, 0.1875, 0.0, 0.11764705181121826, 0.0624999962747097]",SkgpBJrtvS,"['Representation/knowledge distillation by maximizing mutual information between teacher and student', 'This paper combines a contrastive objective measuring the mutual information between the representations learned by teacher and student networks for model distillation, and proposes a model with improvement over existing alternatives on distillation tasks.']","['often wish transfer representational knowledge one neural network another ', 'example include distilling large network smaller one  transferring knowledge one sensory modality second  ensembling collection model single estimator ', 'knowledge distillation  standard approach problem  minimizes kl divergence probabilistic output teacher student network ', 'demonstrate objective ignores important structural knowledge teacher network ', 'motivates alternative objective train student capture significantly information teacher representation data ', 'formulate objective contrastive learning ', 'experiment demonstrate resulting new objective outperforms knowledge distillation variety knowledge transfer task  including single model compression  ensemble distillation  crossmodal transfer ', 'combined knowledge distillation  method set state art many transfer task  sometimes even outperforming teacher network ']","  Often we wish to transfer representational knowledge from one neural network to another., Examples include distilling a large network into a smaller one, transferring knowledge from one sensory modality to a second, or ensembling a collection of models into a single estimator., Knowledge distillation, the standard approach to these problems, minimizes the KL divergence between the probabilistic outputs of a teacher and student network., We demonstrate that this objective ignores important structural knowledge of the teacher network., This motivates an alternative objective by which we train a student to capture significantly more information in the teacher's representation of the data., We formulate this objective as contrastive learning., Experiments demonstrate that our resulting new objective outperforms knowledge distillation on a variety of knowledge transfer tasks, including single model compression, ensemble distillation, and cross-modal transfer., When combined with knowledge distillation, our method sets a state of the art in many transfer tasks, sometimes even outperforming the teacher network.",17,6.089743589743589,9.176470588235293
101,"['Developing effective biologically plausible learning rules for deep neural networks is important for advancing connections between deep learning and neuroscience.', 'To date, local synaptic learning rules like those employed by the brain have failed to match the performance of backpropagation in deep networks.', 'In this work, we employ meta-learning to discover networks that learn using feedback connections and local, biologically motivated learning rules.', 'Importantly, the feedback connections are not tied to the feedforward weights, avoiding any biologically implausible weight transport.', 'It can be shown mathematically that this approach has sufficient expressivity to approximate any online learning algorithm.', 'Our experiments show that the meta-trained networks effectively use feedback connections to perform online credit assignment in multi-layer architectures.', 'Moreover, we demonstrate empirically that this model outperforms a state-of-the-art gradient-based meta-learning algorithm for continual learning on regression and classification benchmarks.', 'This approach represents a step toward biologically plausible learning mechanisms that can not only match gradient descent-based learning, but also overcome its limitations.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.29411762952804565, 0.1538461446762085, 0.4324324131011963, 0.12121211737394333, 0.23529411852359772, 0.1666666567325592, 0.21052631735801697, 0.14999999105930328]",HklfNQFL8H,['Networks that learn with feedback connections and local plasticity rules can be optimized for using meta learning.'],"['developing effective biologically plausible learning rule deep neural network important advancing connection deep learning neuroscience ', 'date  local synaptic learning rule like employed brain failed match performance backpropagation deep network ', 'work  employ metalearning discover network learn using feedback connection local  biologically motivated learning rule ', 'importantly  feedback connection tied feedforward weight  avoiding biologically implausible weight transport ', 'shown mathematically approach sufficient expressivity approximate online learning algorithm ', 'experiment show metatrained network effectively use feedback connection perform online credit assignment multilayer architecture ', 'moreover  demonstrate empirically model outperforms stateoftheart gradientbased metalearning algorithm continual learning regression classification benchmark ', 'approach represents step toward biologically plausible learning mechanism match gradient descentbased learning  also overcome limitation ']","Developing effective biologically plausible learning rules for deep neural networks is important for advancing connections between deep learning and neuroscience., To date, local synaptic learning rules like those employed by the brain have failed to match the performance of backpropagation in deep networks., In this work, we employ meta-learning to discover networks that learn using feedback connections and local, biologically motivated learning rules., Importantly, the feedback connections are not tied to the feedforward weights, avoiding any biologically implausible weight transport., It can be shown mathematically that this approach has sufficient expressivity to approximate any online learning algorithm., Our experiments show that the meta-trained networks effectively use feedback connections to perform online credit assignment in multi-layer architectures., Moreover, we demonstrate empirically that this model outperforms a state-of-the-art gradient-based meta-learning algorithm for continual learning on regression and classification benchmarks., This approach represents a step toward biologically plausible learning mechanisms that can not only match gradient descent-based learning, but also overcome its limitations.",15,6.675,10.666666666666666
102,"['In the visual system, neurons respond to a patch of the input known as their classical receptive field (RF), and can be modulated by stimuli in the surround.', 'These interactions are often mediated by lateral connections, giving rise to extra-classical RFs.', 'We use supervised learning via backpropagation to learn feedforward connections, combined with an unsupervised learning rule to learn lateral connections between units within a convolutional neural network.', 'These connections allow each unit to integrate information from its surround, generating extra-classical receptive fields for the units in our new proposed model (CNNEx).', 'We demonstrate that these connections make the network more robust and achieve better performance on noisy versions of the MNIST and CIFAR-10 datasets.', 'Although the image statistics of MNIST and CIFAR-10 differ greatly, the same unsupervised learning rule generalized to both datasets.', 'Our framework can potentially be applied to networks trained on other tasks, with the learned lateral connections aiding the computations implemented by feedforward connections when the input is unreliable.']","[0, 0, 1, 0, 0, 0, 0]","[0.09302324801683426, 0.19999998807907104, 0.2926829159259796, 0.1463414579629898, 0.21052631735801697, 0.11428570747375488, 0.23255813121795654]",rkxSEQtLUS,['CNNs with biologically-inspired lateral connections learned in an unsupervised manner are more robust to noisy inputs. '],"['visual system  neuron respond patch input known classical receptive field  rf   modulated stimulus surround ', 'interaction often mediated lateral connection  giving rise extraclassical rf ', 'use supervised learning via backpropagation learn feedforward connection  combined unsupervised learning rule learn lateral connection unit within convolutional neural network ', 'connection allow unit integrate information surround  generating extraclassical receptive field unit new proposed model  cnnex  ', 'demonstrate connection make network robust achieve better performance noisy version mnist cifar10 datasets ', 'although image statistic mnist cifar10 differ greatly  unsupervised learning rule generalized datasets ', 'framework potentially applied network trained task  learned lateral connection aiding computation implemented feedforward connection input unreliable ']","In the visual system, neurons respond to a patch of the input known as their classical receptive field (RF), and can be modulated by stimuli in the surround., These interactions are often mediated by lateral connections, giving rise to extra-classical RFs., We use supervised learning via backpropagation to learn feedforward connections, combined with an unsupervised learning rule to learn lateral connections between units within a convolutional neural network., These connections allow each unit to integrate information from its surround, generating extra-classical receptive fields for the units in our new proposed model (CNNEx)., We demonstrate that these connections make the network more robust and achieve better performance on noisy versions of the MNIST and CIFAR-10 datasets., Although the image statistics of MNIST and CIFAR-10 differ greatly, the same unsupervised learning rule generalized to both datasets., Our framework can potentially be applied to networks trained on other tasks, with the learned lateral connections aiding the computations implemented by feedforward connections when the input is unreliable.",14,5.871165644171779,11.642857142857142
103,"['Deep learning (DL) has in recent years been widely used in natural\n', 'language processing (NLP) applications due to its superior\n', 'performance.', 'However, while natural languages are rich in\n', 'grammatical structure, DL has not been able to explicitly\n', 'represent and enforce such structures.', 'This paper proposes a new\n', 'architecture to bridge this gap by exploiting tensor product\n', 'representations (TPR), a structured neural-symbolic framework\n', 'developed in cognitive science over the past 20 years, with the\n', 'aim of integrating DL with explicit language structures and rules.\n', 'We call it the Tensor Product Generation Network\n', '(TPGN), and apply it to image captioning.', 'The key\n', 'ideas of TPGN are:', '1) unsupervised learning of\nrole-unbinding vectors of words via a TPR-based deep neural\nnetwork, and', '2) integration of TPR with typical DL architectures\n', 'including Long Short-Term Memory (LSTM) models.', 'The novelty of our\n', 'approach lies in its ability to generate a sentence and extract\n', 'partial grammatical structure of the sentence by using\n', 'role-unbinding vectors, which are obtained in an unsupervised\n', 'manner.', 'Experimental results demonstrate the effectiveness of the\n', 'proposed approach.']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.0714285671710968, 0.23999999463558197, 0.0833333283662796, 0.07692307233810425, 0.0, 0.27272728085517883, 0.23076923191547394, 0.08695651590824127, 0.0, 0.0714285671710968, 0.0, 0.0833333283662796, 0.0, 0.06451612710952759, 0.0, 0.0, 0.0, 0.2142857164144516, 0.0, 0.0, 0.0]",SkeK5B9LyQ,['This paper is intended to develop a tensor product representation approach for deep-learning-based natural language processinig applications.'],"['deep learning  dl  recent year widely used natural', 'language processing  nlp  application due superior', 'performance ', 'however  natural language rich', 'grammatical structure  dl able explicitly', 'represent enforce structure ', 'paper proposes new', 'architecture bridge gap exploiting tensor product', 'representation  tpr   structured neuralsymbolic framework', 'developed cognitive science past 20 year ', 'aim integrating dl explicit language structure rule ', 'call tensor product generation network', ' tpgn   apply image captioning ', 'key', 'idea tpgn ', '1  unsupervised learning roleunbinding vector word via tprbased deep neural network ', '2  integration tpr typical dl architecture', 'including long shortterm memory  lstm  model ', 'novelty', 'approach lie ability generate sentence extract', 'partial grammatical structure sentence using', 'roleunbinding vector  obtained unsupervised', 'manner ', 'experimental result demonstrate effectiveness', 'proposed approach ']","Deep learning (DL) has in recent years been widely used in natural
, language processing (NLP) applications due to its superior
, performance., However, while natural languages are rich in
, grammatical structure, DL has not been able to explicitly
, represent and enforce such structures., This paper proposes a new
, architecture to bridge this gap by exploiting tensor product
, representations (TPR), a structured neural-symbolic framework
, developed in cognitive science over the past 20 years, with the
, aim of integrating DL with explicit language structures and rules.
, We call it the Tensor Product Generation Network
, (TPGN), and apply it to image captioning., The key
, ideas of TPGN are:, 1) unsupervised learning of
role-unbinding vectors of words via a TPR-based deep neural
network, and, 2) integration of TPR with typical DL architectures
, including Long Short-Term Memory (LSTM) models., The novelty of our
, approach lies in its ability to generate a sentence and extract
, partial grammatical structure of the sentence by using
, role-unbinding vectors, which are obtained in an unsupervised
, manner., Experimental results demonstrate the effectiveness of the
, proposed approach.",32,5.655172413793103,5.4375
104,"['It is well-known that  classifiers are vulnerable to adversarial perturbations.', 'To defend against adversarial perturbations, various certified robustness results have been derived.', 'However, existing certified robustnesses are limited to top-1 predictions.', 'In many real-world applications, top-$k$ predictions are more relevant.', 'In this work, we aim to derive certified robustness for top-$k$ predictions.', 'In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example.', 'We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier.', 'We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise.', 'We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges.', 'We also empirically evaluate our method on CIFAR10 and ImageNet.', 'For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255).', 'Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}.']","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.0, 0.11764705181121826, 0.12903225421905518, 0.06451612710952759, 0.29411762952804565, 0.2666666507720947, 0.21052631735801697, 0.6499999761581421, 0.2631579041481018, 0.1249999925494194, 0.11999999731779099, 0.0]",BkeWw6VFwr,"['We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.', 'This paper extends work on deducing a certified radius using randomized smoothing, and shows the radius at which a smoothed classifier under Gaussian perturbations is certified for the top k predictions.', 'This paper builds upon the random smoothing technique for top-1 prediction, and aims to provide certification on top-k predictions.']","['wellknown classifier vulnerable adversarial perturbation ', 'defend adversarial perturbation  various certified robustness result derived ', 'however  existing certified robustness limited top1 prediction ', 'many realworld application  top  k  prediction relevant ', 'work  aim derive certified robustness top  k  prediction ', 'particular  certified robustness based randomized smoothing  turn classifier new classifier via adding noise input example ', 'adopt randomized smoothing scalable largescale neural network applicable classifier ', 'derive tight robustness  ell2  norm top  k  prediction using randomized smoothing gaussian noise ', 'find generalizing certified robustness top1 top  k  prediction face significant technical challenge ', 'also empirically evaluate method cifar10 imagenet ', 'example  method obtain imagenet classifier certified top5 accuracy 628   ell2  norm adversarial perturbation le 05  127255  ', 'code publicly available  url  http  githubcomjjy1994certifytopk  ']","It is well-known that  classifiers are vulnerable to adversarial perturbations., To defend against adversarial perturbations, various certified robustness results have been derived., However, existing certified robustnesses are limited to top-1 predictions., In many real-world applications, top-$k$ predictions are more relevant., In this work, we aim to derive certified robustness for top-$k$ predictions., In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example., We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier., We derive a tight robustness in $\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise., We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges., We also empirically evaluate our method on CIFAR10 and ImageNet., For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\% when the $\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255)., Our code is publicly available at: \url{https://github.com/jjy1994/Certify_Topk}.",19,6.2601156069364166,9.105263157894736
105,"['Recent work has shown increased interest in using the Variational Autoencoder (VAE) framework to discover interpretable representations of data in an unsupervised way.', 'These methods have focussed largely on modifying the variational cost function to achieve this goal.', 'However, we show that methods like beta-VAE simplify the tendency of variational inference to underfit causing pathological over-pruning and over-orthogonalization of learned components.', 'In this paper we take a complementary approach: to modify the probabilistic model to encourage structured latent variable representations to be discovered.', 'Specifically, the standard VAE probabilistic model is unidentifiable: the likelihood of the parameters is invariant under rotations of the latent space.', 'This means there is no pressure to identify each true factor of variation with a latent variable.\n', 'We therefore employ a rich prior distribution, akin to the ICA model, that breaks the rotational symmetry.\n', 'Extensive quantitative and qualitative experiments demonstrate that the proposed prior mitigates the trade-off introduced by modified cost functions like beta-VAE and TCVAE between reconstruction loss and disentanglement.', 'The proposed prior allows to improve these approaches with respect to both disentanglement and reconstruction quality significantly over the state of the art.']","[0, 0, 0, 0, 0, 0, 0, 1, 0]","[0.22727271914482117, 0.05405404791235924, 0.1818181723356247, 0.1428571343421936, 0.10526315122842789, 0.04999999329447746, 0.1538461446762085, 0.3478260934352875, 0.2790697515010834]",rJl_NhR9K7,"['We present structured priors for unsupervised learning of disentangled representations in VAEs that significantly mitigate the trade-off between disentanglement and reconstruction loss.', 'A general framework to use the family of L^p-nested distributions as the prior for the code vector of VAE, demonstrating a higher MIG.', 'The authors point out issues in current VAE approaches and provide a new perspective on the tradeoff between reconstruction and orthogonalization for VAE, beta-VAE, and beta-TCVAE.']","['recent work shown increased interest using variational autoencoder  vae  framework discover interpretable representation data unsupervised way ', 'method focussed largely modifying variational cost function achieve goal ', 'however  show method like betavae simplify tendency variational inference underfit causing pathological overpruning overorthogonalization learned component ', 'paper take complementary approach  modify probabilistic model encourage structured latent variable representation discovered ', 'specifically  standard vae probabilistic model unidentifiable  likelihood parameter invariant rotation latent space ', 'mean pressure identify true factor variation latent variable ', 'therefore employ rich prior distribution  akin ica model  break rotational symmetry ', 'extensive quantitative qualitative experiment demonstrate proposed prior mitigates tradeoff introduced modified cost function like betavae tcvae reconstruction loss disentanglement ', 'proposed prior allows improve approach respect disentanglement reconstruction quality significantly state art ']","Recent work has shown increased interest in using the Variational Autoencoder (VAE) framework to discover interpretable representations of data in an unsupervised way., These methods have focussed largely on modifying the variational cost function to achieve this goal., However, we show that methods like beta-VAE simplify the tendency of variational inference to underfit causing pathological over-pruning and over-orthogonalization of learned components., In this paper we take a complementary approach: to modify the probabilistic model to encourage structured latent variable representations to be discovered., Specifically, the standard VAE probabilistic model is unidentifiable: the likelihood of the parameters is invariant under rotations of the latent space., This means there is no pressure to identify each true factor of variation with a latent variable.
, We therefore employ a rich prior distribution, akin to the ICA model, that breaks the rotational symmetry.
, Extensive quantitative and qualitative experiments demonstrate that the proposed prior mitigates the trade-off introduced by modified cost functions like beta-VAE and TCVAE between reconstruction loss and disentanglement., The proposed prior allows to improve these approaches with respect to both disentanglement and reconstruction quality significantly over the state of the art.",13,6.164893617021277,14.461538461538462
106,"['Due to the success of residual networks (resnets) and related architectures, shortcut connections have quickly become standard tools for building convolutional neural networks.', 'The explanations in the literature for the apparent effectiveness of shortcuts are varied and often contradictory.', 'We hypothesize that shortcuts work primarily because they act as linear counterparts to nonlinear layers.', 'We test this hypothesis by using several variations on the standard residual block, with different types of linear connections, to build small (100k--1.2M parameter) image classification networks.', 'Our experiments show that other kinds of linear connections can be even more effective than the identity shortcuts.', 'Our results also suggest that the best type of linear connection for a given application may depend on both network width and depth.']","[0, 0, 0, 1, 0, 0]","[0.1904761791229248, 0.11428570747375488, 0.17142856121063232, 0.2083333283662796, 0.10526315122842789, 0.1395348757505417]",rkmoiMbCb,"['We generalize residual blocks to tandem blocks, which use arbitrary linear maps instead of shortcuts, and improve performance over ResNets.', 'This paper performs an analysis of shortcut connections in ResNet-like architectures, and proposes to substitute the identity shortcuts with an alternative convolutional one referred to as tandem block.', 'This paper investigates the effect of replacing identity skip connections with trainable convolutional skip connections in ResNet and finds that performance improves.']","['due success residual network  resnets  related architecture  shortcut connection quickly become standard tool building convolutional neural network ', 'explanation literature apparent effectiveness shortcut varied often contradictory ', 'hypothesize shortcut work primarily act linear counterpart nonlinear layer ', 'test hypothesis using several variation standard residual block  different type linear connection  build small  100k  12m parameter  image classification network ', 'experiment show kind linear connection even effective identity shortcut ', 'result also suggest best type linear connection given application may depend network width depth ']","Due to the success of residual networks (resnets) and related architectures, shortcut connections have quickly become standard tools for building convolutional neural networks., The explanations in the literature for the apparent effectiveness of shortcuts are varied and often contradictory., We hypothesize that shortcuts work primarily because they act as linear counterparts to nonlinear layers., We test this hypothesis by using several variations on the standard residual block, with different types of linear connections, to build small (100k--1.2M parameter) image classification networks., Our experiments show that other kinds of linear connections can be even more effective than the identity shortcuts., Our results also suggest that the best type of linear connection for a given application may depend on both network width and depth.",9,5.89344262295082,13.555555555555555
107,"['Adam-typed optimizers, as a class of adaptive moment estimation methods with the exponential moving average scheme, have been successfully used in many applications of deep learning.', 'Such methods are appealing for capability on large-scale sparse datasets.', 'On top of that, they are computationally efficient and insensitive to the hyper-parameter settings.', 'In this paper, we present a new framework for adapting Adam-typed methods, namely AdamT.', 'Instead of applying a simple exponential weighted average, AdamT also includes the trend information when updating the parameters with the adaptive step size and gradients.', 'The newly added term is expected to efficiently capture the non-horizontal moving patterns on the cost surface, and thus converge more rapidly.', 'We show empirically the importance of the trend component, where AdamT outperforms the conventional Adam method constantly in both convex and non-convex settings.']","[0, 0, 0, 0, 1, 0, 0]","[0.19999998807907104, 0.05714285373687744, 0.1538461446762085, 0.4615384638309479, 0.5416666865348816, 0.1304347813129425, 0.17391303181648254]",Sklw_kHtPH,"['We present a new framework for adapting Adam-typed methods, namely AdamT, to include the trend information when updating the parameters with the adaptive step size and gradients.', ""A new type of Adam variant that uses Holt's linear method to compute the smoothed first order and second order momentum instead of using exponential weighted average.""]","['adamtyped optimizers  class adaptive moment estimation method exponential moving average scheme  successfully used many application deep learning ', 'method appealing capability largescale sparse datasets ', 'top  computationally efficient insensitive hyperparameter setting ', 'paper  present new framework adapting adamtyped method  namely adamt ', 'instead applying simple exponential weighted average  adamt also includes trend information updating parameter adaptive step size gradient ', 'newly added term expected efficiently capture nonhorizontal moving pattern cost surface  thus converge rapidly ', 'show empirically importance trend component  adamt outperforms conventional adam method constantly convex nonconvex setting ']","Adam-typed optimizers, as a class of adaptive moment estimation methods with the exponential moving average scheme, have been successfully used in many applications of deep learning., Such methods are appealing for capability on large-scale sparse datasets., On top of that, they are computationally efficient and insensitive to the hyper-parameter settings., In this paper, we present a new framework for adapting Adam-typed methods, namely AdamT., Instead of applying a simple exponential weighted average, AdamT also includes the trend information when updating the parameters with the adaptive step size and gradients., The newly added term is expected to efficiently capture the non-horizontal moving patterns on the cost surface, and thus converge more rapidly., We show empirically the importance of the trend component, where AdamT outperforms the conventional Adam method constantly in both convex and non-convex settings.",15,5.850746268656716,8.933333333333334
108,"['As machine learning methods see greater adoption and implementation in high stakes applications such\nas medical image diagnosis, the need for model interpretability and explanation has become more\ncritical.', 'Classical approaches that assess feature importance (eg saliency maps) do not explain how and why a particular region of an image is relevant to the prediction.', 'We propose\na method that explains the outcome of a classification black-box by gradually exaggerating\nthe semantic effect of a given class.', 'Given a query input to a classifier, our method produces a\nprogressive set of plausible variations of that query, which gradually change the posterior probability\nfrom its original class to its negation.', ""These counter-factually generated samples preserve features\nunrelated to the classification decision, such that a user can employ our method as a ``tuning knob'' to traverse a data manifold while crossing the decision boundary.  "", 'Our method is model agnostic and only requires the output value and gradient of the predictor with respect to its input.']","[0, 0, 1, 0, 0, 0]","[0.07547169178724289, 0.31372547149658203, 0.3720930218696594, 0.26923075318336487, 0.2181818187236786, 0.22727271914482117]",H1xFWgrFPS,"['A method to explain a classifier, by generating visual perturbation of an image by exaggerating  or diminishing the semantic features that the classifier associates with a target label.', 'A model that when given a query input to a black-box, aims to explain the outcome by providing plausible and progressive variations to the query that can result in a change to the output.', 'A method for explaining the output of black box classification of images, that generates gradual perturbation of outputs in response to gradually perturbed input queries.']","['machine learning method see greater adoption implementation high stake application medical image diagnosis  need model interpretability explanation become critical ', 'classical approach ass feature importance  eg saliency map  explain particular region image relevant prediction ', 'propose method explains outcome classification blackbox gradually exaggerating semantic effect given class ', 'given query input classifier  method produce progressive set plausible variation query  gradually change posterior probability original class negation ', 'counterfactually generated sample preserve feature unrelated classification decision  user employ method  tuning knob  traverse data manifold crossing decision boundary ', 'method model agnostic requires output value gradient predictor respect input ']","As machine learning methods see greater adoption and implementation in high stakes applications such
as medical image diagnosis, the need for model interpretability and explanation has become more
critical., Classical approaches that assess feature importance (eg saliency maps) do not explain how and why a particular region of an image is relevant to the prediction., We propose
a method that explains the outcome of a classification black-box by gradually exaggerating
the semantic effect of a given class., Given a query input to a classifier, our method produces a
progressive set of plausible variations of that query, which gradually change the posterior probability
from its original class to its negation., These counter-factually generated samples preserve features
unrelated to the classification decision, such that a user can employ our method as a ``tuning knob'' to traverse a data manifold while crossing the decision boundary.  , Our method is model agnostic and only requires the output value and gradient of the predictor with respect to its input.",10,5.484662576687117,16.3
109,"['We study the problem of explaining a rich class of behavioral properties of deep neural networks.', 'Our influence-directed explanations approach this problem by peering inside the network to identify neurons with high influence on the property of interest using an axiomatically justified influence measure, and then providing an interpretation for the concepts these neurons represent.', 'We evaluate our approach by training convolutional neural networks on Pubfig, ImageNet, and Diabetic Retinopathy datasets.  ', 'Our evaluation demonstrates that influence-directed explanations (1) localize features used by the network, (2) isolate features distinguishing related instances, (3) help extract the essence of what the network learned about the class, and (4) assist in debugging misclassifications.\n']","[0, 1, 0, 0]","[0.2083333283662796, 0.29411762952804565, 0.19607841968536377, 0.23188404738903046]",SJPpHzW0-,"['We present an influence-directed approach to constructing explanations for the behavior of deep convolutional networks, and show how it can be used to answer a broad set of questions that could not be addressed by prior work.', 'A way to measure influence that satisfies certain axioms, and a notion of influence that can be used to identify what input part is most influential for the output of a neuron in a deep neural network.', 'This paper proposes to measure the influence of single neurons with regard to a quantity of interest represented by another neuron.']","['study problem explaining rich class behavioral property deep neural network ', 'influencedirected explanation approach problem peering inside network identify neuron high influence property interest using axiomatically justified influence measure  providing interpretation concept neuron represent ', 'evaluate approach training convolutional neural network pubfig  imagenet  diabetic retinopathy datasets ', 'evaluation demonstrates influencedirected explanation  1  localize feature used network   2  isolate feature distinguishing related instance   3  help extract essence network learned class   4  assist debugging misclassifications ']","We study the problem of explaining a rich class of behavioral properties of deep neural networks., Our influence-directed explanations approach this problem by peering inside the network to identify neurons with high influence on the property of interest using an axiomatically justified influence measure, and then providing an interpretation for the concepts these neurons represent., We evaluate our approach by training convolutional neural networks on Pubfig, ImageNet, and Diabetic Retinopathy datasets.  , Our evaluation demonstrates that influence-directed explanations (1) localize features used by the network, (2) isolate features distinguishing related instances, (3) help extract the essence of what the network learned about the class, and (4) assist in debugging misclassifications.
",10,6.220183486238532,10.9
110,"['Standard deep learning systems require thousands or millions of examples to learn a concept, and cannot integrate new concepts easily.', 'By contrast, humans have an incredible ability to do one-shot or few-shot learning.', 'For instance, from just hearing a word used in a sentence, humans can infer a great deal about it, by leveraging what the syntax and semantics of the surrounding words tells us.', 'Here, we draw inspiration from this to highlight a simple technique by which deep recurrent networks can similarly exploit their prior knowledge to learn a useful representation for a new word from little data.', 'This could make natural language processing systems much more flexible, by allowing them to learn continually from the new words they encounter.']","[0, 0, 0, 0, 1]","[0.23255813121795654, 0.0555555522441864, 0.19230768084526062, 0.4150943458080292, 0.5777777433395386]",rkYgAJWCZ,"['We highlight a technique by which natural language processing systems can learn a new word from context, allowing them to be much more flexible.', 'A technique for exploiting prior knowledge to learn embedding representations for new words with minimal data.']","['standard deep learning system require thousand million example learn concept  integrate new concept easily ', 'contrast  human incredible ability oneshot fewshot learning ', 'instance  hearing word used sentence  human infer great deal  leveraging syntax semantics surrounding word tell u ', ' draw inspiration highlight simple technique deep recurrent network similarly exploit prior knowledge learn useful representation new word little data ', 'could make natural language processing system much flexible  allowing learn continually new word encounter ']","Standard deep learning systems require thousands or millions of examples to learn a concept, and cannot integrate new concepts easily., By contrast, humans have an incredible ability to do one-shot or few-shot learning., For instance, from just hearing a word used in a sentence, humans can infer a great deal about it, by leveraging what the syntax and semantics of the surrounding words tells us., Here, we draw inspiration from this to highlight a simple technique by which deep recurrent networks can similarly exploit their prior knowledge to learn a useful representation for a new word from little data., This could make natural language processing systems much more flexible, by allowing them to learn continually from the new words they encounter.",12,5.1652892561983474,10.083333333333334
111,"['Recent research developing neural network architectures with external memory have often used the benchmark bAbI question and answering dataset which provides a challenging number of tasks requiring reasoning.', 'Here we employed a classic associative inference task from the human neuroscience literature in order to more carefully probe the reasoning capacity of existing memory-augmented architectures.', 'This task is thought to capture the essence of reasoning -- the appreciation of distant relationships among elements distributed across multiple facts or memories.', 'Surprisingly, we found that current architectures struggle to reason over long distance associations.', 'Similar results were obtained on a more complex task involving finding the shortest path between nodes in a path.', 'We therefore developed a novel architecture, MEMO, endowed with the capacity to reason over longer distances.', 'This was accomplished with the addition of two novel components.', 'First, it introduces a separation between memories/facts stored in external memory and the items that comprise these facts in external memory.', 'Second, it makes use of an adaptive retrieval mechanism, allowing a variable number of memory hops before the answer is produced.', 'MEMO is capable of solving our novel reasoning tasks, as well as all 20 tasks in bAbI.']","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]","[0.11428570747375488, 0.0624999962747097, 0.06896551698446274, 0.09999999403953552, 0.0, 0.0, 0.0, 0.1599999964237213, 0.0, 0.08695651590824127]",rJxlc0EtDr,"['A memory architecture that support inferential reasoning.', 'This paper proposes changes to the End2End Memory Network architecture, introduces a new Paired Associative Inference task that most existing models struggle to solve, and shows that their proposed architecture solves the task better.', 'A new task (paired associate inference) drawn from cognitive psychology, and proposal for a new memory architecture with features that allow for better performance on the paired associate task.']","['recent research developing neural network architecture external memory often used benchmark babi question answering dataset provides challenging number task requiring reasoning ', 'employed classic associative inference task human neuroscience literature order carefully probe reasoning capacity existing memoryaugmented architecture ', 'task thought capture essence reasoning  appreciation distant relationship among element distributed across multiple fact memory ', 'surprisingly  found current architecture struggle reason long distance association ', 'similar result obtained complex task involving finding shortest path node path ', 'therefore developed novel architecture  memo  endowed capacity reason longer distance ', 'accomplished addition two novel component ', 'first  introduces separation memoriesfacts stored external memory item comprise fact external memory ', 'second  make use adaptive retrieval mechanism  allowing variable number  memory hop  answer produced ', 'memo capable solving novel reasoning task  well 20 task babi ']","Recent research developing neural network architectures with external memory have often used the benchmark bAbI question and answering dataset which provides a challenging number of tasks requiring reasoning., Here we employed a classic associative inference task from the human neuroscience literature in order to more carefully probe the reasoning capacity of existing memory-augmented architectures., This task is thought to capture the essence of reasoning -- the appreciation of distant relationships among elements distributed across multiple facts or memories., Surprisingly, we found that current architectures struggle to reason over long distance associations., Similar results were obtained on a more complex task involving finding the shortest path between nodes in a path., We therefore developed a novel architecture, MEMO, endowed with the capacity to reason over longer distances., This was accomplished with the addition of two novel components., First, it introduces a separation between memories/facts stored in external memory and the items that comprise these facts in external memory., Second, it makes use of an adaptive retrieval mechanism, allowing a variable number of memory hops before the answer is produced., MEMO is capable of solving our novel reasoning tasks, as well as all 20 tasks in bAbI.",17,5.728205128205128,11.470588235294118
112,"['Depthwise separable convolutions reduce the number of parameters and computation used in convolutional operations while increasing representational efficiency.\n', 'They have been shown to be successful in image classification models, both in obtaining better models than previously possible for a given parameter count (the Xception architecture) and considerably reducing the number of parameters required to perform at a given level (the MobileNets family of architectures).', 'Recently, convolutional sequence-to-sequence networks have been applied to machine translation tasks with good results.', 'In this work, we study how depthwise separable convolutions can be applied to neural machine translation.', 'We introduce a new architecture inspired by Xception and ByteNet, called SliceNet, which enables a significant reduction of the parameter count and amount of computation needed to obtain results like ByteNet, and, with a similar parameter count, achieves better results.\n', 'In addition to showing that depthwise separable convolutions perform well for machine translation, we investigate the architectural changes that they enable: we observe that thanks to depthwise separability, we can increase the length of convolution windows, removing the need for filter dilation.', 'We also introduce a new super-separable convolution operation that further reduces the number of parameters and computational cost of the models.']","[0, 0, 0, 1, 0, 0, 0]","[0.27586206793785095, 0.07999999821186066, 0.0833333283662796, 0.307692289352417, 0.09090908616781235, 0.1860465109348297, 0.06896550953388214]",S1jBcueAb,"['Depthwise separable convolutions improve neural machine translation: the more separable the better.', 'This paper proposes to use depthwise separable convolution layers in a fully convolutional neural machine translation model, and introduces a new super-separable convolution layer which further reduces computational cost.']","['depthwise separable convolution reduce number parameter computation used convolutional operation increasing representational efficiency ', 'shown successful image classification model  obtaining better model previously possible given parameter count  xception architecture  considerably reducing number parameter required perform given level  mobilenets family architecture  ', 'recently  convolutional sequencetosequence network applied machine translation task good result ', 'work  study depthwise separable convolution applied neural machine translation ', 'introduce new architecture inspired xception bytenet  called slicenet  enables significant reduction parameter count amount computation needed obtain result like bytenet   similar parameter count  achieves better result ', 'addition showing depthwise separable convolution perform well machine translation  investigate architectural change enable  observe thanks depthwise separability  increase length convolution window  removing need filter dilation ', 'also introduce new superseparable convolution operation reduces number parameter computational cost model ']","Depthwise separable convolutions reduce the number of parameters and computation used in convolutional operations while increasing representational efficiency.
, They have been shown to be successful in image classification models, both in obtaining better models than previously possible for a given parameter count (the Xception architecture) and considerably reducing the number of parameters required to perform at a given level (the MobileNets family of architectures)., Recently, convolutional sequence-to-sequence networks have been applied to machine translation tasks with good results., In this work, we study how depthwise separable convolutions can be applied to neural machine translation., We introduce a new architecture inspired by Xception and ByteNet, called SliceNet, which enables a significant reduction of the parameter count and amount of computation needed to obtain results like ByteNet, and, with a similar parameter count, achieves better results.
, In addition to showing that depthwise separable convolutions perform well for machine translation, we investigate the architectural changes that they enable: we observe that thanks to depthwise separability, we can increase the length of convolution windows, removing the need for filter dilation., We also introduce a new super-separable convolution operation that further reduces the number of parameters and computational cost of the models.",18,6.121827411167513,10.944444444444445
113,"['Interpreting generative adversarial network (GAN) training as approximate divergence minimization has been\n', 'theoretically insightful, has spurred discussion, and has lead to theoretically and practically interesting\n', 'extensions such as f-GANs and Wasserstein GANs.', 'For both classic GANs and f-GANs, there is an original variant of training and a ""non-saturating"" variant which uses an alternative form of generator gradient.', 'The original variant is theoretically easier to study, but for GANs the alternative variant performs better in practice.', 'The non-saturating scheme is often regarded as a simple modification to deal with optimization issues, but we show that in fact the non-saturating scheme for GANs is effectively optimizing a reverse KL-like f-divergence.', 'We also develop a number of theoretical tools to help compare and classify f-divergences.', 'We hope these results may help to clarify some of the theoretical discussion surrounding the divergence minimization view of GAN training.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.0952380895614624, 0.0, 0.0, 0.13333332538604736, 0.0, 0.2631579041481018, 0.08695651590824127, 0.1428571343421936]",BygY4grYDr,"['Non-saturating GAN training effectively minimizes a reverse KL-like f-divergence.', 'This paper proposes a useful expression of the class of f-divergences, investigates theoretical properties of popular f-divergences from newly developed tools, and investigates GANs with the non-saturating training scheme.']","['interpreting generative adversarial network  gan  training approximate divergence minimization', 'theoretically insightful  spurred discussion  lead theoretically practically interesting', 'extension fgans wasserstein gans ', 'classic gans fgans  original variant training  nonsaturating  variant us alternative form generator gradient ', 'original variant theoretically easier study  gans alternative variant performs better practice ', 'nonsaturating scheme often regarded simple modification deal optimization issue  show fact nonsaturating scheme gans effectively optimizing reverse kllike fdivergence ', 'also develop number theoretical tool help compare classify fdivergences ', 'hope result may help clarify theoretical discussion surrounding divergence minimization view gan training ']","Interpreting generative adversarial network (GAN) training as approximate divergence minimization has been
, theoretically insightful, has spurred discussion, and has lead to theoretically and practically interesting
, extensions such as f-GANs and Wasserstein GANs., For both classic GANs and f-GANs, there is an original variant of training and a ""non-saturating"" variant which uses an alternative form of generator gradient., The original variant is theoretically easier to study, but for GANs the alternative variant performs better in practice., The non-saturating scheme is often regarded as a simple modification to deal with optimization issues, but we show that in fact the non-saturating scheme for GANs is effectively optimizing a reverse KL-like f-divergence., We also develop a number of theoretical tools to help compare and classify f-divergences., We hope these results may help to clarify some of the theoretical discussion surrounding the divergence minimization view of GAN training.",13,5.916083916083916,11.0
114,"['We introduce a novel method for converting text data into abstract image representations, which allows image-based processing techniques (e.g. image classification networks) to be applied to text-based comparison problems.', 'We apply the technique to entity disambiguation of inventor names in US patents.', 'The method involves converting text from each pairwise comparison between two inventor name records into a 2D RGB (stacked) image representation.', 'We then train an image classification neural network to discriminate between such pairwise comparison images, and use the trained network to label each pair of records as either matched (same inventor) or non-matched (different inventors), obtaining highly accurate results (F1: 99.09%, precision: 99.41%, recall: 98.76%).', 'Our new text-to-image representation method could potentially be used more broadly for other NLP comparison problems, such as disambiguation of academic publications, or for problems that require simultaneous classification of both text and images.']","[1, 0, 0, 0, 0]","[0.47999998927116394, 0.34285715222358704, 0.3255814015865326, 0.17910447716712952, 0.29629629850387573]",HJxB3AEFDS,"['We introduce a novel text representation method which enables image classifiers to be applied to text classification problems, and apply the method to inventor name disambiguation.', 'A method to map a pair of textual information into a 2D RGB image that can be fed to 2D convoutional neural networks (image classifiers).', 'The authors consider the problem of names disambiguisation for patent names inventors and propose to build an image page representation of the two name strings to compare and to apply an image classifier.']","['introduce novel method converting text data abstract image representation  allows imagebased processing technique  eg  image classification network  applied textbased comparison problem ', 'apply technique entity disambiguation inventor name u patent ', 'method involves converting text pairwise comparison two inventor name record 2d rgb  stacked  image representation ', 'train image classification neural network discriminate pairwise comparison image  use trained network label pair record either matched  inventor  nonmatched  different inventor   obtaining highly accurate result  f1  9909   precision  9941   recall  9876   ', 'new texttoimage representation method could potentially used broadly nlp comparison problem  disambiguation academic publication  problem require simultaneous classification text image ']","We introduce a novel method for converting text data into abstract image representations, which allows image-based processing techniques (e.g. image classification networks) to be applied to text-based comparison problems., We apply the technique to entity disambiguation of inventor names in US patents., The method involves converting text from each pairwise comparison between two inventor name records into a 2D RGB (stacked) image representation., We then train an image classification neural network to discriminate between such pairwise comparison images, and use the trained network to label each pair of records as either matched (same inventor) or non-matched (different inventors), obtaining highly accurate results (F1: 99.09%, precision: 99.41%, recall: 98.76%)., Our new text-to-image representation method could potentially be used more broadly for other NLP comparison problems, such as disambiguation of academic publications, or for problems that require simultaneous classification of both text and images.",12,6.147887323943662,10.923076923076923
115,"['We propose a novel algorithm, Difference-Seeking Generative Adversarial Network (DSGAN), developed from traditional GAN.', 'DSGAN considers the scenario that the training samples of target distribution, $p_{t}$, are difficult to collect.\n\n', 'Suppose there are two distributions  $p_{\\bar{d}}$ and $p_{d}$ such that the density of the target distribution can be the differences between the densities of $p_{\\bar{d}}$ and $p_{d}$.', 'We show how to learn the target distribution $p_{t}$ only via samples from $p_{d}$ and $p_{\\bar{d}}$ (relatively easy to obtain).\n\n', 'DSGAN has the flexibility to produce samples from various target distributions (e.g. the out-of-distribution).', 'Two key applications, semi-supervised learning and adversarial training, are taken as examples to validate the effectiveness of DSGAN.', 'We also provide theoretical analyses about the convergence of DSGAN.']","[0, 0, 0, 1, 0, 0, 0]","[0.1818181723356247, 0.2857142686843872, 0.1538461446762085, 0.307692289352417, 0.1818181723356247, 0.10810810327529907, 0.13793103396892548]",ryxDUs05KQ,"['We proposed ""Difference-Seeking Generative Adversarial Network"" (DSGAN) model to learn the target distribution which is hard to collect training data.', 'This paper presents DS-GAN, which aims to learn the difference between any two distributions whose samples are difficult or impossible to collect, and shows its effectiveness on semi-supervised learning and adversarial training tasks.', 'This paper considers the problem of learning a GAN to capture a target distribution with only very few training samples from that distribution available.']","['propose novel algorithm  differenceseeking generative adversarial network  dsgan   developed traditional gan ', 'dsgan considers scenario training sample target distribution   p     difficult collect ', 'suppose two distribution  p  bar      p    density target distribution difference density  p  bar      p    ', 'show learn target distribution  p    via sample  p     p  bar      relatively easy obtain  ', 'dsgan flexibility produce sample various target distribution  eg  outofdistribution  ', 'two key application  semisupervised learning adversarial training  taken example validate effectiveness dsgan ', 'also provide theoretical analysis convergence dsgan ']","We propose a novel algorithm, Difference-Seeking Generative Adversarial Network (DSGAN), developed from traditional GAN., DSGAN considers the scenario that the training samples of target distribution, $p_{t}$, are difficult to collect.

, Suppose there are two distributions  $p_{\bar{d}}$ and $p_{d}$ such that the density of the target distribution can be the differences between the densities of $p_{\bar{d}}$ and $p_{d}$., We show how to learn the target distribution $p_{t}$ only via samples from $p_{d}$ and $p_{\bar{d}}$ (relatively easy to obtain).

, DSGAN has the flexibility to produce samples from various target distributions (e.g. the out-of-distribution)., Two key applications, semi-supervised learning and adversarial training, are taken as examples to validate the effectiveness of DSGAN., We also provide theoretical analyses about the convergence of DSGAN.",13,6.226890756302521,8.5
116,"['Recently, Generative Adversarial Network (GAN) and numbers of its variants have been widely used to solve the image-to-image translation problem and achieved extraordinary results in both a supervised and unsupervised manner.', 'However, most GAN-based methods suffer from the imbalance problem between the generator and discriminator in practice.', 'Namely, the relative model capacities of the generator and discriminator do not match, leading to mode collapse and/or diminished gradients.', 'To tackle this problem, we propose a GuideGAN based on attention mechanism.', 'More specifically, we arm the discriminator with an attention mechanism so not only it estimates the probability that its input is real, but also does it create an attention map that highlights the critical features for such prediction.', 'This attention map then assists the generator to produce more plausible and realistic images.', 'We extensively evaluate the proposed GuideGAN framework on a  number of image transfer tasks.', 'Both qualitative results and quantitative comparison demonstrate the superiority of our proposed approach.']","[0, 0, 0, 0, 0, 0, 1, 0]","[0.12765957415103912, 0.12121211737394333, 0.1621621549129486, 0.06666666269302368, 0.19999998807907104, 0.1249999925494194, 0.25, 0.12903225421905518]",rJl3YC4YPH,"['A general method that improves the image translation performance of GAN framework by using an attention embedded discriminator', 'A feedback mechanism in the GAN framework which improves the quality of generated images in image-to-image translation, and whose discriminator outputs a map indicating where the generator should focus to make its results more convincing.', 'Proposal for a GAN with an attention-based discriminator for I2I translation which provides the probability of real/fake and an attention map which reflects salience for image generation.']","['recently  generative adversarial network  gan  number variant widely used solve imagetoimage translation problem achieved extraordinary result supervised unsupervised manner ', 'however  ganbased method suffer imbalance problem generator discriminator practice ', 'namely  relative model capacity generator discriminator match  leading mode collapse andor diminished gradient ', 'tackle problem  propose guidegan based attention mechanism ', 'specifically  arm discriminator attention mechanism estimate probability input real  also create attention map highlight critical feature prediction ', 'attention map assist generator produce plausible realistic image ', 'extensively evaluate proposed guidegan framework number image transfer task ', 'qualitative result quantitative comparison demonstrate superiority proposed approach ']","Recently, Generative Adversarial Network (GAN) and numbers of its variants have been widely used to solve the image-to-image translation problem and achieved extraordinary results in both a supervised and unsupervised manner., However, most GAN-based methods suffer from the imbalance problem between the generator and discriminator in practice., Namely, the relative model capacities of the generator and discriminator do not match, leading to mode collapse and/or diminished gradients., To tackle this problem, we propose a GuideGAN based on attention mechanism., More specifically, we arm the discriminator with an attention mechanism so not only it estimates the probability that its input is real, but also does it create an attention map that highlights the critical features for such prediction., This attention map then assists the generator to produce more plausible and realistic images., We extensively evaluate the proposed GuideGAN framework on a  number of image transfer tasks., Both qualitative results and quantitative comparison demonstrate the superiority of our proposed approach.",15,5.8734177215189876,10.533333333333333
117,"['The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation.', 'However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains unexplored.', 'This paper specifically aims to study the fact verification given semi-structured data as evidence.', 'To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED.', 'TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning.', 'To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA).', 'Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification.', 'LPA parses statements into LISP-like programs and executes them against the tables to obtain the returned binary value for verification.', 'Both methods achieve similar accuracy but still lag far behind human performance.', 'We also perform a comprehensive analysis to demonstrate great future opportunities.']","[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.17391303181648254, 0.1249999925494194, 0.27586206793785095, 0.17777776718139648, 0.0, 0.0, 0.12121211737394333, 0.11764705181121826, 0.0, 0.23076923191547394]",rkeJRhNYDH,"['We propose a new dataset to investigate the entailment problem under semi-structured table as premise', 'This paper proposes a new dataset for table-based fact verification and introduces methods for the task.', 'The authors propose the problem of fact verification with semi-structured data sources such as tables, create a new dataset, and evaluate baseline models with variations.']","['problem verifying whether textual hypothesis hold based given evidence  also known fact verification  play important role study natural language understanding semantic representation ', 'however  existing study mainly restricted dealing unstructured evidence  eg  natural language sentence document  news  etc   verification structured evidence  table  graph  database  remains unexplored ', 'paper specifically aim study fact verification given semistructured data evidence ', 'end  construct largescale dataset called tabfact 16k wikipedia table evidence 118k humanannotated natural language statement  labeled either entailed refuted ', 'tabfact challenging since involves soft linguistic reasoning hard symbolic reasoning ', 'address reasoning challenge  design two different model  tablebert latent program algorithm  lpa  ', 'tablebert leverage stateoftheart pretrained language model encode linearized table statement continuous vector verification ', 'lpa par statement lisplike program executes table obtain returned binary value verification ', 'method achieve similar accuracy still lag far behind human performance ', 'also perform comprehensive analysis demonstrate great future opportunity ']","The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation., However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains unexplored., This paper specifically aims to study the fact verification given semi-structured data as evidence., To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED., TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning., To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA)., Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification., LPA parses statements into LISP-like programs and executes them against the tables to obtain the returned binary value for verification., Both methods achieve similar accuracy but still lag far behind human performance., We also perform a comprehensive analysis to demonstrate great future opportunities.",24,6.1683168316831685,8.416666666666666
118,"['This work presents a two-stage neural architecture for learning and refining structural correspondences between graphs.', 'First, we use localized node embeddings computed by a graph neural network to obtain an initial ranking of soft correspondences between nodes.', 'Secondly, we employ synchronous message passing networks to iteratively re-rank the soft correspondences to reach a matching consensus in local neighborhoods between graphs.', 'We show, theoretically and empirically, that our message passing scheme computes a well-founded measure of consensus for corresponding neighborhoods, which is then used to guide the iterative re-ranking process.', 'Our purely local and sparsity-aware architecture scales well to large, real-world inputs while still being able to recover global correspondences consistently.', 'We demonstrate the practical effectiveness of our method on real-world tasks from the fields of computer vision and entity alignment between knowledge graphs, on which we improve upon the current state-of-the-art.']","[0, 0, 1, 0, 0, 0]","[0.1875, 0.25641024112701416, 0.3589743673801422, 0.21739129722118378, 0.1621621549129486, 0.09090908616781235]",HyeJf1HKvS,"['We develop a deep graph matching architecture which refines initial correspondences in order to reach neighborhood consensus.', 'A framework for answering graph matching questions consisting of local node embeddings with a message passing refinement step.', 'A two-stage GNN-based architecture to establish correspondences between two graphs that performs well on real-world tasks of image matching and knowledge graph entity alignment.']","['work present twostage neural architecture learning refining structural correspondence graph ', 'first  use localized node embeddings computed graph neural network obtain initial ranking soft correspondence node ', 'secondly  employ synchronous message passing network iteratively rerank soft correspondence reach matching consensus local neighborhood graph ', 'show  theoretically empirically  message passing scheme computes wellfounded measure consensus corresponding neighborhood  used guide iterative reranking process ', 'purely local sparsityaware architecture scale well large  realworld input still able recover global correspondence consistently ', 'demonstrate practical effectiveness method realworld task field computer vision entity alignment knowledge graph  improve upon current stateoftheart ']","This work presents a two-stage neural architecture for learning and refining structural correspondences between graphs., First, we use localized node embeddings computed by a graph neural network to obtain an initial ranking of soft correspondences between nodes., Secondly, we employ synchronous message passing networks to iteratively re-rank the soft correspondences to reach a matching consensus in local neighborhoods between graphs., We show, theoretically and empirically, that our message passing scheme computes a well-founded measure of consensus for corresponding neighborhoods, which is then used to guide the iterative re-ranking process., Our purely local and sparsity-aware architecture scales well to large, real-world inputs while still being able to recover global correspondences consistently., We demonstrate the practical effectiveness of our method on real-world tasks from the fields of computer vision and entity alignment between knowledge graphs, on which we improve upon the current state-of-the-art.",13,6.205673758865248,10.846153846153847
119,"['This paper extends the proof of density of neural networks in the space of continuous (or even measurable) functions on Euclidean spaces to functions on compact sets of probability measures.\n', 'By doing so the work parallels a more then a decade old results on mean-map embedding of probability measures in reproducing kernel Hilbert spaces.  \n', 'The work has wide practical consequences for multi-instance learning, where it theoretically justifies some recently proposed constructions.\n', 'The result is then extended to Cartesian products, yielding universal approximation theorem for tree-structured domains, which naturally occur in data-exchange formats like JSON, XML, YAML, AVRO, and ProtoBuffer.', 'This has important practical implications, as it enables to automatically create an architecture of neural networks for processing structured data (AutoML paradigms), as demonstrated by an accompanied library for JSON format.']","[1, 0, 0, 0, 0]","[1.0, 0.3265306055545807, 0.04651162400841713, 0.07547169178724289, 0.18867923319339752]",HklJV3A9Ym,"['This paper extends the proof of density of neural networks in the space of continuous (or even measurable) functions on Euclidean spaces to functions on compact sets of probability measures. ', 'This paper investigates the approximation properties of a family of neural networks designed to address multi-instance learning problems, and shows that results for standard one layer architectures extend to these models.', 'This paper generalizes the universal approximation theorem to real functions on the space of measures.']","['paper extends proof density neural network space continuous  even measurable  function euclidean space function compact set probability measure ', 'work parallel decade old result meanmap embedding probability measure reproducing kernel hilbert space ', 'work wide practical consequence multiinstance learning  theoretically justifies recently proposed construction ', 'result extended cartesian product  yielding universal approximation theorem treestructured domain  naturally occur dataexchange format like json  xml  yaml  avro  protobuffer ', 'important practical implication  enables automatically create architecture neural network processing structured data  automl paradigm   demonstrated accompanied library json format ']","This paper extends the proof of density of neural networks in the space of continuous (or even measurable) functions on Euclidean spaces to functions on compact sets of probability measures.
, By doing so the work parallels a more then a decade old results on mean-map embedding of probability measures in reproducing kernel Hilbert spaces.  
, The work has wide practical consequences for multi-instance learning, where it theoretically justifies some recently proposed constructions.
, The result is then extended to Cartesian products, yielding universal approximation theorem for tree-structured domains, which naturally occur in data-exchange formats like JSON, XML, YAML, AVRO, and ProtoBuffer., This has important practical implications, as it enables to automatically create an architecture of neural networks for processing structured data (AutoML paradigms), as demonstrated by an accompanied library for JSON format.",14,6.0,9.285714285714286
120,"['Interactions such as double negation in sentences and scene interactions in images are common forms of complex dependencies captured by state-of-the-art machine learning models.', 'We propose Mah, a novel approach to provide Model-Agnostic Hierarchical Explanations of how powerful machine learning models, such as deep neural networks, capture these interactions as either dependent on or free of the context of data instances.', 'Specifically, Mah provides context-dependent explanations by a novel local interpretation algorithm that effectively captures any-order interactions, and obtains context-free explanations through generalizing context-dependent interactions to explain global behaviors.', 'Experimental results show that Mah obtains improved local interaction interpretations over state-of-the-art methods and successfully provides explanations of interactions that are context-free.']","[0, 0, 0, 1]","[0.12121211737394333, 0.045454543083906174, 0.2222222238779068, 0.25806450843811035]",rkMD73A5FX,"['A new framework for context-dependent and context-free explanations of predictions', 'The authors extend the linear local attribution method LIME for interpreting black box models, and propose a method to discern between context-dependent and context-free interactions.', 'A method that can provide hierarchical explanations for a model, including both context-dependent and context-free explanations by a local interpretation algorithm.']","['interaction double negation sentence scene interaction image common form complex dependency captured stateoftheart machine learning model ', 'propose mah  novel approach provide modelagnostic hierarchical explanation powerful machine learning model  deep neural network  capture interaction either dependent free context data instance ', 'specifically  mah provides contextdependent explanation novel local interpretation algorithm effectively capture anyorder interaction  obtains contextfree explanation generalizing contextdependent interaction explain global behavior ', 'experimental result show mah obtains improved local interaction interpretation stateoftheart method successfully provides explanation interaction contextfree ']","Interactions such as double negation in sentences and scene interactions in images are common forms of complex dependencies captured by state-of-the-art machine learning models., We propose Mah, a novel approach to provide Model-Agnostic Hierarchical Explanations of how powerful machine learning models, such as deep neural networks, capture these interactions as either dependent on or free of the context of data instances., Specifically, Mah provides context-dependent explanations by a novel local interpretation algorithm that effectively captures any-order interactions, and obtains context-free explanations through generalizing context-dependent interactions to explain global behaviors., Experimental results show that Mah obtains improved local interaction interpretations over state-of-the-art methods and successfully provides explanations of interactions that are context-free.",9,6.990990990990991,12.333333333333334
121,"['To realize the promise of ubiquitous embedded deep network inference, it is essential to seek limits of energy and area efficiency.  ', 'To this end, low-precision networks offer tremendous promise because both energy and area scale down quadratically with the reduction in precision.  ', 'Here, for the first time, we demonstrate ResNet-18, ResNet-34, ResNet-50, ResNet-152, Inception-v3, densenet-161, and VGG-16bn networks on the ImageNet classification benchmark that, at 8-bit precision exceed the accuracy of the full-precision baseline networks after one epoch of finetuning, thereby leveraging the availability of pretrained models.\n', 'We also demonstrate ResNet-18, ResNet-34, and ResNet-50 4-bit models that match the accuracy of the full-precision baseline networks -- the highest scores to date.', 'Surprisingly, the weights of the low-precision networks are very close (in cosine similarity) to the weights of the corresponding baseline networks, making training from scratch unnecessary.\n\n', 'We find that gradient noise due to quantization during training increases with reduced precision, and seek ways to overcome this noise.', 'The number of iterations required by stochastic gradient descent to achieve a given training error is related to the square of (a) the distance of the initial solution from the final plus (b) the maximum variance of the gradient estimates.  ', 'By drawing inspiration from this observation, we (a) reduce solution distance by starting with pretrained fp32 precision baseline networks and fine-tuning, and (b) combat noise introduced by quantizing weights and activations during training, by using larger batches along with matched learning rate annealing.  ', 'Sensitivity analysis indicates that these techniques, coupled with proper activation function range calibration, offer a promising heuristic to discover low-precision networks, if they exist, close to fp32 precision baseline networks.\n']","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.05714285373687744, 0.1666666567325592, 0.18867924809455872, 0.2222222238779068, 0.0555555522441864, 0.12121211737394333, 0.0, 0.07547169178724289, 0.045454539358615875]",BJx1SsAcYQ,"['Finetuning after quantization matches or exceeds full-precision state-of-the-art networks at both 8- and 4-bit quantization.', 'This paper proposes to improve the performance of low-precision models by doing quantization on pre-trained models, using large batches size, and using proper learning rate annealing with longer training time.', 'A method for low bit quantization to enable inference on efficient hardware that achieves full accuracy on ResNet50 with 4-bit weights and activations, based on observations that fine-tuning at low precision introduces noise in the gradient.']","['realize promise ubiquitous embedded deep network inference  essential seek limit energy area efficiency ', 'end  lowprecision network offer tremendous promise energy area scale quadratically reduction precision ', ' first time  demonstrate resnet18  resnet34  resnet50  resnet152  inceptionv3  densenet161  vgg16bn network imagenet classification benchmark  8bit precision exceed accuracy fullprecision baseline network one epoch finetuning  thereby leveraging availability pretrained model ', 'also demonstrate resnet18  resnet34  resnet50 4bit model match accuracy fullprecision baseline network  highest score date ', 'surprisingly  weight lowprecision network close  cosine similarity  weight corresponding baseline network  making training scratch unnecessary ', 'find gradient noise due quantization training increase reduced precision  seek way overcome noise ', 'number iteration required stochastic gradient descent achieve given training error related square   distance initial solution final plus  b  maximum variance gradient estimate ', 'drawing inspiration observation    reduce solution distance starting pretrained fp32 precision baseline network finetuning   b  combat noise introduced quantizing weight activation training  using larger batch along matched learning rate annealing ', 'sensitivity analysis indicates technique  coupled proper activation function range calibration  offer promising heuristic discover lowprecision network  exist  close fp32 precision baseline network ']","To realize the promise of ubiquitous embedded deep network inference, it is essential to seek limits of energy and area efficiency.  , To this end, low-precision networks offer tremendous promise because both energy and area scale down quadratically with the reduction in precision.  , Here, for the first time, we demonstrate ResNet-18, ResNet-34, ResNet-50, ResNet-152, Inception-v3, densenet-161, and VGG-16bn networks on the ImageNet classification benchmark that, at 8-bit precision exceed the accuracy of the full-precision baseline networks after one epoch of finetuning, thereby leveraging the availability of pretrained models.
, We also demonstrate ResNet-18, ResNet-34, and ResNet-50 4-bit models that match the accuracy of the full-precision baseline networks -- the highest scores to date., Surprisingly, the weights of the low-precision networks are very close (in cosine similarity) to the weights of the corresponding baseline networks, making training from scratch unnecessary.

, We find that gradient noise due to quantization during training increases with reduced precision, and seek ways to overcome this noise., The number of iterations required by stochastic gradient descent to achieve a given training error is related to the square of (a) the distance of the initial solution from the final plus (b) the maximum variance of the gradient estimates.  , By drawing inspiration from this observation, we (a) reduce solution distance by starting with pretrained fp32 precision baseline networks and fine-tuning, and (b) combat noise introduced by quantizing weights and activations during training, by using larger batches along with matched learning rate annealing.  , Sensitivity analysis indicates that these techniques, coupled with proper activation function range calibration, offer a promising heuristic to discover low-precision networks, if they exist, close to fp32 precision baseline networks.
",33,5.952029520295203,8.212121212121213
122,"['  Analysis methods which enable us to better understand the\n  representations and functioning of neural models of language are\n  increasingly needed as deep learning becomes the dominant approach\n  in NLP.', 'Here we present two methods based on Representational\n  Similarity Analysis (RSA) and Tree Kernels (TK) which allow us to\n  directly quantify how strongly the information encoded in neural\n  activation patterns corresponds to information represented by\n  symbolic structures such as syntax trees.', 'We first validate our\n  methods on the case of a simple synthetic language for arithmetic\n  expressions with clearly defined syntax and semantics, and show that\n  they exhibit the expected pattern of results.', 'We then apply our methods to\n  correlate neural representations of English sentences with their\n  constituency parse trees.']","[0, 1, 0, 0]","[0.25, 0.8235294222831726, 0.10344827175140381, 0.1304347813129425]",ryx35Ehi84,['Two methods based on Representational Similarity Analysis (RSA) and Tree Kernels (TK) which directly quantify how strongly information encoded in neural activation patterns corresponds to information represented by symbolic structures.'],"['analysis method enable u better understand representation functioning neural model language increasingly needed deep learning becomes dominant approach nlp ', 'present two method based representational similarity analysis  rsa  tree kernel  tk  allow u directly quantify strongly information encoded neural activation pattern corresponds information represented symbolic structure syntax tree ', 'first validate method case simple synthetic language arithmetic expression clearly defined syntax semantics  show exhibit expected pattern result ', 'apply method correlate neural representation english sentence constituency parse tree ']","  Analysis methods which enable us to better understand the
  representations and functioning of neural models of language are
  increasingly needed as deep learning becomes the dominant approach
  in NLP., Here we present two methods based on Representational
  Similarity Analysis (RSA) and Tree Kernels (TK) which allow us to
  directly quantify how strongly the information encoded in neural
  activation patterns corresponds to information represented by
  symbolic structures such as syntax trees., We first validate our
  methods on the case of a simple synthetic language for arithmetic
  expressions with clearly defined syntax and semantics, and show that
  they exhibit the expected pattern of results., We then apply our methods to
  correlate neural representations of English sentences with their
  constituency parse trees.",5,5.798319327731092,23.8
123,"['Supervised deep learning requires a large amount of training samples with annotations (e.g. label class for classification task, pixel- or voxel-wised label map for segmentation tasks), which are expensive and time-consuming to obtain.', 'During the training of a deep neural network, the annotated samples are fed into the network in a mini-batch way, where they are often regarded of equal importance.', 'However, some of the samples may become less informative during training, as the magnitude of the gradient start to vanish for these samples.', 'In the meantime, other samples of higher utility or hardness may be more demanded for the training process to proceed and require more exploitation.', 'To address the challenges of expensive annotations and loss of sample informativeness, here we propose a novel training framework which adaptively selects informative samples that are fed to the training process.', 'The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model.', 'To evaluate the proposed training framework, we perform experiments on three different datasets, including MNIST and CIFAR-10 for image classification task and a medical image dataset IVUS for biophysical simulation task.', 'On all three datasets, the proposed framework outperforms a random sampling method, which demonstrates the effectiveness of our framework.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.12765957415103912, 0.10526315122842789, 0.05882352590560913, 0.05405404791235924, 0.09302324801683426, 0.4000000059604645, 0.0952380895614624, 0.1875]",Byl3HxBFwH,"['This paper introduces a framework for data-efficient representation learning by adaptive sampling in latent space.', 'A method for sequential and adaptive selection of training examples to be presented to the training algorithm, where selection happens in the latent space based on choosing samples in the direction of the gradient of the loss.', 'A method to efficiently select hard samples during neural network training, achieved via a variational auto-encoder that encodes samples into a latent space.']","['supervised deep learning requires large amount training sample annotation  eg  label class classification task  pixel voxelwised label map segmentation task   expensive timeconsuming obtain ', 'training deep neural network  annotated sample fed network minibatch way  often regarded equal importance ', 'however  sample may become le informative training  magnitude gradient start vanish sample ', 'meantime  sample higher utility hardness may demanded training process proceed require exploitation ', 'address challenge expensive annotation loss sample informativeness  propose novel training framework adaptively selects informative sample fed training process ', 'adaptive selection sampling performed based hardnessaware strategy latent space constructed generative model ', 'evaluate proposed training framework  perform experiment three different datasets  including mnist cifar10 image classification task medical image dataset ivus biophysical simulation task ', 'three datasets  proposed framework outperforms random sampling method  demonstrates effectiveness framework ']","Supervised deep learning requires a large amount of training samples with annotations (e.g. label class for classification task, pixel- or voxel-wised label map for segmentation tasks), which are expensive and time-consuming to obtain., During the training of a deep neural network, the annotated samples are fed into the network in a mini-batch way, where they are often regarded of equal importance., However, some of the samples may become less informative during training, as the magnitude of the gradient start to vanish for these samples., In the meantime, other samples of higher utility or hardness may be more demanded for the training process to proceed and require more exploitation., To address the challenges of expensive annotations and loss of sample informativeness, here we propose a novel training framework which adaptively selects informative samples that are fed to the training process., The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model., To evaluate the proposed training framework, we perform experiments on three different datasets, including MNIST and CIFAR-10 for image classification task and a medical image dataset IVUS for biophysical simulation task., On all three datasets, the proposed framework outperforms a random sampling method, which demonstrates the effectiveness of our framework.",20,5.628571428571429,10.0
124,"['Existing methods for AI-generated artworks still struggle with generating high-quality stylized content, where high-level semantics are preserved, or separating fine-grained styles from various artists.', 'We propose a novel Generative Adversarial Disentanglement Network which can disentangle two complementary factors of variations when only one of them is labelled in general, and fully decompose complex anime illustrations into style and content in particular.', 'Training such model is challenging, since given a style, various content data may exist but not the other way round.', 'Our approach is divided into two stages, one that encodes an input image into a style independent content, and one based on a dual-conditional generator.', 'We demonstrate the ability to generate high-fidelity anime portraits with a fixed content and a large variety of styles from over a thousand artists, and vice versa, using a single end-to-end network and with applications in style transfer.', 'We show this unique capability as well as superior output to the current state-of-the-art.']","[0, 1, 0, 0, 0, 0]","[0.07843136787414551, 0.4590163826942444, 0.12765957415103912, 0.2448979616165161, 0.20338982343673706, 0.0]",BJe4V1HFPr,"['An adversarial training-based method for disentangling two complementary sets of variations in a dataset where only one of them is labelled, tested on style vs. content in anime illustrations.', 'An image generation method combining conditional GANs and conditional VAEs that generates high fidelity anime images with various styles from various artists. ', 'Proposal for a method to learn disentangled style (artist) and content representations in anime.']","['existing method aigenerated artwork still struggle generating highquality stylized content  highlevel semantics preserved  separating finegrained style various artist ', 'propose novel generative adversarial disentanglement network disentangle two complementary factor variation one labelled general  fully decompose complex anime illustration style content particular ', 'training model challenging  since given style  various content data may exist way round ', 'approach divided two stage  one encodes input image style independent content  one based dualconditional generator ', 'demonstrate ability generate highfidelity anime portrait fixed content large variety style thousand artist  vice versa  using single endtoend network application style transfer ', 'show unique capability well superior output current stateoftheart ']","Existing methods for AI-generated artworks still struggle with generating high-quality stylized content, where high-level semantics are preserved, or separating fine-grained styles from various artists., We propose a novel Generative Adversarial Disentanglement Network which can disentangle two complementary factors of variations when only one of them is labelled in general, and fully decompose complex anime illustrations into style and content in particular., Training such model is challenging, since given a style, various content data may exist but not the other way round., Our approach is divided into two stages, one that encodes an input image into a style independent content, and one based on a dual-conditional generator., We demonstrate the ability to generate high-fidelity anime portraits with a fixed content and a large variety of styles from over a thousand artists, and vice versa, using a single end-to-end network and with applications in style transfer., We show this unique capability as well as superior output to the current state-of-the-art.",15,5.689873417721519,10.533333333333333
125,"['Recent research has shown that CNNs are often overly sensitive to high-frequency textural patterns.', 'Inspired by the intuition that humans are more sensitive to the lower-frequency (larger-scale) patterns we design a regularization scheme that penalizes large differences between adjacent components within each convolutional kernel.', 'We apply our regularization onto several popular training methods, demonstrating that the models with the proposed smooth kernels enjoy improved adversarial robustness.', 'Further, building on recent work establishing connections between adversarial robustness and interpretability, we show that our method appears to give more perceptually-aligned gradients.']","[0, 0, 0, 1]","[0.11428570747375488, 0.20408162474632263, 0.2857142686843872, 0.3181818127632141]",BJerUCEtPB,"['We introduce a smoothness regularization for convolutional kernels of CNN that can help improve adversarial robustness and lead to perceptually-aligned gradients', 'This paper proposes a new regularization scheme that encourages convolutional kernels to be smoother, arguing that reducing neural network reliance on high-frequency components helps robustness against adversarial examples. ', 'The authors propose a method for learning smoother convolutional kernels, specifically, a regularizer penalizing large changes between consecutive pixels of the kernel with the intuition of penalizing the use of high-frequency input components.']","['recent research shown cnns often overly sensitive highfrequency textural pattern ', 'inspired intuition human sensitive lowerfrequency  largerscale  pattern design regularization scheme penalizes large difference adjacent component within convolutional kernel ', 'apply regularization onto several popular training method  demonstrating model proposed smooth kernel enjoy improved adversarial robustness ', ' building recent work establishing connection adversarial robustness interpretability  show method appears give perceptuallyaligned gradient ']","Recent research has shown that CNNs are often overly sensitive to high-frequency textural patterns., Inspired by the intuition that humans are more sensitive to the lower-frequency (larger-scale) patterns we design a regularization scheme that penalizes large differences between adjacent components within each convolutional kernel., We apply our regularization onto several popular training methods, demonstrating that the models with the proposed smooth kernels enjoy improved adversarial robustness., Further, building on recent work establishing connections between adversarial robustness and interpretability, we show that our method appears to give more perceptually-aligned gradients.",7,6.719101123595506,12.714285714285714
126,"['Despite an ever growing literature on reinforcement learning algorithms and applications, much less is known about their statistical inference.', 'In this paper, we investigate the large-sample behaviors of the Q-value estimates with closed-form characterizations of the asymptotic variances.', 'This allows us to efficiently construct confidence regions for Q-value and optimal value functions, and to develop policies to minimize their estimation errors.', 'This also leads to a policy exploration strategy that relies on estimating the relative discrepancies among the Q estimates.', 'Numerical experiments show superior performances of our exploration strategy than other benchmark approaches.']","[0, 0, 0, 1, 0]","[0.1428571343421936, 0.3589743673801422, 0.09302324801683426, 0.5853658318519592, 0.1666666567325592]",r1ez_K1wPH,['We investigate the large-sample behaviors of the Q-value estimates and proposed an efficient exploration strategy that relies on estimating the relative discrepancies among the Q estimates. '],"['despite ever growing literature reinforcement learning algorithm application  much le known statistical inference ', 'paper  investigate largesample behavior qvalue estimate closedform characterization asymptotic variance ', 'allows u efficiently construct confidence region qvalue optimal value function  develop policy minimize estimation error ', 'also lead policy exploration strategy relies estimating relative discrepancy among q estimate ', 'numerical experiment show superior performance exploration strategy benchmark approach ']","Despite an ever growing literature on reinforcement learning algorithms and applications, much less is known about their statistical inference., In this paper, we investigate the large-sample behaviors of the Q-value estimates with closed-form characterizations of the asymptotic variances., This allows us to efficiently construct confidence regions for Q-value and optimal value functions, and to develop policies to minimize their estimation errors., This also leads to a policy exploration strategy that relies on estimating the relative discrepancies among the Q estimates., Numerical experiments show superior performances of our exploration strategy than other benchmark approaches.",8,6.344086021505376,11.625
127,"['Entailment vectors are a principled way to encode in a vector what information is known and what is unknown.  ', 'They are designed to model relations where one vector should include all the information in another vector, called entailment.  ', 'This paper investigates the unsupervised learning of entailment vectors for the semantics of words.  ', 'Using simple entailment-based models of the semantics of words in text (distributional semantics), we induce entailment-vector word embeddings which outperform the best previous results for predicting entailment between words, in unsupervised and semi-supervised experiments on hyponymy.\n']","[0, 0, 0, 1]","[0.0, 0.060606054961681366, 0.1538461446762085, 0.25531914830207825]",S1Q79heRW,"['We train word embeddings based on entailment instead of similarity, successfully predicting lexical entailment.', 'The paper presents a word embedding algorithm for lexical entailment which follows the work of Henderson and Popa (ACL, 2016).']","['entailment vector principled way encode vector information known unknown ', 'designed model relation one vector include information another vector  called entailment ', 'paper investigates unsupervised learning entailment vector semantics word ', 'using simple entailmentbased model semantics word text  distributional semantics   induce entailmentvector word embeddings outperform best previous result predicting entailment word  unsupervised semisupervised experiment hyponymy ']","Entailment vectors are a principled way to encode in a vector what information is known and what is unknown.  , They are designed to model relations where one vector should include all the information in another vector, called entailment.  , This paper investigates the unsupervised learning of entailment vectors for the semantics of words.  , Using simple entailment-based models of the semantics of words in text (distributional semantics), we induce entailment-vector word embeddings which outperform the best previous results for predicting entailment between words, in unsupervised and semi-supervised experiments on hyponymy.
",7,6.056818181818182,12.571428571428571
128,"['We describe a simple scheme that allows an agent to learn about its environment in an unsupervised manner.', 'Our scheme pits two versions of the same agent, Alice and Bob, against one another.', 'Alice proposes a task for Bob to complete; and then Bob attempts to complete the task.  ', 'In this work we will focus on two kinds of environments: (nearly) reversible environments and environments that can be reset.', 'Alice will ""propose"" the task by doing a sequence of actions and then Bob must undo or repeat them, respectively.  ', 'Via an appropriate reward structure, Alice and Bob automatically generate a curriculum of exploration, enabling unsupervised training of the agent.', 'When Bob is deployed on an RL task within the environment, this unsupervised training reduces the number of supervised episodes needed to learn, and in some cases converges to a higher reward.']","[0, 0, 0, 0, 0, 1, 0]","[0.07407406717538834, 0.07999999821186066, 0.0833333283662796, 0.06896550953388214, 0.06451612710952759, 0.20689654350280762, 0.09999999403953552]",SkT5Yg-RZ,"['Unsupervised learning for reinforcement learning using an automatic curriculum of self-play', 'A new formulation for exploring the environment in an unsupervised way to aid a specific task later, where one agent proposes increasingly difficult tasks and the learning agent tries to accomplish them.', 'A self-play model where one agent learns to propose tasks that are easy for them but difficult for an opponent, creating a moving target of self-play objectives and learning curriculum. ']","['describe simple scheme allows agent learn environment unsupervised manner ', 'scheme pit two version agent  alice bob  one another ', 'alice proposes task bob complete  bob attempt complete task ', 'work focus two kind environment   nearly  reversible environment environment reset ', 'alice  propose  task sequence action bob must undo repeat  respectively ', 'via appropriate reward structure  alice bob automatically generate curriculum exploration  enabling unsupervised training agent ', 'bob deployed rl task within environment  unsupervised training reduces number supervised episode needed learn  case converges higher reward ']","We describe a simple scheme that allows an agent to learn about its environment in an unsupervised manner., Our scheme pits two versions of the same agent, Alice and Bob, against one another., Alice proposes a task for Bob to complete; and then Bob attempts to complete the task.  , In this work we will focus on two kinds of environments: (nearly) reversible environments and environments that can be reset., Alice will ""propose"" the task by doing a sequence of actions and then Bob must undo or repeat them, respectively.  , Via an appropriate reward structure, Alice and Bob automatically generate a curriculum of exploration, enabling unsupervised training of the agent., When Bob is deployed on an RL task within the environment, this unsupervised training reduces the number of supervised episodes needed to learn, and in some cases converges to a higher reward.",14,5.042553191489362,10.071428571428571
129,"['Many real-world data sets are represented as graphs, such as citation links, social media, and biological interaction.', ""The volatile graph structure makes it non-trivial to employ convolutional neural networks (CNN's) for graph data processing."", 'Recently, graph attention network (GAT) has proven a promising attempt by combining graph neural networks with attention mechanism, so as to achieve massage passing in graphs with arbitrary structures.', 'However, the attention in GAT is computed mainly based on the similarity between the node content, while the structures of the graph remains largely unemployed (except in masking the attention out of one-hop neighbors).', 'In this paper, we propose an `````````````````````````````""ADaptive Structural Fingerprint"" (ADSF) model to fully exploit both topological details of the graph and  content features of the nodes.', 'The key idea is to contextualize each node with a weighted, learnable receptive field  encoding rich and diverse local graph structures.', 'By doing this, structural interactions between the nodes can  be inferred accurately, thus improving subsequent attention layer as well as the convergence of learning.', ""Furthermore, our model provides a useful platform  for different subspaces of node features and various scales of graph structures to ``cross-talk'' with each other through the learning of multi-head attention, being particularly useful in handling complex real-world data.  "", 'Encouraging performance is observed on a number of benchmark data sets in node classification.']","[0, 0, 0, 0, 0, 0, 0, 0, 1]","[0.07407406717538834, 0.07407406717538834, 0.054054051637649536, 0.054054051637649536, 0.05714285373687744, 0.0624999962747097, 0.0, 0.08510638028383255, 0.1599999964237213]",BJxWx0NYPr,"['Exploiting rich strucural details in graph-structued data via adaptive ""strucutral fingerprints\'\'', 'A graph structure based methodology to augment the attention mechanism of graph neural networks, with the main idea to explore interactions between different types of nodes of the local neighborhood of a root node.', 'This paper extends the idea of self-attention in graph NNs, which is typically based on feature similarity between nodes, to include structural similarity.']","['many realworld data set represented graph  citation link  social medium  biological interaction ', 'volatile graph structure make nontrivial employ convolutional neural network  cnn  graph data processing ', 'recently  graph attention network  gat  proven promising attempt combining graph neural network attention mechanism  achieve massage passing graph arbitrary structure ', 'however  attention gat computed mainly based similarity node content  structure graph remains largely unemployed  except masking attention onehop neighbor  ', 'paper  propose                 adaptive structural fingerprint   adsf  model fully exploit topological detail graph content feature node ', 'key idea contextualize node weighted  learnable receptive field encoding rich diverse local graph structure ', ' structural interaction node inferred accurately  thus improving subsequent attention layer well convergence learning ', 'furthermore  model provides useful platform different subspace node feature various scale graph structure  crosstalk  learning multihead attention  particularly useful handling complex realworld data ', 'encouraging performance observed number benchmark data set node classification ']","Many real-world data sets are represented as graphs, such as citation links, social media, and biological interaction., The volatile graph structure makes it non-trivial to employ convolutional neural networks (CNN's) for graph data processing., Recently, graph attention network (GAT) has proven a promising attempt by combining graph neural networks with attention mechanism, so as to achieve massage passing in graphs with arbitrary structures., However, the attention in GAT is computed mainly based on the similarity between the node content, while the structures of the graph remains largely unemployed (except in masking the attention out of one-hop neighbors)., In this paper, we propose an `````````````````````````````""ADaptive Structural Fingerprint"" (ADSF) model to fully exploit both topological details of the graph and  content features of the nodes., The key idea is to contextualize each node with a weighted, learnable receptive field  encoding rich and diverse local graph structures., By doing this, structural interactions between the nodes can  be inferred accurately, thus improving subsequent attention layer as well as the convergence of learning., Furthermore, our model provides a useful platform  for different subspaces of node features and various scales of graph structures to ``cross-talk'' with each other through the learning of multi-head attention, being particularly useful in handling complex real-world data.  , Encouraging performance is observed on a number of benchmark data sets in node classification.",22,5.904545454545454,10.0
130,"['Informed and robust decision making in the face of uncertainty is critical for robots that perform physical tasks alongside people.', 'We formulate this as a Bayesian Reinforcement Learning problem over latent Markov Decision Processes (MDPs).', 'While Bayes-optimality is theoretically the gold standard, existing algorithms do not scale well to continuous state and action spaces.', 'We propose a scalable solution that builds on the following insight: in the absence of uncertainty, each latent MDP is easier to solve.', 'We split the challenge into two simpler components.', 'First, we obtain an ensemble of clairvoyant experts and fuse their advice to compute a baseline policy.', ""Second, we train a Bayesian residual policy to improve upon the ensemble's recommendation and learn to reduce uncertainty."", 'Our algorithm, Bayesian Residual Policy Optimization (BRPO), imports the scalability of policy gradient methods as well as the initialization from prior models.', 'BRPO significantly improves the ensemble of experts and drastically outperforms existing adaptive RL methods.']","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.1304347813129425, 0.3414634168148041, 0.08888888359069824, 0.375, 0.05882352590560913, 0.3720930218696594, 0.1860465109348297, 0.08695651590824127, 0.19999998807907104]",B1grSREtDH,"['We propose a scalable Bayesian Reinforcement Learning algorithm that learns a Bayesian correction over an ensemble of clairvoyant experts to solve problems with complex latent rewards and dynamics.', 'This paper considers Bayesian Reinforcement Learning problem over latent Markov Decision Processes (MDPs) by making decisions with experts.', 'In this paper, the authors motivate and propose a learning algorithm, called Bayesian Residual Policy Optimization (BRPO), for Bayesian reinforcement learning problems.']","['informed robust decision making face uncertainty critical robot perform physical task alongside people ', 'formulate bayesian reinforcement learning problem latent markov decision process  mdps  ', 'bayesoptimality theoretically gold standard  existing algorithm scale well continuous state action space ', 'propose scalable solution build following insight  absence uncertainty  latent mdp easier solve ', 'split challenge two simpler component ', 'first  obtain ensemble clairvoyant expert fuse advice compute baseline policy ', 'second  train bayesian residual policy improve upon ensemble recommendation learn reduce uncertainty ', 'algorithm  bayesian residual policy optimization  brpo   import scalability policy gradient method well initialization prior model ', 'brpo significantly improves ensemble expert drastically outperforms existing adaptive rl method ']","Informed and robust decision making in the face of uncertainty is critical for robots that perform physical tasks alongside people., We formulate this as a Bayesian Reinforcement Learning problem over latent Markov Decision Processes (MDPs)., While Bayes-optimality is theoretically the gold standard, existing algorithms do not scale well to continuous state and action spaces., We propose a scalable solution that builds on the following insight: in the absence of uncertainty, each latent MDP is easier to solve., We split the challenge into two simpler components., First, we obtain an ensemble of clairvoyant experts and fuse their advice to compute a baseline policy., Second, we train a Bayesian residual policy to improve upon the ensemble's recommendation and learn to reduce uncertainty., Our algorithm, Bayesian Residual Policy Optimization (BRPO), imports the scalability of policy gradient methods as well as the initialization from prior models., BRPO significantly improves the ensemble of experts and drastically outperforms existing adaptive RL methods.",15,5.7756410256410255,10.4
131,"['One of the mysteries in the success of neural networks is randomly initialized first order methods like gradient descent can achieve zero training loss even though the objective function is non-convex and non-smooth.', 'This paper demystifies this surprising phenomenon for two-layer fully connected ReLU activated neural networks.', 'For an $m$ hidden node shallow neural network with ReLU activation and $n$ training data, we show as long as $m$ is large enough and no two inputs are parallel, randomly initialized gradient descent converges to a globally optimal solution at a linear convergence rate for the quadratic loss function.\n\n', 'Our analysis relies on the following observation: over-parameterization and random initialization jointly restrict every weight vector to be close to its initialization for all iterations, which allows us to exploit a strong convexity-like property to show that gradient descent converges at a global linear rate to the global optimum.', 'We believe these insights are also useful in analyzing deep models and other first order methods.']","[1, 0, 0, 0, 0]","[0.31111109256744385, 0.13333332538604736, 0.2857142686843872, 0.21052631735801697, 0.0624999962747097]",S1eK3i09YQ,"['We prove gradient descent achieves zero training loss with a linear rate on over-parameterized neural networks.', 'This work considers optimizing a two-layer over-parameterized ReLU network with the squared loss and given a data set with arbituary labels.', 'This paper studies one hidden layer neural networks with square loss, where they show that in over-parameterized setting, random initialization and gradient descent gets to zero loss.']","['one mystery success neural network randomly initialized first order method like gradient descent achieve zero training loss even though objective function nonconvex nonsmooth ', 'paper demystifies surprising phenomenon twolayer fully connected relu activated neural network ', '  hidden node shallow neural network relu activation  n  training data  show long   large enough two input parallel  randomly initialized gradient descent converges globally optimal solution linear convergence rate quadratic loss function ', 'analysis relies following observation  overparameterization random initialization jointly restrict every weight vector close initialization iteration  allows u exploit strong convexitylike property show gradient descent converges global linear rate global optimum ', 'believe insight also useful analyzing deep model first order method ']","One of the mysteries in the success of neural networks is randomly initialized first order methods like gradient descent can achieve zero training loss even though the objective function is non-convex and non-smooth., This paper demystifies this surprising phenomenon for two-layer fully connected ReLU activated neural networks., For an $m$ hidden node shallow neural network with ReLU activation and $n$ training data, we show as long as $m$ is large enough and no two inputs are parallel, randomly initialized gradient descent converges to a globally optimal solution at a linear convergence rate for the quadratic loss function.

, Our analysis relies on the following observation: over-parameterization and random initialization jointly restrict every weight vector to be close to its initialization for all iterations, which allows us to exploit a strong convexity-like property to show that gradient descent converges at a global linear rate to the global optimum., We believe these insights are also useful in analyzing deep models and other first order methods.",8,5.555555555555555,20.25
132,"['For many applications, in particular in natural science, the task is to\n', 'determine hidden system parameters from a set of measurements.', 'Often,\n', 'the forward process from parameter- to measurement-space is well-defined,\n', 'whereas the inverse problem is ambiguous: multiple parameter sets can\n', 'result in the same measurement.', 'To fully characterize this ambiguity, the full\n', 'posterior parameter distribution, conditioned on an observed measurement,\n', 'has to be determined.', 'We argue that a particular class of neural networks\n', 'is well suited for this task  so-called Invertible Neural Networks (INNs).\n', 'Unlike classical neural networks, which attempt to solve the ambiguous\n', 'inverse problem directly, INNs focus on learning the forward process, using\n', 'additional latent output variables to capture the information otherwise\n', 'lost.', 'Due to invertibility, a model of the corresponding inverse process is\n', 'learned implicitly.', 'Given a specific measurement and the distribution of\n', 'the latent variables, the inverse pass of the INN provides the full posterior\n', 'over parameter space.', 'We prove theoretically and verify experimentally, on\n', 'artificial data and real-world problems from medicine and astrophysics, that\n', 'INNs are a powerful analysis tool to find multi-modalities in parameter space,\n', 'uncover parameter correlations, and identify unrecoverable parameters.']","[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.0, 0.0, 0.0, 0.1111111044883728, 0.0, 0.13333332538604736, 0.0, 0.0, 0.0, 0.2857142686843872, 0.0, 0.10526315122842789, 0.0, 0.10526315122842789, 0.0, 0.1111111044883728, 0.0, 0.0, 0.11764705181121826, 0.0, 0.0]",rJed6j0cKX,"['To analyze inverse problems with Invertible Neural Networks', 'The author proposes to use invertible networks to solve ambiguous inverse problems and suggest to not only train the forward model, but also the inverse model with an MMD critic.', 'The research paper proposes an invertible network with observations for posterior probability of complex input distributions with a theoretical valid bidirectional training scheme.\n']","['many application  particular natural science  task', 'determine hidden system parameter set measurement ', 'often ', 'forward process parameter measurementspace welldefined ', 'whereas inverse problem ambiguous  multiple parameter set', 'result measurement ', 'fully characterize ambiguity  full', 'posterior parameter distribution  conditioned observed measurement ', 'determined ', 'argue particular class neural network', 'well suited task  socalled invertible neural network  inn  ', 'unlike classical neural network  attempt solve ambiguous', 'inverse problem directly  inn focus learning forward process  using', 'additional latent output variable capture information otherwise', 'lost ', 'due invertibility  model corresponding inverse process', 'learned implicitly ', 'given specific measurement distribution', 'latent variable  inverse pas inn provides full posterior', 'parameter space ', 'prove theoretically verify experimentally ', 'artificial data realworld problem medicine astrophysics ', 'inn powerful analysis tool find multimodalities parameter space ', 'uncover parameter correlation  identify unrecoverable parameter ']","For many applications, in particular in natural science, the task is to
, determine hidden system parameters from a set of measurements., Often,
, the forward process from parameter- to measurement-space is well-defined,
, whereas the inverse problem is ambiguous: multiple parameter sets can
, result in the same measurement., To fully characterize this ambiguity, the full
, posterior parameter distribution, conditioned on an observed measurement,
, has to be determined., We argue that a particular class of neural networks
, is well suited for this task  so-called Invertible Neural Networks (INNs).
, Unlike classical neural networks, which attempt to solve the ambiguous
, inverse problem directly, INNs focus on learning the forward process, using
, additional latent output variables to capture the information otherwise
, lost., Due to invertibility, a model of the corresponding inverse process is
, learned implicitly., Given a specific measurement and the distribution of
, the latent variables, the inverse pass of the INN provides the full posterior
, over parameter space., We prove theoretically and verify experimentally, on
, artificial data and real-world problems from medicine and astrophysics, that
, INNs are a powerful analysis tool to find multi-modalities in parameter space,
, uncover parameter correlations, and identify unrecoverable parameters.",36,5.973684210526316,5.277777777777778
133,"['Decisions made by machine learning systems have increasing influence on the world.', 'Yet it is common for machine learning algorithms to assume that no such influence exists.', 'An example is the use of the i.i.d.', ""assumption in online learning for applications such as content recommendation, where the (choice of) content displayed can change users' perceptions and preferences, or even drive them away, causing a shift in the distribution of users."", 'Generally speaking, it is possible for an algorithm to change the distribution of its own inputs.', 'We introduce the term self-induced distributional shift (SIDS) to describe this phenomenon.', 'A large body of work in reinforcement learning and causal machine learning aims to deal with distributional shift caused by deploying learning systems previously trained offline.', 'Our goal is similar, but distinct: we point out that changes to the learning algorithm, such as the introduction of meta-learning, can reveal hidden incentives for distributional shift (HIDS), and aim to diagnose and prevent problems associated with hidden incentives.', 'We design a simple \xa0environment as a ""unit test"" for HIDS, as well as a content recommendation environment which allows us to disentangle different types of SIDS.\xa0 ', 'We demonstrate the potential for HIDS to cause unexpected or undesirable behavior in these environments, and propose and test a mitigation strategy.\xa0']","[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.08695651590824127, 0.0, 0.10526315122842789, 0.04651162400841713, 0.07407406717538834, 0.08695651590824127, 0.0, 0.043478257954120636, 0.0, 0.060606054961681366]",SJeFNlHtPS,"[""Performance metrics are incomplete specifications; the ends don't always justify the means."", 'The authors show how meta-learning reveals the hidden incentives for distributional shift and propose an approach based on swapping learners between environments to reduce self introduced distributional shift.', 'The paper generalizes the inherent incentive for the learner to win by making the task easier in meta-learning to a larger class of problems.']","['decision made machine learning system increasing influence world ', 'yet common machine learning algorithm assume influence exists ', 'example use iid ', 'assumption online learning application content recommendation   choice  content displayed change user  perception preference  even drive away  causing shift distribution user ', 'generally speaking  possible algorithm change distribution input ', 'introduce term selfinduced distributional shift  sids  describe phenomenon ', 'large body work reinforcement learning causal machine learning aim deal distributional shift caused deploying learning system previously trained offline ', 'goal similar  distinct  point change learning algorithm  introduction metalearning  reveal hidden incentive distributional shift  hids   aim diagnose prevent problem associated hidden incentive ', 'design simple environment  unit test  hids  well content recommendation environment allows u disentangle different type sids ', 'demonstrate potential hids cause unexpected undesirable behavior environment  propose test mitigation strategy ']","Decisions made by machine learning systems have increasing influence on the world., Yet it is common for machine learning algorithms to assume that no such influence exists., An example is the use of the i.i.d., assumption in online learning for applications such as content recommendation, where the (choice of) content displayed can change users' perceptions and preferences, or even drive them away, causing a shift in the distribution of users., Generally speaking, it is possible for an algorithm to change the distribution of its own inputs., We introduce the term self-induced distributional shift (SIDS) to describe this phenomenon., A large body of work in reinforcement learning and causal machine learning aims to deal with distributional shift caused by deploying learning systems previously trained offline., Our goal is similar, but distinct: we point out that changes to the learning algorithm, such as the introduction of meta-learning, can reveal hidden incentives for distributional shift (HIDS), and aim to diagnose and prevent problems associated with hidden incentives., We design a simple environment as a ""unit test"" for HIDS, as well as a content recommendation environment which allows us to disentangle different types of SIDS. , We demonstrate the potential for HIDS to cause unexpected or undesirable behavior in these environments, and propose and test a mitigation strategy.",20,5.502347417840376,10.65
134,"['In one-class-learning tasks, only the normal case can be modeled with data, whereas the variation of all possible anomalies is too large to be described sufficiently by samples.', 'Thus, due to the lack of representative data, the wide-spread discriminative approaches cannot cover such learning tasks, and rather generative models, which attempt to learn the input density of the normal cases, are used.', 'However, generative models suffer from a large input dimensionality (as in images) and are typically inefficient learners.', 'We propose to learn the data distribution more efficiently with a multi-hypotheses autoencoder.', 'Moreover, the model is criticized by a discriminator, which prevents artificial data modes not supported by data, and which enforces diversity across hypotheses.', 'This consistency-based anomaly detection (ConAD) framework allows the reliable identification of outof- distribution samples.', 'For anomaly detection on CIFAR-10, it yields up to 3.9% points improvement over previously reported results.', 'On a real anomaly detection task, the approach reduces the error of the baseline models from 6.8% to 1.5%.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.09090908616781235, 0.04255318641662598, 0.0, 0.25806450843811035, 0.051282044500112534, 0.0624999962747097, 0.0, 0.10810810327529907]",r1ledo0ctX,"['We propose an anomaly-detection approach that combines modeling the foreground class via multiple local densities with adversarial training.', 'The paper proposes a technique to make generative models more robust by making them consistent with the local density.']","['oneclasslearning task  normal case modeled data  whereas variation possible anomaly large described sufficiently sample ', 'thus  due lack representative data  widespread discriminative approach cover learning task  rather generative model  attempt learn input density normal case  used ', 'however  generative model suffer large input dimensionality  image  typically inefficient learner ', 'propose learn data distribution efficiently multihypotheses autoencoder ', 'moreover  model criticized discriminator  prevents artificial data mode supported data  enforces diversity across hypothesis ', 'consistencybased anomaly detection  conad  framework allows reliable identification outof distribution sample ', 'anomaly detection cifar10  yield 39  point improvement previously reported result ', 'real anomaly detection task  approach reduces error baseline model 68  15  ']","In one-class-learning tasks, only the normal case can be modeled with data, whereas the variation of all possible anomalies is too large to be described sufficiently by samples., Thus, due to the lack of representative data, the wide-spread discriminative approaches cannot cover such learning tasks, and rather generative models, which attempt to learn the input density of the normal cases, are used., However, generative models suffer from a large input dimensionality (as in images) and are typically inefficient learners., We propose to learn the data distribution more efficiently with a multi-hypotheses autoencoder., Moreover, the model is criticized by a discriminator, which prevents artificial data modes not supported by data, and which enforces diversity across hypotheses., This consistency-based anomaly detection (ConAD) framework allows the reliable identification of outof- distribution samples., For anomaly detection on CIFAR-10, it yields up to 3.9% points improvement over previously reported results., On a real anomaly detection task, the approach reduces the error of the baseline models from 6.8% to 1.5%.",21,5.780487804878049,7.809523809523809
135,"['Generative Adversarial Networks (GAN) can achieve promising performance on learning complex data distributions on different types of data.', 'In this paper, we first show that a straightforward extension of an existing GAN algorithm is not applicable to point clouds, because the constraint required for discriminators is undefined for set data.', 'We propose a two fold modification to a GAN algorithm to be able to generate point clouds (PC-GAN).', 'First, we combine ideas from hierarchical Bayesian modeling and implicit generative models by learning a hierarchical and interpretable sampling process.', 'A key component of our method is that we train a posterior inference network for the hidden variables.', 'Second, PC-GAN defines a generic framework that can incorporate many existing GAN algorithms.', 'We further propose a sandwiching objective, which results in a tighter Wasserstein distance estimate than the commonly used dual form in WGAN.', 'We validate our claims on the ModelNet40 benchmark dataset and observe that PC- GAN trained by the sandwiching objective achieves better results on test data than existing methods.', 'We also conduct studies on several tasks, including generalization on unseen point clouds, latent space interpolation, classification, and image to point clouds transformation, to demonstrate the versatility of the proposed PC-GAN algorithm.']","[0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.0, 0.13793103396892548, 0.3720930218696594, 0.08695651590824127, 0.043478257954120636, 0.09756097197532654, 0.2916666567325592, 0.1111111044883728, 0.3571428656578064]",S1xim8UFuV,"['We propose a GAN variant which learns to generate point clouds. Different studies have been explores, including tighter Wasserstein distance estimate,  conditional generation, generalization to unseen point clouds and image to point cloud.', 'This paper proposes using GAN to generate 3D point cloud and introduces a sandwiching objective, averaging the upper and lower bound of Wasserstein distance between distributions.', 'This paper proposes a new generative model for unordered data, with a particular application to point clouds, which includes an inference method and a novel objective function. ']","['generative adversarial network  gan  achieve promising performance learning complex data distribution different type data ', 'paper  first show straightforward extension existing gan algorithm applicable point cloud  constraint required discriminator undefined set data ', 'propose two fold modification gan algorithm able generate point cloud  pcgan  ', 'first  combine idea hierarchical bayesian modeling implicit generative model learning hierarchical interpretable sampling process ', 'key component method train posterior inference network hidden variable ', 'second  pcgan defines generic framework incorporate many existing gan algorithm ', 'propose sandwiching objective  result tighter wasserstein distance estimate commonly used dual form wgan ', 'validate claim modelnet40 benchmark dataset observe pc gan trained sandwiching objective achieves better result test data existing method ', 'also conduct study several task  including generalization unseen point cloud  latent space interpolation  classification  image point cloud transformation  demonstrate versatility proposed pcgan algorithm ']","Generative Adversarial Networks (GAN) can achieve promising performance on learning complex data distributions on different types of data., In this paper, we first show that a straightforward extension of an existing GAN algorithm is not applicable to point clouds, because the constraint required for discriminators is undefined for set data., We propose a two fold modification to a GAN algorithm to be able to generate point clouds (PC-GAN)., First, we combine ideas from hierarchical Bayesian modeling and implicit generative models by learning a hierarchical and interpretable sampling process., A key component of our method is that we train a posterior inference network for the hidden variables., Second, PC-GAN defines a generic framework that can incorporate many existing GAN algorithms., We further propose a sandwiching objective, which results in a tighter Wasserstein distance estimate than the commonly used dual form in WGAN., We validate our claims on the ModelNet40 benchmark dataset and observe that PC- GAN trained by the sandwiching objective achieves better results on test data than existing methods., We also conduct studies on several tasks, including generalization on unseen point clouds, latent space interpolation, classification, and image to point clouds transformation, to demonstrate the versatility of the proposed PC-GAN algorithm.",19,5.7164179104477615,10.578947368421053
136,"['Existing attention mechanisms, are mostly item-based in that a model is trained to attend to individual items in a collection (the memory) where each item has a predefined, fixed granularity, e.g., a character or a word.', 'Intuitively, an area in the memory consisting of multiple items can be worth attending to as a whole.', 'We propose area attention: a way to attend to an area of the memory, where each area contains a group of items that are either spatially adjacent when the memory has a 2-dimensional structure, such as images, or temporally adjacent for 1-dimensional memory, such as natural language sentences.', 'Importantly, the size of an area, i.e., the number of items in an area or the level of aggregation, is dynamically determined via learning, which can vary depending on the learned coherence of the adjacent items.', 'By giving the model the option to attend to an area of items, instead of only individual items, a model can attend to information with varying granularity.', 'Area attention can work along multi-head attention for attending to multiple areas in the memory.', 'We evaluate area attention on two tasks: neural machine translation (both character and token-level) and image captioning, and improve upon strong (state-of-the-art) baselines in all the cases.', 'These improvements are obtainable with a basic form of area attention that is parameter free.', 'In addition to proposing the novel concept of area attention, we contribute an efficient way for computing it by leveraging the technique of summed area tables.']","[0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.07407406717538834, 0.19999998807907104, 0.20338982343673706, 0.07843136787414551, 0.1428571343421936, 0.1111111044883728, 0.1702127605676651, 0.1621621549129486, 0.13333332538604736]",rygp3iRcF7,"['The paper presents a novel approach for attentional mechanisms that can benefit a range of tasks such as machine translation and image captioning.', 'This paper extends the current attention models from word level to the combination of adjacent words, by applying the models to items made from merged adjacent words.']","['existing attention mechanism  mostly itembased model trained attend individual item collection  memory  item predefined  fixed granularity  eg  character word ', 'intuitively  area memory consisting multiple item worth attending whole ', 'propose area attention  way attend area memory  area contains group item either spatially adjacent memory 2dimensional structure  image  temporally adjacent 1dimensional memory  natural language sentence ', 'importantly  size area  ie  number item area level aggregation  dynamically determined via learning  vary depending learned coherence adjacent item ', 'giving model option attend area item  instead individual item  model attend information varying granularity ', 'area attention work along multihead attention attending multiple area memory ', 'evaluate area attention two task  neural machine translation  character tokenlevel  image captioning  improve upon strong  stateoftheart  baseline case ', 'improvement obtainable basic form area attention parameter free ', 'addition proposing novel concept area attention  contribute efficient way computing leveraging technique summed area table ']","Existing attention mechanisms, are mostly item-based in that a model is trained to attend to individual items in a collection (the memory) where each item has a predefined, fixed granularity, e.g., a character or a word., Intuitively, an area in the memory consisting of multiple items can be worth attending to as a whole., We propose area attention: a way to attend to an area of the memory, where each area contains a group of items that are either spatially adjacent when the memory has a 2-dimensional structure, such as images, or temporally adjacent for 1-dimensional memory, such as natural language sentences., Importantly, the size of an area, i.e., the number of items in an area or the level of aggregation, is dynamically determined via learning, which can vary depending on the learned coherence of the adjacent items., By giving the model the option to attend to an area of items, instead of only individual items, a model can attend to information with varying granularity., Area attention can work along multi-head attention for attending to multiple areas in the memory., We evaluate area attention on two tasks: neural machine translation (both character and token-level) and image captioning, and improve upon strong (state-of-the-art) baselines in all the cases., These improvements are obtainable with a basic form of area attention that is parameter free., In addition to proposing the novel concept of area attention, we contribute an efficient way for computing it by leveraging the technique of summed area tables.",27,5.108870967741935,9.185185185185185
137,"['We identify a phenomenon, which we refer to as *multi-model forgetting*, that occurs when sequentially training multiple deep networks with partially-shared parameters; the performance of previously-trained models degrades as one optimizes a subsequent one, due to the overwriting of shared parameters.', ""To overcome this, we introduce a statistically-justified weight plasticity loss that regularizes the learning of a model's shared parameters according to their importance for the previous models, and demonstrate its effectiveness when training two models sequentially and for neural architecture search."", 'Adding weight plasticity in neural architecture search preserves the best models to the end of the search and yields improved results in both natural language processing and computer vision tasks.']","[0, 1, 0]","[0.19607843458652496, 0.38461539149284363, 0.25]",r1fE3sAcYQ,"['We identify a phenomenon, neural brainwashing, and introduce a statistically-justified weight plasticity loss to overcome this.', 'This paper discusses the phenomena of neural brainwashing, which refers to that the performance of one model is affected via another model sharing model parameters.']","['identify phenomenon  refer  multimodel forgetting   occurs sequentially training multiple deep network partiallyshared parameter  performance previouslytrained model degrades one optimizes subsequent one  due overwriting shared parameter ', 'overcome  introduce statisticallyjustified weight plasticity loss regularizes learning model shared parameter according importance previous model  demonstrate effectiveness training two model sequentially neural architecture search ', 'adding weight plasticity neural architecture search preserve best model end search yield improved result natural language processing computer vision task ']","We identify a phenomenon, which we refer to as *multi-model forgetting*, that occurs when sequentially training multiple deep networks with partially-shared parameters; the performance of previously-trained models degrades as one optimizes a subsequent one, due to the overwriting of shared parameters., To overcome this, we introduce a statistically-justified weight plasticity loss that regularizes the learning of a model's shared parameters according to their importance for the previous models, and demonstrate its effectiveness when training two models sequentially and for neural architecture search., Adding weight plasticity in neural architecture search preserves the best models to the end of the search and yields improved results in both natural language processing and computer vision tasks.",8,6.133928571428571,14.0
138,"['Revealing latent structure in data is an active field of research, having introduced exciting technologies such as variational autoencoders and adversarial networks, and is essential to push machine learning towards unsupervised knowledge discovery.', 'However, a major challenge is the lack of suitable benchmarks for an objective and quantitative evaluation of learned representations.', 'To address this issue we introduce Morpho-MNIST, a framework that aims to answer: ""to what extent has my model learned to represent specific factors of variation in the data?""', 'We extend the popular MNIST dataset by adding a morphometric analysis enabling quantitative comparison of trained models, identification of the roles of latent variables, and characterisation of sample diversity.', 'We further propose a set of quantifiable perturbations to assess the performance of unsupervised and supervised methods on challenging tasks such as outlier detection and domain adaptation.']","[0, 1, 0, 0, 0]","[0.20408162474632263, 0.277777761220932, 0.17391303181648254, 0.1860465109348297, 0.1395348757505417]",r1esnoAqt7,"['This paper introduces Morpho-MNIST, a collection of shape metrics and perturbations, in a step towards quantitative evaluation of representation learning.', 'This paper discusses the problem of evaluating and diagnosing the represenatations learnt using a generative model.', 'Authors present a set of criteria to categorize MNISt digists and a set of interesting perturbations to modify MNIST dataset.']","['revealing latent structure data active field research  introduced exciting technology variational autoencoders adversarial network  essential push machine learning towards unsupervised knowledge discovery ', 'however  major challenge lack suitable benchmark objective quantitative evaluation learned representation ', 'address issue introduce morphomnist  framework aim answer   extent model learned represent specific factor variation data  ', 'extend popular mnist dataset adding morphometric analysis enabling quantitative comparison trained model  identification role latent variable  characterisation sample diversity ', 'propose set quantifiable perturbation ass performance unsupervised supervised method challenging task outlier detection domain adaptation ']","Revealing latent structure in data is an active field of research, having introduced exciting technologies such as variational autoencoders and adversarial networks, and is essential to push machine learning towards unsupervised knowledge discovery., However, a major challenge is the lack of suitable benchmarks for an objective and quantitative evaluation of learned representations., To address this issue we introduce Morpho-MNIST, a framework that aims to answer: ""to what extent has my model learned to represent specific factors of variation in the data?"", We extend the popular MNIST dataset by adding a morphometric analysis enabling quantitative comparison of trained models, identification of the roles of latent variables, and characterisation of sample diversity., We further propose a set of quantifiable perturbations to assess the performance of unsupervised and supervised methods on challenging tasks such as outlier detection and domain adaptation.",11,5.992700729927007,12.454545454545455
139,"['Exploration in environments with sparse rewards is a key challenge for reinforcement learning.', 'How do we design agents with generic inductive biases so that they can explore in a consistent manner instead of just using local exploration schemes like epsilon-greedy?', 'We propose an unsupervised reinforcement learning agent which learns a discrete pixel grouping model that preserves spatial geometry of the sensors and implicitly of the environment as well.', 'We use this representation to derive geometric intrinsic reward functions, like centroid coordinates and area, and learn policies to control each one of them with off-policy learning.', 'These policies form a basis set of behaviors (options) which allows us explore in a consistent way and use them in a hierarchical reinforcement learning setup to solve for extrinsically defined rewards.', 'We show that our approach can scale to a variety of domains with competitive performance, including navigation in 3D environments and Atari games with sparse rewards.']","[1, 0, 0, 0, 0, 0]","[0.23076923191547394, 0.09999999403953552, 0.20512820780277252, 0.15789473056793213, 0.1904761791229248, 0.10526315122842789]",HJlWXhC5Km,"['structured exploration in deep reinforcement learning via unsupervised visual abstraction discovery and control', 'The paper introduces visual abstractions that are used for reinforcement learning, where an algorithm learns to ""control"" each abstraction as well as select the options to achieve the overall task.']","['exploration environment sparse reward key challenge reinforcement learning ', 'design agent generic inductive bias explore consistent manner instead using local exploration scheme like epsilongreedy ', 'propose unsupervised reinforcement learning agent learns discrete pixel grouping model preserve spatial geometry sensor implicitly environment well ', 'use representation derive geometric intrinsic reward function  like centroid coordinate area  learn policy control one offpolicy learning ', 'policy form basis set behavior  option  allows u explore consistent way use hierarchical reinforcement learning setup solve extrinsically defined reward ', 'show approach scale variety domain competitive performance  including navigation 3d environment atari game sparse reward ']","Exploration in environments with sparse rewards is a key challenge for reinforcement learning., How do we design agents with generic inductive biases so that they can explore in a consistent manner instead of just using local exploration schemes like epsilon-greedy?, We propose an unsupervised reinforcement learning agent which learns a discrete pixel grouping model that preserves spatial geometry of the sensors and implicitly of the environment as well., We use this representation to derive geometric intrinsic reward functions, like centroid coordinates and area, and learn policies to control each one of them with off-policy learning., These policies form a basis set of behaviors (options) which allows us explore in a consistent way and use them in a hierarchical reinforcement learning setup to solve for extrinsically defined rewards., We show that our approach can scale to a variety of domains with competitive performance, including navigation in 3D environments and Atari games with sparse rewards.",9,5.588235294117647,17.0
140,"['Combinatorial optimization is a common theme in computer science.', 'While in general such problems are NP-Hard, from a practical point of view, locally optimal solutions can be useful.', 'In some combinatorial problems however, it can be hard to define meaningful solution neighborhoods that connect large portions of the search space, thus hindering methods that search this space directly.', 'We suggest to circumvent such cases by utilizing a policy gradient algorithm that transforms the problem to the continuous domain, and to optimize a new surrogate objective that renders the former as generic stochastic optimizer.', 'This is achieved by producing a surrogate objective whose distribution is fixed and predetermined, thus removing the need to fine-tune various hyper-parameters in a case by case manner.', 'Since we are interested in methods which can successfully recover locally optimal solutions, we use the problem of finding locally maximal cliques as a challenging experimental benchmark, and we report results on a large dataset of graphs that is designed to test clique finding algorithms.', 'Notably, we show in this benchmark that fixing the distribution of the surrogate is key to consistently recovering locally optimal solutions, and that our surrogate objective leads to an algorithm that outperforms other methods we have tested in a number of measures.']","[0, 0, 0, 1, 0, 0, 0]","[0.05714285373687744, 0.17777776718139648, 0.1111111044883728, 0.2181818187236786, 0.07999999821186066, 0.1846153736114502, 0.1666666567325592]",Hkx-ii05FQ,"['A new policy gradient algorithm designed to approach black-box combinatorial optimization problems. The algorithm relies only on function evaluations, and returns locally optimal solutions with high probability.', 'The paper proposes an approach to construct surrogate objectives for the application of policy gradient methods to combinatorial optimization with the goal of reducing the need of hyper-parameter tuning.', 'The paper propose to replace the reward term in the policy gradient algorithm with its centered empirical cumulative distribution. ']","['combinatorial optimization common theme computer science ', 'general problem nphard  practical point view  locally optimal solution useful ', 'combinatorial problem however  hard define meaningful solution neighborhood connect large portion search space  thus hindering method search space directly ', 'suggest circumvent case utilizing policy gradient algorithm transforms problem continuous domain  optimize new surrogate objective render former generic stochastic optimizer ', 'achieved producing surrogate objective whose distribution fixed predetermined  thus removing need finetune various hyperparameters case case manner ', 'since interested method successfully recover locally optimal solution  use problem finding locally maximal clique challenging experimental benchmark  report result large dataset graph designed test clique finding algorithm ', 'notably  show benchmark fixing distribution surrogate key consistently recovering locally optimal solution  surrogate objective lead algorithm outperforms method tested number measure ']","Combinatorial optimization is a common theme in computer science., While in general such problems are NP-Hard, from a practical point of view, locally optimal solutions can be useful., In some combinatorial problems however, it can be hard to define meaningful solution neighborhoods that connect large portions of the search space, thus hindering methods that search this space directly., We suggest to circumvent such cases by utilizing a policy gradient algorithm that transforms the problem to the continuous domain, and to optimize a new surrogate objective that renders the former as generic stochastic optimizer., This is achieved by producing a surrogate objective whose distribution is fixed and predetermined, thus removing the need to fine-tune various hyper-parameters in a case by case manner., Since we are interested in methods which can successfully recover locally optimal solutions, we use the problem of finding locally maximal cliques as a challenging experimental benchmark, and we report results on a large dataset of graphs that is designed to test clique finding algorithms., Notably, we show in this benchmark that fixing the distribution of the surrogate is key to consistently recovering locally optimal solutions, and that our surrogate objective leads to an algorithm that outperforms other methods we have tested in a number of measures.",17,5.5,12.235294117647058
141,"['Deterministic neural networks (NNs) are increasingly being deployed in safety critical domains, where calibrated, robust and efficient measures of uncertainty are crucial.', 'While it is possible to train regression networks to output the parameters of a probability distribution by maximizing a Gaussian likelihood function, the resulting model remains oblivious to the underlying confidence of its predictions.', 'In this paper, we propose a novel method for training deterministic NNs to not only estimate the desired target but also the associated evidence in support of that target.', 'We accomplish this by  placing evidential priors over our original Gaussian likelihood function and training our NN to infer the hyperparameters of our evidential distribution.', 'We impose priors during training such that the model is penalized when its predicted evidence is not aligned with the correct output.', 'Thus the model estimates not only the probabilistic mean and variance of our target but also the underlying uncertainty associated with each of those parameters.', 'We observe that our evidential regression method learns well-calibrated measures of uncertainty on various benchmarks, scales to complex computer vision tasks, and is robust to adversarial input perturbations.\n']","[1, 0, 0, 0, 0, 0, 0]","[0.20000000298023224, 0.054054051637649536, 0.0555555522441864, 0.0, 0.0, 0.06451612710952759, 0.054054051637649536]",S1eSoeSYwr,"['Fast, calibrated uncertainty estimation for neural networks without sampling', 'This paper proposes a novel approach to estimate the confidence of predictions in a regression setting, opening the door to online applications with fully integrated uncertainty estimates.', 'This paper proposed deep evidential regression, a method for training neural networks to not only estimate the output but also the associated evidence in support of that output.']","['deterministic neural network  nns  increasingly deployed safety critical domain  calibrated  robust efficient measure uncertainty crucial ', 'possible train regression network output parameter probability distribution maximizing gaussian likelihood function  resulting model remains oblivious underlying confidence prediction ', 'paper  propose novel method training deterministic nns estimate desired target also associated evidence support target ', 'accomplish placing evidential prior original gaussian likelihood function training nn infer hyperparameters evidential distribution ', 'impose prior training model penalized predicted evidence aligned correct output ', 'thus model estimate probabilistic mean variance target also underlying uncertainty associated parameter ', 'observe evidential regression method learns wellcalibrated measure uncertainty various benchmark  scale complex computer vision task  robust adversarial input perturbation ']","Deterministic neural networks (NNs) are increasingly being deployed in safety critical domains, where calibrated, robust and efficient measures of uncertainty are crucial., While it is possible to train regression networks to output the parameters of a probability distribution by maximizing a Gaussian likelihood function, the resulting model remains oblivious to the underlying confidence of its predictions., In this paper, we propose a novel method for training deterministic NNs to not only estimate the desired target but also the associated evidence in support of that target., We accomplish this by  placing evidential priors over our original Gaussian likelihood function and training our NN to infer the hyperparameters of our evidential distribution., We impose priors during training such that the model is penalized when its predicted evidence is not aligned with the correct output., Thus the model estimates not only the probabilistic mean and variance of our target but also the underlying uncertainty associated with each of those parameters., We observe that our evidential regression method learns well-calibrated measures of uncertainty on various benchmarks, scales to complex computer vision tasks, and is robust to adversarial input perturbations.
",13,5.8,14.23076923076923
142,"['The Lottery Ticket Hypothesis from Frankle & Carbin (2019) conjectures that, for typically-sized neural networks, it is possible to find small sub-networks which train faster and yield superior performance than their original counterparts.', 'The proposed algorithm to search for such sub-networks (winning tickets), Iterative Magnitude Pruning (IMP), consistently finds sub-networks with 90-95% less parameters which indeed train faster and better than the overparameterized models they were extracted from, creating potential applications to problems such as transfer learning.\n\n', ""In this paper, we propose a new algorithm to search for winning tickets, Continuous Sparsification, which continuously removes parameters from a network during training, and learns the sub-network's structure with gradient-based methods instead of relying on pruning strategies."", 'We show empirically that our method is capable of finding tickets that outperforms the ones learned by Iterative Magnitude Pruning, and at the same time providing up to 5 times faster search, when measured in number of training epochs.']","[0, 0, 1, 0]","[0.043478257954120636, 0.072727270424366, 0.20000000298023224, 0.16326530277729034]",BJe4oxHYPB,"['We propose a new algorithm that quickly finds winning tickets in neural networks.', 'This paper proposes a novel objective function that can be used to jointly optimize a classification objective while encouraging sparsification in a network that performs with high accuracy.', 'This work propose a new iterative pruning methods named Continuous Sparsification, which continuously prunes the current weight until it reaches the target ratio.']","['lottery ticket hypothesis frankle  carbin  2019  conjecture  typicallysized neural network  possible find small subnetworks train faster yield superior performance original counterpart ', 'proposed algorithm search subnetworks  winning ticket   iterative magnitude pruning  imp   consistently find subnetworks 9095  le parameter indeed train faster better overparameterized model extracted  creating potential application problem transfer learning ', 'paper  propose new algorithm search winning ticket  continuous sparsification  continuously remove parameter network training  learns subnetwork structure gradientbased method instead relying pruning strategy ', 'show empirically method capable finding ticket outperforms one learned iterative magnitude pruning  time providing 5 time faster search  measured number training epoch ']","The Lottery Ticket Hypothesis from Frankle & Carbin (2019) conjectures that, for typically-sized neural networks, it is possible to find small sub-networks which train faster and yield superior performance than their original counterparts., The proposed algorithm to search for such sub-networks (winning tickets), Iterative Magnitude Pruning (IMP), consistently finds sub-networks with 90-95% less parameters which indeed train faster and better than the overparameterized models they were extracted from, creating potential applications to problems such as transfer learning.

, In this paper, we propose a new algorithm to search for winning tickets, Continuous Sparsification, which continuously removes parameters from a network during training, and learns the sub-network's structure with gradient-based methods instead of relying on pruning strategies., We show empirically that our method is capable of finding tickets that outperforms the ones learned by Iterative Magnitude Pruning, and at the same time providing up to 5 times faster search, when measured in number of training epochs.",15,6.01948051948052,10.266666666666667
143,"['In most practical settings and theoretical analyses, one assumes that a model can be trained until convergence.', 'However, the growing complexity of machine learning datasets and models may violate such assumptions.', 'Indeed, current approaches for hyper-parameter tuning and neural architecture search tend to be limited by practical resource constraints.', 'Therefore, we introduce a formal setting for studying training under the non-asymptotic, resource-constrained regime, i.e., budgeted training.', 'We analyze the following problem: ""given a dataset, algorithm, and fixed resource budget, what is the best achievable performance?""', 'We focus on the number of optimization iterations as the representative resource.', 'Under such a setting, we show that it is critical to adjust the learning rate schedule according to the given budget.', 'Among budget-aware learning schedules, we find simple linear decay to be both robust and high-performing.', 'We support our claim through extensive experiments with state-of-the-art models on ImageNet (image classification), Kinetics (video classification), MS COCO (object detection and instance segmentation), and Cityscapes (semantic segmentation).', 'We also analyze our results and find that the key to a good schedule is budgeted convergence, a phenomenon whereby the gradient vanishes at the end of each allowed budget.', 'We also revisit existing approaches for fast convergence and show that budget-aware learning schedules readily outperform such approaches under (the practical but under-explored) budgeted training setting.']","[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.12903225421905518, 0.1428571343421936, 0.1249999925494194, 0.375, 0.1249999925494194, 0.0, 0.24242423474788666, 0.27586206793785095, 0.04999999701976776, 0.19512194395065308, 0.3589743673801422]",HyxLRTVKPH,"['Introduce a formal setting for budgeted training and propose a budget-aware linear learning rate schedule', 'This work presents a technique for tuning the learning rate for Neural Network training when under a fixed number of epochs.', 'This paper analyzed which learning rate schedule should be used when the number of iteration is limited using an introduced concept of BAS (Budget-Aware Schedule).']","['practical setting theoretical analysis  one assumes model trained convergence ', 'however  growing complexity machine learning datasets model may violate assumption ', 'indeed  current approach hyperparameter tuning neural architecture search tend limited practical resource constraint ', 'therefore  introduce formal setting studying training nonasymptotic  resourceconstrained regime  ie  budgeted training ', 'analyze following problem   given dataset  algorithm  fixed resource budget  best achievable performance  ', 'focus number optimization iteration representative resource ', 'setting  show critical adjust learning rate schedule according given budget ', 'among budgetaware learning schedule  find simple linear decay robust highperforming ', 'support claim extensive experiment stateoftheart model imagenet  image classification   kinetics  video classification   m coco  object detection instance segmentation   cityscape  semantic segmentation  ', 'also analyze result find key good schedule budgeted convergence  phenomenon whereby gradient vanishes end allowed budget ', 'also revisit existing approach fast convergence show budgetaware learning schedule readily outperform approach  practical underexplored  budgeted training setting ']","In most practical settings and theoretical analyses, one assumes that a model can be trained until convergence., However, the growing complexity of machine learning datasets and models may violate such assumptions., Indeed, current approaches for hyper-parameter tuning and neural architecture search tend to be limited by practical resource constraints., Therefore, we introduce a formal setting for studying training under the non-asymptotic, resource-constrained regime, i.e., budgeted training., We analyze the following problem: ""given a dataset, algorithm, and fixed resource budget, what is the best achievable performance?"", We focus on the number of optimization iterations as the representative resource., Under such a setting, we show that it is critical to adjust the learning rate schedule according to the given budget., Among budget-aware learning schedules, we find simple linear decay to be both robust and high-performing., We support our claim through extensive experiments with state-of-the-art models on ImageNet (image classification), Kinetics (video classification), MS COCO (object detection and instance segmentation), and Cityscapes (semantic segmentation)., We also analyze our results and find that the key to a good schedule is budgeted convergence, a phenomenon whereby the gradient vanishes at the end of each allowed budget., We also revisit existing approaches for fast convergence and show that budget-aware learning schedules readily outperform such approaches under (the practical but under-explored) budgeted training setting.",27,6.092165898617512,8.037037037037036
144,"['We present a new approach for efficient exploration which leverages a low-dimensional encoding of the environment learned with a combination of model-based and model-free objectives.', 'Our approach uses intrinsic rewards that are based on a weighted distance of nearest neighbors in the low dimensional representational space to gauge novelty.\n', 'We then leverage these intrinsic rewards for sample-efficient exploration with planning routines in representational space.\n', 'One key element of our approach is that we perform more gradient steps in-between every environment step in order to ensure the model accuracy.', 'We test our approach on a number of maze tasks, as well as a control problem and show that our exploration approach is more sample-efficient compared to strong baselines.']","[0, 1, 0, 0, 0]","[0.19512194395065308, 0.6818181872367859, 0.4000000059604645, 0.1395348757505417, 0.27272728085517883]",SJeoE0VKDS,"['We conduct exploration using intrinsic rewards that are based on a weighted distance of nearest neighbors in representational space.', 'This paper proposes a method for efficient exploration in tabular MDPs as well as a simple control environment, using deterministic encoders to learn a low dimensional representation of the environment dynamics.', 'This paper proposes a method of sample-efficient exploration for RL agent using a combination of model-based and model-free approaches with a novelty metric.']","['present new approach efficient exploration leverage lowdimensional encoding environment learned combination modelbased modelfree objective ', 'approach us intrinsic reward based weighted distance nearest neighbor low dimensional representational space gauge novelty ', 'leverage intrinsic reward sampleefficient exploration planning routine representational space ', 'one key element approach perform gradient step inbetween every environment step order ensure model accuracy ', 'test approach number maze task  well control problem show exploration approach sampleefficient compared strong baseline ']","We present a new approach for efficient exploration which leverages a low-dimensional encoding of the environment learned with a combination of model-based and model-free objectives., Our approach uses intrinsic rewards that are based on a weighted distance of nearest neighbors in the low dimensional representational space to gauge novelty.
, We then leverage these intrinsic rewards for sample-efficient exploration with planning routines in representational space.
, One key element of our approach is that we perform more gradient steps in-between every environment step in order to ensure the model accuracy., We test our approach on a number of maze tasks, as well as a control problem and show that our exploration approach is more sample-efficient compared to strong baselines.",6,5.666666666666667,19.5
145,"['Neural networks are vulnerable to small adversarial perturbations.', 'While existing literature largely focused on the vulnerability of learned models, we demonstrate an intriguing phenomenon that adversarial robustness, unlike clean accuracy, is sensitive to the input data distribution.', 'Even a semantics-preserving transformations on the input data distribution can cause a significantly different robustness for the adversarially trained model that is both trained and evaluated on the new distribution.', 'We show this by constructing semantically- identical variants for MNIST and CIFAR10 respectively, and show that standardly trained models achieve similar clean accuracies on them, but adversarially trained models achieve significantly different robustness accuracies.', 'This counter-intuitive phenomenon indicates that input data distribution alone can affect the adversarial robustness of trained neural networks, not necessarily the tasks themselves.', 'Lastly, we discuss the practical implications on evaluating adversarial robustness, and make initial attempts to understand this complex phenomenon.']","[0, 1, 0, 0, 0, 0]","[0.12903225421905518, 0.15686273574829102, 0.12765957415103912, 0.07843136787414551, 0.13333332538604736, 0.0952380895614624]",S1lFD4HnnE,"['Robustness performance of PGD trained models are sensitive to semantics-preserving transformation of image datasets, which implies the trickiness of evaluation of robust learning algorithms in practice.']","['neural network vulnerable small adversarial perturbation ', 'existing literature largely focused vulnerability learned model  demonstrate intriguing phenomenon adversarial robustness  unlike clean accuracy  sensitive input data distribution ', 'even semanticspreserving transformation input data distribution cause significantly different robustness adversarially trained model trained evaluated new distribution ', 'show constructing semantically identical variant mnist cifar10 respectively  show standardly trained model achieve similar clean accuracy  adversarially trained model achieve significantly different robustness accuracy ', 'counterintuitive phenomenon indicates input data distribution alone affect adversarial robustness trained neural network  necessarily task ', 'lastly  discus practical implication evaluating adversarial robustness  make initial attempt understand complex phenomenon ']","Neural networks are vulnerable to small adversarial perturbations., While existing literature largely focused on the vulnerability of learned models, we demonstrate an intriguing phenomenon that adversarial robustness, unlike clean accuracy, is sensitive to the input data distribution., Even a semantics-preserving transformations on the input data distribution can cause a significantly different robustness for the adversarially trained model that is both trained and evaluated on the new distribution., We show this by constructing semantically- identical variants for MNIST and CIFAR10 respectively, and show that standardly trained models achieve similar clean accuracies on them, but adversarially trained models achieve significantly different robustness accuracies., This counter-intuitive phenomenon indicates that input data distribution alone can affect the adversarial robustness of trained neural networks, not necessarily the tasks themselves., Lastly, we discuss the practical implications on evaluating adversarial robustness, and make initial attempts to understand this complex phenomenon.",14,6.664335664335664,10.214285714285714
146,"['Sample inefficiency is a long-lasting problem in reinforcement learning (RL).  ', 'The state-of-the-art uses action value function to derive policy while it usually involves an extensive search over the state-action space and unstable optimization.', 'Towards the sample-efficient RL, we propose ranking policy gradient (RPG), a policy gradient method that learns the optimal rank of a set of discrete actions.  ', 'To accelerate the learning of policy gradient methods, we establish the equivalence between maximizing the lower bound of return and imitating a near-optimal policy without accessing any oracles.', 'These results lead to a general off-policy learning framework, which preserves the optimality, reduces variance, and improves the sample-efficiency.', 'We conduct extensive experiments showing that when consolidating with the off-policy learning framework, RPG substantially reduces the sample complexity, comparing to the state-of-the-art.']","[0, 0, 1, 0, 0, 0]","[0.10256409645080566, 0.15686273574829102, 0.4897959232330322, 0.307692289352417, 0.3478260934352875, 0.2857142686843872]",rJld3hEYvS,"['We propose ranking policy gradient that learns the optimal rank of actions to maximize return. We propose a general off-policy learning framework with the properties of optimality preserving, variance reduction, and sample-efficiency.', 'This paper proposes to reparameterize the policy using a form of ranking to convert the RL problem into a supervised learning problem.', 'This paper presents a new view on policy gradient methods from the perspective of ranking. ']","['sample inefficiency longlasting problem reinforcement learning  rl  ', 'stateoftheart us action value function derive policy usually involves extensive search stateaction space unstable optimization ', 'towards sampleefficient rl  propose ranking policy gradient  rpg   policy gradient method learns optimal rank set discrete action ', 'accelerate learning policy gradient method  establish equivalence maximizing lower bound return imitating nearoptimal policy without accessing oracle ', 'result lead general offpolicy learning framework  preserve optimality  reduces variance  improves sampleefficiency ', 'conduct extensive experiment showing consolidating offpolicy learning framework  rpg substantially reduces sample complexity  comparing stateoftheart ']","Sample inefficiency is a long-lasting problem in reinforcement learning (RL).  , The state-of-the-art uses action value function to derive policy while it usually involves an extensive search over the state-action space and unstable optimization., Towards the sample-efficient RL, we propose ranking policy gradient (RPG), a policy gradient method that learns the optimal rank of a set of discrete actions.  , To accelerate the learning of policy gradient methods, we establish the equivalence between maximizing the lower bound of return and imitating a near-optimal policy without accessing any oracles., These results lead to a general off-policy learning framework, which preserves the optimality, reduces variance, and improves the sample-efficiency., We conduct extensive experiments showing that when consolidating with the off-policy learning framework, RPG substantially reduces the sample complexity, comparing to the state-of-the-art.",14,6.2578125,9.142857142857142
147,"['We introduce MultiGrain, a neural network architecture that generates compact image embedding vectors that solve multiple tasks of different granularity: class, instance, and copy recognition.', 'MultiGrain is trained jointly for classification by optimizing the cross-entropy loss and for instance/copy recognition by optimizing a self-supervised ranking loss.', 'The self-supervised loss only uses data augmentation and thus does not require additional labels.', 'Remarkably, the unified embeddings are not only much more compact than using several specialized embeddings, but they also have the same or better accuracy.', 'When fed to a linear classifier, MultiGrain using ResNet-50 achieves 79.4% top-1 accuracy on ImageNet, a +1.8% absolute improvement over the the current state-of-the-art AutoAugment method.', 'The same embeddings perform on par with state-of-the-art instance retrieval with images of moderate resolution.', 'An ablation study shows that our approach benefits from the self-supervision, the pooling method and the mini-batches with repeated augmentations of the same image.\n']","[1, 0, 0, 0, 0, 0, 0]","[0.2926829159259796, 0.23529411852359772, 0.06451612710952759, 0.0, 0.09302324801683426, 0.06451612710952759, 0.10256409645080566]",SkeGURNtDH,"['Combining classification and image retrieval in a neural network architecture, we obtain an improvement for both tasks.', 'This paper proposes a unified embedding for image classification and instance retrieval to enhance the performance for both tasks.', 'The paper proposes to jointy train a deep neural net for image classification, instance, and copy recognition.']","['introduce multigrain  neural network architecture generates compact image embedding vector solve multiple task different granularity  class  instance  copy recognition ', 'multigrain trained jointly classification optimizing crossentropy loss instancecopy recognition optimizing selfsupervised ranking loss ', 'selfsupervised loss us data augmentation thus require additional label ', 'remarkably  unified embeddings much compact using several specialized embeddings  also better accuracy ', 'fed linear classifier  multigrain using resnet50 achieves 794  top1 accuracy imagenet  18  absolute improvement current stateoftheart autoaugment method ', 'embeddings perform par stateoftheart instance retrieval image moderate resolution ', 'ablation study show approach benefit selfsupervision  pooling method minibatches repeated augmentation image ']","We introduce MultiGrain, a neural network architecture that generates compact image embedding vectors that solve multiple tasks of different granularity: class, instance, and copy recognition., MultiGrain is trained jointly for classification by optimizing the cross-entropy loss and for instance/copy recognition by optimizing a self-supervised ranking loss., The self-supervised loss only uses data augmentation and thus does not require additional labels., Remarkably, the unified embeddings are not only much more compact than using several specialized embeddings, but they also have the same or better accuracy., When fed to a linear classifier, MultiGrain using ResNet-50 achieves 79.4% top-1 accuracy on ImageNet, a +1.8% absolute improvement over the the current state-of-the-art AutoAugment method., The same embeddings perform on par with state-of-the-art instance retrieval with images of moderate resolution., An ablation study shows that our approach benefits from the self-supervision, the pooling method and the mini-batches with repeated augmentations of the same image.
",15,6.201342281879195,9.933333333333334
148,"[' In this paper, we investigate mapping the hyponymy relation of\n wordnet to feature vectors.\n  ', 'We aim to model lexical knowledge in such a way that it can be used as\n  input in generic machine-learning models, such as phrase entailment\n  predictors.\n  ', 'We propose two models.', 'The first one leverages an existing mapping of\n  words to feature vectors (fasttext), and attempts to classify\n  such vectors as within or outside of each class.', 'The second model is fully supervised,\n  using solely wordnet as a ground truth.', 'It maps each concept to an\n  interval or a disjunction thereof.\n  ', 'On the first model, we approach, but not quite attain state of the\n  art performance.', 'The second model can achieve near-perfect accuracy.\n']","[1, 0, 0, 0, 0, 0, 0, 0]","[0.7692307829856873, 0.11428570747375488, 0.13333332538604736, 0.29411762952804565, 0.0833333283662796, 0.08695651590824127, 0.1599999964237213, 0.0]",r1xywsC9tQ,"['We investigate mapping the hyponymy relation of wordnet to feature vectors', 'This paper studies how hyponymy between words can be mapped to feature representations.', 'This paper explores the notion of hyponymy in word vector representations and describes a method of organizing WordNet relations into a tree structure to define hyponymy.']","['paper  investigate mapping hyponymy relation wordnet feature vector ', 'aim model lexical knowledge way used input generic machinelearning model  phrase entailment predictor ', 'propose two model ', 'first one leverage existing mapping word feature vector  fasttext   attempt classify vector within outside class ', 'second model fully supervised  using solely wordnet ground truth ', 'map concept interval disjunction thereof ', 'first model  approach  quite attain state art performance ', 'second model achieve nearperfect accuracy ']"," In this paper, we investigate mapping the hyponymy relation of
 wordnet to feature vectors.
  , We aim to model lexical knowledge in such a way that it can be used as
  input in generic machine-learning models, such as phrase entailment
  predictors.
  , We propose two models., The first one leverages an existing mapping of
  words to feature vectors (fasttext), and attempts to classify
  such vectors as within or outside of each class., The second model is fully supervised,
  using solely wordnet as a ground truth., It maps each concept to an
  interval or a disjunction thereof.
  , On the first model, we approach, but not quite attain state of the
  art performance., The second model can achieve near-perfect accuracy.
",13,4.982758620689655,8.923076923076923
149,"['Recurrent Neural Networks (RNNs) are powerful autoregressive sequence models for learning prevalent patterns in natural language.   ', 'Yet language generated by RNNs often shows several degenerate characteristics that are uncommon in human language; while fluent, RNN language production can be overly generic, repetitive, and even self-contradictory.  ', 'We postulate that the objective function optimized by RNN language models, which amounts to the overall perplexity of a text, is not expressive enough to capture the abstract qualities of good generation such as Grices Maxims.', 'In this paper, we introduce a general learning framework that can construct a decoding objective better suited for generation.', 'Starting with a generatively trained RNN language model, our framework learns to construct a substantially stronger generator by combining several discriminatively trained models that can collectively address the limitations of RNN generation.  ', 'Human evaluation demonstrates that text generated by the resulting generator is preferred over  that  of  baselines  by  a  large  margin  and  significantly  enhances  the  overall coherence, style, and information content of the generated text.']","[0, 0, 0, 0, 1, 0]","[0.09756097197532654, 0.11320754140615463, 0.3214285671710968, 0.0952380895614624, 0.37037035822868347, 0.19999998807907104]",r1lfpfZAb,"['We build a stronger natural language generator by discriminatively training scoring functions that rank candidate generations with respect to various qualities of good writing.', 'This paper proposes to bring together multiple inductive biases that hope to correct for inconsistencies in sequence decoding and proposes to optimize for the parameters of a pre-defined combination of various sub-objectives. ', 'This paper combines RNN language model with several discriminatively trained models to improve the language generation.', ""This paper proposes to improve RNN language model generation using augmented objectives inspired by Grice's maxims of communication.""]","['recurrent neural network  rnns  powerful autoregressive sequence model learning prevalent pattern natural language ', 'yet language generated rnns often show several degenerate characteristic uncommon human language  fluent  rnn language production overly generic  repetitive  even selfcontradictory ', 'postulate objective function optimized rnn language model  amount overall perplexity text  expressive enough capture abstract quality good generation grice  maxim ', 'paper  introduce general learning framework construct decoding objective better suited generation ', 'starting generatively trained rnn language model  framework learns construct substantially stronger generator combining several discriminatively trained model collectively address limitation rnn generation ', 'human evaluation demonstrates text generated resulting generator preferred baseline large margin significantly enhances overall coherence  style  information content generated text ']","Recurrent Neural Networks (RNNs) are powerful autoregressive sequence models for learning prevalent patterns in natural language.   , Yet language generated by RNNs often shows several degenerate characteristics that are uncommon in human language; while fluent, RNN language production can be overly generic, repetitive, and even self-contradictory.  , We postulate that the objective function optimized by RNN language models, which amounts to the overall perplexity of a text, is not expressive enough to capture the abstract qualities of good generation such as Grices Maxims., In this paper, we introduce a general learning framework that can construct a decoding objective better suited for generation., Starting with a generatively trained RNN language model, our framework learns to construct a substantially stronger generator by combining several discriminatively trained models that can collectively address the limitations of RNN generation.  , Human evaluation demonstrates that text generated by the resulting generator is preferred over  that  of  baselines  by  a  large  margin  and  significantly  enhances  the  overall coherence, style, and information content of the generated text.",15,6.0602409638554215,11.066666666666666
150,"['In recent years, the efficiency and even the feasibility of traditional load-balancing policies are challenged by the rapid growth of cloud infrastructure with increasing levels of server heterogeneity and increasing size of cloud services and applications.', 'In such many software-load-balancers heterogeneous systems, traditional solutions, such as JSQ, incur an increasing communication overhead, whereas low-communication alternatives, such as JSQ(d) and the recently proposed JIQ scheme are either unstable or provide poor performance.\n\n', 'We argue that a better low-communication load balancing scheme can be established by allowing each dispatcher to have a different view of the system and keep using JSQ, rather than greedily trying to avoid starvation on a per-decision basis. \n', 'accordingly, we introduce the Loosely-Shortest -Queue family of load balancing algorithms.', 'Roughly speaking, in Loosely-shortest -Queue, each dispatcher keeps a different approximation of the server queue lengths and routes jobs to the shortest among them.', 'Communication is used only to update the approximations and make sure that they are not too far from the real queue lengths in expectation.', 'We formally establish the strong stability of any Loosely-Shortest -Queue policy and provide an easy-to-verify sufficient condition for verifying that a policy is Loosely-Shortest -Queue.', 'We further demonstrate that the Loosely-Shortest -Queue approach allows constructing throughput optimal policies with an arbitrarily low communication budget.\n\n', 'Finally, using extensive simulations that consider homogeneous, heterogeneous and highly skewed heterogeneous systems in scenarios with a single dispatcher as well as with multiple dispatchers, we show that the examined Loosely-Shortest -Queue example policies are always stable as dictated by theory.', 'Moreover, it exhibits an appealing performance and significantly outperforms well-known low-communication policies, such as JSQ(d) and JIQ, while using a similar communication budget.']","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]","[0.08695651590824127, 0.11538460850715637, 0.1428571343421936, 0.13333332538604736, 0.0476190410554409, 0.0476190410554409, 0.1463414579629898, 0.20512819290161133, 0.1090909019112587, 0.09756097197532654]",BJxN9Hvf-V,['Scalable and low communication load balancing solution for heterogeneous-server multi-dispatcher systems with strong theoretical guarantees and promising empirical results. '],"['recent year  efficiency even feasibility traditional loadbalancing policy challenged rapid growth cloud infrastructure increasing level server heterogeneity increasing size cloud service application ', 'many softwareloadbalancers heterogeneous system  traditional solution  jsq  incur increasing communication overhead  whereas lowcommunication alternative  jsq   recently proposed jiq scheme either unstable provide poor performance ', 'argue better lowcommunication load balancing scheme established allowing dispatcher different view system keep using jsq  rather greedily trying avoid starvation perdecision basis ', 'accordingly  introduce looselyshortest queue family load balancing algorithm ', 'roughly speaking  looselyshortest queue  dispatcher keep different approximation server queue length route job shortest among ', 'communication used update approximation make sure far real queue length expectation ', 'formally establish strong stability looselyshortest queue policy provide easytoverify sufficient condition verifying policy looselyshortest queue ', 'demonstrate looselyshortest queue approach allows constructing throughput optimal policy arbitrarily low communication budget ', 'finally  using extensive simulation consider homogeneous  heterogeneous highly skewed heterogeneous system scenario single dispatcher well multiple dispatcher  show examined looselyshortest queue example policy always stable dictated theory ', 'moreover  exhibit appealing performance significantly outperforms wellknown lowcommunication policy  jsq   jiq  using similar communication budget ']","In recent years, the efficiency and even the feasibility of traditional load-balancing policies are challenged by the rapid growth of cloud infrastructure with increasing levels of server heterogeneity and increasing size of cloud services and applications., In such many software-load-balancers heterogeneous systems, traditional solutions, such as JSQ, incur an increasing communication overhead, whereas low-communication alternatives, such as JSQ(d) and the recently proposed JIQ scheme are either unstable or provide poor performance.

, We argue that a better low-communication load balancing scheme can be established by allowing each dispatcher to have a different view of the system and keep using JSQ, rather than greedily trying to avoid starvation on a per-decision basis. 
, accordingly, we introduce the Loosely-Shortest -Queue family of load balancing algorithms., Roughly speaking, in Loosely-shortest -Queue, each dispatcher keeps a different approximation of the server queue lengths and routes jobs to the shortest among them., Communication is used only to update the approximations and make sure that they are not too far from the real queue lengths in expectation., We formally establish the strong stability of any Loosely-Shortest -Queue policy and provide an easy-to-verify sufficient condition for verifying that a policy is Loosely-Shortest -Queue., We further demonstrate that the Loosely-Shortest -Queue approach allows constructing throughput optimal policies with an arbitrarily low communication budget.

, Finally, using extensive simulations that consider homogeneous, heterogeneous and highly skewed heterogeneous systems in scenarios with a single dispatcher as well as with multiple dispatchers, we show that the examined Loosely-Shortest -Queue example policies are always stable as dictated by theory., Moreover, it exhibits an appealing performance and significantly outperforms well-known low-communication policies, such as JSQ(d) and JIQ, while using a similar communication budget.",26,6.20216606498195,10.653846153846153
151,"['We propose a novel quantitative measure to predict the performance of a deep neural network classifier, where the measure is derived exclusively from the graph structure of the network.', 'We expect that this measure is a fundamental first step in developing a method to evaluate new network architectures and reduce the reliance on the computationally expensive trial and error or ""brute force"" optimisation processes involved in model selection.', 'The measure is derived in the context of multi-layer perceptrons (MLPs), but the definitions are shown to be useful also in the context of deep convolutional neural networks (CNN), where it is able to estimate and compare the relative performance of different types of neural networks, such as VGG, ResNet, and DenseNet.', 'Our measure is also used to study the effects of some important ""hidden"" hyper-parameters of the DenseNet architecture, such as number of layers, growth rate and the dimension of 1x1 convolutions in DenseNet-BC.', 'Ultimately, our measure facilitates the optimisation of the DenseNet design, which shows improved results compared to the baseline.\n']","[1, 0, 0, 0, 0]","[0.5294117331504822, 0.1702127605676651, 0.23076923191547394, 0.20000000298023224, 0.27586206793785095]",Bkx8JJBtDS,"['A quantitative measure to predict the performances of deep neural network models.', 'The paper proposes a novel quantity that counts the number of path in the neural network which is predictive of the performance of neural networks with the same number of parameters.', 'The paper presents a method for counting paths in deep neural networks that arguably can be used to measure the performance of the network.']","['propose novel quantitative measure predict performance deep neural network classifier  measure derived exclusively graph structure network ', 'expect measure fundamental first step developing method evaluate new network architecture reduce reliance computationally expensive trial error  brute force  optimisation process involved model selection ', 'measure derived context multilayer perceptrons  mlps   definition shown useful also context deep convolutional neural network  cnn   able estimate compare relative performance different type neural network  vgg  resnet  densenet ', 'measure also used study effect important  hidden  hyperparameters densenet architecture  number layer  growth rate dimension 1x1 convolution densenetbc ', 'ultimately  measure facilitates optimisation densenet design  show improved result compared baseline ']","We propose a novel quantitative measure to predict the performance of a deep neural network classifier, where the measure is derived exclusively from the graph structure of the network., We expect that this measure is a fundamental first step in developing a method to evaluate new network architectures and reduce the reliance on the computationally expensive trial and error or ""brute force"" optimisation processes involved in model selection., The measure is derived in the context of multi-layer perceptrons (MLPs), but the definitions are shown to be useful also in the context of deep convolutional neural networks (CNN), where it is able to estimate and compare the relative performance of different types of neural networks, such as VGG, ResNet, and DenseNet., Our measure is also used to study the effects of some important ""hidden"" hyper-parameters of the DenseNet architecture, such as number of layers, growth rate and the dimension of 1x1 convolutions in DenseNet-BC., Ultimately, our measure facilitates the optimisation of the DenseNet design, which shows improved results compared to the baseline.
",15,5.432748538011696,11.4
152,"['There is a stark disparity between the learning rate schedules used in the practice of large scale machine learning and what are considered admissible learning rate schedules prescribed in the theory of stochastic approximation.', ""Recent results, such as in the 'super-convergence' methods which use oscillating learning rates, serve to emphasize this point even more.\n"", ""One plausible explanation is that non-convex neural network training procedures are better suited to the use of fundamentally different learning rate  schedules, such as the ``cut the learning rate every constant number of epochs'' method (which more closely resembles an exponentially decaying learning rate schedule); note that this widely used schedule is in stark contrast to the polynomial decay schemes prescribed in the stochastic approximation literature, which are indeed shown to be (worst case) optimal for classes of convex optimization problems.\n\n"", 'The main contribution of this work shows that the picture is far more nuanced, where we do not even need to move to non-convex optimization to show other learning rate schemes can be far more effective.', ""In fact, even for the simple case of stochastic linear regression with a fixed time horizon, the rate achieved by any polynomial decay scheme is sub-optimal compared to the statistical minimax rate (by a factor of condition number); in contrast the ```''cut the learning rate every constant number of epochs'' provides an exponential improvement (depending only logarithmically on the condition number) compared to any polynomial decay scheme.  "", 'Finally, it is important to ask if our theoretical insights are somehow fundamentally tied to quadratic loss minimization (where we have circumvented minimax lower bounds for more general convex optimization problems)?', 'Here, we conjecture that recent results which make the gradient norm small at a near optimal rate, for both convex and non-convex optimization, may also provide more insights into learning rate schedules used in practice.\n']","[1, 0, 0, 0, 0, 0, 0]","[0.3050847351551056, 0.1111111044883728, 0.14141413569450378, 0.2153846174478531, 0.1666666567325592, 0.0317460261285305, 0.17391303181648254]",HJePy3RcF7,"['This paper presents a rigorous study of why practically used learning rate schedules (for a given computational budget) offer significant advantages even though these schemes are not advocated by the classical theory of Stochastic Approximation.', 'This paper presents a theoretical study of different learning rate schedules that resulted in statistical minimax lower bounds for both polynomial and constant-and-cut schemes.', 'The paper studies the effect of learning-rate choices for stochastic optimization, focusing on least-mean-squares with decaying stepsizes']","['stark disparity learning rate schedule used practice large scale machine learning considered admissible learning rate schedule prescribed theory stochastic approximation ', 'recent result  superconvergence  method use oscillating learning rate  serve emphasize point even ', 'one plausible explanation nonconvex neural network training procedure better suited use fundamentally different learning rate schedule   cut learning rate every constant number epoch  method  closely resembles exponentially decaying learning rate schedule   note widely used schedule stark contrast polynomial decay scheme prescribed stochastic approximation literature  indeed shown  worst case  optimal class convex optimization problem ', 'main contribution work show picture far nuanced  even need move nonconvex optimization show learning rate scheme far effective ', 'fact  even simple case stochastic linear regression fixed time horizon  rate achieved polynomial decay scheme suboptimal compared statistical minimax rate  factor condition number   contrast    cut learning rate every constant number epoch  provides exponential improvement  depending logarithmically condition number  compared polynomial decay scheme ', 'finally  important ask theoretical insight somehow fundamentally tied quadratic loss minimization  circumvented minimax lower bound general convex optimization problem  ', ' conjecture recent result make gradient norm small near optimal rate  convex nonconvex optimization  may also provide insight learning rate schedule used practice ']","There is a stark disparity between the learning rate schedules used in the practice of large scale machine learning and what are considered admissible learning rate schedules prescribed in the theory of stochastic approximation., Recent results, such as in the 'super-convergence' methods which use oscillating learning rates, serve to emphasize this point even more.
, One plausible explanation is that non-convex neural network training procedures are better suited to the use of fundamentally different learning rate  schedules, such as the ``cut the learning rate every constant number of epochs'' method (which more closely resembles an exponentially decaying learning rate schedule); note that this widely used schedule is in stark contrast to the polynomial decay schemes prescribed in the stochastic approximation literature, which are indeed shown to be (worst case) optimal for classes of convex optimization problems.

, The main contribution of this work shows that the picture is far more nuanced, where we do not even need to move to non-convex optimization to show other learning rate schemes can be far more effective., In fact, even for the simple case of stochastic linear regression with a fixed time horizon, the rate achieved by any polynomial decay scheme is sub-optimal compared to the statistical minimax rate (by a factor of condition number); in contrast the ```''cut the learning rate every constant number of epochs'' provides an exponential improvement (depending only logarithmically on the condition number) compared to any polynomial decay scheme.  , Finally, it is important to ask if our theoretical insights are somehow fundamentally tied to quadratic loss minimization (where we have circumvented minimax lower bounds for more general convex optimization problems)?, Here, we conjecture that recent results which make the gradient norm small at a near optimal rate, for both convex and non-convex optimization, may also provide more insights into learning rate schedules used in practice.
",18,5.5855263157894735,16.88888888888889
153,"['We present Value Propagation (VProp), a set of parameter-efficient differentiable planning modules built on Value Iteration which can successfully be trained using reinforcement learning to solve unseen tasks, has the capability to generalize to larger map sizes, and can learn to navigate in dynamic environments.', 'We show that the modules enable learning to plan when the environment also includes stochastic elements, providing a cost-efficient learning system to build low-level size-invariant planners for a variety of interactive navigation problems.', 'We evaluate on static and dynamic configurations of MazeBase grid-worlds, with randomly generated environments of several different sizes, and on a StarCraft navigation scenario, with more complex dynamics, and pixels as input.']","[0, 1, 0]","[0.27586206793785095, 0.2978723347187042, 0.2222222238779068]",SJG6G2RqtX,"['We present planners based on convnets that are sample-efficient and that generalize to larger instances of navigation and pathfinding problems.', 'Proposes methods, which can be seen as modifications of Value Iteration Networks (VIN), with some improvements aimed at improving sample efficiency and generalization to large environment sizes.', 'The paper presents an extension of the original value iteration networks (VIN) by considering a state-dependent transition function.']","['present value propagation  vprop   set parameterefficient differentiable planning module built value iteration successfully trained using reinforcement learning solve unseen task  capability generalize larger map size  learn navigate dynamic environment ', 'show module enable learning plan environment also includes stochastic element  providing costefficient learning system build lowlevel sizeinvariant planner variety interactive navigation problem ', 'evaluate static dynamic configuration mazebase gridworlds  randomly generated environment several different size  starcraft navigation scenario  complex dynamic  pixel input ']","We present Value Propagation (VProp), a set of parameter-efficient differentiable planning modules built on Value Iteration which can successfully be trained using reinforcement learning to solve unseen tasks, has the capability to generalize to larger map sizes, and can learn to navigate in dynamic environments., We show that the modules enable learning to plan when the environment also includes stochastic elements, providing a cost-efficient learning system to build low-level size-invariant planners for a variety of interactive navigation problems., We evaluate on static and dynamic configurations of MazeBase grid-worlds, with randomly generated environments of several different sizes, and on a StarCraft navigation scenario, with more complex dynamics, and pixels as input.",11,6.054545454545455,10.0
154,"['Learning high-quality word embeddings is of significant importance in achieving better performance in many down-stream learning tasks.', 'On one hand, traditional word embeddings are trained on a large scale corpus for general-purpose tasks, which are often sub-optimal for many domain-specific tasks.', 'On the other hand, many domain-specific tasks do not have a large enough domain corpus to obtain high-quality embeddings.', 'We observe that domains are not isolated and a small domain corpus can leverage the learned knowledge from many past domains to augment that corpus in order to generate high-quality embeddings.', 'In this paper, we formulate the learning of word embeddings as a lifelong learning process.', 'Given knowledge learned from many previous domains and a small new domain corpus, the proposed method can effectively generate new domain embeddings by leveraging a simple but effective algorithm and a meta-learner, where the meta-learner is able to provide word context similarity information at the domain-level.', 'Experimental results demonstrate that the proposed method can effectively learn new domain embeddings from a small corpus and past domain knowledges\\footnote{We will release the code after final revisions.}.', 'We', 'also demonstrate that general-purpose embeddings trained from a large scale corpus are sub-optimal in domain-specific tasks.']","[0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.25, 0.06666666269302368, 0.14814814925193787, 0.17142856121063232, 0.27272728085517883, 0.12765957415103912, 0.17142856121063232, 0.0833333283662796]",H1BO9M-0Z,"['learning better domain embeddings via lifelong learning and meta-learning', 'Presents a lifelong learning method for learning word embeddings.', 'This paper proposes an approach to learn embeddings in new domains and significantly beats the baseline on an aspect extraction task. ']","['learning highquality word embeddings significant importance achieving better performance many downstream learning task ', 'one hand  traditional word embeddings trained large scale corpus generalpurpose task  often suboptimal many domainspecific task ', 'hand  many domainspecific task large enough domain corpus obtain highquality embeddings ', 'observe domain isolated small domain corpus leverage learned knowledge many past domain augment corpus order generate highquality embeddings ', 'paper  formulate learning word embeddings lifelong learning process ', 'given knowledge learned many previous domain small new domain corpus  proposed method effectively generate new domain embeddings leveraging simple effective algorithm metalearner  metalearner able provide word context similarity information domainlevel ', 'experimental result demonstrate proposed method effectively learn new domain embeddings small corpus past domain knowledgesfootnote  release code final revision   ', '', 'also demonstrate generalpurpose embeddings trained large scale corpus suboptimal domainspecific task ']","Learning high-quality word embeddings is of significant importance in achieving better performance in many down-stream learning tasks., On one hand, traditional word embeddings are trained on a large scale corpus for general-purpose tasks, which are often sub-optimal for many domain-specific tasks., On the other hand, many domain-specific tasks do not have a large enough domain corpus to obtain high-quality embeddings., We observe that domains are not isolated and a small domain corpus can leverage the learned knowledge from many past domains to augment that corpus in order to generate high-quality embeddings., In this paper, we formulate the learning of word embeddings as a lifelong learning process., Given knowledge learned from many previous domains and a small new domain corpus, the proposed method can effectively generate new domain embeddings by leveraging a simple but effective algorithm and a meta-learner, where the meta-learner is able to provide word context similarity information at the domain-level., Experimental results demonstrate that the proposed method can effectively learn new domain embeddings from a small corpus and past domain knowledges\footnote{We will release the code after final revisions.}., We, also demonstrate that general-purpose embeddings trained from a large scale corpus are sub-optimal in domain-specific tasks.",15,5.862944162436548,12.375
155,"['Parameter pruning is a promising approach for CNN compression and acceleration by eliminating redundant model parameters with tolerable performance loss.', 'Despite its effectiveness, existing regularization-based parameter pruning methods usually drive weights towards zero with large and constant regularization factors, which neglects the fact that the expressiveness of CNNs is fragile and needs a more gentle way of regularization for the networks to adapt during pruning.', 'To solve this problem, we propose a new regularization-based pruning method (named IncReg) to incrementally assign different regularization factors to different weight groups based on their relative importance, whose effectiveness is proved on popular CNNs compared with state-of-the-art methods.']","[0, 0, 1]","[0.0952380895614624, 0.16393442451953888, 0.7241379022598267]",S1e_xM7_iQ,"[' we propose a new regularization-based pruning method (named IncReg) to incrementally assign different regularization factors to different weight groups based on their relative importance.', 'This paper proposes a regularization-based pruning method to incrementally assign different regularization factors to different weight groups based on their relative importance.']","['parameter pruning promising approach cnn compression acceleration eliminating redundant model parameter tolerable performance loss ', 'despite effectiveness  existing regularizationbased parameter pruning method usually drive weight towards zero large constant regularization factor  neglect fact expressiveness cnns fragile need gentle way regularization network adapt pruning ', 'solve problem  propose new regularizationbased pruning method  named increg  incrementally assign different regularization factor different weight group based relative importance  whose effectiveness proved popular cnns compared stateoftheart method ']","Parameter pruning is a promising approach for CNN compression and acceleration by eliminating redundant model parameters with tolerable performance loss., Despite its effectiveness, existing regularization-based parameter pruning methods usually drive weights towards zero with large and constant regularization factors, which neglects the fact that the expressiveness of CNNs is fragile and needs a more gentle way of regularization for the networks to adapt during pruning., To solve this problem, we propose a new regularization-based pruning method (named IncReg) to incrementally assign different regularization factors to different weight groups based on their relative importance, whose effectiveness is proved on popular CNNs compared with state-of-the-art methods.",7,6.384615384615385,14.857142857142858
156,"[""Momentum based stochastic gradient methods such as heavy ball (HB) and Nesterov's accelerated gradient descent (NAG) method are widely used in practice for training deep networks and other supervised learning models, as they often provide significant improvements over stochastic gradient descent (SGD)."", 'Rigorously speaking, fast gradient methods have provable improvements over gradient descent only for the deterministic case, where the gradients are exact.', 'In the stochastic case, the popular explanations for their wide applicability is that when these fast gradient methods are applied in the stochastic case, they partially mimic their exact gradient counterparts, resulting in some practical gain.', 'This work provides a counterpoint to this belief by proving that there exist simple problem instances where these methods cannot outperform SGD despite the best setting of its parameters.', 'These negative problem instances are, in an informal sense, generic; they do not look like carefully constructed pathological instances.', ""These results suggest (along with empirical evidence) that HB or NAG's practical performance gains are a by-product of minibatching.\n\n"", ""Furthermore, this work provides a viable (and provable) alternative, which, on the same set of problem instances, significantly improves over HB, NAG, and SGD's performance."", ""This algorithm, referred to as Accelerated Stochastic Gradient Descent (ASGD), is a simple to implement stochastic algorithm, based on a relatively less popular variant of Nesterov's Acceleration."", 'Extensive empirical results in this paper show that ASGD has performance gains over HB, NAG, and SGD.', 'The code for implementing the ASGD Algorithm can be found at https://github.com/rahulkidambi/AccSGD.\n']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.317460298538208, 0.1304347813129425, 0.1071428507566452, 0.0, 0.08888888359069824, 0.04255318641662598, 0.07692307233810425, 0.11764705181121826, 0.09090908616781235, 0.0]",rJTutzbA-,"[""Existing momentum/acceleration schemes such as heavy ball method and Nesterov's acceleration employed with stochastic gradients do not improve over vanilla stochastic gradient descent, especially when employed with small batch sizes.""]","['momentum based stochastic gradient method heavy ball  hb  nesterov accelerated gradient descent  nag  method widely used practice training deep network supervised learning model  often provide significant improvement stochastic gradient descent  sgd  ', 'rigorously speaking  fast gradient method provable improvement gradient descent deterministic case  gradient exact ', 'stochastic case  popular explanation wide applicability fast gradient method applied stochastic case  partially mimic exact gradient counterpart  resulting practical gain ', 'work provides counterpoint belief proving exist simple problem instance method outperform sgd despite best setting parameter ', 'negative problem instance  informal sense  generic  look like carefully constructed pathological instance ', 'result suggest  along empirical evidence  hb nag practical performance gain byproduct minibatching ', 'furthermore  work provides viable  provable  alternative   set problem instance  significantly improves hb  nag  sgd performance ', 'algorithm  referred accelerated stochastic gradient descent  asgd   simple implement stochastic algorithm  based relatively le popular variant nesterov acceleration ', 'extensive empirical result paper show asgd performance gain hb  nag  sgd ', 'code implementing asgd algorithm found http  githubcomrahulkidambiaccsgd ']","Momentum based stochastic gradient methods such as heavy ball (HB) and Nesterov's accelerated gradient descent (NAG) method are widely used in practice for training deep networks and other supervised learning models, as they often provide significant improvements over stochastic gradient descent (SGD)., Rigorously speaking, fast gradient methods have provable improvements over gradient descent only for the deterministic case, where the gradients are exact., In the stochastic case, the popular explanations for their wide applicability is that when these fast gradient methods are applied in the stochastic case, they partially mimic their exact gradient counterparts, resulting in some practical gain., This work provides a counterpoint to this belief by proving that there exist simple problem instances where these methods cannot outperform SGD despite the best setting of its parameters., These negative problem instances are, in an informal sense, generic; they do not look like carefully constructed pathological instances., These results suggest (along with empirical evidence) that HB or NAG's practical performance gains are a by-product of minibatching.

, Furthermore, this work provides a viable (and provable) alternative, which, on the same set of problem instances, significantly improves over HB, NAG, and SGD's performance., This algorithm, referred to as Accelerated Stochastic Gradient Descent (ASGD), is a simple to implement stochastic algorithm, based on a relatively less popular variant of Nesterov's Acceleration., Extensive empirical results in this paper show that ASGD has performance gains over HB, NAG, and SGD., The code for implementing the ASGD Algorithm can be found at https://github.com/rahulkidambi/AccSGD.
",29,5.955465587044534,8.517241379310345
157,"['Oversubscription planning (OSP) is the problem of finding plans that maximize the utility value of their end state while staying within a specified cost bound.', 'Recently, it has been shown that OSP problems can be reformulated as classical planning problems with multiple cost functions but no utilities.  ', 'Here we take advantage of this reformulation to show that OSP problems can be solved optimally using the A* search algorithm, in contrast to previous approaches that have used variations on branch-and-bound search.', 'This allows many powerful techniques developed for classical planning to be applied to OSP problems.', 'We also introduce novel bound-sensitive heuristics, which are able to reason about the primary cost of a solution while taking into account secondary cost functions and bounds, to provide superior guidance compared to heuristics that do not take these bounds into account.', 'We implement two such bound-sensitive variants of existing classical planning heuristics, and show experimentally that the resulting search is significantly more informed than comparable heuristics that do not consider bounds.']","[0, 0, 0, 0, 0, 1]","[0.09999999403953552, 0.20512819290161133, 0.2978723347187042, 0.19354838132858276, 0.25925925374031067, 0.30434781312942505]",BJlBNZDaP4,"['We show that oversubscription planning tasks can be solved using A* and introduce novel bound-sensitive heuristics for oversubscription planning tasks.', 'Presents an approach to solve oversubscription planning (OSP) tasks optimally by using a translation to classical planning with multiple cost functions.', 'The paper proposes modifications to admissible heuristics to make them better informed in a multi-criteria setting where.']","['oversubscription planning  osp  problem finding plan maximize utility value end state staying within specified cost bound ', 'recently  shown osp problem reformulated classical planning problem multiple cost function utility ', 'take advantage reformulation show osp problem solved optimally using  search algorithm  contrast previous approach used variation branchandbound search ', 'allows many powerful technique developed classical planning applied osp problem ', 'also introduce novel boundsensitive heuristic  able reason primary cost solution taking account secondary cost function bound  provide superior guidance compared heuristic take bound account ', 'implement two boundsensitive variant existing classical planning heuristic  show experimentally resulting search significantly informed comparable heuristic consider bound ']","Oversubscription planning (OSP) is the problem of finding plans that maximize the utility value of their end state while staying within a specified cost bound., Recently, it has been shown that OSP problems can be reformulated as classical planning problems with multiple cost functions but no utilities.  , Here we take advantage of this reformulation to show that OSP problems can be solved optimally using the A* search algorithm, in contrast to previous approaches that have used variations on branch-and-bound search., This allows many powerful techniques developed for classical planning to be applied to OSP problems., We also introduce novel bound-sensitive heuristics, which are able to reason about the primary cost of a solution while taking into account secondary cost functions and bounds, to provide superior guidance compared to heuristics that do not take these bounds into account., We implement two such bound-sensitive variants of existing classical planning heuristics, and show experimentally that the resulting search is significantly more informed than comparable heuristics that do not consider bounds.",11,5.676646706586826,15.181818181818182
158,"['Previous work on adversarially robust neural networks requires large training sets and computationally expensive training procedures.  ', 'On the other hand, few-shot learning methods are highly vulnerable to adversarial examples.  ', 'The goal of our work is to produce networks which both perform well at few-shot tasks and are simultaneously robust to adversarial examples.  ', 'We adapt adversarial training for meta-learning, we adapt robust architectural features to small networks for meta-learning, we test pre-processing defenses as an alternative to adversarial training for meta-learning, and we investigate the advantages of robust meta-learning over robust transfer-learning for few-shot tasks.  ', 'This work provides a thorough analysis of adversarially robust methods in the context of meta-learning, and we lay the foundation for future work on defenses for few-shot tasks.']","[0, 0, 0, 0, 1]","[0.1599999964237213, 0.260869562625885, 0.1249999925494194, 0.25641024112701416, 0.3030303120613098]",SyekweSFPr,"['We develop meta-learning methods for adversarially robust few-shot learning.', 'This paper presents a method that enhances the robustness of few-shot learning by introducing adversarial query data attack in the inner-task fine-tuning phase of a meta-learning algorithm.', 'The authors of this paper propose a novel approach for training a robust few-shot model. ']","['previous work adversarially robust neural network requires large training set computationally expensive training procedure ', 'hand  fewshot learning method highly vulnerable adversarial example ', 'goal work produce network perform well fewshot task simultaneously robust adversarial example ', 'adapt adversarial training metalearning  adapt robust architectural feature small network metalearning  test preprocessing defense alternative adversarial training metalearning  investigate advantage robust metalearning robust transferlearning fewshot task ', 'work provides thorough analysis adversarially robust method context metalearning  lay foundation future work defense fewshot task ']","Previous work on adversarially robust neural networks requires large training sets and computationally expensive training procedures.  , On the other hand, few-shot learning methods are highly vulnerable to adversarial examples.  , The goal of our work is to produce networks which both perform well at few-shot tasks and are simultaneously robust to adversarial examples.  , We adapt adversarial training for meta-learning, we adapt robust architectural features to small networks for meta-learning, we test pre-processing defenses as an alternative to adversarial training for meta-learning, and we investigate the advantages of robust meta-learning over robust transfer-learning for few-shot tasks.  , This work provides a thorough analysis of adversarially robust methods in the context of meta-learning, and we lay the foundation for future work on defenses for few-shot tasks.",10,6.098360655737705,12.2
159,"['Many of our core assumptions about how neural networks operate remain empirically untested.', 'One common assumption is that convolutional neural networks need to be stable to small translations and deformations to solve image recognition tasks.', 'For many years, this stability was baked into CNN architectures by incorporating interleaved pooling layers.', 'Recently, however, interleaved pooling has largely been abandoned.', 'This raises a number of questions: Are our intuitions about deformation stability right at all?', 'Is it important?', 'Is pooling necessary for deformation invariance?', 'If not, how is deformation invariance achieved in its absence?', 'In this work, we rigorously test these questions, and find that deformation stability in convolutional networks is more nuanced than it first appears: (1) Deformation invariance is not a binary property, but rather that different tasks require different degrees of deformation stability at different layers.', '(2) Deformation stability is not a fixed property of a network and is heavily adjusted over the course of training, largely through the smoothness of the convolutional filters.', '(3) Interleaved pooling layers are neither necessary nor sufficient for achieving the optimal form of deformation stability for natural image classification.', '(4) Pooling confers \\emph{too much} deformation stability for image classification at initialization, and during training, networks have to learn to \\emph{counteract} this inductive bias.', 'Together, these findings provide new insights into the role of interleaved pooling and deformation invariance in CNNs, and demonstrate the importance of rigorous empirical testing of even our most basic assumptions about the working of neural networks.']","[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.0, 0.09756097197532654, 0.1111111044883728, 0.06896550953388214, 0.1111111044883728, 0.0, 0.14814814925193787, 0.12903225421905518, 0.23333333432674408, 0.1860465109348297, 0.1463414579629898, 0.13636362552642822, 0.19230768084526062]",HJeuOiRqKQ,['We find that pooling alone does not determine deformation stability in CNNs and that filter smoothness plays an important role in determining stability. '],"['many core assumption neural network operate remain empirically untested ', 'one common assumption convolutional neural network need stable small translation deformation solve image recognition task ', 'many year  stability baked cnn architecture incorporating interleaved pooling layer ', 'recently  however  interleaved pooling largely abandoned ', 'raise number question  intuition deformation stability right ', 'important ', 'pooling necessary deformation invariance ', ' deformation invariance achieved absence ', 'work  rigorously test question  find deformation stability convolutional network nuanced first appears   1  deformation invariance binary property  rather different task require different degree deformation stability different layer ', ' 2  deformation stability fixed property network heavily adjusted course training  largely smoothness convolutional filter ', ' 3  interleaved pooling layer neither necessary sufficient achieving optimal form deformation stability natural image classification ', ' 4  pooling confers emph  much  deformation stability image classification initialization  training  network learn emph  counteract  inductive bias ', 'together  finding provide new insight role interleaved pooling deformation invariance cnns  demonstrate importance rigorous empirical testing even basic assumption working neural network ']","Many of our core assumptions about how neural networks operate remain empirically untested., One common assumption is that convolutional neural networks need to be stable to small translations and deformations to solve image recognition tasks., For many years, this stability was baked into CNN architectures by incorporating interleaved pooling layers., Recently, however, interleaved pooling has largely been abandoned., This raises a number of questions: Are our intuitions about deformation stability right at all?, Is it important?, Is pooling necessary for deformation invariance?, If not, how is deformation invariance achieved in its absence?, In this work, we rigorously test these questions, and find that deformation stability in convolutional networks is more nuanced than it first appears: (1) Deformation invariance is not a binary property, but rather that different tasks require different degrees of deformation stability at different layers., (2) Deformation stability is not a fixed property of a network and is heavily adjusted over the course of training, largely through the smoothness of the convolutional filters., (3) Interleaved pooling layers are neither necessary nor sufficient for achieving the optimal form of deformation stability for natural image classification., (4) Pooling confers \emph{too much} deformation stability for image classification at initialization, and during training, networks have to learn to \emph{counteract} this inductive bias., Together, these findings provide new insights into the role of interleaved pooling and deformation invariance in CNNs, and demonstrate the importance of rigorous empirical testing of even our most basic assumptions about the working of neural networks.",25,5.947368421052632,9.88
160,"['Deep neural networks (DNNs) have been shown to over-fit a dataset when being trained with noisy labels for a long enough time.', 'To overcome this problem, we present a simple and effective method self-ensemble label filtering (SELF) to progressively filter out the wrong labels during training.', 'Our method improves the task performance by gradually allowing supervision only from the potentially non-noisy (clean) labels and stops learning on the filtered noisy labels.', 'For the filtering, we form running averages of predictions over the entire training dataset using the network output at different training epochs.', 'We show that these ensemble estimates yield more accurate identification of inconsistent predictions throughout training than the single estimates of the network at the most recent training epoch.', 'While filtered samples are removed entirely from the supervised training loss, we dynamically leverage them via semi-supervised learning in the unsupervised loss.', 'We demonstrate the positive effect of such an approach on various image classification tasks under both symmetric and asymmetric label noise and at different noise ratios.', 'It substantially outperforms all previous works on noise-aware learning across different datasets and can be applied to a broad set of network architectures.']","[0, 0, 0, 0, 0, 0, 0, 1]","[0.1621621549129486, 0.14999999105930328, 0.10526315122842789, 0.0, 0.10256409645080566, 0.05405404791235924, 0.09999999403953552, 0.20512819290161133]",HkgsPhNYPS,"['We propose a self-ensemble framework to train more robust deep learning models under noisy labeled datasets.', 'This paper proposed ""self-ensemble label filtering"" for learning with noisy labels where the label noise is instance-independent, which yield more accurate identification of inconsistent predictions. ', 'This paper proposes an algorithm for learning from data with noisy labels which alternates between updating the model and removing samples that look like they have noisy labels.']","['deep neural network  dnns  shown overfit dataset trained noisy label long enough time ', 'overcome problem  present simple effective method selfensemble label filtering  self  progressively filter wrong label training ', 'method improves task performance gradually allowing supervision potentially nonnoisy  clean  label stop learning filtered noisy label ', 'filtering  form running average prediction entire training dataset using network output different training epoch ', 'show ensemble estimate yield accurate identification inconsistent prediction throughout training single estimate network recent training epoch ', 'filtered sample removed entirely supervised training loss  dynamically leverage via semisupervised learning unsupervised loss ', 'demonstrate positive effect approach various image classification task symmetric asymmetric label noise different noise ratio ', 'substantially outperforms previous work noiseaware learning across different datasets applied broad set network architecture ']","Deep neural networks (DNNs) have been shown to over-fit a dataset when being trained with noisy labels for a long enough time., To overcome this problem, we present a simple and effective method self-ensemble label filtering (SELF) to progressively filter out the wrong labels during training., Our method improves the task performance by gradually allowing supervision only from the potentially non-noisy (clean) labels and stops learning on the filtered noisy labels., For the filtering, we form running averages of predictions over the entire training dataset using the network output at different training epochs., We show that these ensemble estimates yield more accurate identification of inconsistent predictions throughout training than the single estimates of the network at the most recent training epoch., While filtered samples are removed entirely from the supervised training loss, we dynamically leverage them via semi-supervised learning in the unsupervised loss., We demonstrate the positive effect of such an approach on various image classification tasks under both symmetric and asymmetric label noise and at different noise ratios., It substantially outperforms all previous works on noise-aware learning across different datasets and can be applied to a broad set of network architectures.",11,5.78125,17.454545454545453
161,"['Long training times of deep neural networks are a bottleneck in machine learning research.', 'The major impediment to fast training is the quadratic growth of both memory and compute requirements of dense and convolutional layers with respect to their information bandwidth.', ""Recently, training `a priori' sparse networks has been proposed as a method for allowing layers to retain high information bandwidth, while keeping memory and compute low."", 'However, the choice of which sparse topology should be used in these networks is unclear.', 'In this work, we provide a theoretical foundation for the choice of intra-layer topology.', 'First, we derive a new sparse neural network initialization scheme that allows us to explore the space of very deep sparse networks.', 'Next, we evaluate several topologies and show that seemingly similar topologies can often have a large difference in attainable accuracy.', 'To explain these differences, we develop a data-free heuristic that can evaluate a topology independently from the dataset the network will be trained on.', 'We then derive a set of requirements that make a good topology, and arrive at a single topology that satisfies all of them.']","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.17142856121063232, 0.13333332538604736, 0.2978723347187042, 0.3888888955116272, 0.22857142984867096, 0.1904761791229248, 0.09999999403953552, 0.1395348757505417, 0.19999998807907104]",HJgCcCNtwH,"['We investigate pruning DNNs before training and provide an answer to which topology should be used for training a priori sparse networks.', 'The authors propose to replace dense layers with sparsely-connected linear layers and an approach to finding the best topology by measuring how well the sparse layers approximate random weights of their dense counterparts.', 'The paper proposes a sparse cascade architecture that is a multiplication of several sparse matrices and a specific connectivity pattern that outperforms other provided considerations.']","['long training time deep neural network bottleneck machine learning research ', 'major impediment fast training quadratic growth memory compute requirement dense convolutional layer respect information bandwidth ', 'recently  training  priori  sparse network proposed method allowing layer retain high information bandwidth  keeping memory compute low ', 'however  choice sparse topology used network unclear ', 'work  provide theoretical foundation choice intralayer topology ', 'first  derive new sparse neural network initialization scheme allows u explore space deep sparse network ', 'next  evaluate several topology show seemingly similar topology often large difference attainable accuracy ', 'explain difference  develop datafree heuristic evaluate topology independently dataset network trained ', 'derive set requirement make good topology  arrive single topology satisfies ']","Long training times of deep neural networks are a bottleneck in machine learning research., The major impediment to fast training is the quadratic growth of both memory and compute requirements of dense and convolutional layers with respect to their information bandwidth., Recently, training `a priori' sparse networks has been proposed as a method for allowing layers to retain high information bandwidth, while keeping memory and compute low., However, the choice of which sparse topology should be used in these networks is unclear., In this work, we provide a theoretical foundation for the choice of intra-layer topology., First, we derive a new sparse neural network initialization scheme that allows us to explore the space of very deep sparse networks., Next, we evaluate several topologies and show that seemingly similar topologies can often have a large difference in attainable accuracy., To explain these differences, we develop a data-free heuristic that can evaluate a topology independently from the dataset the network will be trained on., We then derive a set of requirements that make a good topology, and arrive at a single topology that satisfies all of them.",17,5.302702702702702,10.882352941176471
162,"['Deep learning models require extensive architecture design exploration and hyperparameter optimization to perform well on a given task.', 'The exploration of the model design space is often made by a human expert, and optimized using a combination of grid search and search heuristics over a large space of possible choices.', 'Neural Architecture Search (NAS) is a Reinforcement Learning approach that has been proposed to automate architecture design.', 'NAS has been successfully applied to generate Neural Networks that rival the best human-designed architectures.', 'However, NAS requires sampling, constructing, and training hundreds to thousands of models to achieve well-performing architectures.', 'This procedure needs to be executed from scratch for each new task.', 'The application of NAS to a wide set of tasks currently lacks a way to transfer generalizable knowledge across tasks.\n', 'In this paper, we present the Multitask Neural Model Search (MNMS) controller.', 'Our goal is to learn a generalizable framework that can condition model construction on successful model searches for previously seen tasks, thus significantly speeding up the search for new tasks.', 'We demonstrate that MNMS can conduct an automated architecture search for multiple tasks simultaneously while still learning well-performing, specialized models for each task.', 'We then show that pre-trained MNMS controllers can transfer learning to new tasks.', 'By leveraging knowledge from previous searches, we find that pre-trained MNMS models start from a better location in the search space and reduce search time on unseen tasks, while still discovering models that outperform published human-designed models.']","[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]","[0.307692289352417, 0.1304347813129425, 0.2631579041481018, 0.1666666567325592, 0.1666666567325592, 0.12121211737394333, 0.21052631735801697, 0.24242423474788666, 0.2448979616165161, 0.41860464215278625, 0.4117647111415863, 0.18867923319339752]",SyAbZb-0Z,"['We present Multitask Neural Model Search, a Meta-learner that can design models for multiple tasks simultaneously and transfer learning to unseen tasks.', 'This paper extends Neural Architecture Search to the multi-task learning problem where a task conditioned model search controller is learned to handle multiple tasks simultaneously.', 'In this paper, authors summarize their work on building a framework, called Multitask Neural Model Search controller, for automated neural network construction across multiple tasks simultaneously.']","['deep learning model require extensive architecture design exploration hyperparameter optimization perform well given task ', 'exploration model design space often made human expert  optimized using combination grid search search heuristic large space possible choice ', 'neural architecture search  na  reinforcement learning approach proposed automate architecture design ', 'na successfully applied generate neural network rival best humandesigned architecture ', 'however  na requires sampling  constructing  training hundred thousand model achieve wellperforming architecture ', 'procedure need executed scratch new task ', 'application na wide set task currently lack way transfer generalizable knowledge across task ', 'paper  present multitask neural model search  mnms  controller ', 'goal learn generalizable framework condition model construction successful model search previously seen task  thus significantly speeding search new task ', 'demonstrate mnms conduct automated architecture search multiple task simultaneously still learning wellperforming  specialized model task ', 'show pretrained mnms controller transfer learning new task ', 'leveraging knowledge previous search  find pretrained mnms model start better location search space reduce search time unseen task  still discovering model outperform published humandesigned model ']","Deep learning models require extensive architecture design exploration and hyperparameter optimization to perform well on a given task., The exploration of the model design space is often made by a human expert, and optimized using a combination of grid search and search heuristics over a large space of possible choices., Neural Architecture Search (NAS) is a Reinforcement Learning approach that has been proposed to automate architecture design., NAS has been successfully applied to generate Neural Networks that rival the best human-designed architectures., However, NAS requires sampling, constructing, and training hundreds to thousands of models to achieve well-performing architectures., This procedure needs to be executed from scratch for each new task., The application of NAS to a wide set of tasks currently lacks a way to transfer generalizable knowledge across tasks.
, In this paper, we present the Multitask Neural Model Search (MNMS) controller., Our goal is to learn a generalizable framework that can condition model construction on successful model searches for previously seen tasks, thus significantly speeding up the search for new tasks., We demonstrate that MNMS can conduct an automated architecture search for multiple tasks simultaneously while still learning well-performing, specialized models for each task., We then show that pre-trained MNMS controllers can transfer learning to new tasks., By leveraging knowledge from previous searches, we find that pre-trained MNMS models start from a better location in the search space and reduce search time on unseen tasks, while still discovering models that outperform published human-designed models.",21,5.775510204081633,11.666666666666666
163,"['This work studies the problem of modeling non-linear visual processes by leveraging deep generative architectures for learning linear, Gaussian models of observed sequences.', 'We propose a joint learning framework, combining a multivariate autoregressive model and deep convolutional generative networks.', 'After justification of theoretical assumptions of inearization, we propose an architecture that allows Variational Autoencoders and Generative Adversarial Networks to simultaneously learn the non-linear observation as well as the linear state-transition model from a sequence of observed frames.', 'Finally, we demonstrate our approach on conceptual toy examples and dynamic textures.']","[0, 1, 0, 0]","[0.3529411852359772, 0.4444444477558136, 0.1304347813129425, 0.0]",SkMPNoCcKQ,"['We model non-linear visual processes as autoregressive noise via generative deep learning.', 'Proposes a new method that models non-linear visual process with a deep version of a linear process (Markov process).', 'This paper proposes a new deep generative model for sequences, particularly image sequences and video, which uses a linear structure in part of the model.']","['work study problem modeling nonlinear visual process leveraging deep generative architecture learning linear  gaussian model observed sequence ', 'propose joint learning framework  combining multivariate autoregressive model deep convolutional generative network ', 'justification theoretical assumption inearization  propose architecture allows variational autoencoders generative adversarial network simultaneously learn nonlinear observation well linear statetransition model sequence observed frame ', 'finally  demonstrate approach conceptual toy example dynamic texture ']","This work studies the problem of modeling non-linear visual processes by leveraging deep generative architectures for learning linear, Gaussian models of observed sequences., We propose a joint learning framework, combining a multivariate autoregressive model and deep convolutional generative networks., After justification of theoretical assumptions of inearization, we propose an architecture that allows Variational Autoencoders and Generative Adversarial Networks to simultaneously learn the non-linear observation as well as the linear state-transition model from a sequence of observed frames., Finally, we demonstrate our approach on conceptual toy examples and dynamic textures.",8,6.651685393258427,11.125
164,"['Partial differential equations (PDEs)  play a prominent role in many disciplines such as applied mathematics, physics, chemistry, material science, computer science, etc.', 'PDEs are commonly derived based on physical laws or empirical observations.', 'However, the governing equations for many complex systems in modern applications are still not fully known.', 'With the rapid development of sensors, computational power, and data storage in the past decade, huge quantities of data can be easily collected and efficiently stored.', 'Such vast quantity of data offers new opportunities for data-driven discovery of hidden physical laws.', 'Inspired by the latest development of neural network designs in deep learning, we propose a new feed-forward deep network, called PDE-Net, to fulfill two objectives at the same time: to accurately predict dynamics of complex systems and to uncover the underlying hidden PDE models.', 'The basic idea of the proposed PDE-Net is to learn differential operators by learning convolution kernels (filters), and apply neural networks or other machine learning methods to approximate the unknown nonlinear responses.', 'Comparing with existing approaches, which either assume the form of the nonlinear response is known or fix certain finite difference approximations of differential operators, our approach has the most flexibility by learning both differential operators and the nonlinear responses.', 'A special feature of the proposed PDE-Net is that all filters are properly constrained, which enables us to easily identify the governing PDE models while still maintaining the expressive and predictive power of the network.', 'These constrains are carefully designed by fully exploiting the relation between the orders of differential operators and the orders of sum rules of filters (an important concept originated from wavelet theory).', 'We also discuss relations of the PDE-Net with some existing networks in computer vision such as Network-In-Network (NIN) and Residual Neural Network (ResNet).', 'Numerical experiments show that the PDE-Net has the potential to uncover the hidden PDE of the observed dynamics, and predict the dynamical behavior for a relatively long time, even in a noisy environment.']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.0555555522441864, 0.07692307233810425, 0.0, 0.05405404791235924, 0.13793103396892548, 0.22641509771347046, 0.09090908616781235, 0.0, 0.043478257954120636, 0.04878048226237297, 0.0, 0.09302324801683426]",SylJ1D1C-,"['This paper proposes a new feed-forward network, call PDE-Net, to learn PDEs from data. ', 'The paper expores the use of deep learning machinery for the purpose of identifying dynamical systems specified by PDEs.', 'The paper proposes a neural network based algorithm for learning from data that arises from dynamical systems with governing equations that can be written as partial differential equations.', 'This paper addresses complex dynamical systems modelling through nonparametric Partial Differential Equations using neural architectures, with the most important idea of the papier (PDE-net) to learn both differential operators and the function that governs the PDE.']","['partial differential equation  pdes  play prominent role many discipline applied mathematics  physic  chemistry  material science  computer science  etc ', 'pdes commonly derived based physical law empirical observation ', 'however  governing equation many complex system modern application still fully known ', 'rapid development sensor  computational power  data storage past decade  huge quantity data easily collected efficiently stored ', 'vast quantity data offer new opportunity datadriven discovery hidden physical law ', 'inspired latest development neural network design deep learning  propose new feedforward deep network  called pdenet  fulfill two objective time  accurately predict dynamic complex system uncover underlying hidden pde model ', 'basic idea proposed pdenet learn differential operator learning convolution kernel  filter   apply neural network machine learning method approximate unknown nonlinear response ', 'comparing existing approach  either assume form nonlinear response known fix certain finite difference approximation differential operator  approach flexibility learning differential operator nonlinear response ', 'special feature proposed pdenet filter properly constrained  enables u easily identify governing pde model still maintaining expressive predictive power network ', 'constrains carefully designed fully exploiting relation order differential operator order sum rule filter  important concept originated wavelet theory  ', 'also discus relation pdenet existing network computer vision networkinnetwork  nin  residual neural network  resnet  ', 'numerical experiment show pdenet potential uncover hidden pde observed dynamic  predict dynamical behavior relatively long time  even noisy environment ']","Partial differential equations (PDEs)  play a prominent role in many disciplines such as applied mathematics, physics, chemistry, material science, computer science, etc., PDEs are commonly derived based on physical laws or empirical observations., However, the governing equations for many complex systems in modern applications are still not fully known., With the rapid development of sensors, computational power, and data storage in the past decade, huge quantities of data can be easily collected and efficiently stored., Such vast quantity of data offers new opportunities for data-driven discovery of hidden physical laws., Inspired by the latest development of neural network designs in deep learning, we propose a new feed-forward deep network, called PDE-Net, to fulfill two objectives at the same time: to accurately predict dynamics of complex systems and to uncover the underlying hidden PDE models., The basic idea of the proposed PDE-Net is to learn differential operators by learning convolution kernels (filters), and apply neural networks or other machine learning methods to approximate the unknown nonlinear responses., Comparing with existing approaches, which either assume the form of the nonlinear response is known or fix certain finite difference approximations of differential operators, our approach has the most flexibility by learning both differential operators and the nonlinear responses., A special feature of the proposed PDE-Net is that all filters are properly constrained, which enables us to easily identify the governing PDE models while still maintaining the expressive and predictive power of the network., These constrains are carefully designed by fully exploiting the relation between the orders of differential operators and the orders of sum rules of filters (an important concept originated from wavelet theory)., We also discuss relations of the PDE-Net with some existing networks in computer vision such as Network-In-Network (NIN) and Residual Neural Network (ResNet)., Numerical experiments show that the PDE-Net has the potential to uncover the hidden PDE of the observed dynamics, and predict the dynamical behavior for a relatively long time, even in a noisy environment.",30,5.724770642201835,10.9
165,"['Each training step for a variational autoencoder (VAE) requires us to sample from the approximate posterior, so we usually choose simple (e.g. factorised) approximate posteriors in which sampling is an efficient computation that fully exploits GPU parallelism.  ', 'However, such simple approximate posteriors are often insufficient, as they eliminate statistical dependencies in the posterior.  ', 'While it is possible to use normalizing flow approximate posteriors for continuous latents, there is nothing analogous for discrete latents.', 'The most natural approach to model discrete dependencies is an autoregressive distribution, but sampling from such distributions is inherently sequential and thus slow.  ', 'We develop a fast, parallel sampling procedure for autoregressive distributions based on fixed-point iterations which enables efficient and accurate variational inference in discrete state-space models.  ', 'To optimize the variational bound, we considered two ways to evaluate probabilities: inserting the relaxed samples directly into the pmf for the discrete distribution, or converting to continuous logistic latent variables and interpreting the K-step fixed-point iterations as a normalizing flow.  ', 'We found that converting to continuous latent variables gave considerable additional scope for mismatch between the true and approximate posteriors, which resulted in biased inferences, we thus used the former approach.  ', 'We tested our approach on the neuroscience problem of inferring discrete spiking activity from noisy calcium-imaging data, and found that it gave accurate connectivity estimates in an order of magnitude less time.']","[0, 0, 0, 0, 1, 0, 0, 0]","[0.11764705181121826, 0.0, 0.12903225421905518, 0.1111111044883728, 0.3589743673801422, 0.1599999964237213, 0.13636362552642822, 0.09090908616781235]",HyxOIoRqFQ,"['We give a fast normalising-flow like sampling procedure for discrete latent variable models.', 'This paper uses an autoregressive filtering variational approximation for parameter estimation in discrete dynamical systems by using fixed point iterations.', 'The authors posit a general autoregressive posterior family for discrete variables or their continuous relaxations. ', 'This paper has two main contributions: it extends normalizing flows to discrete settings and presents an approximate fixed-point update rule for autoregressive time-series that can exploit GPU parallelism. ']","['training step variational autoencoder  vae  requires u sample approximate posterior  usually choose simple  eg  factorised  approximate posterior sampling efficient computation fully exploit gpu parallelism ', 'however  simple approximate posterior often insufficient  eliminate statistical dependency posterior ', 'possible use normalizing flow approximate posterior continuous latents  nothing analogous discrete latents ', 'natural approach model discrete dependency autoregressive distribution  sampling distribution inherently sequential thus slow ', 'develop fast  parallel sampling procedure autoregressive distribution based fixedpoint iteration enables efficient accurate variational inference discrete statespace model ', 'optimize variational bound  considered two way evaluate probability  inserting relaxed sample directly pmf discrete distribution  converting continuous logistic latent variable interpreting kstep fixedpoint iteration normalizing flow ', 'found converting continuous latent variable gave considerable additional scope mismatch true approximate posterior  resulted biased inference  thus used former approach ', 'tested approach neuroscience problem inferring discrete spiking activity noisy calciumimaging data  found gave accurate connectivity estimate order magnitude le time ']","Each training step for a variational autoencoder (VAE) requires us to sample from the approximate posterior, so we usually choose simple (e.g. factorised) approximate posteriors in which sampling is an efficient computation that fully exploits GPU parallelism.  , However, such simple approximate posteriors are often insufficient, as they eliminate statistical dependencies in the posterior.  , While it is possible to use normalizing flow approximate posteriors for continuous latents, there is nothing analogous for discrete latents., The most natural approach to model discrete dependencies is an autoregressive distribution, but sampling from such distributions is inherently sequential and thus slow.  , We develop a fast, parallel sampling procedure for autoregressive distributions based on fixed-point iterations which enables efficient and accurate variational inference in discrete state-space models.  , To optimize the variational bound, we considered two ways to evaluate probabilities: inserting the relaxed samples directly into the pmf for the discrete distribution, or converting to continuous logistic latent variables and interpreting the K-step fixed-point iterations as a normalizing flow.  , We found that converting to continuous latent variables gave considerable additional scope for mismatch between the true and approximate posteriors, which resulted in biased inferences, we thus used the former approach.  , We tested our approach on the neuroscience problem of inferring discrete spiking activity from noisy calcium-imaging data, and found that it gave accurate connectivity estimates in an order of magnitude less time.",19,6.208888888888889,11.25
166,"['Deep neural networks (DNNs) had great success on NLP tasks such as language modeling, machine translation and certain question answering (QA) tasks.', 'However, the success is limited at more knowledge intensive tasks such as QA from a big corpus.', 'Existing end-to-end deep QA models (Miller et al., 2016; Weston et al., 2014) need to read the entire text after observing the question, and therefore their complexity in responding a question is linear in the text size.', 'This is prohibitive for practical tasks such as QA from Wikipedia, a novel, or the Web.', 'We propose to solve this scalability issue by using symbolic meaning representations, which can be indexed and retrieved efficiently with complexity that is independent of the text size.', 'More specifically, we use sequence-to-sequence models to encode knowledge symbolically and generate programs to answer questions from the encoded knowledge.', 'We apply our approach, called the N-Gram Machine (NGM), to the bAbI tasks (Weston et al., 2015) and a special version of them (life-long bAbI) which has stories of up to 10 million sentences.', 'Our experiments show that NGM can successfully solve both of these tasks accurately and efficiently.', 'Unlike fully differentiable memory models, NGMs time complexity and answering quality are not affected by the story length.', 'The whole system of NGM is trained end-to-end with REINFORCE (Williams, 1992).', 'To avoid high variance in gradient estimation, which is typical in discrete latent variable models, we use beam search instead of sampling.', 'To tackle the exponentially large search space, we use a stabilized auto-encoding objective and a structure tweak procedure to iteratively reduce and refine the search space.\n']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.052631575614213943, 0.1764705777168274, 0.16326530277729034, 0.12121211737394333, 0.2666666507720947, 0.514285683631897, 0.20408162474632263, 0.1249999925494194, 0.11428570747375488, 0.0, 0.0, 0.19999998807907104]",By3v9k-RZ,"['We propose a framework that learns to encode knowledge symbolically and generate programs to reason about the encoded knowledge.', '\nThe authors propose the N-Gram machine to answer questions over long documents.', 'This paper presents the n-gram machine, a model that encodes sentences into simple symbolic representations which can be queried efficiently.']","['deep neural network  dnns  great success nlp task language modeling  machine translation certain question answering  qa  task ', 'however  success limited knowledge intensive task qa big corpus ', 'existing endtoend deep qa model  miller et al  2016  weston et al  2014  need read entire text observing question  therefore complexity responding question linear text size ', 'prohibitive practical task qa wikipedia  novel  web ', 'propose solve scalability issue using symbolic meaning representation  indexed retrieved efficiently complexity independent text size ', 'specifically  use sequencetosequence model encode knowledge symbolically generate program answer question encoded knowledge ', 'apply approach  called ngram machine  ngm   babi task  weston et al  2015  special version   lifelong babi   story 10 million sentence ', 'experiment show ngm successfully solve task accurately efficiently ', 'unlike fully differentiable memory model  ngm  time complexity answering quality affected story length ', 'whole system ngm trained endtoend reinforce  williams  1992  ', 'avoid high variance gradient estimation  typical discrete latent variable model  use beam search instead sampling ', 'tackle exponentially large search space  use stabilized autoencoding objective structure tweak procedure iteratively reduce refine search space ']","Deep neural networks (DNNs) had great success on NLP tasks such as language modeling, machine translation and certain question answering (QA) tasks., However, the success is limited at more knowledge intensive tasks such as QA from a big corpus., Existing end-to-end deep QA models (Miller et al., 2016; Weston et al., 2014) need to read the entire text after observing the question, and therefore their complexity in responding a question is linear in the text size., This is prohibitive for practical tasks such as QA from Wikipedia, a novel, or the Web., We propose to solve this scalability issue by using symbolic meaning representations, which can be indexed and retrieved efficiently with complexity that is independent of the text size., More specifically, we use sequence-to-sequence models to encode knowledge symbolically and generate programs to answer questions from the encoded knowledge., We apply our approach, called the N-Gram Machine (NGM), to the bAbI tasks (Weston et al., 2015) and a special version of them (life-long bAbI) which has stories of up to 10 million sentences., Our experiments show that NGM can successfully solve both of these tasks accurately and efficiently., Unlike fully differentiable memory models, NGMs time complexity and answering quality are not affected by the story length., The whole system of NGM is trained end-to-end with REINFORCE (Williams, 1992)., To avoid high variance in gradient estimation, which is typical in discrete latent variable models, we use beam search instead of sampling., To tackle the exponentially large search space, we use a stabilized auto-encoding objective and a structure tweak procedure to iteratively reduce and refine the search space.
",29,5.348314606741573,9.206896551724139
167,"['We propose to use a meta-learning objective that maximizes the speed of transfer on a modified distribution to learn how to modularize acquired knowledge.', 'In particular, we focus on how to factor a joint distribution into appropriate conditionals, consistent with the causal directions.', 'We explain when this can work, using the assumption that the changes in distributions are localized (e.g. to one of the marginals, for example due to an intervention on one of the variables).', 'We prove that under this assumption of localized changes in causal mechanisms, the correct causal graph will tend to have only a few of its parameters with non-zero gradient, i.e. that need to be adapted (those of the modified variables).', 'We argue and observe experimentally that this leads to faster adaptation, and use this property to define a meta-learning surrogate score which, in addition to a continuous parametrization of graphs, would favour correct causal graphs.', 'Finally, motivated by the AI agent point of view (e.g. of a robot discovering its environment autonomously), we consider how the same objective can discover the causal variables themselves, as a transformation of observed low-level variables with no causal meaning.', 'Experiments in the two-variable case validate the proposed ideas and theoretical results.']","[1, 0, 0, 0, 0, 0, 0]","[0.39024388790130615, 0.20512819290161133, 0.1666666567325592, 0.145454540848732, 0.23999999463558197, 0.2222222238779068, 0.06451612710952759]",ryxWIgBFPS,"['This paper proposes a meta-learning objective based on speed of adaptation to transfer distributions to discover a modular decomposition and causal variables.', 'The paper shows that a model with the correct underlying structure will adapt faster to a causal intervention than a model with the incorrect structure.', 'In this work, the authors proposed a general and systematic framework of meta-transfer objective incorporating the causal structure learning under unknown interventions.']","['propose use metalearning objective maximizes speed transfer modified distribution learn modularize acquired knowledge ', 'particular  focus factor joint distribution appropriate conditionals  consistent causal direction ', 'explain work  using assumption change distribution localized  eg  one marginals  example due intervention one variable  ', 'prove assumption localized change causal mechanism  correct causal graph tend parameter nonzero gradient  ie  need adapted  modified variable  ', 'argue observe experimentally lead faster adaptation  use property define metalearning surrogate score  addition continuous parametrization graph  would favour correct causal graph ', 'finally  motivated ai agent point view  eg  robot discovering environment autonomously   consider objective discover causal variable  transformation observed lowlevel variable causal meaning ', 'experiment twovariable case validate proposed idea theoretical result ']","We propose to use a meta-learning objective that maximizes the speed of transfer on a modified distribution to learn how to modularize acquired knowledge., In particular, we focus on how to factor a joint distribution into appropriate conditionals, consistent with the causal directions., We explain when this can work, using the assumption that the changes in distributions are localized (e.g. to one of the marginals, for example due to an intervention on one of the variables)., We prove that under this assumption of localized changes in causal mechanisms, the correct causal graph will tend to have only a few of its parameters with non-zero gradient, i.e. that need to be adapted (those of the modified variables)., We argue and observe experimentally that this leads to faster adaptation, and use this property to define a meta-learning surrogate score which, in addition to a continuous parametrization of graphs, would favour correct causal graphs., Finally, motivated by the AI agent point of view (e.g. of a robot discovering its environment autonomously), we consider how the same objective can discover the causal variables themselves, as a transformation of observed low-level variables with no causal meaning., Experiments in the two-variable case validate the proposed ideas and theoretical results.",19,5.394088669950739,9.227272727272727
168,"['Continual learning is a longstanding goal of artificial intelligence, but is often counfounded by catastrophic forgetting that prevents neural networks from learning tasks sequentially.', 'Previous methods in continual learning have demonstrated how to mitigate catastrophic forgetting, and learn new tasks while retaining performance on the previous tasks.', 'We analyze catastrophic forgetting from the perspective of change in classifier likelihood and propose a simple L1 minimization criterion which can be adapted to different use cases.', 'We further investigate two ways to minimize forgetting as quantified by this criterion and propose strategies to achieve finer control over forgetting.', 'Finally, we evaluate our strategies on 3 datasets of varying difficulty and demonstrate improvements over previously known L2 strategies for mitigating catastrophic forgetting.']","[0, 0, 0, 0, 1]","[0.14814814925193787, 0.14814814925193787, 0.1875, 0.07999999821186066, 0.2222222238779068]",BJlLQlrFwS,"['Another perspective on catastrophic forgetting', 'This paper introduces a framework for combatting catastrophic forgetting based upon changing the loss term to minimise changes in classifier likelihood, obtained via a Taylor series approximation.', 'This paper tries to solve the continual learning prolem by focusing on regularization approaches, and it proposes a L_1 strategy to mitigate the problem.']","['continual learning longstanding goal artificial intelligence  often counfounded catastrophic forgetting prevents neural network learning task sequentially ', 'previous method continual learning demonstrated mitigate catastrophic forgetting  learn new task retaining performance previous task ', 'analyze catastrophic forgetting perspective change classifier likelihood propose simple l1 minimization criterion adapted different use case ', 'investigate two way minimize forgetting quantified criterion propose strategy achieve finer control forgetting ', 'finally  evaluate strategy 3 datasets varying difficulty demonstrate improvement previously known l2 strategy mitigating catastrophic forgetting ']","Continual learning is a longstanding goal of artificial intelligence, but is often counfounded by catastrophic forgetting that prevents neural networks from learning tasks sequentially., Previous methods in continual learning have demonstrated how to mitigate catastrophic forgetting, and learn new tasks while retaining performance on the previous tasks., We analyze catastrophic forgetting from the perspective of change in classifier likelihood and propose a simple L1 minimization criterion which can be adapted to different use cases., We further investigate two ways to minimize forgetting as quantified by this criterion and propose strategies to achieve finer control over forgetting., Finally, we evaluate our strategies on 3 datasets of varying difficulty and demonstrate improvements over previously known L2 strategies for mitigating catastrophic forgetting.",8,6.260504201680672,14.875
169,"['We propose an approach to construct realistic 3D facial morphable models (3DMM) that allows an intuitive facial attribute\n', 'editing workflow.', 'Current face modeling methods using 3DMM suffer from the lack of local control.', 'We thus create a 3DMM by\n', 'combining local part-based 3DMM for the eyes, nose, mouth, ears, and facial mask regions.', 'Our local PCA-based approach\n', 'uses a novel method to select the best eigenvectors from the local 3DMM to ensure that the combined 3DMM is expressive\n', 'while allowing accurate reconstruction.', 'The editing controls we provide to the user are intuitive as they are extracted from\n', 'anthropometric measurements found in the literature.', 'Out of a large set of possible anthropometric measurements, we filter the\n', 'ones that have meaningful generative power given the face data set.', 'We bind the measurements to the part-based 3DMM through\n', 'mapping matrices derived from our data set of facial scans.', 'Our part-based 3DMM is compact yet accurate, and compared to\n', 'other 3DMM methods, it provides a new trade-off between local and global control.', 'We tested our approach on a data set of 135\n', 'scans used to derive the 3DMM, plus 19 scans that served for validation.', 'The results show that our part-based 3DMM approach\n', 'has excellent generative properties and allows intuitive local control to the user.\n\n']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.7272727489471436, 0.09756097197532654, 0.11764705926179886, 0.1428571343421936, 0.0624999962747097, 0.2222222238779068, 0.0, 0.1904761791229248, 0.1764705926179886, 0.1538461446762085, 0.10256409645080566, 0.2222222238779068, 0.10526315122842789, 0.10526315122842789, 0.04878048226237297, 0.15789473056793213, 0.14999999105930328, 0.1111111044883728, 0.24390242993831635]",Q7Cy_qHg6Y,"['We propose an approach to construct realistic 3D facial morphable models (3DMM) that allows an intuitive facial attribute editing workflow by selecting the best sets of eigenvectors and anthropometric measurements.', 'Proposes a piecewise morphable model for human face meshes and also proposes a mapping between anthropometric measurements of the face and the parameters of the model in order to synthesize and edit faces with desired attributes. ', 'This paper describes a method of part-based morphable facial model allowing for localized user control.']","['propose approach construct realistic 3d facial morphable model  3dmm  allows intuitive facial attribute', 'editing workflow ', 'current face modeling method using 3dmm suffer lack local control ', 'thus create 3dmm', 'combining local partbased 3dmm eye  nose  mouth  ear  facial mask region ', 'local pcabased approach', 'us novel method select best eigenvectors local 3dmm ensure combined 3dmm expressive', 'allowing accurate reconstruction ', 'editing control provide user intuitive extracted', 'anthropometric measurement found literature ', 'large set possible anthropometric measurement  filter', 'one meaningful generative power given face data set ', 'bind measurement partbased 3dmm', 'mapping matrix derived data set facial scan ', 'partbased 3dmm compact yet accurate  compared', '3dmm method  provides new tradeoff local global control ', 'tested approach data set 135', 'scan used derive 3dmm  plus 19 scan served validation ', 'result show partbased 3dmm approach', 'excellent generative property allows intuitive local control user ']","We propose an approach to construct realistic 3D facial morphable models (3DMM) that allows an intuitive facial attribute
, editing workflow., Current face modeling methods using 3DMM suffer from the lack of local control., We thus create a 3DMM by
, combining local part-based 3DMM for the eyes, nose, mouth, ears, and facial mask regions., Our local PCA-based approach
, uses a novel method to select the best eigenvectors from the local 3DMM to ensure that the combined 3DMM is expressive
, while allowing accurate reconstruction., The editing controls we provide to the user are intuitive as they are extracted from
, anthropometric measurements found in the literature., Out of a large set of possible anthropometric measurements, we filter the
, ones that have meaningful generative power given the face data set., We bind the measurements to the part-based 3DMM through
, mapping matrices derived from our data set of facial scans., Our part-based 3DMM is compact yet accurate, and compared to
, other 3DMM methods, it provides a new trade-off between local and global control., We tested our approach on a data set of 135
, scans used to derive the 3DMM, plus 19 scans that served for validation., The results show that our part-based 3DMM approach
, has excellent generative properties and allows intuitive local control to the user.

",28,5.18957345971564,7.535714285714286
170,"['We review eight machine learning classification algorithms to analyze Electroencephalographic (EEG) signals in order to distinguish EEG patterns associated with five basic educational tasks.', 'There is a large variety of classifiers being used in this EEG-based Brain-Computer Interface (BCI) field.', 'While previous EEG experiments used several classifiers in the same experiments or reviewed different algorithms on datasets from different experiments, our approach focuses on review eight classifier categories on the same dataset, including linear classifiers, non-linear Bayesian classifiers, nearest neighbour classifiers, ensemble methods, adaptive classifiers, tensor classifiers, transfer learning and deep learning.', 'Besides, we intend to find an approach which can run smoothly on the current mainstream personal computers and smartphones.  ', 'The empirical evaluation demonstrated that Random Forest and LSTM (Long Short-Term Memory) outperform other approaches.', 'We used a data set which users were conducting five frequently-conduct learning-related tasks, including reading, writing, and typing.', 'Results showed that these best two algorithms could correctly classify different users with an accuracy increase of  5% to 9%, use each task independently.', 'Within each subject, the tasks could be recognized with an accuracy increase of  4% to 7%, compared with other approaches.', 'This work suggests that Random Forest could be a recommended approach (fast and accurate) for current mainstream hardware, while LSTM has the potential to be the first-choice approach when the mainstream computers and smartphones can process more data in a shorter time.']","[0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.060606054961681366, 0.1538461446762085, 0.07843136787414551, 0.06666666269302368, 0.0, 0.0714285671710968, 0.0, 0.0, 0.04444444179534912]",BkxmOn4FwH,['Two Algorithms outperformed eight others on a EEG-based BCI experiment'],"['review eight machine learning classification algorithm analyze electroencephalographic  eeg  signal order distinguish eeg pattern associated five basic educational task ', 'large variety classifier used eegbased braincomputer interface  bci  field ', 'previous eeg experiment used several classifier experiment reviewed different algorithm datasets different experiment  approach focus review eight classifier category dataset  including linear classifier  nonlinear bayesian classifier  nearest neighbour classifier  ensemble method  adaptive classifier  tensor classifier  transfer learning deep learning ', 'besides  intend find approach run smoothly current mainstream personal computer smartphones ', 'empirical evaluation demonstrated random forest lstm  long shortterm memory  outperform approach ', 'used data set user conducting five frequentlyconduct learningrelated task  including reading  writing  typing ', 'result showed best two algorithm could correctly classify different user accuracy increase 5  9   use task independently ', 'within subject  task could recognized accuracy increase 4  7   compared approach ', 'work suggests random forest could recommended approach  fast accurate  current mainstream hardware  lstm potential firstchoice approach mainstream computer smartphones process data shorter time ']","We review eight machine learning classification algorithms to analyze Electroencephalographic (EEG) signals in order to distinguish EEG patterns associated with five basic educational tasks., There is a large variety of classifiers being used in this EEG-based Brain-Computer Interface (BCI) field., While previous EEG experiments used several classifiers in the same experiments or reviewed different algorithms on datasets from different experiments, our approach focuses on review eight classifier categories on the same dataset, including linear classifiers, non-linear Bayesian classifiers, nearest neighbour classifiers, ensemble methods, adaptive classifiers, tensor classifiers, transfer learning and deep learning., Besides, we intend to find an approach which can run smoothly on the current mainstream personal computers and smartphones.  , The empirical evaluation demonstrated that Random Forest and LSTM (Long Short-Term Memory) outperform other approaches., We used a data set which users were conducting five frequently-conduct learning-related tasks, including reading, writing, and typing., Results showed that these best two algorithms could correctly classify different users with an accuracy increase of  5% to 9%, use each task independently., Within each subject, the tasks could be recognized with an accuracy increase of  4% to 7%, compared with other approaches., This work suggests that Random Forest could be a recommended approach (fast and accurate) for current mainstream hardware, while LSTM has the potential to be the first-choice approach when the mainstream computers and smartphones can process more data in a shorter time.",25,6.1,9.2
171,"['Multi-agent reinforcement learning offers a way to study how communication could emerge in communities of agents needing to solve specific problems.', 'In this paper, we study the emergence of communication in the negotiation environment, a semi-cooperative model of agent interaction.', 'We introduce two communication protocols - one grounded in the semantics of the game, and one which is a priori ungrounded.  ', 'We show that self-interested agents can use the pre-grounded communication channel to negotiate fairly, but are unable to effectively use the ungrounded, cheap talk channel to do the same.  ', 'However, prosocial agents do learn to use cheap talk to find an optimal negotiating strategy, suggesting that cooperation is necessary for language to emerge.', 'We also study communication behaviour in a setting where one agent interacts with agents in a community with different levels of prosociality and show how agent identifiability can aid negotiation.']","[0, 0, 0, 1, 0, 0]","[0.2380952388048172, 0.10256409645080566, 0.1904761791229248, 0.43478259444236755, 0.27272728085517883, 0.25]",Hk6WhagRW,"['We teach agents to negotiate using only reinforcement learning; selfish agents can do so, but only using a trustworthy communication channel, and prosocial agents can negotiate using cheap talk.', 'The authors describe a variant of the negotation game with the consideration of a secondary communication channel for cheap talk, finding that the secondary channel improves negotation outcomes.', 'This paper explores how agents can learn to communicate to solve a negotiation task and find that prosocial agents are able to learn to ground symbols using RL, but self-interested agents are not.', 'Examines problems of how agents can use communication to maximise their rewards in a simple negotiation game.']","['multiagent reinforcement learning offer way study communication could emerge community agent needing solve specific problem ', 'paper  study emergence communication negotiation environment  semicooperative model agent interaction ', 'introduce two communication protocol  one grounded semantics game  one priori ungrounded ', 'show selfinterested agent use pregrounded communication channel negotiate fairly  unable effectively use ungrounded  cheap talk channel ', 'however  prosocial agent learn use cheap talk find optimal negotiating strategy  suggesting cooperation necessary language emerge ', 'also study communication behaviour setting one agent interacts agent community different level prosociality show agent identifiability aid negotiation ']","Multi-agent reinforcement learning offers a way to study how communication could emerge in communities of agents needing to solve specific problems., In this paper, we study the emergence of communication in the negotiation environment, a semi-cooperative model of agent interaction., We introduce two communication protocols - one grounded in the semantics of the game, and one which is a priori ungrounded.  , We show that self-interested agents can use the pre-grounded communication channel to negotiate fairly, but are unable to effectively use the ungrounded, cheap talk channel to do the same.  , However, prosocial agents do learn to use cheap talk to find an optimal negotiating strategy, suggesting that cooperation is necessary for language to emerge., We also study communication behaviour in a setting where one agent interacts with agents in a community with different levels of prosociality and show how agent identifiability can aid negotiation.",13,5.569444444444445,11.076923076923077
172,"['The goal of few-shot learning is to learn a classifier that generalizes well even when trained with a limited number of training instances per class.', 'The recently introduced meta-learning approaches tackle this problem by learning a generic classifier across a large number of multiclass classification tasks and generalizing the model to a new task.', 'Yet, even with such meta-learning, the low-data problem in the novel classification task still remains.', 'In this paper, we propose Transductive Propagation Network (TPN), a novel meta-learning framework for transductive inference that classifies the entire test set at once to alleviate the low-data problem.', 'Specifically, we propose to learn to propagate labels from labeled instances to unlabeled test instances, by learning a graph construction module that exploits the manifold structure in the data.', 'TPN jointly learns both the parameters of feature embedding and the graph construction in an end-to-end manner.  ', 'We validate TPN on multiple benchmark datasets, on which it largely outperforms existing few-shot learning approaches and achieves the state-of-the-art results.']","[0, 0, 0, 1, 0, 0, 0]","[0.13636362552642822, 0.2083333283662796, 0.22857142984867096, 0.8163264989852905, 0.25531914830207825, 0.052631575614213943, 0.09756097197532654]",SyVuRiC5K7,"['We propose a novel meta-learning framework for transductive inference that classifies the entire test set at once to alleviate the low-data problem.', '\nThis paper proposes to address few-shot learning in a transductive way by learning a label propagation model in an end-to-end manner, the first to learn label propagation for transductive few-shot learning and produced effective empirical results. ', 'This paper proposes a meta-learning framework that leverages unlabeled data by learning the graph-based label propogation in an end-to-end manner.', 'Studies few-host learning in a transductive setting: using meta learning to learn to propagate labels from training samples to test samples. ']","['goal fewshot learning learn classifier generalizes well even trained limited number training instance per class ', 'recently introduced metalearning approach tackle problem learning generic classifier across large number multiclass classification task generalizing model new task ', 'yet  even metalearning  lowdata problem novel classification task still remains ', 'paper  propose transductive propagation network  tpn   novel metalearning framework transductive inference classifies entire test set alleviate lowdata problem ', 'specifically  propose learn propagate label labeled instance unlabeled test instance  learning graph construction module exploit manifold structure data ', 'tpn jointly learns parameter feature embedding graph construction endtoend manner ', 'validate tpn multiple benchmark datasets  largely outperforms existing fewshot learning approach achieves stateoftheart result ']","The goal of few-shot learning is to learn a classifier that generalizes well even when trained with a limited number of training instances per class., The recently introduced meta-learning approaches tackle this problem by learning a generic classifier across a large number of multiclass classification tasks and generalizing the model to a new task., Yet, even with such meta-learning, the low-data problem in the novel classification task still remains., In this paper, we propose Transductive Propagation Network (TPN), a novel meta-learning framework for transductive inference that classifies the entire test set at once to alleviate the low-data problem., Specifically, we propose to learn to propagate labels from labeled instances to unlabeled test instances, by learning a graph construction module that exploits the manifold structure in the data., TPN jointly learns both the parameters of feature embedding and the graph construction in an end-to-end manner.  , We validate TPN on multiple benchmark datasets, on which it largely outperforms existing few-shot learning approaches and achieves the state-of-the-art results.",14,5.793939393939394,11.785714285714286
173,"['We describe the use of an automated scheduling system for observation policy design and to schedule operations of the NASA (National Aeronautics and Space Administration) ECOSystem Spaceborne Thermal Radiometer Experiment on Space Station (ECOSTRESS).', 'We describe the adaptation of the Compressed Large-scale Activity Scheduler and Planner (CLASP) scheduling system to the ECOSTRESS scheduling problem, highlighting multiple use cases for automated scheduling and several challenges for the scheduling technology: handling long-term campaigns with changing information, Mass Storage Unit Ring Buffer operations challenges, and orbit uncertainty.', 'The described scheduling system has been used for operations of the ECOSTRESS instrument since its nominal operations start July 2018 and is expected to operate until mission end in Summer 2019.']","[1, 0, 0]","[0.6800000071525574, 0.4262295067310333, 0.4000000059604645]",rklVVW5qKN,"[""We describe the use of an automated scheduling system for observation policy design and to schedule operations of NASA's ECOSTRESS mission."", 'This paper presents an adaptation of an automated scheduling system, CLASP, to target an EO experiment (ECOSTRESS) on the ISS. ']","['describe use automated scheduling system observation policy design schedule operation nasa  national aeronautics space administration  ecosystem spaceborne thermal radiometer experiment space station  ecostress  ', 'describe adaptation compressed largescale activity scheduler planner  clasp  scheduling system ecostress scheduling problem  highlighting multiple use case automated scheduling several challenge scheduling technology  handling longterm campaign changing information  mass storage unit ring buffer operation challenge  orbit uncertainty ', 'described scheduling system used operation ecostress instrument since nominal operation start july 2018 expected operate mission end summer 2019 ']","We describe the use of an automated scheduling system for observation policy design and to schedule operations of the NASA (National Aeronautics and Space Administration) ECOSystem Spaceborne Thermal Radiometer Experiment on Space Station (ECOSTRESS)., We describe the adaptation of the Compressed Large-scale Activity Scheduler and Planner (CLASP) scheduling system to the ECOSTRESS scheduling problem, highlighting multiple use cases for automated scheduling and several challenges for the scheduling technology: handling long-term campaigns with changing information, Mass Storage Unit Ring Buffer operations challenges, and orbit uncertainty., The described scheduling system has been used for operations of the ECOSTRESS instrument since its nominal operations start July 2018 and is expected to operate until mission end in Summer 2019.",6,6.28695652173913,19.166666666666668
174,"['Adversarial examples are modified samples that preserve original image structures but deviate classifiers.', 'Researchers have put efforts into developing methods for generating adversarial examples and finding out origins.', 'Past research put much attention on decision boundary changes caused by these methods.', 'This paper, in contrast, discusses the origin of adversarial examples from a more underlying knowledge representation point of view.', 'Human beings can learn and classify prototypes as well as transformations of objects.', 'While neural networks store learned knowledge in a more hybrid way of combining all prototypes and transformations as a whole distribution.', 'Hybrid storage may lead to lower distances between different classes so that small modifications can mislead the classifier.', 'A one-step distribution imitation method is designed to imitate distribution of the nearest different class neighbor.', 'Experiments show that simply by imitating distributions from a training set without any knowledge of the classifier can still lead to obvious impacts on classification results from deep networks.', 'It also implies that adversarial examples can be in more forms than small perturbations.', 'Potential ways of alleviating adversarial examples are discussed from the representation point of view.', 'The first path is to change the encoding of data sent to the training step.', 'Training data that are more prototypical can help seize more robust and accurate structural knowledge.', 'The second path requires constructing learning frameworks with improved representations.']","[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.07407406717538834, 0.27586206793785095, 0.0, 0.375, 0.1538461446762085, 0.29411762952804565, 0.1249999925494194, 0.06896550953388214, 0.1428571343421936, 0.2142857164144516, 0.29629629850387573, 0.07407406717538834, 0.1428571343421936, 0.0]",BylRVjC9K7,['Hybird storage and representation of learned knowledge may be a reason for adversarial examples.'],"['adversarial example modified sample preserve original image structure deviate classifier ', 'researcher put effort developing method generating adversarial example finding origin ', 'past research put much attention decision boundary change caused method ', 'paper  contrast  discus origin adversarial example underlying knowledge representation point view ', 'human being learn classify prototype well transformation object ', 'neural network store learned knowledge hybrid way combining prototype transformation whole distribution ', 'hybrid storage may lead lower distance different class small modification mislead classifier ', 'onestep distribution imitation method designed imitate distribution nearest different class neighbor ', 'experiment show simply imitating distribution training set without knowledge classifier still lead obvious impact classification result deep network ', 'also implies adversarial example form small perturbation ', 'potential way alleviating adversarial example discussed representation point view ', 'first path change encoding data sent training step ', 'training data prototypical help seize robust accurate structural knowledge ', 'second path requires constructing learning framework improved representation ']","Adversarial examples are modified samples that preserve original image structures but deviate classifiers., Researchers have put efforts into developing methods for generating adversarial examples and finding out origins., Past research put much attention on decision boundary changes caused by these methods., This paper, in contrast, discusses the origin of adversarial examples from a more underlying knowledge representation point of view., Human beings can learn and classify prototypes as well as transformations of objects., While neural networks store learned knowledge in a more hybrid way of combining all prototypes and transformations as a whole distribution., Hybrid storage may lead to lower distances between different classes so that small modifications can mislead the classifier., A one-step distribution imitation method is designed to imitate distribution of the nearest different class neighbor., Experiments show that simply by imitating distributions from a training set without any knowledge of the classifier can still lead to obvious impacts on classification results from deep networks., It also implies that adversarial examples can be in more forms than small perturbations., Potential ways of alleviating adversarial examples are discussed from the representation point of view., The first path is to change the encoding of data sent to the training step., Training data that are more prototypical can help seize more robust and accurate structural knowledge., The second path requires constructing learning frameworks with improved representations.",16,5.955555555555556,14.0625
175,"['Differently from the popular Deep Q-Network (DQN) learning, Alternating Q-learning (AltQ) does not fully fit a target Q-function at each iteration, and is generally known to be unstable and inefficient.', 'Limited applications of AltQ mostly rely on substantially altering the algorithm architecture in order to improve its performance.', 'Although Adam appears to be a natural solution, its performance in AltQ has rarely been studied before.', 'In this paper, we first provide a solid exploration on how well AltQ performs with Adam.', 'We then take a further step to improve the implementation by adopting the technique of parameter restart.', 'More specifically, the proposed algorithms are tested on a batch of Atari 2600 games and exhibit superior performance than the DQN learning method.', 'The convergence rate of the slightly modified version of the proposed algorithms is characterized under the linear function approximation.', 'To the best of our knowledge, this is the first theoretical study on the Adam-type algorithms in Q-learning.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.054054051637649536, 0.0, 0.07999999821186066, 0.0833333283662796, 0.0, 0.06666666269302368, 0.0, 0.0]",H1eD7REtPr,"['New Experiments and Theory for Adam Based Q-Learning', 'This paper provides a convergence result for traditional Q-learning with linear function approximation when using an Adam-like update. ', 'This paper describes a method to improve the AltQ algorithm by using a combination of an Adam optimizer and regularly restarting the internal parameters of the Adam optimizer.']","['differently popular deep qnetwork  dqn  learning  alternating qlearning  altq  fully fit target qfunction iteration  generally known unstable inefficient ', 'limited application altq mostly rely substantially altering algorithm architecture order improve performance ', 'although adam appears natural solution  performance altq rarely studied ', 'paper  first provide solid exploration well altq performs adam ', 'take step improve implementation adopting technique parameter restart ', 'specifically  proposed algorithm tested batch atari 2600 game exhibit superior performance dqn learning method ', 'convergence rate slightly modified version proposed algorithm characterized linear function approximation ', 'best knowledge  first theoretical study adamtype algorithm qlearning ']","Differently from the popular Deep Q-Network (DQN) learning, Alternating Q-learning (AltQ) does not fully fit a target Q-function at each iteration, and is generally known to be unstable and inefficient., Limited applications of AltQ mostly rely on substantially altering the algorithm architecture in order to improve its performance., Although Adam appears to be a natural solution, its performance in AltQ has rarely been studied before., In this paper, we first provide a solid exploration on how well AltQ performs with Adam., We then take a further step to improve the implementation by adopting the technique of parameter restart., More specifically, the proposed algorithms are tested on a batch of Atari 2600 games and exhibit superior performance than the DQN learning method., The convergence rate of the slightly modified version of the proposed algorithms is characterized under the linear function approximation., To the best of our knowledge, this is the first theoretical study on the Adam-type algorithms in Q-learning.",14,5.474683544303797,11.285714285714286
176,"['In search for more accurate predictive models, we customize capsule networks for the learning to diagnose problem.', 'We also propose Spectral Capsule Networks, a novel variation of capsule networks, that converge faster than capsule network with EM routing.', 'Spectral capsule networks  consist of spatial coincidence filters that detect entities based on the alignment of extracted features on a one-dimensional linear subspace.', 'Experiments on a public benchmark learning to diagnose dataset not only shows the success of capsule networks on this task, but also confirm the faster convergence of the spectral capsule networks.']","[0, 1, 0, 0]","[0.0714285671710968, 0.25, 0.1818181723356247, 0.21621620655059814]",HJuMvYPaM,"['A new capsule network that converges faster on our healthcare benchmark experiments.', 'Presents a variant of capsule networks that instead of using EM routing employs a linear subspace spanned by the dominant eigenvector on the weighted votes matrix from the previous capsule.', 'The paper proposes an improved routing method, which employs tools of eigendecomposition to find capsule activation and pose.']","['search accurate predictive model  customize capsule network learning diagnose problem ', 'also propose spectral capsule network  novel variation capsule network  converge faster capsule network em routing ', 'spectral capsule network consist spatial coincidence filter detect entity based alignment extracted feature onedimensional linear subspace ', 'experiment public benchmark learning diagnose dataset show success capsule network task  also confirm faster convergence spectral capsule network ']","In search for more accurate predictive models, we customize capsule networks for the learning to diagnose problem., We also propose Spectral Capsule Networks, a novel variation of capsule networks, that converge faster than capsule network with EM routing., Spectral capsule networks  consist of spatial coincidence filters that detect entities based on the alignment of extracted features on a one-dimensional linear subspace., Experiments on a public benchmark learning to diagnose dataset not only shows the success of capsule networks on this task, but also confirm the faster convergence of the spectral capsule networks.",8,5.728260869565218,11.5
177,"['One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by the algorithm.', 'In language modeling, users language (e.g. in private messaging) could change in a year and be completely different from what we observe in publicly available data.', 'At the same time, public data can be used for obtaining general knowledge (i.e. general model of English).', 'We study approaches to distributed fine-tuning of a general model on user private data with the additional requirements of maintaining the quality on the general data and minimization of communication costs.', 'We propose a novel technique that significantly improves prediction quality on users language compared to a general model and outperforms gradient compression methods in terms of communication efficiency.', 'The proposed procedure is fast and leads to an almost 70% perplexity reduction and 8.7 percentage point improvement in keystroke saving rate on informal English texts.', 'Finally, we propose an experimental framework for evaluating differential privacy of distributed training of language models and show that our approach has good privacy guarantees.']","[0, 0, 0, 1, 0, 0, 0]","[0.10810810327529907, 0.19999998807907104, 0.11764705181121826, 0.44999998807907104, 0.2790697515010834, 0.0476190410554409, 0.25641024112701416]",HkgNdt26Z,"['We propose a method of distributed fine-tuning of language models on user devices without collection of private data', 'This paper deals with improving language models on mobile equipments based on small portion of text that the user has inputted by employing a linearly interpolated objectives between user specific text and general English. ']","['one big challenge machine learning application training data different realworld data faced algorithm ', 'language modeling  user  language  eg  private messaging  could change year completely different observe publicly available data ', 'time  public data used obtaining general knowledge  ie  general model english  ', 'study approach distributed finetuning general model user private data additional requirement maintaining quality general data minimization communication cost ', 'propose novel technique significantly improves prediction quality user  language compared general model outperforms gradient compression method term communication efficiency ', 'proposed procedure fast lead almost 70  perplexity reduction 87 percentage point improvement keystroke saving rate informal english text ', 'finally  propose experimental framework evaluating differential privacy distributed training language model show approach good privacy guarantee ']","One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by the algorithm., In language modeling, users language (e.g. in private messaging) could change in a year and be completely different from what we observe in publicly available data., At the same time, public data can be used for obtaining general knowledge (i.e. general model of English)., We study approaches to distributed fine-tuning of a general model on user private data with the additional requirements of maintaining the quality on the general data and minimization of communication costs., We propose a novel technique that significantly improves prediction quality on users language compared to a general model and outperforms gradient compression methods in terms of communication efficiency., The proposed procedure is fast and leads to an almost 70% perplexity reduction and 8.7 percentage point improvement in keystroke saving rate on informal English texts., Finally, we propose an experimental framework for evaluating differential privacy of distributed training of language models and show that our approach has good privacy guarantees.",10,5.629213483146067,14.833333333333334
178,"['We propose that approximate Bayesian algorithms should optimize a new criterion, directly derived from the loss, to calculate their approximate posterior which we refer to as pseudo-posterior.', 'Unlike standard variational inference which optimizes a lower bound on the log marginal likelihood, the new algorithms can be analyzed to provide loss guarantees on the predictions with the pseudo-posterior.', 'Our criterion can be used to derive new sparse Gaussian process algorithms that have error guarantees applicable to various likelihoods.']","[0, 1, 0]","[0.2181818187236786, 0.3928571343421936, 0.36734694242477417]",HygJq12VtH,['This paper utilizes the analysis of Lipschitz loss on a bounded hypothesis space to derive new ERM-type algorithms with strong performance guarantees that can be applied to the non-conjugate sparse GP model.'],"['propose approximate bayesian algorithm optimize new criterion  directly derived loss  calculate approximate posterior refer pseudoposterior ', 'unlike standard variational inference optimizes lower bound log marginal likelihood  new algorithm analyzed provide loss guarantee prediction pseudoposterior ', 'criterion used derive new sparse gaussian process algorithm error guarantee applicable various likelihood ']","We propose that approximate Bayesian algorithms should optimize a new criterion, directly derived from the loss, to calculate their approximate posterior which we refer to as pseudo-posterior., Unlike standard variational inference which optimizes a lower bound on the log marginal likelihood, the new algorithms can be analyzed to provide loss guarantees on the predictions with the pseudo-posterior., Our criterion can be used to derive new sparse Gaussian process algorithms that have error guarantees applicable to various likelihoods.",6,5.9480519480519485,12.833333333333334
179,"['In this paper, we propose a novel regularization method, RotationOut, for neural networks. \n', 'Different from Dropout that handles each neuron/channel independently, RotationOut regards its input layer as an entire vector and introduces regularization by randomly rotating the vector. \n', 'RotationOut can also be used in convolutional layers and recurrent layers with a small modification.\n', 'We further use a noise analysis method to interpret the difference between RotationOut and Dropout in co-adaptation reduction. \n', 'Using this method, we also show how to use RotationOut/Dropout together with Batch Normalization. \n', 'Extensive experiments in vision and language tasks are conducted to show the effectiveness of the proposed method. \n', 'Codes will be available.']","[0, 0, 0, 1, 0, 0, 0]","[0.4000000059604645, 0.1111111044883728, 0.1538461446762085, 0.4000000059604645, 0.0, 0.1428571343421936, 0.0]",r1e7M6VYwH,"['We propose a regularization method for neural network and a noise analysis method', 'This paper proposes a new regularization method to mitigate the overfitting issue of deep neural networks by rotating features with a random rotation matrix to reduce co-adaptation.', 'This paper proposes a novel regularization method for training neural networks, which adds noise neurons in an inter-dependent fashion.']","['paper  propose novel regularization method  rotationout  neural network ', 'different dropout handle neuronchannel independently  rotationout regard input layer entire vector introduces regularization randomly rotating vector ', 'rotationout also used convolutional layer recurrent layer small modification ', 'use noise analysis method interpret difference rotationout dropout coadaptation reduction ', 'using method  also show use rotationoutdropout together batch normalization ', 'extensive experiment vision language task conducted show effectiveness proposed method ', 'code available ']","In this paper, we propose a novel regularization method, RotationOut, for neural networks. 
, Different from Dropout that handles each neuron/channel independently, RotationOut regards its input layer as an entire vector and introduces regularization by randomly rotating the vector. 
, RotationOut can also be used in convolutional layers and recurrent layers with a small modification.
, We further use a noise analysis method to interpret the difference between RotationOut and Dropout in co-adaptation reduction. 
, Using this method, we also show how to use RotationOut/Dropout together with Batch Normalization. 
, Extensive experiments in vision and language tasks are conducted to show the effectiveness of the proposed method. 
, Codes will be available.",12,6.0,8.833333333333334
180,"['Formulating the reinforcement learning (RL) problem in the framework of probabilistic inference not only offers a new perspective about RL, but also yields practical algorithms that are more robust and easier to train.', 'While this connection between RL and probabilistic inference has been extensively studied in the single-agent setting, it has not yet been fully understood in the multi-agent setup.', 'In this paper, we pose the problem of multi-agent reinforcement learning as the problem of performing inference in a particular graphical model.', 'We model the environment, as seen by each of the agents, using separate but related Markov decision processes.', 'We derive a practical off-policy maximum-entropy actor-critic algorithm that we call Multi-agent Soft Actor-Critic (MA-SAC) for performing approximate inference in the proposed model using variational inference.', 'MA-SAC can be employed in both cooperative and competitive settings.', 'Through experiments, we demonstrate that MA-SAC outperforms a strong baseline on several multi-agent scenarios.', 'While MA-SAC is one resultant multi-agent RL algorithm that can be derived from the proposed probabilistic framework, our work provides a unified view of maximum-entropy algorithms in the multi-agent setting.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.20512820780277252, 0.13333332538604736, 0.23076923191547394, 0.0, 0.0624999962747097, 0.0, 0.0952380895614624, 0.11428570747375488]",S1ef6JBtPr,"['A probabilistic framework for multi-agent reinforcement learning', 'This paper proposes a new algorithm named Multi-Agent Soft Actor-Critic (MA-SAC) based on the off-policy maximum-entropy actor critic algorithm Soft Actor-Critic (SAC)']","['formulating reinforcement learning  rl  problem framework probabilistic inference offer new perspective rl  also yield practical algorithm robust easier train ', 'connection rl probabilistic inference extensively studied singleagent setting  yet fully understood multiagent setup ', 'paper  pose problem multiagent reinforcement learning problem performing inference particular graphical model ', 'model environment  seen agent  using separate related markov decision process ', 'derive practical offpolicy maximumentropy actorcritic algorithm call multiagent soft actorcritic  masac  performing approximate inference proposed model using variational inference ', 'masac employed cooperative competitive setting ', 'experiment  demonstrate masac outperforms strong baseline several multiagent scenario ', 'masac one resultant multiagent rl algorithm derived proposed probabilistic framework  work provides unified view maximumentropy algorithm multiagent setting ']","Formulating the reinforcement learning (RL) problem in the framework of probabilistic inference not only offers a new perspective about RL, but also yields practical algorithms that are more robust and easier to train., While this connection between RL and probabilistic inference has been extensively studied in the single-agent setting, it has not yet been fully understood in the multi-agent setup., In this paper, we pose the problem of multi-agent reinforcement learning as the problem of performing inference in a particular graphical model., We model the environment, as seen by each of the agents, using separate but related Markov decision processes., We derive a practical off-policy maximum-entropy actor-critic algorithm that we call Multi-agent Soft Actor-Critic (MA-SAC) for performing approximate inference in the proposed model using variational inference., MA-SAC can be employed in both cooperative and competitive settings., Through experiments, we demonstrate that MA-SAC outperforms a strong baseline on several multi-agent scenarios., While MA-SAC is one resultant multi-agent RL algorithm that can be derived from the proposed probabilistic framework, our work provides a unified view of maximum-entropy algorithms in the multi-agent setting.",15,5.955555555555556,12.0
181,"['Sorting input objects is an important step in many machine learning pipelines.', 'However, the sorting operator is non-differentiable with respect to its inputs, which prohibits end-to-end gradient-based optimization.', 'In this work, we propose NeuralSort, a general-purpose continuous relaxation of the output of the sorting operator from permutation matrices to the set of unimodal row-stochastic matrices, where every row sums to one and has a distinct argmax.', 'This relaxation permits straight-through optimization of any computational graph involve a sorting operation.', 'Further, we use this relaxation to enable gradient-based stochastic optimization over the combinatorially large space of permutations by deriving a reparameterized gradient estimator for the Plackett-Luce family of distributions over permutations.', 'We demonstrate the usefulness of our framework on three tasks that require learning semantic orderings of high-dimensional objects, including a fully differentiable, parameterized extension of the k-nearest neighbors algorithm']","[0, 0, 0, 0, 1, 0]","[0.0, 0.3333333134651184, 0.260869562625885, 0.29629629850387573, 0.3414634168148041, 0.14999999105930328]",H1eSS3CcKX,"['We provide a continuous relaxation to the sorting operator, enabling end-to-end, gradient-based stochastic optimization.', 'The paper considers how to sort a number of items without explicitly necessarily learning their actual meanings or values and proposes a method to perform the optimization via a continuous relaxation.', ""This work builds on a sum(top k) identity to derive a pathwise differentiable sampler of 'unimodal row stochastic' matrices."", 'Introduces a continuous relaxation of the sorting operator in order to construct an end-to-end gradient-based optimization and introduces a stochastic extension of its method using Placket-Luce distributions and Monte Carlo.']","['sorting input object important step many machine learning pipeline ', 'however  sorting operator nondifferentiable respect input  prohibits endtoend gradientbased optimization ', 'work  propose neuralsort  generalpurpose continuous relaxation output sorting operator permutation matrix set unimodal rowstochastic matrix  every row sum one distinct argmax ', 'relaxation permit straightthrough optimization computational graph involve sorting operation ', ' use relaxation enable gradientbased stochastic optimization combinatorially large space permutation deriving reparameterized gradient estimator plackettluce family distribution permutation ', 'demonstrate usefulness framework three task require learning semantic ordering highdimensional object  including fully differentiable  parameterized extension knearest neighbor algorithm']","Sorting input objects is an important step in many machine learning pipelines., However, the sorting operator is non-differentiable with respect to its inputs, which prohibits end-to-end gradient-based optimization., In this work, we propose NeuralSort, a general-purpose continuous relaxation of the output of the sorting operator from permutation matrices to the set of unimodal row-stochastic matrices, where every row sums to one and has a distinct argmax., This relaxation permits straight-through optimization of any computational graph involve a sorting operation., Further, we use this relaxation to enable gradient-based stochastic optimization over the combinatorially large space of permutations by deriving a reparameterized gradient estimator for the Plackett-Luce family of distributions over permutations., We demonstrate the usefulness of our framework on three tasks that require learning semantic orderings of high-dimensional objects, including a fully differentiable, parameterized extension of the k-nearest neighbors algorithm",14,6.453237410071942,9.928571428571429
182,"['Transferring knowledge across tasks to improve data-efficiency is one of\n', 'the open key challenges in the area of global optimization algorithms.', 'Readily\n', 'available algorithms are typically designed to be universal optimizers and, thus,\n', 'often suboptimal for specific tasks.', 'We propose a novel transfer learning method to\n', 'obtain customized optimizers within the well-established framework of Bayesian\n', 'optimization, allowing our algorithm to utilize the proven generalization\n', 'capabilities of Gaussian processes.', 'Using reinforcement learning to meta-train an\n', 'acquisition function (AF) on a set of related tasks, the proposed method learns to\n', 'extract implicit structural information and to exploit it for improved data-efficiency.\n', 'We present experiments on a sim-to-real transfer task as well as on several simulated\n', 'functions and two hyperparameter search problems.', 'The results show that our\n', 'algorithm (1) automatically identifies structural properties of objective functions\n', 'from available source tasks or simulations, (2) performs favourably in settings with\n', 'both scarse and abundant source data, and (3) falls back to the performance level\n', 'of general AFs if no structure is present.']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.0714285671710968, 0.2857142686843872, 0.0, 0.0, 0.23076923191547394, 0.29629629850387573, 0.07407406717538834, 0.09090908616781235, 0.0833333283662796, 0.1875, 0.06666666269302368, 0.13333332538604736, 0.1666666567325592, 0.0, 0.14814814925193787, 0.06666666269302368, 0.12903225421905518, 0.07692307233810425]",ryeYpJSKwr,"['We perform efficient and flexible transfer learning in the framework of Bayesian optimization through meta-learned neural acquisition functions.', 'The authors present MetaBO which uses reinforcement learning to meta-learn the acquisition function for Bayesian Optimization, showing increasing sample efficiency on new tasks.', 'The authors propose a meta-learning based alternative to standard acquisition functions (AFs), whereby a pretrained neural network outputs acquisition values as a function of hand-chosen features.']","['transferring knowledge across task improve dataefficiency one', 'open key challenge area global optimization algorithm ', 'readily', 'available algorithm typically designed universal optimizers  thus ', 'often suboptimal specific task ', 'propose novel transfer learning method', 'obtain customized optimizers within wellestablished framework bayesian', 'optimization  allowing algorithm utilize proven generalization', 'capability gaussian process ', 'using reinforcement learning metatrain', 'acquisition function  af  set related task  proposed method learns', 'extract implicit structural information exploit improved dataefficiency ', 'present experiment simtoreal transfer task well several simulated', 'function two hyperparameter search problem ', 'result show', 'algorithm  1  automatically identifies structural property objective function', 'available source task simulation   2  performs favourably setting', 'scarse abundant source data   3  fall back performance level', 'general afs structure present ']","Transferring knowledge across tasks to improve data-efficiency is one of
, the open key challenges in the area of global optimization algorithms., Readily
, available algorithms are typically designed to be universal optimizers and, thus,
, often suboptimal for specific tasks., We propose a novel transfer learning method to
, obtain customized optimizers within the well-established framework of Bayesian
, optimization, allowing our algorithm to utilize the proven generalization
, capabilities of Gaussian processes., Using reinforcement learning to meta-train an
, acquisition function (AF) on a set of related tasks, the proposed method learns to
, extract implicit structural information and to exploit it for improved data-efficiency.
, We present experiments on a sim-to-real transfer task as well as on several simulated
, functions and two hyperparameter search problems., The results show that our
, algorithm (1) automatically identifies structural properties of objective functions
, from available source tasks or simulations, (2) performs favourably in settings with
, both scarse and abundant source data, and (3) falls back to the performance level
, of general AFs if no structure is present.",24,6.0359281437125745,6.958333333333333
183,"['We study the evolution of internal representations during deep neural network (DNN) training, aiming to demystify the compression aspect of the information bottleneck theory.', 'The theory suggests that DNN training comprises a rapid fitting phase followed by a slower compression phase, in which the mutual information I(X;T) between the input X and internal representations T decreases.', 'Several papers observe compression of estimated mutual information on different DNN models, but the true I(X;T) over these networks is provably either constant (discrete X) or infinite (continuous X).', 'This work explains the discrepancy between theory and experiments, and clarifies what was actually measured by these past works.', ""To this end, we introduce an auxiliary (noisy) DNN framework for which I(X;T) is a meaningful quantity that depends on the network's parameters."", 'This noisy framework is shown to be a good proxy for the original (deterministic) DNN both in terms of performance and the learned representations.', 'We then develop a rigorous estimator for I(X;T) in noisy DNNs and observe compression in various models.', 'By relating I(X;T) in the noisy DNN to an information-theoretic communication problem, we show that compression is driven by the progressive clustering of hidden representations of inputs from the same class.', 'Several methods to directly monitor clustering of hidden representations, both in noisy and deterministic DNNs, are used to show that meaningful clusters form in the T space.', 'Finally, we return to the estimator of I(X;T) employed in past works, and demonstrate that while it fails to capture the true (vacuous) mutual information, it does serve as a measure for clustering.', 'This clarifies the past observations of compression and isolates the geometric clustering of hidden representations as the true phenomenon of interest.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.11764705181121826, 0.0, 0.09756097197532654, 0.0, 0.0, 0.0, 0.0, 0.04878048226237297, 0.0, 0.04651162400841713, 0.0]",HkxOoiAcYX,"['Deterministic deep neural networks do not discard information, but they do cluster their inputs.', 'This paper provides a principled way to examine the compression phrase in deep neural networks by providing an theoretical sounding entropy estimator to estimate mutual information. ']","['study evolution internal representation deep neural network  dnn  training  aiming demystify compression aspect information bottleneck theory ', 'theory suggests dnn training comprises rapid fitting phase followed slower compression phase  mutual information  x   input x internal representation decrease ', 'several paper observe compression estimated mutual information different dnn model  true  x   network provably either constant  discrete x  infinite  continuous x  ', 'work explains discrepancy theory experiment  clarifies actually measured past work ', 'end  introduce auxiliary  noisy  dnn framework  x   meaningful quantity depends network parameter ', 'noisy framework shown good proxy original  deterministic  dnn term performance learned representation ', 'develop rigorous estimator  x   noisy dnns observe compression various model ', 'relating  x   noisy dnn informationtheoretic communication problem  show compression driven progressive clustering hidden representation input class ', 'several method directly monitor clustering hidden representation  noisy deterministic dnns  used show meaningful cluster form space ', 'finally  return estimator  x   employed past work  demonstrate fails capture true  vacuous  mutual information  serve measure clustering ', 'clarifies past observation compression isolates geometric clustering hidden representation true phenomenon interest ']","We study the evolution of internal representations during deep neural network (DNN) training, aiming to demystify the compression aspect of the information bottleneck theory., The theory suggests that DNN training comprises a rapid fitting phase followed by a slower compression phase, in which the mutual information I(X;T) between the input X and internal representations T decreases., Several papers observe compression of estimated mutual information on different DNN models, but the true I(X;T) over these networks is provably either constant (discrete X) or infinite (continuous X)., This work explains the discrepancy between theory and experiments, and clarifies what was actually measured by these past works., To this end, we introduce an auxiliary (noisy) DNN framework for which I(X;T) is a meaningful quantity that depends on the network's parameters., This noisy framework is shown to be a good proxy for the original (deterministic) DNN both in terms of performance and the learned representations., We then develop a rigorous estimator for I(X;T) in noisy DNNs and observe compression in various models., By relating I(X;T) in the noisy DNN to an information-theoretic communication problem, we show that compression is driven by the progressive clustering of hidden representations of inputs from the same class., Several methods to directly monitor clustering of hidden representations, both in noisy and deterministic DNNs, are used to show that meaningful clusters form in the T space., Finally, we return to the estimator of I(X;T) employed in past works, and demonstrate that while it fails to capture the true (vacuous) mutual information, it does serve as a measure for clustering., This clarifies the past observations of compression and isolates the geometric clustering of hidden representations as the true phenomenon of interest.",22,5.564285714285714,12.727272727272727
184,"['A central challenge in multi-agent reinforcement learning is the induction of coordination between agents of a team.', 'In this work, we investigate how to promote inter-agent coordination using policy regularization and discuss two possible avenues respectively based on inter-agent modelling and synchronized sub-policy selection.', 'We test each approach in four challenging continuous control tasks with sparse rewards and compare them against three baselines including MADDPG, a state-of-the-art multi-agent reinforcement learning algorithm.', 'To ensure a fair comparison, we rely on a thorough hyper-parameter selection and training methodology that allows a fixed hyper-parameter search budget for each algorithm and environment.', 'We consequently assess both the hyper-parameter sensitivity, sample-efficiency and asymptotic performance of each learning method.', 'Our experiments show that the proposed methods lead to significant improvements on cooperative problems.', 'We further analyse the effects of the proposed regularizations on the behaviors learned by the agents.']","[0, 0, 0, 0, 0, 1, 0]","[0.13333332538604736, 0.1538461446762085, 0.1463414579629898, 0.1621621549129486, 0.06896550953388214, 0.2142857164144516, 0.14814814925193787]",BkggGREKvS,"['We propose regularization objectives for multi-agent RL algorithms that foster coordination on cooperative tasks.', 'This paper proposes two methods of biasing agents towards learning coordinated behaviours and evaluates both rigorously across multi-agent domains of suitable complexity.', 'This paper proposes two methods building upon MADDPG to encourage collaboration amongst decentralized MARL agents.']","['central challenge multiagent reinforcement learning induction coordination agent team ', 'work  investigate promote interagent coordination using policy regularization discus two possible avenue respectively based interagent modelling synchronized subpolicy selection ', 'test approach four challenging continuous control task sparse reward compare three baseline including maddpg  stateoftheart multiagent reinforcement learning algorithm ', 'ensure fair comparison  rely thorough hyperparameter selection training methodology allows fixed hyperparameter search budget algorithm environment ', 'consequently ass hyperparameter sensitivity  sampleefficiency asymptotic performance learning method ', 'experiment show proposed method lead significant improvement cooperative problem ', 'analyse effect proposed regularization behavior learned agent ']","A central challenge in multi-agent reinforcement learning is the induction of coordination between agents of a team., In this work, we investigate how to promote inter-agent coordination using policy regularization and discuss two possible avenues respectively based on inter-agent modelling and synchronized sub-policy selection., We test each approach in four challenging continuous control tasks with sparse rewards and compare them against three baselines including MADDPG, a state-of-the-art multi-agent reinforcement learning algorithm., To ensure a fair comparison, we rely on a thorough hyper-parameter selection and training methodology that allows a fixed hyper-parameter search budget for each algorithm and environment., We consequently assess both the hyper-parameter sensitivity, sample-efficiency and asymptotic performance of each learning method., Our experiments show that the proposed methods lead to significant improvements on cooperative problems., We further analyse the effects of the proposed regularizations on the behaviors learned by the agents.",11,6.440559440559441,13.0
185,"['Multimodal sentiment analysis is a core research area that studies speaker sentiment expressed from the language, visual, and acoustic modalities.', 'The central challenge in multimodal learning involves inferring joint representations that can process and relate information from these modalities.', 'However, existing work learns joint representations using multiple modalities as input and may be sensitive to noisy or missing modalities at test time.', 'With the recent success of sequence to sequence models in machine translation, there is an opportunity to explore new ways of learning joint representations that may not require all input modalities at test time.', 'In this paper, we propose a method to learn robust joint representations by translating between modalities.', 'Our method is based on the key insight that translation from a source to a target modality provides a method of learning joint representations using only the source modality as input.', 'We augment modality translations with a cycle consistency loss to ensure that our joint representations retain maximal information from all modalities.', 'Once our translation model is trained with paired multimodal data, we only need data from the source modality at test-time for prediction.', 'This ensures that our model remains robust from perturbations or missing target modalities.', 'We train our model with a coupled translation-prediction objective and it achieves new state-of-the-art results on multimodal sentiment analysis datasets: CMU-MOSI, ICT-MMMO, and YouTube.', 'Additional experiments show that our model learns increasingly discriminative joint representations with more input modalities while maintaining robustness to perturbations of all other modalities.']","[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.1666666567325592, 0.2222222238779068, 0.25641024112701416, 0.1666666567325592, 0.42424240708351135, 0.1904761791229248, 0.3684210479259491, 0.05128204822540283, 0.2666666507720947, 0.14999999105930328, 0.29999998211860657]",rkgx8x1js7,"['We present a model that learns robust joint representations by performing hierarchical cyclic translations between multiple modalities.', 'This paper presents the Multimodal Cyclic Translation Network (MCTN) and evaluates it for multimodal sentiment analysis.']","['multimodal sentiment analysis core research area study speaker sentiment expressed language  visual  acoustic modality ', 'central challenge multimodal learning involves inferring joint representation process relate information modality ', 'however  existing work learns joint representation using multiple modality input may sensitive noisy missing modality test time ', 'recent success sequence sequence model machine translation  opportunity explore new way learning joint representation may require input modality test time ', 'paper  propose method learn robust joint representation translating modality ', 'method based key insight translation source target modality provides method learning joint representation using source modality input ', 'augment modality translation cycle consistency loss ensure joint representation retain maximal information modality ', 'translation model trained paired multimodal data  need data source modality testtime prediction ', 'ensures model remains robust perturbation missing target modality ', 'train model coupled translationprediction objective achieves new stateoftheart result multimodal sentiment analysis datasets  cmumosi  ictmmmo  youtube ', 'additional experiment show model learns increasingly discriminative joint representation input modality maintaining robustness perturbation modality ']","Multimodal sentiment analysis is a core research area that studies speaker sentiment expressed from the language, visual, and acoustic modalities., The central challenge in multimodal learning involves inferring joint representations that can process and relate information from these modalities., However, existing work learns joint representations using multiple modalities as input and may be sensitive to noisy or missing modalities at test time., With the recent success of sequence to sequence models in machine translation, there is an opportunity to explore new ways of learning joint representations that may not require all input modalities at test time., In this paper, we propose a method to learn robust joint representations by translating between modalities., Our method is based on the key insight that translation from a source to a target modality provides a method of learning joint representations using only the source modality as input., We augment modality translations with a cycle consistency loss to ensure that our joint representations retain maximal information from all modalities., Once our translation model is trained with paired multimodal data, we only need data from the source modality at test-time for prediction., This ensures that our model remains robust from perturbations or missing target modalities., We train our model with a coupled translation-prediction objective and it achieves new state-of-the-art results on multimodal sentiment analysis datasets: CMU-MOSI, ICT-MMMO, and YouTube., Additional experiments show that our model learns increasingly discriminative joint representations with more input modalities while maintaining robustness to perturbations of all other modalities.",19,5.94331983805668,13.0
186,"['The geometric properties of loss surfaces, such as the local flatness of a solution, are associated with generalization in deep learning.', 'The Hessian is often used to understand these geometric properties.', 'We investigate the differences between the eigenvalues of the neural network Hessian evaluated over the empirical dataset, the Empirical Hessian, and the eigenvalues of the Hessian under the data generating distribution, which we term the True Hessian.', 'Under mild assumptions, we use random matrix theory to show that the True Hessian has eigenvalues of smaller absolute value than the Empirical Hessian.', 'We support these results for different SGD schedules on both a 110-Layer ResNet and VGG-16.', 'To perform these experiments we propose a framework for spectral visualization, based on GPU accelerated stochastic Lanczos quadrature.', 'This approach is an order of magnitude faster than state-of-the-art methods for spectral visualization, and can be generically used to investigate the spectral properties of matrices in deep learning.']","[0, 0, 1, 0, 0, 0, 0]","[0.06666666269302368, 0.09999999403953552, 0.4571428596973419, 0.1875, 0.0, 0.0, 0.054054051637649536]",H1gza2NtwH,"['Understanding the neural network Hessian eigenvalues under the data generating distribution.', 'This paper analyzes the spectrum of the Hessian matrix of large neural networks, with an analysis of max/min eigenvalues and visualization of spectra using a Lanczos quadrature approach.', 'This paper uses the random matrix theory to study the spectrum distribution of the empirical Hessian and true Hessian for deep learning, and proposes an efficient spectrum visualization methods.']","['geometric property loss surface  local flatness solution  associated generalization deep learning ', 'hessian often used understand geometric property ', 'investigate difference eigenvalue neural network hessian evaluated empirical dataset  empirical hessian  eigenvalue hessian data generating distribution  term true hessian ', 'mild assumption  use random matrix theory show true hessian eigenvalue smaller absolute value empirical hessian ', 'support result different sgd schedule 110layer resnet vgg16 ', 'perform experiment propose framework spectral visualization  based gpu accelerated stochastic lanczos quadrature ', 'approach order magnitude faster stateoftheart method spectral visualization  generically used investigate spectral property matrix deep learning ']","The geometric properties of loss surfaces, such as the local flatness of a solution, are associated with generalization in deep learning., The Hessian is often used to understand these geometric properties., We investigate the differences between the eigenvalues of the neural network Hessian evaluated over the empirical dataset, the Empirical Hessian, and the eigenvalues of the Hessian under the data generating distribution, which we term the True Hessian., Under mild assumptions, we use random matrix theory to show that the True Hessian has eigenvalues of smaller absolute value than the Empirical Hessian., We support these results for different SGD schedules on both a 110-Layer ResNet and VGG-16., To perform these experiments we propose a framework for spectral visualization, based on GPU accelerated stochastic Lanczos quadrature., This approach is an order of magnitude faster than state-of-the-art methods for spectral visualization, and can be generically used to investigate the spectral properties of matrices in deep learning.",15,5.701298701298701,10.266666666666667
187,"['Summarization of long sequences into a concise statement is a core problem in natural language processing, requiring non-trivial understanding of the input.', 'Based on the promising results of graph neural networks on highly structured data, we develop a framework to extend existing sequence encoders with a graph component that can reason about long-distance relationships in weakly structured data such as text.', 'In an extensive evaluation, we show that the resulting hybrid sequence-graph models outperform both pure sequence models as well as pure graph models on a range of summarization tasks.']","[0, 1, 0]","[0.060606054961681366, 0.2083333283662796, 0.15789473056793213]",H1ersoRqtm,"['One simple trick to improve sequence models: Compose them with a graph model', 'This paper presents a structural summarization model with a graph-based encoder extended from RNN.', 'This work combines Graph Neural Networks with a sequential approach to abstractive summarization, effective across all datasets in comparison to external baselines.']","['summarization long sequence concise statement core problem natural language processing  requiring nontrivial understanding input ', 'based promising result graph neural network highly structured data  develop framework extend existing sequence encoders graph component reason longdistance relationship weakly structured data text ', 'extensive evaluation  show resulting hybrid sequencegraph model outperform pure sequence model well pure graph model range summarization task ']","Summarization of long sequences into a concise statement is a core problem in natural language processing, requiring non-trivial understanding of the input., Based on the promising results of graph neural networks on highly structured data, we develop a framework to extend existing sequence encoders with a graph component that can reason about long-distance relationships in weakly structured data such as text., In an extensive evaluation, we show that the resulting hybrid sequence-graph models outperform both pure sequence models as well as pure graph models on a range of summarization tasks.",6,5.611111111111111,15.0
188,"['In probabilistic classification, a discriminative model based on Gaussian mixture exhibits flexible fitting capability.', 'Nevertheless, it is difficult to determine the number of components.', 'We propose a sparse classifier based on a discriminative Gaussian mixture model (GMM), which is named sparse discriminative Gaussian mixture (SDGM).', 'In the SDGM, a GMM-based discriminative model is trained by sparse Bayesian learning.', 'This learning algorithm improves the generalization capability by obtaining a sparse solution and automatically determines the number of components by removing redundant components.', 'The SDGM can be embedded into neural networks (NNs) such as convolutional NNs and can be trained in an end-to-end manner.', 'Experimental results indicated that the proposed method prevented overfitting by obtaining sparsity.', 'Furthermore, we demonstrated that the proposed method outperformed a fully connected layer with the softmax function in certain cases when it was used as the last layer of a deep NN.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.375, 0.0, 0.5294117331504822, 0.19354838132858276, 0.10526315122842789, 0.2702702581882477, 0.0, 0.04444443807005882]",r1xapAEKwS,"['A sparse classifier based on a discriminative Gaussian mixture model, which can also be embedded into a neural network.', 'The paper presents a Gaussian mixture model trained via gradient descent arguments which allows for inducing sparsity and reducing the trainable model layer parameters.', 'This paper proposes a classifier, called SDGM, based on discriminative Gaussian mixture and its sparse parameter estimation.']","['probabilistic classification  discriminative model based gaussian mixture exhibit flexible fitting capability ', 'nevertheless  difficult determine number component ', 'propose sparse classifier based discriminative gaussian mixture model  gmm   named sparse discriminative gaussian mixture  sdgm  ', 'sdgm  gmmbased discriminative model trained sparse bayesian learning ', 'learning algorithm improves generalization capability obtaining sparse solution automatically determines number component removing redundant component ', 'sdgm embedded neural network  nns  convolutional nns trained endtoend manner ', 'experimental result indicated proposed method prevented overfitting obtaining sparsity ', 'furthermore  demonstrated proposed method outperformed fully connected layer softmax function certain case used last layer deep nn ']","In probabilistic classification, a discriminative model based on Gaussian mixture exhibits flexible fitting capability., Nevertheless, it is difficult to determine the number of components., We propose a sparse classifier based on a discriminative Gaussian mixture model (GMM), which is named sparse discriminative Gaussian mixture (SDGM)., In the SDGM, a GMM-based discriminative model is trained by sparse Bayesian learning., This learning algorithm improves the generalization capability by obtaining a sparse solution and automatically determines the number of components by removing redundant components., The SDGM can be embedded into neural networks (NNs) such as convolutional NNs and can be trained in an end-to-end manner., Experimental results indicated that the proposed method prevented overfitting by obtaining sparsity., Furthermore, we demonstrated that the proposed method outperformed a fully connected layer with the softmax function in certain cases when it was used as the last layer of a deep NN.",13,5.944827586206896,11.153846153846153
189,"['We recently observed that convolutional filters initialized\n', 'farthest apart from each other using offthe-\n', 'shelf pre-computed Grassmannian subspace\n', 'packing codebooks performed surprisingly well\n', 'across many datasets.', 'Through this short paper,\n', 'wed like to disseminate some initial results in this\n', 'regard in the hope that we stimulate the curiosity\n', 'of the deep-learning community towards considering\n', 'classical Grassmannian subspace packing\n', 'results as a source of new ideas for more efficient\n', 'initialization strategies.']","[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.0, 0.10526315122842789, 0.1249999925494194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1249999925494194, 0.0]",BJgb3k3qpE,"['Initialize weights using off-the-shelf Grassmannian codebooks, get  faster training and better accuracy']","['recently observed convolutional filter initialized', 'farthest apart using offthe', 'shelf precomputed grassmannian subspace', 'packing codebooks performed surprisingly well', 'across many datasets ', 'short paper ', ' like disseminate initial result', 'regard hope stimulate curiosity', 'deeplearning community towards considering', 'classical grassmannian subspace packing', 'result source new idea efficient', 'initialization strategy ']","We recently observed that convolutional filters initialized
, farthest apart from each other using offthe-
, shelf pre-computed Grassmannian subspace
, packing codebooks performed surprisingly well
, across many datasets., Through this short paper,
, wed like to disseminate some initial results in this
, regard in the hope that we stimulate the curiosity
, of the deep-learning community towards considering
, classical Grassmannian subspace packing
, results as a source of new ideas for more efficient
, initialization strategies.",12,6.357142857142857,5.833333333333333
190,"['Domain adaptation is critical for success in new, unseen environments.\n', 'Adversarial adaptation models applied in feature spaces discover domain invariant representations, but are difficult to visualize and sometimes fail to capture pixel-level and low-level domain shifts.\n', 'Recent work has shown that generative adversarial networks combined with cycle-consistency constraints are surprisingly effective at  mapping images between domains, even without the use of aligned image pairs.\n', 'We propose a novel discriminatively-trained Cycle-Consistent Adversarial Domain Adaptation model.\n', 'CyCADA adapts representations at both the pixel-level and feature-level, enforces cycle-consistency while leveraging a task loss, and does not require aligned pairs.  ', 'Our model can be applied in a variety of visual recognition and prediction settings.\n', 'We show new state-of-the-art results across multiple adaptation tasks, including digit classification and semantic segmentation of road scenes demonstrating transfer from synthetic to real world domains.']","[0, 0, 0, 0, 1, 0, 0]","[0.07999999821186066, 0.21052631735801697, 0.09302324801683426, 0.0, 0.277777761220932, 0.06896550953388214, 0.09999999403953552]",SktLlGbRZ,"['An unsupervised domain adaptation approach which adapts at both the pixel and feature levels', 'This paper proposes a domain adaptation approach by extending the CycleGAN with task specific loss functions and loss imposed over both pixels and features. ', 'This paper proposes the use of CycleGANs for Domain Adaptation', 'This paper makes a novel extension to the previous work on CycleGAN by coupling it with adversarial adaptation approaches, including a new feature and semantic loss in the overall objective of the CycleGAN, with clear benefits.']","['domain adaptation critical success new  unseen environment ', 'adversarial adaptation model applied feature space discover domain invariant representation  difficult visualize sometimes fail capture pixellevel lowlevel domain shift ', 'recent work shown generative adversarial network combined cycleconsistency constraint surprisingly effective mapping image domain  even without use aligned image pair ', 'propose novel discriminativelytrained cycleconsistent adversarial domain adaptation model ', 'cycada adapts representation pixellevel featurelevel  enforces cycleconsistency leveraging task loss  require aligned pair ', 'model applied variety visual recognition prediction setting ', 'show new stateoftheart result across multiple adaptation task  including digit classification semantic segmentation road scene demonstrating transfer synthetic real world domain ']","Domain adaptation is critical for success in new, unseen environments.
, Adversarial adaptation models applied in feature spaces discover domain invariant representations, but are difficult to visualize and sometimes fail to capture pixel-level and low-level domain shifts.
, Recent work has shown that generative adversarial networks combined with cycle-consistency constraints are surprisingly effective at  mapping images between domains, even without the use of aligned image pairs.
, We propose a novel discriminatively-trained Cycle-Consistent Adversarial Domain Adaptation model.
, CyCADA adapts representations at both the pixel-level and feature-level, enforces cycle-consistency while leveraging a task loss, and does not require aligned pairs.  , Our model can be applied in a variety of visual recognition and prediction settings.
, We show new state-of-the-art results across multiple adaptation tasks, including digit classification and semantic segmentation of road scenes demonstrating transfer from synthetic to real world domains.",13,6.5661764705882355,10.461538461538462
191,"['Stemming is the process of removing affixes( i.e. prefixes, infixes and suffixes) that improve the accuracy and performance of information retrieval systems.This paper presents the reduction of Amharic words to corresponding stem where with the intention that it preserves semantic information.', 'The proposed approach efficiently removes affixes from an Amharic word.', 'The process of removing such affixes (prefixes, infixes and suffixes) from a word to its base form is called stemming.', 'While many stemmers exist for dominant languages such as English, under resourced languages such as Amharic which lacks such powerful tool support.', 'In this paper, we design a light Amharic stemmer relying on the rules that receives an Amharic word and then it finds a match to the beginning of a word to the possible prefixes and to its ending with the possible suffixes and finally it checks whether it has infix.', 'The final result is the stem if there is any prefix, infix or/and suffix, otherwise it remains in one of the earlier states.', 'The technique does not rely on any additional resource (e.g. dictionary) to verify the generated stem.', 'The performance of the generated stemmer is evaluated using manually annotated Amharic words.', 'The result is compared with current state-of-the-art stemmer for Amharic showing an increase of 7% in stemmer correctness.']","[0, 0, 0, 0, 0, 0, 0, 1, 0]","[0.17391304671764374, 0.0952380895614624, 0.12903225421905518, 0.13793103396892548, 0.08510638028383255, 0.1249999925494194, 0.0, 0.3333333432674408, 0.2857142686843872]",r1edp2VYwH,"['Amharic Light Stemmer is designed for improving performance of  Amharic Sentiment Classification.', 'This paper studies the stemming for morphologically rich languages with a light stemmer that only removes affixes to the extent that the original semantic information in the word is kept.', 'This paper proposes a technique for Amharic light stemming using a cascade of transformations that standardize the form, remove suffixes, prefixes, and infixes.']","['stemming process removing affix  ie  prefix  infix suffix  improve accuracy performance information retrieval systemsthis paper present reduction amharic word corresponding stem intention preserve semantic information ', 'proposed approach efficiently remove affix amharic word ', 'process removing affix  prefix  infix suffix  word base form called stemming ', 'many stemmer exist dominant language english  resourced language amharic lack powerful tool support ', 'paper  design light amharic stemmer relying rule receives amharic word find match beginning word possible prefix ending possible suffix finally check whether infix ', 'final result stem prefix  infix orand suffix  otherwise remains one earlier state ', 'technique rely additional resource  eg  dictionary  verify generated stem ', 'performance generated stemmer evaluated using manually annotated amharic word ', 'result compared current stateoftheart stemmer amharic showing increase 7  stemmer correctness ']","Stemming is the process of removing affixes( i.e. prefixes, infixes and suffixes) that improve the accuracy and performance of information retrieval systems.This paper presents the reduction of Amharic words to corresponding stem where with the intention that it preserves semantic information., The proposed approach efficiently removes affixes from an Amharic word., The process of removing such affixes (prefixes, infixes and suffixes) from a word to its base form is called stemming., While many stemmers exist for dominant languages such as English, under resourced languages such as Amharic which lacks such powerful tool support., In this paper, we design a light Amharic stemmer relying on the rules that receives an Amharic word and then it finds a match to the beginning of a word to the possible prefixes and to its ending with the possible suffixes and finally it checks whether it has infix., The final result is the stem if there is any prefix, infix or/and suffix, otherwise it remains in one of the earlier states., The technique does not rely on any additional resource (e.g. dictionary) to verify the generated stem., The performance of the generated stemmer is evaluated using manually annotated Amharic words., The result is compared with current state-of-the-art stemmer for Amharic showing an increase of 7% in stemmer correctness.",15,5.291079812206573,12.529411764705882
192,"['Place and grid-cells are known to aid navigation in animals and humans.', 'Together with concept cells, they allow humans to form an internal representation of the external world, namely the concept space.', 'We investigate the presence of such a space in deep neural networks by plotting the activation profile of its hidden layer neurons.', 'Although place cell and concept-cell like properties are found, grid-cell like firing patterns are absent thereby indicating a lack of path integration or feature transformation functionality in trained networks.', 'Overall, we present a plausible inadequacy in current deep learning practices that restrict deep networks from performing analogical reasoning and memory retrieval tasks.']","[0, 0, 1, 0, 0]","[0.06666666269302368, 0.1621621549129486, 0.3589743673801422, 0.08695651590824127, 0.24390242993831635]",Hye5NQYU8r,['We investigated if simple deep networks possess grid cell-like artificial neurons while memory retrieval in the learned concept space.'],"['place gridcells known aid navigation animal human ', 'together concept cell  allow human form internal representation external world  namely concept space ', 'investigate presence space deep neural network plotting activation profile hidden layer neuron ', 'although place cell conceptcell like property found  gridcell like firing pattern absent thereby indicating lack path integration feature transformation functionality trained network ', 'overall  present plausible inadequacy current deep learning practice restrict deep network performing analogical reasoning memory retrieval task ']","Place and grid-cells are known to aid navigation in animals and humans., Together with concept cells, they allow humans to form an internal representation of the external world, namely the concept space., We investigate the presence of such a space in deep neural networks by plotting the activation profile of its hidden layer neurons., Although place cell and concept-cell like properties are found, grid-cell like firing patterns are absent thereby indicating a lack of path integration or feature transformation functionality in trained networks., Overall, we present a plausible inadequacy in current deep learning practices that restrict deep networks from performing analogical reasoning and memory retrieval tasks.",9,5.745283018867925,11.777777777777779
193,"['We develop a comprehensive description of the active inference framework, as proposed by Friston (2010), under a machine-learning compliant perspective.', 'Stemming from a biological inspiration and the auto-encoding principles, a sketch of a cognitive architecture is proposed that should provide ways to implement estimation-oriented control policies.  ', 'Computer simulations illustrate the effectiveness of the approach through a foveated inspection of the input data.', 'The pros and cons of the control policy are analyzed in detail, showing interesting promises in terms of processing compression.', 'Though optimizing future posterior entropy over the actions set is shown enough to attain locally optimal action selection, offline calculation using class-specific saliency maps is shown better for it saves processing costs through saccades pathways pre-processing, with a negligible effect on the recognition/compression rates.']","[1, 0, 0, 0, 0]","[0.25806450843811035, 0.1621621549129486, 0.1599999964237213, 0.19999998807907104, 0.037735845893621445]",H1u8fMW0b,"['Pros and cons of saccade-based computer vision under a predictive coding perspective', 'Presents a computational framework for the active vision problem and explains how the control policy can be learned to reduce the entropy of the posterior belief.']","['develop comprehensive description active inference framework  proposed friston  2010   machinelearning compliant perspective ', 'stemming biological inspiration autoencoding principle  sketch cognitive architecture proposed provide way implement estimationoriented control policy ', 'computer simulation illustrate effectiveness approach foveated inspection input data ', 'pro con control policy analyzed detail  showing interesting promise term processing compression ', 'though optimizing future posterior entropy action set shown enough attain locally optimal action selection  offline calculation using classspecific saliency map shown better save processing cost saccade pathway preprocessing  negligible effect recognitioncompression rate ']","We develop a comprehensive description of the active inference framework, as proposed by Friston (2010), under a machine-learning compliant perspective., Stemming from a biological inspiration and the auto-encoding principles, a sketch of a cognitive architecture is proposed that should provide ways to implement estimation-oriented control policies.  , Computer simulations illustrate the effectiveness of the approach through a foveated inspection of the input data., The pros and cons of the control policy are analyzed in detail, showing interesting promises in terms of processing compression., Though optimizing future posterior entropy over the actions set is shown enough to attain locally optimal action selection, offline calculation using class-specific saliency maps is shown better for it saves processing costs through saccades pathways pre-processing, with a negligible effect on the recognition/compression rates.",11,6.2936507936507935,11.454545454545455
194,"['Graphs possess exotic features like variable size and absence of natural ordering of the nodes that make them difficult to analyze and compare.', 'To circumvent this problem and learn on graphs, graph feature representation is required.', 'Main difficulties with feature extraction lie in the trade-off between expressiveness, consistency and efficiency, i.e. the capacity to extract features that represent the structural information of the graph while being deformation-consistent and isomorphism-invariant.', 'While state-of-the-art methods enhance expressiveness with powerful graph neural-networks, we propose to leverage natural spectral properties of graphs to study a simple graph feature: the graph Laplacian spectrum (GLS).', 'We analyze the representational power of this object that satisfies both isomorphism-invariance, expressiveness and deformation-consistency.', 'In particular, we propose a theoretical analysis based on graph perturbation to understand what kind of comparison between graphs we do when comparing GLS.', 'To do so, we derive bounds for the distance between GLS that are related to the divergence to isomorphism, a standard computationally expensive graph divergence.', 'Finally, we experiment GLS as graph representation through consistency tests and classification tasks, and show that it is a strong graph feature representation baseline.']","[0, 0, 0, 0, 0, 0, 0, 1]","[0.11764705181121826, 0.07692307233810425, 0.1395348757505417, 0.20512820780277252, 0.2142857164144516, 0.0, 0.05714285373687744, 0.23529411852359772]",Bkeqb1BFvB,"['We study theoretically the consistency the Laplacian spectrum and use it as whole-graph embeddding', 'This paper forcuses on the laplacian spectrum of a graph as means to generate a representation to be used to compare graphs and classify them.', 'This work proposed to use Graph Laplacian spectrum to learn graph representation.']","['graph posse exotic feature like variable size absence natural ordering node make difficult analyze compare ', 'circumvent problem learn graph  graph feature representation required ', 'main difficulty feature extraction lie tradeoff expressiveness  consistency efficiency  ie  capacity extract feature represent structural information graph deformationconsistent isomorphisminvariant ', 'stateoftheart method enhance expressiveness powerful graph neuralnetworks  propose leverage natural spectral property graph study simple graph feature  graph laplacian spectrum  gls  ', 'analyze representational power object satisfies isomorphisminvariance  expressiveness deformationconsistency ', 'particular  propose theoretical analysis based graph perturbation understand kind comparison graph comparing gls ', ' derive bound distance gls related divergence isomorphism  standard computationally expensive graph divergence ', 'finally  experiment gls graph representation consistency test classification task  show strong graph feature representation baseline ']","Graphs possess exotic features like variable size and absence of natural ordering of the nodes that make them difficult to analyze and compare., To circumvent this problem and learn on graphs, graph feature representation is required., Main difficulties with feature extraction lie in the trade-off between expressiveness, consistency and efficiency, i.e. the capacity to extract features that represent the structural information of the graph while being deformation-consistent and isomorphism-invariant., While state-of-the-art methods enhance expressiveness with powerful graph neural-networks, we propose to leverage natural spectral properties of graphs to study a simple graph feature: the graph Laplacian spectrum (GLS)., We analyze the representational power of this object that satisfies both isomorphism-invariance, expressiveness and deformation-consistency., In particular, we propose a theoretical analysis based on graph perturbation to understand what kind of comparison between graphs we do when comparing GLS., To do so, we derive bounds for the distance between GLS that are related to the divergence to isomorphism, a standard computationally expensive graph divergence., Finally, we experiment GLS as graph representation through consistency tests and classification tasks, and show that it is a strong graph feature representation baseline.",18,6.231182795698925,9.789473684210526
195,"['Adversarial training, a method for learning robust deep networks, is typically assumed to be more expensive than traditional training due to the necessity of constructing adversarial examples via a first-order method like projected gradient decent (PGD).  ', 'In this paper, we make the surprising discovery that it is possible to train empirically robust models using a much weaker and cheaper adversary, an approach that was previously believed to be ineffective, rendering the method no more costly than standard training in practice.  ', 'Specifically, we show that adversarial training with the fast gradient sign method (FGSM), when combined with random initialization, is as effective as PGD-based training but has significantly lower cost.  ', ""Furthermore we show that FGSM adversarial training can be further accelerated by using standard techniques for efficient training of deep networks, allowing us to learn a robust CIFAR10 classifier with 45% robust accuracy at epsilon=8/255 in 6 minutes, and a robust ImageNet classifier with 43% robust accuracy at epsilon=2/255 in 12 hours, in comparison to past work based on ``free'' adversarial training which took 10 and 50 hours to reach the same respective thresholds.""]","[0, 0, 0, 1]","[0.1538461446762085, 0.21917808055877686, 0.17241378128528595, 0.3146067261695862]",BJx040EFvH,"['FGSM-based adversarial training, with randomization, works just as well as PGD-based adversarial training: we can use this to train a robust classifier in 6 minutes on CIFAR10, and 12 hours on ImageNet, on a single machine.', 'This paper revisits Random+FGSM method to train robust models against strong PGD evasion attacks faster than previous methods.', 'The main claim of this paper is that a simple strategy of randomization plus fast gradient sign method (FGSM) adversarial training yields robust neural networks.']","['adversarial training  method learning robust deep network  typically assumed expensive traditional training due necessity constructing adversarial example via firstorder method like projected gradient decent  pgd  ', 'paper  make surprising discovery possible train empirically robust model using much weaker cheaper adversary  approach previously believed ineffective  rendering method costly standard training practice ', 'specifically  show adversarial training fast gradient sign method  fgsm   combined random initialization  effective pgdbased training significantly lower cost ', 'furthermore show fgsm adversarial training accelerated using standard technique efficient training deep network  allowing u learn robust cifar10 classifier 45  robust accuracy epsilon8255 6 minute  robust imagenet classifier 43  robust accuracy epsilon2255 12 hour  comparison past work based  free  adversarial training took 10 50 hour reach respective threshold ']","Adversarial training, a method for learning robust deep networks, is typically assumed to be more expensive than traditional training due to the necessity of constructing adversarial examples via a first-order method like projected gradient decent (PGD).  , In this paper, we make the surprising discovery that it is possible to train empirically robust models using a much weaker and cheaper adversary, an approach that was previously believed to be ineffective, rendering the method no more costly than standard training in practice.  , Specifically, we show that adversarial training with the fast gradient sign method (FGSM), when combined with random initialization, is as effective as PGD-based training but has significantly lower cost.  , Furthermore we show that FGSM adversarial training can be further accelerated by using standard techniques for efficient training of deep networks, allowing us to learn a robust CIFAR10 classifier with 45% robust accuracy at epsilon=8/255 in 6 minutes, and a robust ImageNet classifier with 43% robust accuracy at epsilon=2/255 in 12 hours, in comparison to past work based on ``free'' adversarial training which took 10 and 50 hours to reach the same respective thresholds.",15,5.5683060109289615,12.2
196,"['In seeking for sparse and efficient neural network models, many previous works investigated on enforcing L1 or L0 regularizers to encourage weight sparsity during training.', 'The L0 regularizer measures the parameter sparsity directly and is invariant to the scaling of parameter values.', 'But it cannot provide useful gradients and therefore requires complex optimization techniques.', 'The L1 regularizer is almost everywhere differentiable and can be easily optimized with gradient descent.', 'Yet it is not scale-invariant and causes the same shrinking rate to all parameters, which is inefficient in increasing sparsity.', 'Inspired by the Hoyer measure (the ratio between L1 and L2 norms) used in traditional compressed sensing problems, we present DeepHoyer, a set of sparsity-inducing regularizers that are both differentiable almost everywhere and scale-invariant.', 'Our experiments show that enforcing DeepHoyer regularizers can produce even sparser neural network models than previous works, under the same accuracy level.', 'We also show that DeepHoyer can be applied to both element-wise and structural pruning.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.25531914830207825, 0.21621620655059814, 0.05882352590560913, 0.2702702581882477, 0.19512194395065308, 0.1818181723356247, 0.09090908616781235, 0.2222222238779068]",rylBK34FDS,"['We propose almost everywhere differentiable and scale invariant regularizers for DNN pruning, which can lead to supremum sparsity through standard SGD training.', 'The paper proposes a scale-invariant regularizer (DeepHoyer) inspired by the Hoyer measure to enforce sparsity in neural networks. ']","['seeking sparse efficient neural network model  many previous work investigated enforcing l1 l0 regularizers encourage weight sparsity training ', 'l0 regularizer measure parameter sparsity directly invariant scaling parameter value ', 'provide useful gradient therefore requires complex optimization technique ', 'l1 regularizer almost everywhere differentiable easily optimized gradient descent ', 'yet scaleinvariant cause shrinking rate parameter  inefficient increasing sparsity ', 'inspired hoyer measure  ratio l1 l2 norm  used traditional compressed sensing problem  present deephoyer  set sparsityinducing regularizers differentiable almost everywhere scaleinvariant ', 'experiment show enforcing deephoyer regularizers produce even sparser neural network model previous work  accuracy level ', 'also show deephoyer applied elementwise structural pruning ']","In seeking for sparse and efficient neural network models, many previous works investigated on enforcing L1 or L0 regularizers to encourage weight sparsity during training., The L0 regularizer measures the parameter sparsity directly and is invariant to the scaling of parameter values., But it cannot provide useful gradients and therefore requires complex optimization techniques., The L1 regularizer is almost everywhere differentiable and can be easily optimized with gradient descent., Yet it is not scale-invariant and causes the same shrinking rate to all parameters, which is inefficient in increasing sparsity., Inspired by the Hoyer measure (the ratio between L1 and L2 norms) used in traditional compressed sensing problems, we present DeepHoyer, a set of sparsity-inducing regularizers that are both differentiable almost everywhere and scale-invariant., Our experiments show that enforcing DeepHoyer regularizers can produce even sparser neural network models than previous works, under the same accuracy level., We also show that DeepHoyer can be applied to both element-wise and structural pruning.",13,5.930817610062893,12.23076923076923
197,"['Self-supervision, in which a target task is improved without external supervision, has primarily been explored in settings that assume the availability of additional data.', 'However, in many cases, particularly in healthcare, one may not have access to additional data (labeled or otherwise).', 'In such settings, we hypothesize that self-supervision based solely on the structure of the data at-hand can help.', 'We explore a novel self-supervision framework for time-series data, in which multiple auxiliary tasks (e.g., forecasting) are included to improve overall performance on a sequence-level target task without additional training data.', 'We call this approach limited self-supervision, as we limit ourselves to only the data at-hand.', 'We demonstrate the utility of limited self-supervision on three sequence-level classification tasks, two pertaining to real clinical data and one using synthetic data.', 'Within this framework, we introduce novel forms of self-supervision and demonstrate their utility in improving performance on the target task.', 'Our results indicate that limited self-supervision leads to a consistent improvement over a supervised baseline, across a range of domains.', 'In particular, for the task of identifying atrial fibrillation from small amounts of electrocardiogram data, we observe a nearly 13% improvement in the area under the receiver operating characteristics curve (AUC-ROC) relative to the baseline (AUC-ROC=0.55 vs. AUC-ROC=0.62).', 'Limited self-supervision applied to sequential data can aid in learning intermediate representations, making it particularly applicable in settings where data collection is difficult.']","[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.1304347813129425, 0.14999999105930328, 0.09999999403953552, 0.2181818187236786, 0.15789473056793213, 0.17777776718139648, 0.04651162400841713, 0.09756097197532654, 0.06779660284519196, 0.13636362552642822]",rJl5MeHKvB,"['We show that extra unlabeled data is not required for self-supervised auxiliary tasks to be useful for time series classification, and present new and effective auxiliary tasks.', ""This paper proposes a self-supervised method for learning from time series data in healthcare settings via designing auxilliary tasks based on data's internal structure to create more labeled auxilliary training tasks."", 'This paper propose an approach for self-supervised learning on time series.']","['selfsupervision  target task improved without external supervision  primarily explored setting assume availability additional data ', 'however  many case  particularly healthcare  one may access additional data  labeled otherwise  ', 'setting  hypothesize selfsupervision based solely structure data athand help ', 'explore novel selfsupervision framework timeseries data  multiple auxiliary task  eg  forecasting  included improve overall performance sequencelevel target task without additional training data ', 'call approach limited selfsupervision  limit data athand ', 'demonstrate utility limited selfsupervision three sequencelevel classification task  two pertaining real clinical data one using synthetic data ', 'within framework  introduce novel form selfsupervision demonstrate utility improving performance target task ', 'result indicate limited selfsupervision lead consistent improvement supervised baseline  across range domain ', 'particular  task identifying atrial fibrillation small amount electrocardiogram data  observe nearly 13  improvement area receiver operating characteristic curve  aucroc  relative baseline  aucroc055 v aucroc062  ', 'limited selfsupervision applied sequential data aid learning intermediate representation  making particularly applicable setting data collection difficult ']","Self-supervision, in which a target task is improved without external supervision, has primarily been explored in settings that assume the availability of additional data., However, in many cases, particularly in healthcare, one may not have access to additional data (labeled or otherwise)., In such settings, we hypothesize that self-supervision based solely on the structure of the data at-hand can help., We explore a novel self-supervision framework for time-series data, in which multiple auxiliary tasks (e.g., forecasting) are included to improve overall performance on a sequence-level target task without additional training data., We call this approach limited self-supervision, as we limit ourselves to only the data at-hand., We demonstrate the utility of limited self-supervision on three sequence-level classification tasks, two pertaining to real clinical data and one using synthetic data., Within this framework, we introduce novel forms of self-supervision and demonstrate their utility in improving performance on the target task., Our results indicate that limited self-supervision leads to a consistent improvement over a supervised baseline, across a range of domains., In particular, for the task of identifying atrial fibrillation from small amounts of electrocardiogram data, we observe a nearly 13% improvement in the area under the receiver operating characteristics curve (AUC-ROC) relative to the baseline (AUC-ROC=0.55 vs. AUC-ROC=0.62)., Limited self-supervision applied to sequential data can aid in learning intermediate representations, making it particularly applicable in settings where data collection is difficult.",25,6.086956521739131,9.2
198,"['Are neural networks biased toward simple functions?\n', 'Does depth always help learn more complex features?\n', 'Is training the last layer of a network as good as training all layers?\n', 'These questions seem unrelated at face value, but in this work we give all of them a common treatment from the spectral perspective.\n', 'We will study the spectra of the *Conjugate Kernel, CK,* (also called the *Neural Network-Gaussian Process Kernel*), and the *Neural Tangent Kernel, NTK*.\n', 'Roughly, the CK and the NTK tell us respectively ``""what a network looks like at initialization"" and ""``what a network looks like during and after training.""\n', 'Their spectra then encode valuable information about the initial distribution and the training and generalization properties of neural networks.\n', 'By analyzing the eigenvalues, we lend novel insights into the questions put forth at the beginning, and we verify these insights by extensive experiments of neural networks.\n', 'We believe the computational tools we develop here for analyzing the spectra of CK and NTK serve as a solid foundation for future studies of deep neural networks.\n', 'We have open-sourced the code for it and for generating the plots in this paper at github.com/jxVmnLgedVwv6mNcGCBy/NNspectra.']","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.0555555522441864, 0.0, 0.1463414579629898, 0.11320754140615463, 0.1666666567325592, 0.12244897335767746, 0.21276594698429108, 0.15094339847564697, 0.145454540848732, 0.13333332538604736]",HJlU-AVtvS,"['Eigenvalues of Conjugate (aka NNGP) and Neural Tangent Kernel can be computed in closed form over the Boolean cube and reveal the effects of hyperparameters on neural network inductive bias, training, and generalization.', ""This paper gives a spectral analysis on neural networks' conjugate kernel and neural tangent kernel on boolean cube to resolve why deep networks are biased towards simple functions.""]","['neural network biased toward simple function ', 'depth always help learn complex feature ', 'training last layer network good training layer ', 'question seem unrelated face value  work give common treatment spectral perspective ', 'study spectrum  conjugate kernel  ck    also called  neural networkgaussian process kernel     neural tangent kernel  ntk  ', 'roughly  ck ntk tell u respectively   network look like initialization    network look like training  ', 'spectrum encode valuable information initial distribution training generalization property neural network ', 'analyzing eigenvalue  lend novel insight question put forth beginning  verify insight extensive experiment neural network ', 'believe computational tool develop analyzing spectrum ck ntk serve solid foundation future study deep neural network ', 'opensourced code generating plot paper githubcomjxvmnlgedvwv6mncgcbynnspectra ']","Are neural networks biased toward simple functions?
, Does depth always help learn more complex features?
, Is training the last layer of a network as good as training all layers?
, These questions seem unrelated at face value, but in this work we give all of them a common treatment from the spectral perspective.
, We will study the spectra of the *Conjugate Kernel, CK,* (also called the *Neural Network-Gaussian Process Kernel*), and the *Neural Tangent Kernel, NTK*.
, Roughly, the CK and the NTK tell us respectively ``""what a network looks like at initialization"" and ""``what a network looks like during and after training.""
, Their spectra then encode valuable information about the initial distribution and the training and generalization properties of neural networks.
, By analyzing the eigenvalues, we lend novel insights into the questions put forth at the beginning, and we verify these insights by extensive experiments of neural networks.
, We believe the computational tools we develop here for analyzing the spectra of CK and NTK serve as a solid foundation for future studies of deep neural networks.
, We have open-sourced the code for it and for generating the plots in this paper at github.com/jxVmnLgedVwv6mNcGCBy/NNspectra.",17,5.369791666666667,11.294117647058824
199,"['To communicate, to ground hypotheses, to analyse data, neuroscientists often refer to divisions of the brain.', 'Here we consider atlases used to parcellate the brain when studying brain function.', 'We discuss the meaning and the validity of these parcellations, from a conceptual point of view as well as by running various analytical tasks on popular functional brain parcellations.']","[0, 0, 1]","[0.08695651590824127, 0.0952380895614624, 0.17142856121063232]",B1lKNXYU8S,"['All functional brain parcellations are wrong, but some are useful']","['communicate  ground hypothesis  analyse data  neuroscientist often refer division brain ', 'consider atlas used parcellate brain studying brain function ', 'discus meaning validity parcellation  conceptual point view well running various analytical task popular functional brain parcellation ']","To communicate, to ground hypotheses, to analyse data, neuroscientists often refer to divisions of the brain., Here we consider atlases used to parcellate the brain when studying brain function., We discuss the meaning and the validity of these parcellations, from a conceptual point of view as well as by running various analytical tasks on popular functional brain parcellations.",7,5.482758620689655,8.285714285714286
200,"['High-dimensional sparse reward tasks present major challenges for reinforcement learning agents.  ', 'In this work we use imitation learning to address two of these challenges:  how to learn a useful representation of the world e.g.  from pixels, and how to explore efficiently given the rarity of a reward signal?', 'We show that adversarial imitation can work well even in this high dimensional observation space.', 'Surprisingly the adversary itself, acting as the learned reward function, can be tiny, comprising as few as 128 parameters, and can be easily trained using the most basic GAN formulation.', 'Our approach removes limitations present in most contemporary imitation approaches: requiring no demonstrator actions (only video), no special initial conditions or warm starts, and no explicit tracking of any single demo.', 'The proposed agent can solve a challenging robot manipulation task of block stacking from only video demonstrations and sparse reward, in which the non-imitating agents fail to learn completely.  ', 'Furthermore, our agent learns much faster than competing approaches that depend on hand-crafted, staged dense reward functions, and also better compared to standard GAIL baselines.', 'Finally, we develop a new adversarial goal recognizer that in some cases allows the agent to learn stacking without any task reward, purely from imitation.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.13793103396892548, 0.2083333283662796, 0.0, 0.1463414579629898, 0.1304347813129425, 0.21276594698429108, 0.0952380895614624, 0.1428571343421936]",rygVV205KQ,"['Imitation from pixels, with sparse or no reward, using off-policy RL and a tiny adversarially-learned reward function.', 'The paper proposes to use a ""minimal adversary"" in generative adversarial imitation learning under high-dimensional visual spaces.', 'This paper aims at solving the problem of estimating sparse rewards in a high-dimensional input setting.']","['highdimensional sparse reward task present major challenge reinforcement learning agent ', 'work use imitation learning address two challenge  learn useful representation world eg  pixel  explore efficiently given rarity reward signal ', 'show adversarial imitation work well even high dimensional observation space ', 'surprisingly adversary  acting learned reward function  tiny  comprising 128 parameter  easily trained using basic gan formulation ', 'approach remove limitation present contemporary imitation approach  requiring demonstrator action  video   special initial condition warm start  explicit tracking single demo ', 'proposed agent solve challenging robot manipulation task block stacking video demonstration sparse reward  nonimitating agent fail learn completely ', 'furthermore  agent learns much faster competing approach depend handcrafted  staged dense reward function  also better compared standard gail baseline ', 'finally  develop new adversarial goal recognizer case allows agent learn stacking without task reward  purely imitation ']","High-dimensional sparse reward tasks present major challenges for reinforcement learning agents.  , In this work we use imitation learning to address two of these challenges:  how to learn a useful representation of the world e.g.  from pixels, and how to explore efficiently given the rarity of a reward signal?, We show that adversarial imitation can work well even in this high dimensional observation space., Surprisingly the adversary itself, acting as the learned reward function, can be tiny, comprising as few as 128 parameters, and can be easily trained using the most basic GAN formulation., Our approach removes limitations present in most contemporary imitation approaches: requiring no demonstrator actions (only video), no special initial conditions or warm starts, and no explicit tracking of any single demo., The proposed agent can solve a challenging robot manipulation task of block stacking from only video demonstrations and sparse reward, in which the non-imitating agents fail to learn completely.  , Furthermore, our agent learns much faster than competing approaches that depend on hand-crafted, staged dense reward functions, and also better compared to standard GAIL baselines., Finally, we develop a new adversarial goal recognizer that in some cases allows the agent to learn stacking without any task reward, purely from imitation.",21,5.58128078817734,9.227272727272727
201,"['In this paper we show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.', 'One strategy is based on the statistical analysis and comparison of raw pixel values and features extracted from them.', 'The other strategy learns formal specifications from the real data and shows that fake samples violate the specifications of the real data.', 'We show that fake samples produced with GANs have a universal signature that can be used to identify fake samples.', 'We provide results on MNIST, CIFAR10, music and speech data.']","[1, 0, 0, 0, 0]","[0.8484848141670227, 0.060606054961681366, 0.1875, 0.4375, 0.07999999821186066]",Bkl2SjCcKQ,"['We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.', 'Show that fake samples created with common generative adversarial network (GAN) implementations are easily identified using various statistical techniques. ', 'The paper proposes statistics to identify fake data generated using GANs based on simple marginal statistics or formal specifications automatically generated from real data.']","['paper show strategy easily identify fake sample generated generative adversarial network framework ', 'one strategy based statistical analysis comparison raw pixel value feature extracted ', 'strategy learns formal specification real data show fake sample violate specification real data ', 'show fake sample produced gans universal signature used identify fake sample ', 'provide result mnist  cifar10  music speech data ']","In this paper we show strategies to easily identify fake samples generated with the Generative Adversarial Network framework., One strategy is based on the statistical analysis and comparison of raw pixel values and features extracted from them., The other strategy learns formal specifications from the real data and shows that fake samples violate the specifications of the real data., We show that fake samples produced with GANs have a universal signature that can be used to identify fake samples., We provide results on MNIST, CIFAR10, music and speech data.",7,5.280898876404494,12.714285714285714
202,"['Efforts to reduce the numerical precision of computations in deep learning training have yielded systems that aggressively quantize weights and activations, yet employ wide high-precision accumulators for partial sums in inner-product operations to preserve the quality of convergence.', 'The absence of any framework to analyze the precision requirements of partial sum accumulations results in conservative design choices.', 'This imposes an upper-bound on the reduction of complexity of multiply-accumulate units.', 'We present a statistical approach to analyze the impact of reduced accumulation precision on deep learning training.', 'Observing that a bad choice for accumulation precision results in loss of information that manifests itself as a reduction in variance in an ensemble of partial sums, we derive a set of equations that relate this variance to the length of accumulation and the minimum number of bits needed for accumulation.', 'We apply our analysis to three benchmark networks: CIFAR-10 ResNet 32, ImageNet ResNet 18 and ImageNet AlexNet.', 'In each case, with accumulation precision set in accordance with our proposed equations, the networks successfully converge to the single precision floating-point baseline.', 'We also show that reducing accumulation precision further degrades the quality of the trained network, proving that our equations produce tight bounds.', 'Overall this analysis enables precise tailoring of computation hardware to the application, yielding area- and power-optimal systems.']","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.25806450843811035, 0.260869562625885, 0.1538461446762085, 0.4000000059604645, 0.21875, 0.23255813121795654, 0.2083333283662796, 0.2083333283662796, 0.17777776718139648]",BklMjsRqY7,"['We present an analytical framework to determine accumulation bit-width requirements in all three deep learning training GEMMs and verify the validity and tightness of our method via benchmarking experiments.', 'The authors propose an analytical method to predict the number of mantissa bits needed for partial summations for convolutional and fully connected layers', 'The authors conduct a thorough analysis of the numeric precision required for the accumulation operations in neural network training and show the theoretical impact of reducing number of bits in the floating point accumulator.']","['effort reduce numerical precision computation deep learning training yielded system aggressively quantize weight activation  yet employ wide highprecision accumulator partial sum innerproduct operation preserve quality convergence ', 'absence framework analyze precision requirement partial sum accumulation result conservative design choice ', 'imposes upperbound reduction complexity multiplyaccumulate unit ', 'present statistical approach analyze impact reduced accumulation precision deep learning training ', 'observing bad choice accumulation precision result loss information manifest reduction variance ensemble partial sum  derive set equation relate variance length accumulation minimum number bit needed accumulation ', 'apply analysis three benchmark network  cifar10 resnet 32  imagenet resnet 18 imagenet alexnet ', 'case  accumulation precision set accordance proposed equation  network successfully converge single precision floatingpoint baseline ', 'also show reducing accumulation precision degrades quality trained network  proving equation produce tight bound ', 'overall analysis enables precise tailoring computation hardware application  yielding area poweroptimal system ']","Efforts to reduce the numerical precision of computations in deep learning training have yielded systems that aggressively quantize weights and activations, yet employ wide high-precision accumulators for partial sums in inner-product operations to preserve the quality of convergence., The absence of any framework to analyze the precision requirements of partial sum accumulations results in conservative design choices., This imposes an upper-bound on the reduction of complexity of multiply-accumulate units., We present a statistical approach to analyze the impact of reduced accumulation precision on deep learning training., Observing that a bad choice for accumulation precision results in loss of information that manifests itself as a reduction in variance in an ensemble of partial sums, we derive a set of equations that relate this variance to the length of accumulation and the minimum number of bits needed for accumulation., We apply our analysis to three benchmark networks: CIFAR-10 ResNet 32, ImageNet ResNet 18 and ImageNet AlexNet., In each case, with accumulation precision set in accordance with our proposed equations, the networks successfully converge to the single precision floating-point baseline., We also show that reducing accumulation precision further degrades the quality of the trained network, proving that our equations produce tight bounds., Overall this analysis enables precise tailoring of computation hardware to the application, yielding area- and power-optimal systems.",16,5.944444444444445,13.5
203,"['Unsupervised domain adaptation is a promising avenue to enhance the performance of deep neural networks on a target domain, using labels only from a source domain.', 'However, the two predominant methods, domain discrepancy reduction learning and semi-supervised learning, are not readily applicable when source and target domains do not share a common label space.', 'This paper addresses the above scenario by learning a representation space that retains discriminative power on both the (labeled) source and (unlabeled) target domains while keeping representations for the two domains well-separated.', 'Inspired by a theoretical analysis, we first reformulate the disjoint classification task, where the source and target domains correspond to non-overlapping class labels, to a verification one.', 'To handle both within and cross domain verifications, we propose a Feature Transfer Network (FTN) to separate the target feature space from the original source space while aligned with a transformed source space.', 'Moreover, we present a non-parametric multi-class entropy minimization loss to further boost the discriminative power of FTNs on the target domain.', 'In experiments, we first illustrate how FTN works in a controlled setting of adapting from MNIST-M to MNIST with disjoint digit classes between the two domains and then demonstrate the effectiveness of FTNs through state-of-the-art performances on a cross-ethnicity face recognition problem.\n']","[1, 0, 0, 0, 0, 0, 0]","[0.1818181723356247, 0.12765957415103912, 0.11999999731779099, 0.08888888359069824, 0.12244897335767746, 0.1463414579629898, 0.16393442451953888]",BklhAj09K7,"['A new theory of unsupervised domain adaptation for distance metric learning and its application to face recognition across diverse ethnicity variations.', 'Proposes a novel feature transfer network that optimizes domain adversarial loss and domain separation loss.']","['unsupervised domain adaptation promising avenue enhance performance deep neural network target domain  using label source domain ', 'however  two predominant method  domain discrepancy reduction learning semisupervised learning  readily applicable source target domain share common label space ', 'paper address scenario learning representation space retains discriminative power  labeled  source  unlabeled  target domain keeping representation two domain wellseparated ', 'inspired theoretical analysis  first reformulate disjoint classification task  source target domain correspond nonoverlapping class label  verification one ', 'handle within cross domain verification  propose feature transfer network  ftn  separate target feature space original source space aligned transformed source space ', 'moreover  present nonparametric multiclass entropy minimization loss boost discriminative power ftns target domain ', 'experiment  first illustrate ftn work controlled setting adapting mnistm mnist disjoint digit class two domain demonstrate effectiveness ftns stateoftheart performance crossethnicity face recognition problem ']","Unsupervised domain adaptation is a promising avenue to enhance the performance of deep neural networks on a target domain, using labels only from a source domain., However, the two predominant methods, domain discrepancy reduction learning and semi-supervised learning, are not readily applicable when source and target domains do not share a common label space., This paper addresses the above scenario by learning a representation space that retains discriminative power on both the (labeled) source and (unlabeled) target domains while keeping representations for the two domains well-separated., Inspired by a theoretical analysis, we first reformulate the disjoint classification task, where the source and target domains correspond to non-overlapping class labels, to a verification one., To handle both within and cross domain verifications, we propose a Feature Transfer Network (FTN) to separate the target feature space from the original source space while aligned with a transformed source space., Moreover, we present a non-parametric multi-class entropy minimization loss to further boost the discriminative power of FTNs on the target domain., In experiments, we first illustrate how FTN works in a controlled setting of adapting from MNIST-M to MNIST with disjoint digit classes between the two domains and then demonstrate the effectiveness of FTNs through state-of-the-art performances on a cross-ethnicity face recognition problem.
",17,5.866028708133971,12.294117647058824
204,"['In this paper, we consider the problem of training neural networks (NN).', 'To promote a NN with specific structures, we explicitly take into consideration the nonsmooth regularization (such as L1-norm) and constraints (such as interval constraint).', 'This is formulated as a constrained nonsmooth nonconvex optimization problem, and we propose a convergent proximal-type stochastic gradient descent (Prox-SGD) algorithm.', 'We show that under properly selected learning rates, momentum eventually resembles the unknown real gradient and thus is crucial in analyzing the convergence.', 'We establish that with probability 1, every limit point of the sequence generated by the proposed Prox-SGD is a stationary point.', 'Then the Prox-SGD is tailored to train a sparse neural network and a binary neural network, and the theoretical analysis is also supported by extensive numerical tests.']","[0, 0, 1, 0, 0, 0]","[0.0, 0.10810810327529907, 0.6857143044471741, 0.10810810327529907, 0.11764705181121826, 0.05405404791235924]",HygpthEtvr,"['We propose a convergent proximal-type stochastic gradient descent algorithm for constrained nonsmooth nonconvex optimization problems', 'This paper proposes Prox-SGD, a theoretical framework for stochastic optimization algorithms shown to converge asymptotically to stationarity for smooth non-convvex loss + convex constraint/regularizer.', 'The paper proposes a new gradient-based stochastic optimization algorithm with gradient averaging by adapting theory for proximal algorithms to the non-convex setting.']","['paper  consider problem training neural network  nn  ', 'promote nn specific structure  explicitly take consideration nonsmooth regularization  l1norm  constraint  interval constraint  ', 'formulated constrained nonsmooth nonconvex optimization problem  propose convergent proximaltype stochastic gradient descent  proxsgd  algorithm ', 'show properly selected learning rate  momentum eventually resembles unknown real gradient thus crucial analyzing convergence ', 'establish probability 1  every limit point sequence generated proposed proxsgd stationary point ', 'proxsgd tailored train sparse neural network binary neural network  theoretical analysis also supported extensive numerical test ']","In this paper, we consider the problem of training neural networks (NN)., To promote a NN with specific structures, we explicitly take into consideration the nonsmooth regularization (such as L1-norm) and constraints (such as interval constraint)., This is formulated as a constrained nonsmooth nonconvex optimization problem, and we propose a convergent proximal-type stochastic gradient descent (Prox-SGD) algorithm., We show that under properly selected learning rates, momentum eventually resembles the unknown real gradient and thus is crucial in analyzing the convergence., We establish that with probability 1, every limit point of the sequence generated by the proposed Prox-SGD is a stationary point., Then the Prox-SGD is tailored to train a sparse neural network and a binary neural network, and the theoretical analysis is also supported by extensive numerical tests.",12,5.7890625,10.666666666666666
205,"['The loss of a few neurons in a brain rarely results in any visible loss of function.', 'However, the insight into what few means in this context is unclear.', 'How many random neuron failures will it take to lead to a visible loss of function?', 'In this paper, we address the fundamental question of the impact of the crash of a random subset of neurons on the overall computation of a neural network and the error in the output it produces.', 'We study fault tolerance of neural networks subject to small random neuron/weight crash failures in a probabilistic setting.', 'We give provable guarantees on the robustness of the network to these crashes.', 'Our main contribution is a bound on the error in the output of a network under small random Bernoulli crashes proved by using a Taylor expansion in the continuous limit, where close-by neurons at a layer are similar.', 'The failure mode we adopt in our model is characteristic of neuromorphic hardware, a promising technology to speed up artificial neural networks, as well as of biological networks.', 'We show that our theoretical bounds can be used to compare the fault tolerance of different architectures and to design a regularizer improving the fault tolerance of a given architecture.', 'We design an algorithm achieving fault tolerance using a reasonable number of neurons.', 'In addition to the theoretical proof, we also provide experimental validation of our results and suggest a connection to the generalization capacity problem.']","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.20512820780277252, 0.10526315122842789, 0.19512194395065308, 0.3461538553237915, 0.27272728085517883, 0.2631579041481018, 0.5862069129943848, 0.11538460850715637, 0.1599999964237213, 0.25641024112701416, 0.12765957415103912]",rkl_f6EFPS,"['We give a bound for NNs on the output error in case of random weight failures using a Taylor expansion in the continuous limit where nearby neurons are similar', 'This paper considers the problem of dropping neurons from a neural network, showing that if the goal is to become robust to randomly dropped neurons during evaluation, then it is sufficient to just train with dropout.', 'This contribution studies the impact of deletions of random neurons on prediction accuracy of trained architecture, with the application to failure analysis and the specific context of neuromorphic hardware.']","['loss neuron brain rarely result visible loss function ', 'however  insight   mean context unclear ', 'many random neuron failure take lead visible loss function ', 'paper  address fundamental question impact crash random subset neuron overall computation neural network error output produce ', 'study fault tolerance neural network subject small random neuronweight crash failure probabilistic setting ', 'give provable guarantee robustness network crash ', 'main contribution bound error output network small random bernoulli crash proved using taylor expansion continuous limit  closeby neuron layer similar ', 'failure mode adopt model characteristic neuromorphic hardware  promising technology speed artificial neural network  well biological network ', 'show theoretical bound used compare fault tolerance different architecture design regularizer improving fault tolerance given architecture ', 'design algorithm achieving fault tolerance using reasonable number neuron ', 'addition theoretical proof  also provide experimental validation result suggest connection generalization capacity problem ']","The loss of a few neurons in a brain rarely results in any visible loss of function., However, the insight into what few means in this context is unclear., How many random neuron failures will it take to lead to a visible loss of function?, In this paper, we address the fundamental question of the impact of the crash of a random subset of neurons on the overall computation of a neural network and the error in the output it produces., We study fault tolerance of neural networks subject to small random neuron/weight crash failures in a probabilistic setting., We give provable guarantees on the robustness of the network to these crashes., Our main contribution is a bound on the error in the output of a network under small random Bernoulli crashes proved by using a Taylor expansion in the continuous limit, where close-by neurons at a layer are similar., The failure mode we adopt in our model is characteristic of neuromorphic hardware, a promising technology to speed up artificial neural networks, as well as of biological networks., We show that our theoretical bounds can be used to compare the fault tolerance of different architectures and to design a regularizer improving the fault tolerance of a given architecture., We design an algorithm achieving fault tolerance using a reasonable number of neurons., In addition to the theoretical proof, we also provide experimental validation of our results and suggest a connection to the generalization capacity problem.",17,5.008196721311475,14.352941176470589
206,"['Truly intelligent agents need to capture the interplay of all their senses to build a rich physical understanding of their world.', 'In robotics, we have seen tremendous progress in using visual and tactile perception; however we have often ignored a key sense: sound.', 'This is primarily due to lack of data that captures the interplay of action and sound.', 'In this work, we perform the first large-scale study of the interactions between sound and robotic action.', 'To do this, we create the largest available sound-action-vision dataset with 15,000 interactions on 60 objects using our robotic platform Tilt-Bot.', 'By tilting objects and allowing them to crash into the walls of a robotic tray, we collect rich four-channel audio information.', 'Using this data, we explore the synergies between sound and action, and present three key insights.', 'First, sound is indicative of fine-grained object class information, e.g., sound can differentiate a metal screwdriver from a metal wrench.', 'Second, sound also contains information about the causal effects of an action, i.e. given the sound produced, we can predict what action was applied on the object.', 'Finally, object representations derived from audio embeddings are indicative of implicit physical properties.', 'We demonstrate that on previously unseen objects, audio embeddings generated through interactions can predict forward models 24% better than passive visual embeddings.']","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.07407406717538834, 0.13793103396892548, 0.3333333432674408, 0.47999998927116394, 0.06666666269302368, 0.13333332538604736, 0.5, 0.0714285671710968, 0.1764705777168274, 0.0, 0.06666666269302368]",SJeUm1HtDH,"['We explore and study the synergies between sound and action.', 'This paper explores the connections between action and sound by building a sound-action-vision dataset with a tilt-bot.', 'This paper studies the role of audio in object and action perception, as well as how auditory information can help learning forward and inverse dynamics models.']","['truly intelligent agent need capture interplay sens build rich physical understanding world ', 'robotics  seen tremendous progress using visual tactile perception  however often ignored key sense  sound ', 'primarily due lack data capture interplay action sound ', 'work  perform first largescale study interaction sound robotic action ', ' create largest available soundactionvision dataset 15000 interaction 60 object using robotic platform tiltbot ', 'tilting object allowing crash wall robotic tray  collect rich fourchannel audio information ', 'using data  explore synergy sound action  present three key insight ', 'first  sound indicative finegrained object class information  eg  sound differentiate metal screwdriver metal wrench ', 'second  sound also contains information causal effect action  ie  given sound produced  predict action applied object ', 'finally  object representation derived audio embeddings indicative implicit physical property ', 'demonstrate previously unseen object  audio embeddings generated interaction predict forward model 24  better passive visual embeddings ']","Truly intelligent agents need to capture the interplay of all their senses to build a rich physical understanding of their world., In robotics, we have seen tremendous progress in using visual and tactile perception; however we have often ignored a key sense: sound., This is primarily due to lack of data that captures the interplay of action and sound., In this work, we perform the first large-scale study of the interactions between sound and robotic action., To do this, we create the largest available sound-action-vision dataset with 15,000 interactions on 60 objects using our robotic platform Tilt-Bot., By tilting objects and allowing them to crash into the walls of a robotic tray, we collect rich four-channel audio information., Using this data, we explore the synergies between sound and action, and present three key insights., First, sound is indicative of fine-grained object class information, e.g., sound can differentiate a metal screwdriver from a metal wrench., Second, sound also contains information about the causal effects of an action, i.e. given the sound produced, we can predict what action was applied on the object., Finally, object representations derived from audio embeddings are indicative of implicit physical properties., We demonstrate that on previously unseen objects, audio embeddings generated through interactions can predict forward models 24% better than passive visual embeddings.",25,5.5,8.307692307692308
207,"['Hierarchical label structures widely exist in many machine learning tasks, ranging from those with explicit label hierarchies such as image classification to the ones that have latent label hierarchies such as semantic segmentation.', 'Unfortunately, state-of-the-art methods often utilize cross-entropy loss which in-explicitly assumes the independence among class labels.', 'Motivated by the fact that class members from the same hierarchy need to be similar to each others, we design a new training diagram called Hierarchical Complement Objective Training (HCOT).', 'In HCOT, in addition to maximizing the probability of the ground truth class, we also neutralize the probabilities of rest of the classes in a hierarchical fashion, making the model take advantage of the label hierarchy explicitly.', 'We conduct our method on both image classification and semantic segmentation.', 'Results show that HCOT outperforms state-of-the-art models in CIFAR100, Imagenet, and PASCAL-context.', 'Our experiments also demonstrate that HCOT can be applied on tasks with latent label hierarchies, which is a common characteristic in many machine learning tasks.']","[0, 0, 0, 0, 1, 0, 0]","[0.29629629850387573, 0.04878048226237297, 0.29629629850387573, 0.18518517911434174, 0.4324324429035187, 0.10526315122842789, 0.11999999731779099]",SyxQh3EFDr,"['We propose Hierarchical Complement Objective Training, a novel training paradigm to effectively leverage category hierarchy in the labeling space on both image classification and semantic segmentation.', 'A method that regularizes the entropy of the posterior distribution over classes which can be useful for image classsification and segmentation tasks']","['hierarchical label structure widely exist many machine learning task  ranging explicit label hierarchy image classification one latent label hierarchy semantic segmentation ', 'unfortunately  stateoftheart method often utilize crossentropy loss inexplicitly assumes independence among class label ', 'motivated fact class member hierarchy need similar others  design new training diagram called hierarchical complement objective training  hcot  ', 'hcot  addition maximizing probability ground truth class  also neutralize probability rest class hierarchical fashion  making model take advantage label hierarchy explicitly ', 'conduct method image classification semantic segmentation ', 'result show hcot outperforms stateoftheart model cifar100  imagenet  pascalcontext ', 'experiment also demonstrate hcot applied task latent label hierarchy  common characteristic many machine learning task ']","Hierarchical label structures widely exist in many machine learning tasks, ranging from those with explicit label hierarchies such as image classification to the ones that have latent label hierarchies such as semantic segmentation., Unfortunately, state-of-the-art methods often utilize cross-entropy loss which in-explicitly assumes the independence among class labels., Motivated by the fact that class members from the same hierarchy need to be similar to each others, we design a new training diagram called Hierarchical Complement Objective Training (HCOT)., In HCOT, in addition to maximizing the probability of the ground truth class, we also neutralize the probabilities of rest of the classes in a hierarchical fashion, making the model take advantage of the label hierarchy explicitly., We conduct our method on both image classification and semantic segmentation., Results show that HCOT outperforms state-of-the-art models in CIFAR100, Imagenet, and PASCAL-context., Our experiments also demonstrate that HCOT can be applied on tasks with latent label hierarchies, which is a common characteristic in many machine learning tasks.",16,5.920245398773006,10.1875
208,"['There is a growing interest in automated neural architecture search (NAS).', 'To improve the efficiency of NAS, previous approaches adopt  weight sharing method to force all models share the same set of weights.  ', 'However, it has been observed that a model performing better with shared weights does not necessarily perform  better when trained alone.', 'In this paper, we analyse existing weight sharing one-shot NAS approaches from a Bayesian point of view and identify the posterior fading problem, which compromises the effectiveness of shared weights.', 'To alleviate this problem, we present a practical approach to guide the parameter posterior towards its true distribution.', 'Moreover, a hard latency constraint is introduced during the search so that the desired latency can be achieved.', 'The resulted method, namely Posterior Convergent NAS (PC-NAS), achieves state-of-the-art performance under standard GPU latency constraint on ImageNet.', 'In our small search space, our model PC-NAS-S attains76.8% top-1 accuracy, 2.1% higher than MobileNetV2 (1.4x) with the same latency.', 'When adopted to our large search space, PC-NAS-L achieves 78.1% top-1 accuracy within 11ms.', 'The discovered architecture also transfers well to other computer vision applications such as object detection and person re-identification.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.3030303120613098, 0.1860465109348297, 0.0476190410554409, 0.2800000011920929, 0.19999998807907104, 0.15789473056793213, 0.04999999329447746, 0.09090908616781235, 0.05405404791235924, 0.09999999403953552]",HJgJNCEKPr,"['Our paper identifies the issue of existing weight sharing approach in neural architecture search and propose a practical method, achieving strong results.', 'Author identifies an issue with NAS called posterior fading and introduces Posterior Convergent NAS to mitigate this effect']","['growing interest automated neural architecture search  na  ', 'improve efficiency na  previous approach adopt weight sharing method force model share set weight ', 'however  observed model performing better shared weight necessarily perform better trained alone ', 'paper  analyse existing weight sharing oneshot na approach bayesian point view identify posterior fading problem  compromise effectiveness shared weight ', 'alleviate problem  present practical approach guide parameter posterior towards true distribution ', 'moreover  hard latency constraint introduced search desired latency achieved ', 'resulted method  namely posterior convergent na  pcnas   achieves stateoftheart performance standard gpu latency constraint imagenet ', 'small search space  model pcnass attains768  top1 accuracy  21  higher mobilenetv2  14x  latency ', 'adopted large search space  pcnasl achieves 781  top1 accuracy within 11ms ', 'discovered architecture also transfer well computer vision application object detection person reidentification ']","There is a growing interest in automated neural architecture search (NAS)., To improve the efficiency of NAS, previous approaches adopt  weight sharing method to force all models share the same set of weights.  , However, it has been observed that a model performing better with shared weights does not necessarily perform  better when trained alone., In this paper, we analyse existing weight sharing one-shot NAS approaches from a Bayesian point of view and identify the posterior fading problem, which compromises the effectiveness of shared weights., To alleviate this problem, we present a practical approach to guide the parameter posterior towards its true distribution., Moreover, a hard latency constraint is introduced during the search so that the desired latency can be achieved., The resulted method, namely Posterior Convergent NAS (PC-NAS), achieves state-of-the-art performance under standard GPU latency constraint on ImageNet., In our small search space, our model PC-NAS-S attains76.8% top-1 accuracy, 2.1% higher than MobileNetV2 (1.4x) with the same latency., When adopted to our large search space, PC-NAS-L achieves 78.1% top-1 accuracy within 11ms., The discovered architecture also transfers well to other computer vision applications such as object detection and person re-identification.",21,5.794736842105263,9.047619047619047
209,"['Noisy labels are very common in real-world training data, which lead to poor generalization on test data because of overfitting to the noisy labels.', 'In this paper, we claim that such overfitting can be avoided by ""early stopping"" training a deep neural network before the noisy labels are severely memorized.', 'Then, we resume training the early stopped network using a ""maximal safe set,"" which maintains a collection of almost certainly true-labeled samples at each epoch since the early stop point.', 'Putting them all together, our novel two-phase training method, called Prestopping, realizes noise-free training under any type of label noise for practical use.', 'Extensive experiments using four image benchmark data sets verify that our method significantly outperforms four state-of-the-art methods in test error by 0.48.2 percent points under existence of real-world noise.']","[0, 1, 0, 0, 0]","[0.21621620655059814, 0.2926829159259796, 0.0952380895614624, 0.21621620655059814, 0.0]",BklSwn4tDH,"['We propose a novel two-phase training approach based on ""early stopping"" for robust training on noisy labels.', 'Paper proposes to study how early stopping in optimization helps find confident examples', 'This paper proposes a two-phase training method for learning with label noise.']","['noisy label common realworld training data  lead poor generalization test data overfitting noisy label ', 'paper  claim overfitting avoided  early stopping  training deep neural network noisy label severely memorized ', ' resume training early stopped network using  maximal safe set   maintains collection almost certainly truelabeled sample epoch since early stop point ', 'putting together  novel twophase training method  called prestopping  realizes noisefree training type label noise practical use ', 'extensive experiment using four image benchmark data set verify method significantly outperforms four stateoftheart method test error 0482 percent point existence realworld noise ']","Noisy labels are very common in real-world training data, which lead to poor generalization on test data because of overfitting to the noisy labels., In this paper, we claim that such overfitting can be avoided by ""early stopping"" training a deep neural network before the noisy labels are severely memorized., Then, we resume training the early stopped network using a ""maximal safe set,"" which maintains a collection of almost certainly true-labeled samples at each epoch since the early stop point., Putting them all together, our novel two-phase training method, called Prestopping, realizes noise-free training under any type of label noise for practical use., Extensive experiments using four image benchmark data sets verify that our method significantly outperforms four state-of-the-art methods in test error by 0.48.2 percent points under existence of real-world noise.",11,5.598484848484849,12.0
210,"['Learning when to communicate and doing that effectively is essential in multi-agent tasks.', 'Recent works show that continuous communication allows efficient training with back-propagation in multi-agent scenarios, but have been restricted to fully-cooperative tasks.', 'In this paper, we present Individualized Controlled Continuous Communication Model (IC3Net) which has better training efficiency than simple continuous communication model, and can be applied to semi-cooperative and competitive settings along with the cooperative settings.', 'IC3Net controls continuous communication with a gating mechanism and uses individualized rewards foreach agent to gain better performance and scalability while fixing credit assignment issues.', 'Using variety of tasks including StarCraft BroodWars explore and combat scenarios, we show that our network yields improved performance and convergence rates than the baselines as the scale increases.', 'Our results convey that IC3Net agents learn when to communicate based on the scenario and profitability.']","[0, 0, 0, 0, 0, 1]","[0.2926829159259796, 0.16326530277729034, 0.19672130048274994, 0.11538460850715637, 0.1818181723356247, 0.3181818127632141]",rye7knCqK7,"['We introduce IC3Net, a single network which can be used to train agents in cooperative, competitive and mixed scenarios. We also show that agents can learn when to communicate using our model.', 'Author proposes a new architecture for multi-agent reinforcement learning that uses several LSTM controllers with tied weights that transmit a continuous vector to each other', 'The authors propose an interesting gating scheme allowing agents to communicate in an multi-agent RL setting. ']","['learning communicate effectively essential multiagent task ', 'recent work show continuous communication allows efficient training backpropagation multiagent scenario  restricted fullycooperative task ', 'paper  present individualized controlled continuous communication model  ic3net  better training efficiency simple continuous communication model  applied semicooperative competitive setting along cooperative setting ', 'ic3net control continuous communication gating mechanism us individualized reward foreach agent gain better performance scalability fixing credit assignment issue ', 'using variety task including starcraft broodwars explore combat scenario  show network yield improved performance convergence rate baseline scale increase ', 'result convey ic3net agent learn communicate based scenario profitability ']","Learning when to communicate and doing that effectively is essential in multi-agent tasks., Recent works show that continuous communication allows efficient training with back-propagation in multi-agent scenarios, but have been restricted to fully-cooperative tasks., In this paper, we present Individualized Controlled Continuous Communication Model (IC3Net) which has better training efficiency than simple continuous communication model, and can be applied to semi-cooperative and competitive settings along with the cooperative settings., IC3Net controls continuous communication with a gating mechanism and uses individualized rewards foreach agent to gain better performance and scalability while fixing credit assignment issues., Using variety of tasks including StarCraft BroodWars explore and combat scenarios, we show that our network yields improved performance and convergence rates than the baselines as the scale increases., Our results convey that IC3Net agents learn when to communicate based on the scenario and profitability.",10,6.446043165467626,13.9
211,"['Neural sequence-to-sequence models are a recently proposed family of approaches used in abstractive summarization of text documents, useful for producing condensed versions of source text narratives without being restricted to using only words from the original text.', ""Despite the advances in abstractive summarization, custom generation of summaries (e.g. towards a user's preference) remains unexplored."", 'In this paper, we present CATS, an abstractive neural summarization model, that summarizes content in a sequence-to-sequence fashion but also introduces a new mechanism to control the underlying latent topic distribution of the produced summaries.', 'Our experimental results on the well-known CNN/DailyMail dataset show that our model achieves state-of-the-art performance.']","[0, 0, 1, 0]","[0.17391304671764374, 0.25806450843811035, 0.30434781312942505, 0.1428571343421936]",Hkef0EqHa4,['We present the first neural abstractive summarization model capable of customization of generated summaries.'],"['neural sequencetosequence model recently proposed family approach used abstractive summarization text document  useful producing condensed version source text narrative without restricted using word original text ', 'despite advance abstractive summarization  custom generation summary  eg  towards user preference  remains unexplored ', 'paper  present cat  abstractive neural summarization model  summarizes content sequencetosequence fashion also introduces new mechanism control underlying latent topic distribution produced summary ', 'experimental result wellknown cnndailymail dataset show model achieves stateoftheart performance ']","Neural sequence-to-sequence models are a recently proposed family of approaches used in abstractive summarization of text documents, useful for producing condensed versions of source text narratives without being restricted to using only words from the original text., Despite the advances in abstractive summarization, custom generation of summaries (e.g. towards a user's preference) remains unexplored., In this paper, we present CATS, an abstractive neural summarization model, that summarizes content in a sequence-to-sequence fashion but also introduces a new mechanism to control the underlying latent topic distribution of the produced summaries., Our experimental results on the well-known CNN/DailyMail dataset show that our model achieves state-of-the-art performance.",9,6.423076923076923,10.4
212,"['We propose a software framework based on ideas of the Learning-Compression algorithm , that allows one to compress any neural network by different compression mechanisms (pruning, quantization, low-rank, etc.).', 'By design, the learning of the neural net (handled by SGD) is decoupled from the compression of its parameters (handled by a signal compression function), so that the framework can be easily extended to handle different combinations of neural net and compression type.', 'In addition, it has other advantages, such as easy integration with deep learning frameworks, efficient training time, competitive practical performance in the loss-compression tradeoff, and reasonable convergence guarantees.', 'Our toolkit is written in Python and Pytorch and we plan to make it available by the workshop time, and eventually open it for contributions from the community.']","[1, 0, 0, 0]","[1.0, 0.32258063554763794, 0.03448275476694107, 0.1111111044883728]",H1fZLbSti7,"['We propose a software framework based on ideas of the Learning-Compression algorithm , that allows one to compress any neural network by different compression mechanisms (pruning, quantization, low-rank, etc.).', 'This paper presents the design of a software library that makes it easier for the user to compress their networks by hiding away the details of the compression methods.']","['propose software framework based idea learningcompression algorithm  allows one compress neural network different compression mechanism  pruning  quantization  lowrank  etc   ', 'design  learning neural net  handled sgd  decoupled compression parameter  handled signal compression function   framework easily extended handle different combination neural net compression type ', 'addition  advantage  easy integration deep learning framework  efficient training time  competitive practical performance losscompression tradeoff  reasonable convergence guarantee ', 'toolkit written python pytorch plan make available workshop time  eventually open contribution community ']","We propose a software framework based on ideas of the Learning-Compression algorithm , that allows one to compress any neural network by different compression mechanisms (pruning, quantization, low-rank, etc.)., By design, the learning of the neural net (handled by SGD) is decoupled from the compression of its parameters (handled by a signal compression function), so that the framework can be easily extended to handle different combinations of neural net and compression type., In addition, it has other advantages, such as easy integration with deep learning frameworks, efficient training time, competitive practical performance in the loss-compression tradeoff, and reasonable convergence guarantees., Our toolkit is written in Python and Pytorch and we plan to make it available by the workshop time, and eventually open it for contributions from the community.",16,5.724409448818897,7.529411764705882
213,"['This work seeks the possibility of generating the human face from voice solely based on the audio-visual data without any human-labeled annotations.', 'To this end, we propose a multi-modal learning framework that links the inference stage and generation stage.', 'First, the inference networks are trained to match the speaker identity between the two different modalities.', 'Then the pre-trained inference networks cooperate with the generation network by giving conditional information about the voice.']","[1, 0, 0, 0]","[0.3684210479259491, 0.29411762952804565, 0.0, 0.060606054961681366]",H1guaREYPr,"['This paper proposes a method of end-to-end multi-modal generation of human face from speech based on a self-supervised learning framework.', 'This paper presents a multi-modal learning framework that links the inference stage and generation stage for seeking the possibility of generating the human face from voice solely.', 'This work aims to build one conditional face image generation framework from the audio signal. ']","['work seek possibility generating human face voice solely based audiovisual data without humanlabeled annotation ', 'end  propose multimodal learning framework link inference stage generation stage ', 'first  inference network trained match speaker identity two different modality ', 'pretrained inference network cooperate generation network giving conditional information voice ']","This work seeks the possibility of generating the human face from voice solely based on the audio-visual data without any human-labeled annotations., To this end, we propose a multi-modal learning framework that links the inference stage and generation stage., First, the inference networks are trained to match the speaker identity between the two different modalities., Then the pre-trained inference networks cooperate with the generation network by giving conditional information about the voice.",6,5.888888888888889,12.0
214,"['We present a simple neural model that given a formula and a property tries to answer the question whether the formula has the given property, for example whether a propositional formula is always true.', 'The structure of the formula is captured by a feedforward neural network recursively built for the given formula in a top-down manner.', 'The results of this network are then processed by two recurrent neural networks.', 'One of the interesting aspects of our model is how propositional atoms are treated.', 'For example, the model is insensitive to their names, it only matters whether they are the same or distinct.']","[0, 1, 0, 0, 0]","[0.20512820780277252, 0.3030303120613098, 0.2222222238779068, 0.2222222238779068, 0.1249999925494194]",Byg5QhR5FQ,"['A top-down approach how to recursively represent propositional formulae by neural networks is presented.', 'This paper provides a new neural-net model of logical formulae that gathers information about a given formula by traversing its parse tree top-down.', 'The paper pursues the path of a tree-structured network isomorphic to the parse tree of a propositional-calculus formula, but by passing information top-down rather than bottom-up.']","['present simple neural model given formula property try answer question whether formula given property  example whether propositional formula always true ', 'structure formula captured feedforward neural network recursively built given formula topdown manner ', 'result network processed two recurrent neural network ', 'one interesting aspect model propositional atom treated ', 'example  model insensitive name  matter whether distinct ']","We present a simple neural model that given a formula and a property tries to answer the question whether the formula has the given property, for example whether a propositional formula is always true., The structure of the formula is captured by a feedforward neural network recursively built for the given formula in a top-down manner., The results of this network are then processed by two recurrent neural networks., One of the interesting aspects of our model is how propositional atoms are treated., For example, the model is insensitive to their names, it only matters whether they are the same or distinct.",8,4.96078431372549,12.75
215,"[""Despite significant advances in the field of deep Reinforcement Learning (RL), today's algorithms still fail to learn human-level policies consistently over a set of diverse tasks such as Atari 2600 games."", 'We identify three key challenges that any algorithm needs to master in order to perform well on all games:  processing diverse reward distributions, reasoning over long time horizons, and exploring efficiently.  ', 'In this paper, we propose an algorithm that addresses each of these challenges and is able to learn human-level policies on nearly all Atari games.', 'A new transformed Bellman operator allows our algorithm to process rewards of varying densities and scales; an auxiliary temporal consistency loss allows us to train stably using a discount factor of 0.999 (instead of 0.99) extending the effective planning horizon by an order of magnitude; and we ease the exploration problem by using human demonstrations that guide the agent towards rewarding states.', 'When tested on a set of 42 Atari games, our algorithm exceeds the performance  of an average human on 40 games using a common set of hyper parameters.']","[0, 0, 0, 0, 1]","[0.07692307233810425, 0.037735845893621445, 0.08510638028383255, 0.0810810774564743, 0.13333332538604736]",BkfPnoActQ,"['Ape-X DQfD = Distributed (many actors + one learner + prioritized replay) DQN with demonstrations optimizing the unclipped 0.999-discounted return on Atari.', 'The paper proposes three extensions (Bellman update, temporal consistency loss, and expert demonstration) to DQN to improve the learning performance on Atari games, achieving outperformance over the state-of-the-art results for Atari games. ', 'This paper proposes a transformed Bellman operator that aims to solve sensitivity to unclipped reward, robustness to the value of the discount factor, and the exploration problem.']","['despite significant advance field deep reinforcement learning  rl   today algorithm still fail learn humanlevel policy consistently set diverse task atari 2600 game ', 'identify three key challenge algorithm need master order perform well game  processing diverse reward distribution  reasoning long time horizon  exploring efficiently ', 'paper  propose algorithm address challenge able learn humanlevel policy nearly atari game ', 'new transformed bellman operator allows algorithm process reward varying density scale  auxiliary temporal consistency loss allows u train stably using discount factor 0999  instead 099  extending effective planning horizon order magnitude  ease exploration problem using human demonstration guide agent towards rewarding state ', 'tested set 42 atari game  algorithm exceeds performance average human 40 game using common set hyper parameter ']","Despite significant advances in the field of deep Reinforcement Learning (RL), today's algorithms still fail to learn human-level policies consistently over a set of diverse tasks such as Atari 2600 games., We identify three key challenges that any algorithm needs to master in order to perform well on all games:  processing diverse reward distributions, reasoning over long time horizons, and exploring efficiently.  , In this paper, we propose an algorithm that addresses each of these challenges and is able to learn human-level policies on nearly all Atari games., A new transformed Bellman operator allows our algorithm to process rewards of varying densities and scales; an auxiliary temporal consistency loss allows us to train stably using a discount factor of 0.999 (instead of 0.99) extending the effective planning horizon by an order of magnitude; and we ease the exploration problem by using human demonstrations that guide the agent towards rewarding states., When tested on a set of 42 Atari games, our algorithm exceeds the performance  of an average human on 40 games using a common set of hyper parameters.",10,5.288135593220339,17.7
216,"['The knowledge that humans hold about a problem often extends far beyond a set of training data and output labels.', 'While the success of deep learning mostly relies on supervised training, important properties cannot be inferred efficiently from end-to-end annotations alone, for example causal relations or domain-specific invariances.', 'We present a general technique to supplement supervised training with prior knowledge expressed as relations between training instances.', 'We illustrate the method on the task of visual question answering to exploit various auxiliary annotations, including relations of equivalence and of logical entailment between questions.', 'Existing methods to use these annotations, including auxiliary losses and data augmentation, cannot guarantee the strict inclusion of these relations into the model since they require a careful balancing against the end-to-end objective.', 'Our method uses these relations to shape the embedding space of the model, and treats them as strict constraints on its learned representations.', '%The resulting model encodes relations that better generalize across instances.', 'In the context of VQA, this approach brings significant improvements in accuracy and robustness, in particular over the common practice of incorporating the constraints as a soft regularizer.', 'We also show that incorporating this type of prior knowledge with our method brings consistent improvements, independently from the amount of supervised data used.', 'It demonstrates the value of an additional training signal that is otherwise difficult to extract from end-to-end annotations alone.']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.05714285373687744, 0.09090908616781235, 0.1818181723356247, 0.307692289352417, 0.08695651590824127, 0.31578946113586426, 0.0, 0.04999999701976776, 0.10256409645080566, 0.11428570747375488]",H1ggKyrYwB,"['Training method to enforce strict constraints on learned embeddings during supervised training. Applied to visual question answering.', 'The authors propose a framework to incorporate additional semantic prior knowledge into the traditional training of deep learning models to regularize the embedding space instead of the parameter space.', 'The paper argues for encoding external knowledge in the linguistic embedding layer of a multimodal neural network, as a set of hard constraints.']","['knowledge human hold problem often extends far beyond set training data output label ', 'success deep learning mostly relies supervised training  important property inferred efficiently endtoend annotation alone  example causal relation domainspecific invariance ', 'present general technique supplement supervised training prior knowledge expressed relation training instance ', 'illustrate method task visual question answering exploit various auxiliary annotation  including relation equivalence logical entailment question ', 'existing method use annotation  including auxiliary loss data augmentation  guarantee strict inclusion relation model since require careful balancing endtoend objective ', 'method us relation shape embedding space model  treat strict constraint learned representation ', ' resulting model encodes relation better generalize across instance ', 'context vqa  approach brings significant improvement accuracy robustness  particular common practice incorporating constraint soft regularizer ', 'also show incorporating type prior knowledge method brings consistent improvement  independently amount supervised data used ', 'demonstrates value additional training signal otherwise difficult extract endtoend annotation alone ']","The knowledge that humans hold about a problem often extends far beyond a set of training data and output labels., While the success of deep learning mostly relies on supervised training, important properties cannot be inferred efficiently from end-to-end annotations alone, for example causal relations or domain-specific invariances., We present a general technique to supplement supervised training with prior knowledge expressed as relations between training instances., We illustrate the method on the task of visual question answering to exploit various auxiliary annotations, including relations of equivalence and of logical entailment between questions., Existing methods to use these annotations, including auxiliary losses and data augmentation, cannot guarantee the strict inclusion of these relations into the model since they require a careful balancing against the end-to-end objective., Our method uses these relations to shape the embedding space of the model, and treats them as strict constraints on its learned representations., %The resulting model encodes relations that better generalize across instances., In the context of VQA, this approach brings significant improvements in accuracy and robustness, in particular over the common practice of incorporating the constraints as a soft regularizer., We also show that incorporating this type of prior knowledge with our method brings consistent improvements, independently from the amount of supervised data used., It demonstrates the value of an additional training signal that is otherwise difficult to extract from end-to-end annotations alone.",19,6.0,12.052631578947368
217,"['Artificial neural networks revolutionized many areas of computer science in recent years since they provide solutions to a number of previously unsolved problems.\n', 'On the other hand, for many problems, classic algorithms exist, which typically exceed the accuracy and stability of neural networks.\n', 'To combine these two concepts, we present a new kind of neural networksalgorithmic neural networks (AlgoNets).\n', 'These networks integrate smooth versions of classic algorithms into the topology of neural networks.\n', 'Our novel reconstructive adversarial network (RAN) enables solving inverse problems without or with only weak supervision.']","[0, 0, 0, 1, 0]","[0.1621621549129486, 0.1764705777168274, 0.06666666269302368, 0.29629629850387573, 0.13333332538604736]",ByxLnmnqUr,['Solving inverse problems by using smooth approximations of the forward algorithms to train the inverse models.'],"['artificial neural network revolutionized many area computer science recent year since provide solution number previously unsolved problem ', 'hand  many problem  classic algorithm exist  typically exceed accuracy stability neural network ', 'combine two concept  present new kind neural networksalgorithmic neural network  algonets  ', 'network integrate smooth version classic algorithm topology neural network ', 'novel reconstructive adversarial network  ran  enables solving inverse problem without weak supervision ']","Artificial neural networks revolutionized many areas of computer science in recent years since they provide solutions to a number of previously unsolved problems.
, On the other hand, for many problems, classic algorithms exist, which typically exceed the accuracy and stability of neural networks.
, To combine these two concepts, we present a new kind of neural networksalgorithmic neural networks (AlgoNets).
, These networks integrate smooth versions of classic algorithms into the topology of neural networks.
, Our novel reconstructive adversarial network (RAN) enables solving inverse problems without or with only weak supervision.",9,6.067415730337078,9.88888888888889
218,"['Pointwise localization allows more precise localization and accurate interpretability, compared to bounding box, in applications where objects are highly unstructured such as in medical domain.', 'In this work, we focus on  weakly supervised localization (WSL) where a model is trained to classify an image and localize regions of interest at pixel-level using only global image annotation.', 'Typical convolutional attentions maps are prune to high false positive regions.', 'To alleviate this issue, we propose a new deep learning method for WSL, composed of a localizer and a classifier, where the localizer is constrained to determine relevant and irrelevant regions using conditional entropy (CE) with the aim to reduce false positive regions.', 'Experimental results on a public medical dataset and two natural datasets, using Dice index, show that, compared to state of the art WSL methods, our proposal can provide significant improvements in terms of image-level classification and pixel-level localization (low false positive) with robustness to overfitting.', 'A public reproducible PyTorch implementation is provided.']","[0, 0, 0, 1, 0, 0]","[0.11538460850715637, 0.2711864411830902, 0.20000000298023224, 0.4307692348957062, 0.19718308746814728, 0.0555555522441864]",HkeO76EKDr,"['A deep learning method for weakly-supervised pointwise localization that learns using image-level label only. It relies on conditional entropy to localize relevant and irrelevant regions aiming to minimize false positive regions.', 'This work explores the problem of WSL using a novel design of regularization terms and a recursive erasing algorithm.', 'This paper presents a new weakly supervised approach for learning object segmentation with image-level class labels.']","['pointwise localization allows precise localization accurate interpretability  compared bounding box  application object highly unstructured medical domain ', 'work  focus weakly supervised localization  wsl  model trained classify image localize region interest pixellevel using global image annotation ', 'typical convolutional attention map prune high false positive region ', 'alleviate issue  propose new deep learning method wsl  composed localizer classifier  localizer constrained determine relevant irrelevant region using conditional entropy  ce  aim reduce false positive region ', 'experimental result public medical dataset two natural datasets  using dice index  show  compared state art wsl method  proposal provide significant improvement term imagelevel classification pixellevel localization  low false positive  robustness overfitting ', 'public reproducible pytorch implementation provided ']","Pointwise localization allows more precise localization and accurate interpretability, compared to bounding box, in applications where objects are highly unstructured such as in medical domain., In this work, we focus on  weakly supervised localization (WSL) where a model is trained to classify an image and localize regions of interest at pixel-level using only global image annotation., Typical convolutional attentions maps are prune to high false positive regions., To alleviate this issue, we propose a new deep learning method for WSL, composed of a localizer and a classifier, where the localizer is constrained to determine relevant and irrelevant regions using conditional entropy (CE) with the aim to reduce false positive regions., Experimental results on a public medical dataset and two natural datasets, using Dice index, show that, compared to state of the art WSL methods, our proposal can provide significant improvements in terms of image-level classification and pixel-level localization (low false positive) with robustness to overfitting., A public reproducible PyTorch implementation is provided.",16,5.814814814814815,10.125
219,"['Model-based reinforcement learning has been empirically demonstrated as a successful strategy to improve sample efficiency.', 'Particularly, Dyna architecture, as an elegant model-based architecture integrating learning and planning, provides huge flexibility of using a model.', 'One of the most important components in Dyna is called search-control, which refers to the process of generating state or state-action pairs from which we query the model to acquire simulated experiences.', 'Search-control is critical to improve learning efficiency.', 'In this work, we propose a simple and novel search-control strategy by searching high frequency region on value function.', 'Our main intuition is built on Shannon sampling theorem from signal processing, which indicates that a high frequency signal requires more samples to reconstruct.', 'We empirically show that a high frequency function is more difficult to approximate.', 'This suggests a search-control strategy: we should use states in high frequency region of the value function to query the model to acquire more samples.', 'We develop a simple strategy to locally measure the frequency of a function by gradient norm, and provide theoretical justification for this approach.', 'We then apply our strategy to search-control in Dyna, and conduct experiments to show its property and effectiveness on benchmark domains.']","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]","[0.0, 0.06896550953388214, 0.1621621549129486, 0.0, 0.27586206793785095, 0.1818181723356247, 0.17391303181648254, 0.3636363446712494, 0.1249999925494194, 0.13793103396892548]",B1gskyStwr,"['Acquire states from high frequency region for search-control in Dyna.', 'The authors propose to do sampling in the high-frequency domain to increase the sample efficiency', 'This paper proposes a new way to select states from which do do transitions in dyna algorithm.']","['modelbased reinforcement learning empirically demonstrated successful strategy improve sample efficiency ', 'particularly  dyna architecture  elegant modelbased architecture integrating learning planning  provides huge flexibility using model ', 'one important component dyna called searchcontrol  refers process generating state stateaction pair query model acquire simulated experience ', 'searchcontrol critical improve learning efficiency ', 'work  propose simple novel searchcontrol strategy searching high frequency region value function ', 'main intuition built shannon sampling theorem signal processing  indicates high frequency signal requires sample reconstruct ', 'empirically show high frequency function difficult approximate ', 'suggests searchcontrol strategy  use state high frequency region value function query model acquire sample ', 'develop simple strategy locally measure frequency function gradient norm  provide theoretical justification approach ', 'apply strategy searchcontrol dyna  conduct experiment show property effectiveness benchmark domain ']","Model-based reinforcement learning has been empirically demonstrated as a successful strategy to improve sample efficiency., Particularly, Dyna architecture, as an elegant model-based architecture integrating learning and planning, provides huge flexibility of using a model., One of the most important components in Dyna is called search-control, which refers to the process of generating state or state-action pairs from which we query the model to acquire simulated experiences., Search-control is critical to improve learning efficiency., In this work, we propose a simple and novel search-control strategy by searching high frequency region on value function., Our main intuition is built on Shannon sampling theorem from signal processing, which indicates that a high frequency signal requires more samples to reconstruct., We empirically show that a high frequency function is more difficult to approximate., This suggests a search-control strategy: we should use states in high frequency region of the value function to query the model to acquire more samples., We develop a simple strategy to locally measure the frequency of a function by gradient norm, and provide theoretical justification for this approach., We then apply our strategy to search-control in Dyna, and conduct experiments to show its property and effectiveness on benchmark domains.",18,5.787878787878788,11.0
220,"['We propose a new architecture for distributed image compression from a group of distributed data sources.', 'The work is motivated by practical needs of data-driven codec design, low power consumption, robustness, and data privacy.', 'The proposed architecture, which we refer to as Distributed Recurrent Autoencoder for Scalable Image Compression (DRASIC), is able to train distributed encoders and one joint decoder on correlated data sources.', 'Its compression capability is much better than the method of training codecs separately.', 'Meanwhile, for 10 distributed sources, our distributed system remarkably performs within 2 dB peak signal-to-noise ratio (PSNR) of that of a single codec trained with all data sources.', 'We experiment distributed sources with different correlations and show how our methodology well matches the Slepian-Wolf Theorem in Distributed Source Coding (DSC).', 'Our method is also shown to be robust to the lack of presence of encoded data from a number of distributed sources.', 'Moreover, it is scalable in the sense that codes can be decoded simultaneously at more than one compression quality level.', 'To the best of our knowledge, this is the first data-driven DSC framework for general distributed code design with deep learning.']","[0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.19354838132858276, 0.05714285373687744, 0.3478260934352875, 0.0, 0.09302324801683426, 0.20512819290161133, 0.0555555522441864, 0.0, 0.1621621549129486]",SyxBxCNFwr,"['We introduce a data-driven Distributed Source Coding framework based on Distributed Recurrent Autoencoder for Scalable Image Compression (DRASIC).', 'The paper proposed a distributed recurrent auto-encoder for image compression that uses a ConvLSTM to learn binary codes that are constructed progressively from residuals of previously encoded information', 'The authors propose a method to train image compression models on multiple sources, with a separate encoder on each source, and a shared decoder. ']","['propose new architecture distributed image compression group distributed data source ', 'work motivated practical need datadriven codec design  low power consumption  robustness  data privacy ', 'proposed architecture  refer distributed recurrent autoencoder scalable image compression  drasic   able train distributed encoders one joint decoder correlated data source ', 'compression capability much better method training codecs separately ', 'meanwhile  10 distributed source  distributed system remarkably performs within 2 db peak signaltonoise ratio  psnr  single codec trained data source ', 'experiment distributed source different correlation show methodology well match slepianwolf theorem distributed source coding  dsc  ', 'method also shown robust lack presence encoded data number distributed source ', 'moreover  scalable sense code decoded simultaneously one compression quality level ', 'best knowledge  first datadriven dsc framework general distributed code design deep learning ']","We propose a new architecture for distributed image compression from a group of distributed data sources., The work is motivated by practical needs of data-driven codec design, low power consumption, robustness, and data privacy., The proposed architecture, which we refer to as Distributed Recurrent Autoencoder for Scalable Image Compression (DRASIC), is able to train distributed encoders and one joint decoder on correlated data sources., Its compression capability is much better than the method of training codecs separately., Meanwhile, for 10 distributed sources, our distributed system remarkably performs within 2 dB peak signal-to-noise ratio (PSNR) of that of a single codec trained with all data sources., We experiment distributed sources with different correlations and show how our methodology well matches the Slepian-Wolf Theorem in Distributed Source Coding (DSC)., Our method is also shown to be robust to the lack of presence of encoded data from a number of distributed sources., Moreover, it is scalable in the sense that codes can be decoded simultaneously at more than one compression quality level., To the best of our knowledge, this is the first data-driven DSC framework for general distributed code design with deep learning.",18,5.521052631578947,10.555555555555555
221,"['Long short-term memory networks (LSTMs) were introduced to combat vanishing gradients in simple recurrent neural networks (S-RNNs) by augmenting them with additive recurrent connections controlled by gates.', 'We present an alternate view to explain the success of LSTMs: the gates themselves are powerful recurrent models that provide more representational power than previously appreciated.', ""We do this by showing that the LSTM's gates can be decoupled from the embedded S-RNN, producing a restricted class of RNNs where the main recurrence computes an element-wise weighted sum of context-independent functions of the inputs."", 'Experiments on a range of challenging NLP problems demonstrate that the simplified gate-based models work substantially better than S-RNNs, and often just as well as the original LSTMs, strongly suggesting that the gates are doing much more in practice than just alleviating vanishing gradients.']","[0, 0, 1, 0]","[0.12765957415103912, 0.0416666604578495, 0.1818181723356247, 0.09836065024137497]",HJOQ7MgAW,"['Gates do all the heavy lifting in LSTMs by computing element-wise weighted sums, and removing the internal simple RNN does not degrade model performance.', 'This paper proposes a simplified LSTM variants by removing the non-linearity of content item and output gate', 'This paper presents an analysis of LSTMS, showing that they have a form where the memory cell contents at each step is a weighted combination of the content update values computed at each time step and offers a simplification of LSTMs that compute the value by which the memory cell at each time step in terms of a deterministic function of the input rather than a function of the input and the current context.', 'The paper proposes a new insight to LSTM in which the core is an element-wise weighted sum and argues that LSTM is redundant by keeping only input and forget gates to compute the weights']","['long shortterm memory network  lstms  introduced combat vanishing gradient simple recurrent neural network  srnns  augmenting additive recurrent connection controlled gate ', 'present alternate view explain success lstms  gate powerful recurrent model provide representational power previously appreciated ', 'showing lstm gate decoupled embedded srnn  producing restricted class rnns main recurrence computes elementwise weighted sum contextindependent function input ', 'experiment range challenging nlp problem demonstrate simplified gatebased model work substantially better srnns  often well original lstms  strongly suggesting gate much practice alleviating vanishing gradient ']","Long short-term memory networks (LSTMs) were introduced to combat vanishing gradients in simple recurrent neural networks (S-RNNs) by augmenting them with additive recurrent connections controlled by gates., We present an alternate view to explain the success of LSTMs: the gates themselves are powerful recurrent models that provide more representational power than previously appreciated., We do this by showing that the LSTM's gates can be decoupled from the embedded S-RNN, producing a restricted class of RNNs where the main recurrence computes an element-wise weighted sum of context-independent functions of the inputs., Experiments on a range of challenging NLP problems demonstrate that the simplified gate-based models work substantially better than S-RNNs, and often just as well as the original LSTMs, strongly suggesting that the gates are doing much more in practice than just alleviating vanishing gradients.",7,5.850746268656716,19.142857142857142
222,"['Machine learning algorithms designed to characterize, monitor, and intervene on human health (ML4H) are expected to perform safely and reliably when operating at scale, potentially outside strict human supervision.', 'This requirement warrants a stricter attention to issues of reproducibility than other fields of machine learning.', 'In this work, we conduct a systematic evaluation of over 100 recently published ML4H research papers along several dimensions related to reproducibility we identified.', 'We find that the field of ML4H compares poorly to more established machine learning fields, particularly concerning data accessibility and code accessibility.  ', 'Finally, drawing from success in other fields of science, we propose recommendations to data providers, academic publishers, and the ML4H research community in order to promote reproducible research moving forward.']","[0, 1, 0, 0, 0]","[0.1111111044883728, 0.3255814015865326, 0.15686273574829102, 0.19999998807907104, 0.1818181723356247]",HylgS2IpLN,"['By analyzing more than 300 papers in recent machine learning conferences, we found that Machine Learning for Health (ML4H) applications lag behind other machine learning fields in terms of reproducibility metrics.', 'This paper conducts a quantitative and qualitative review of the state of the reproducibility for ML healthcare applications and proposes reccomendations to make research more reproducible.']","['machine learning algorithm designed characterize  monitor  intervene human health  ml4h  expected perform safely reliably operating scale  potentially outside strict human supervision ', 'requirement warrant stricter attention issue reproducibility field machine learning ', 'work  conduct systematic evaluation 100 recently published ml4h research paper along several dimension related reproducibility identified ', 'find field ml4h compare poorly established machine learning field  particularly concerning data accessibility code accessibility ', 'finally  drawing success field science  propose recommendation data provider  academic publisher  ml4h research community order promote reproducible research moving forward ']","Machine learning algorithms designed to characterize, monitor, and intervene on human health (ML4H) are expected to perform safely and reliably when operating at scale, potentially outside strict human supervision., This requirement warrants a stricter attention to issues of reproducibility than other fields of machine learning., In this work, we conduct a systematic evaluation of over 100 recently published ML4H research papers along several dimensions related to reproducibility we identified., We find that the field of ML4H compares poorly to more established machine learning fields, particularly concerning data accessibility and code accessibility.  , Finally, drawing from success in other fields of science, we propose recommendations to data providers, academic publishers, and the ML4H research community in order to promote reproducible research moving forward.",14,6.132231404958677,8.642857142857142
223,"['We propose a solution for evaluation of mathematical expression.', 'However, instead of designing a single end-to-end model we propose a Lego bricks style architecture.', 'In this architecture instead of training a complex end-to-end neural network, many small networks can be trained independently each accomplishing one specific operation and acting a single lego brick.', 'More difficult or complex task can then be solved using a combination of these smaller network.', 'In this work we first identify 8 fundamental operations that are commonly used to solve arithmetic operations (such as 1 digit multiplication, addition, subtraction, sign calculator etc).', 'These fundamental operations are then learned using simple feed forward neural networks.', 'We then shows that different operations can be designed simply by reusing these smaller networks.', 'As an example we reuse these smaller networks to develop larger and a more complex network to solve n-digit multiplication, n-digit division, and cross product.', 'This bottom-up strategy not only introduces reusability, we also show that it allows to generalize for computations involving n-digits and we show results for up to 7 digit numbers.', 'Unlike existing methods, our solution also generalizes for both positive as well as negative numbers.']","[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.2222222238779068, 0.0624999962747097, 0.30434781312942505, 0.23529411852359772, 0.13636362552642822, 0.2666666507720947, 0.3030303120613098, 0.25, 0.09302324801683426, 0.0624999962747097]",HyerxgHYvH,"['We train many small networks each for a specific operation, these are then combined to perform complex operations', 'This paper proposes to use neural networks to evaluate the mathematical expressions by designing 8 small building blocks for 8 fundamental operations, e.g., addition, subtraction, etc and then designing multi-digit multiplication and division using these small blocks.', 'The paper proposes a method to design a NN based mathematical expression evaluation engine.']","['propose solution evaluation mathematical expression ', 'however  instead designing single endtoend model propose lego brick style architecture ', 'architecture instead training complex endtoend neural network  many small network trained independently accomplishing one specific operation acting single lego brick ', 'difficult complex task solved using combination smaller network ', 'work first identify 8 fundamental operation commonly used solve arithmetic operation  1 digit multiplication  addition  subtraction  sign calculator etc  ', 'fundamental operation learned using simple feed forward neural network ', 'show different operation designed simply reusing smaller network ', 'example reuse smaller network develop larger complex network solve ndigit multiplication  ndigit division  cross product ', 'bottomup strategy introduces reusability  also show allows generalize computation involving ndigits show result 7 digit number ', 'unlike existing method  solution also generalizes positive well negative number ']","We propose a solution for evaluation of mathematical expression., However, instead of designing a single end-to-end model we propose a Lego bricks style architecture., In this architecture instead of training a complex end-to-end neural network, many small networks can be trained independently each accomplishing one specific operation and acting a single lego brick., More difficult or complex task can then be solved using a combination of these smaller network., In this work we first identify 8 fundamental operations that are commonly used to solve arithmetic operations (such as 1 digit multiplication, addition, subtraction, sign calculator etc)., These fundamental operations are then learned using simple feed forward neural networks., We then shows that different operations can be designed simply by reusing these smaller networks., As an example we reuse these smaller networks to develop larger and a more complex network to solve n-digit multiplication, n-digit division, and cross product., This bottom-up strategy not only introduces reusability, we also show that it allows to generalize for computations involving n-digits and we show results for up to 7 digit numbers., Unlike existing methods, our solution also generalizes for both positive as well as negative numbers.",19,5.635416666666667,10.105263157894736
224,"['In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real.', 'The generator is trained to increase the probability that fake data is real.', 'We argue that it should also simultaneously decrease the probability that real data is real because', '1) this would account for a priori knowledge that half of the data in the mini-batch is fake,', '2) this would be observed with divergence minimization, and', '3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. \n\n', 'We show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data.', 'We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average.', 'We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs).', 'We show that IPM-based GANs are a subset of RGANs which use the identity function. \n\n', 'Empirically, we observe that', '1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts,', '2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and', '3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization.\n\n', 'The code is freely available on https://github.com/AlexiaJM/RelativisticGAN.']","[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.060606054961681366, 0.06666666269302368, 0.0624999962747097, 0.17142856121063232, 0.07407406717538834, 0.060606054961681366, 0.17777776718139648, 0.09756097197532654, 0.15789473056793213, 0.29411762952804565, 0.0, 0.17142856121063232, 0.19999998807907104, 0.2142857164144516, 0.0]",S1erHoR5t7,"['Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.', 'The paper proposes a relativistic discriminator, whic helps in some settings, although a bit sensitive to hyperparameters, architectures, and datasets.', 'In this work, the authors considers a variation of GAN by simultaneously decreasing the probability that real data is real for the generator.']","['standard generative adversarial network  sgan   discriminator estimate probability input data real ', 'generator trained increase probability fake data real ', 'argue also simultaneously decrease probability real data real', '1  would account priori knowledge half data minibatch fake ', '2  would observed divergence minimization ', '3  optimal setting  sgan would equivalent integral probability metric  ipm  gans ', 'show property induced using relativistic discriminator estimate probability given real data realistic randomly sampled fake data ', 'also present variant discriminator estimate probability given real data realistic fake data  average ', 'generalize approach nonstandard gan loss function refer respectively relativistic gans  rgans  relativistic average gans  ragans  ', 'show ipmbased gans subset rgans use identity function ', 'empirically  observe', '1  rgans ragans significantly stable generate higher quality data sample nonrelativistic counterpart ', '2  standard ragan gradient penalty generate data better quality wgangp requiring single discriminator update per generator update  reducing time taken reaching stateoftheart 400   ', '3  ragans able generate plausible high resolution image  256x256  small sample  n2011   gan lsgan  image significantly better quality one generated wgangp sgan spectral normalization ', 'code freely available http  githubcomalexiajmrelativisticgan ']","In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real., The generator is trained to increase the probability that fake data is real., We argue that it should also simultaneously decrease the probability that real data is real because, 1) this would account for a priori knowledge that half of the data in the mini-batch is fake,, 2) this would be observed with divergence minimization, and, 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. 

, We show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data., We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average., We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs)., We show that IPM-based GANs are a subset of RGANs which use the identity function. 

, Empirically, we observe that, 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts,, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and, 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization.

, The code is freely available on https://github.com/AlexiaJM/RelativisticGAN.",22,5.519298245614035,12.954545454545455
225,"['Some of the most successful applications of deep reinforcement learning to challenging domains in discrete and continuous control have used policy gradient methods in the on-policy setting.', 'However, policy gradients can suffer from large variance that may limit performance, and in practice require carefully tuned entropy regularization to prevent policy collapse.', 'As an alternative to policy gradient algorithms, we introduce V-MPO, an on-policy adaptation of Maximum a Posteriori Policy Optimization (MPO) that performs policy iteration based on a learned state-value function.', 'We show that V-MPO surpasses previously reported scores for both the Atari-57 and DMLab-30 benchmark suites in the multi-task setting, and does so reliably without importance weighting, entropy regularization, or population-based tuning of hyperparameters.', 'On individual DMLab and Atari levels, the proposed algorithm can achieve scores that are substantially higher than has previously been reported.', 'V-MPO is also applicable to problems with high-dimensional, continuous action spaces, which we demonstrate in the context of learning to control simulated humanoids with 22 degrees of freedom from full state observations and 56 degrees of freedom from pixel observations, as well as example OpenAI Gym tasks where V-MPO achieves substantially higher asymptotic scores than previously reported.']","[1, 0, 0, 0, 0, 0]","[0.2790697515010834, 0.1428571343421936, 0.17391303181648254, 0.15686273574829102, 0.09999999403953552, 0.20895521342754364]",SylOlp4FvH,"['A state-value function-based version of MPO that achieves good results in a wide range of tasks in discrete and continuous control.', 'This paper presents an algorithm for on-policy reinforcement learning that can handle both continuous/discrete control, single/multi-task learning and use both low dimensional states and pixels.', 'The paper proposes an online variant of MPO, V-MPO, which learns the V-function and updates the non-parametric distribution towards the advantages.']","['successful application deep reinforcement learning challenging domain discrete continuous control used policy gradient method onpolicy setting ', 'however  policy gradient suffer large variance may limit performance  practice require carefully tuned entropy regularization prevent policy collapse ', 'alternative policy gradient algorithm  introduce vmpo  onpolicy adaptation maximum posteriori policy optimization  mpo  performs policy iteration based learned statevalue function ', 'show vmpo surpasses previously reported score atari57 dmlab30 benchmark suite multitask setting  reliably without importance weighting  entropy regularization  populationbased tuning hyperparameters ', 'individual dmlab atari level  proposed algorithm achieve score substantially higher previously reported ', 'vmpo also applicable problem highdimensional  continuous action space  demonstrate context learning control simulated humanoid 22 degree freedom full state observation 56 degree freedom pixel observation  well example openai gym task vmpo achieves substantially higher asymptotic score previously reported ']","Some of the most successful applications of deep reinforcement learning to challenging domains in discrete and continuous control have used policy gradient methods in the on-policy setting., However, policy gradients can suffer from large variance that may limit performance, and in practice require carefully tuned entropy regularization to prevent policy collapse., As an alternative to policy gradient algorithms, we introduce V-MPO, an on-policy adaptation of Maximum a Posteriori Policy Optimization (MPO) that performs policy iteration based on a learned state-value function., We show that V-MPO surpasses previously reported scores for both the Atari-57 and DMLab-30 benchmark suites in the multi-task setting, and does so reliably without importance weighting, entropy regularization, or population-based tuning of hyperparameters., On individual DMLab and Atari levels, the proposed algorithm can achieve scores that are substantially higher than has previously been reported., V-MPO is also applicable to problems with high-dimensional, continuous action spaces, which we demonstrate in the context of learning to control simulated humanoids with 22 degrees of freedom from full state observations and 56 degrees of freedom from pixel observations, as well as example OpenAI Gym tasks where V-MPO achieves substantially higher asymptotic scores than previously reported.",17,6.077720207253886,11.352941176470589
226,"['Turing complete computation and reasoning are often regarded as necessary pre- cursors to general intelligence.', 'There has been a significant body of work studying neural networks that mimic general computation, but these networks fail to generalize to data distributions that are outside of their training set.', 'We study this problem through the lens of fundamental computer science problems: sorting and graph processing.', 'We modify the masking mechanism of a transformer in order to allow them to implement rudimentary functions with strong generalization.', 'We call this model the Neural Execution Engine, and show that it learns, through supervision, to numerically compute the basic subroutines comprising these algorithms with near perfect accuracy.', 'Moreover, it retains this level of accuracy while generalizing to unseen data and long sequences outside of the training distribution.']","[0, 0, 0, 1, 0, 0]","[0.10526315122842789, 0.19999998807907104, 0.20512819290161133, 0.3333333432674408, 0.19999998807907104, 0.1904761791229248]",rJg7BA4YDr,"['We propose neural execution engines (NEEs), which leverage a learned mask and supervised execution traces to mimic the functionality of subroutines and demonstrate strong generalization.', 'This paper investigates a problem of building a program execution engine with neural networks and proposes a transformer-based model to learn basic subroutines and applies them in several standard algorithms.', 'This paper deals with the problem of designing neural network architectures that can learn and implement general programs.']","['turing complete computation reasoning often regarded necessary pre cursor general intelligence ', 'significant body work studying neural network mimic general computation  network fail generalize data distribution outside training set ', 'study problem lens fundamental computer science problem  sorting graph processing ', 'modify masking mechanism transformer order allow implement rudimentary function strong generalization ', 'call model neural execution engine  show learns  supervision  numerically compute basic subroutine comprising algorithm near perfect accuracy ', 'moreover  retains level accuracy generalizing unseen data long sequence outside training distribution ']","Turing complete computation and reasoning are often regarded as necessary pre- cursors to general intelligence., There has been a significant body of work studying neural networks that mimic general computation, but these networks fail to generalize to data distributions that are outside of their training set., We study this problem through the lens of fundamental computer science problems: sorting and graph processing., We modify the masking mechanism of a transformer in order to allow them to implement rudimentary functions with strong generalization., We call this model the Neural Execution Engine, and show that it learns, through supervision, to numerically compute the basic subroutines comprising these algorithms with near perfect accuracy., Moreover, it retains this level of accuracy while generalizing to unseen data and long sequences outside of the training distribution.",11,5.7846153846153845,11.818181818181818
227,"['Meta-learning is a promising strategy for learning to efficiently learn within new tasks, using data gathered from a distribution of tasks.', 'However, the meta-learning literature thus far has focused on the task segmented setting, where at train-time, offline data is assumed to be split according to the underlying task, and at test-time, the algorithms are optimized to learn in a single task.', 'In this work, we enable the application of generic meta-learning algorithms to settings where this task segmentation is unavailable, such as continual online learning with a time-varying task.', 'We present meta-learning via online changepoint analysis (MOCA), an approach which augments a meta-learning algorithm with a differentiable Bayesian changepoint detection scheme.', 'The framework allows both training and testing directly on time series data without segmenting it into discrete tasks.', 'We demonstrate the utility of this approach on a nonlinear meta-regression benchmark as well as two meta-image-classification benchmarks.']","[0, 0, 0, 0, 1, 0]","[0.13333332538604736, 0.09090908616781235, 0.0555555522441864, 0.27586206793785095, 0.2857142686843872, 0.0]",r1l1myStwr,"['Bayesian changepoint detection enables meta-learning directly from time series data.', 'The paper considers the meta-learning in the task un-segmented setting and apply Bayesian online change point detection with meta-learning.', 'This paper pushes meta-learning towards task-unsegmented settings, where the MOCA framework adopts a Bayesian changepoint estimation scheme for task change detection.']","['metalearning promising strategy learning efficiently learn within new task  using data gathered distribution task ', 'however  metalearning literature thus far focused task segmented setting  traintime  offline data assumed split according underlying task  testtime  algorithm optimized learn single task ', 'work  enable application generic metalearning algorithm setting task segmentation unavailable  continual online learning timevarying task ', 'present metalearning via online changepoint analysis  moca   approach augments metalearning algorithm differentiable bayesian changepoint detection scheme ', 'framework allows training testing directly time series data without segmenting discrete task ', 'demonstrate utility approach nonlinear metaregression benchmark well two metaimageclassification benchmark ']","Meta-learning is a promising strategy for learning to efficiently learn within new tasks, using data gathered from a distribution of tasks., However, the meta-learning literature thus far has focused on the task segmented setting, where at train-time, offline data is assumed to be split according to the underlying task, and at test-time, the algorithms are optimized to learn in a single task., In this work, we enable the application of generic meta-learning algorithms to settings where this task segmentation is unavailable, such as continual online learning with a time-varying task., We present meta-learning via online changepoint analysis (MOCA), an approach which augments a meta-learning algorithm with a differentiable Bayesian changepoint detection scheme., The framework allows both training and testing directly on time series data without segmenting it into discrete tasks., We demonstrate the utility of this approach on a nonlinear meta-regression benchmark as well as two meta-image-classification benchmarks.",15,5.858108108108108,9.866666666666667
228,"['People with high-frequency hearing loss rely on hearing aids that employ frequency lowering algorithms.', 'These algorithms shift some of the sounds from the high frequency band to the lower frequency band where the sounds become more perceptible for the people with the condition.', 'Fricative phonemes have an important part of their content concentrated in high frequency bands.', 'It is important that the frequency lowering algorithm is activated exactly for the duration of a fricative phoneme, and kept off at all other times.', 'Therefore, timely (with zero delay) and accurate fricative phoneme detection is a key problem for high quality hearing aids.', 'In this paper we present a deep learning based fricative phoneme detection algorithm that has zero detection delay and achieves state-of-the-art fricative phoneme detection accuracy on the TIMIT Speech Corpus.', 'All reported results are reproducible and come with easy to use code that could serve as a baseline for future research.\n']","[0, 0, 0, 0, 0, 1, 0]","[0.0, 0.0624999962747097, 0.0, 0.11764705181121826, 0.3333333432674408, 0.4324324429035187, 0.060606054961681366]",BJxlmeBKwS,"['A deep learning based approach for zero delay fricative phoneme detection', 'This paper apples supervised deep learning methods to detect exact duration of a fricative phoneme in order to improve practical frequency lowering algorithm.']","['people highfrequency hearing loss rely hearing aid employ frequency lowering algorithm ', 'algorithm shift sound high frequency band lower frequency band sound become perceptible people condition ', 'fricative phoneme important part content concentrated high frequency band ', 'important frequency lowering algorithm activated exactly duration fricative phoneme  kept time ', 'therefore  timely  zero delay  accurate fricative phoneme detection key problem high quality hearing aid ', 'paper present deep learning based fricative phoneme detection algorithm zero detection delay achieves stateoftheart fricative phoneme detection accuracy timit speech corpus ', 'reported result reproducible come easy use code could serve baseline future research ']","People with high-frequency hearing loss rely on hearing aids that employ frequency lowering algorithms., These algorithms shift some of the sounds from the high frequency band to the lower frequency band where the sounds become more perceptible for the people with the condition., Fricative phonemes have an important part of their content concentrated in high frequency bands., It is important that the frequency lowering algorithm is activated exactly for the duration of a fricative phoneme, and kept off at all other times., Therefore, timely (with zero delay) and accurate fricative phoneme detection is a key problem for high quality hearing aids., In this paper we present a deep learning based fricative phoneme detection algorithm that has zero detection delay and achieves state-of-the-art fricative phoneme detection accuracy on the TIMIT Speech Corpus., All reported results are reproducible and come with easy to use code that could serve as a baseline for future research.
",9,5.440789473684211,16.88888888888889
229,"['Sequence-to-sequence models with soft attention have been successfully applied to a wide variety of problems, but their decoding process incurs a quadratic time and space cost and is inapplicable to real-time sequence transduction.', 'To address these issues, we propose Monotonic Chunkwise Attention (MoChA), which adaptively splits the input sequence into small chunks over which soft attention is computed.', 'We show that models utilizing MoChA can be trained efficiently with standard backpropagation while allowing online and linear-time decoding at test time.', 'When applied to online speech recognition, we obtain state-of-the-art results and match the performance of a model using an offline soft attention mechanism.', 'In document summarization experiments where we do not expect monotonic alignments, we show significantly improved performance compared to a baseline monotonic attention-based model.']","[0, 0, 0, 1, 0]","[0.21739129722118378, 0.3499999940395355, 0.21052631735801697, 0.3589743673801422, 0.0]",Hko85plCW,"['An online and linear-time attention mechanism that performs soft attention over adaptively-located chunks of the input sequence.', 'This paper proposes a small modification to the monotonic attention in [1] by adding a soft attention to the segment predicted by the monotonic attention.', 'The paper proposes an extension to a previous monotonic attention model (Raffel et al 2017) to attend to a fixed-sized window up to the alignment position.']","['sequencetosequence model soft attention successfully applied wide variety problem  decoding process incurs quadratic time space cost inapplicable realtime sequence transduction ', 'address issue  propose monotonic chunkwise attention  mocha   adaptively split input sequence small chunk soft attention computed ', 'show model utilizing mocha trained efficiently standard backpropagation allowing online lineartime decoding test time ', 'applied online speech recognition  obtain stateoftheart result match performance model using offline soft attention mechanism ', 'document summarization experiment expect monotonic alignment  show significantly improved performance compared baseline monotonic attentionbased model ']","Sequence-to-sequence models with soft attention have been successfully applied to a wide variety of problems, but their decoding process incurs a quadratic time and space cost and is inapplicable to real-time sequence transduction., To address these issues, we propose Monotonic Chunkwise Attention (MoChA), which adaptively splits the input sequence into small chunks over which soft attention is computed., We show that models utilizing MoChA can be trained efficiently with standard backpropagation while allowing online and linear-time decoding at test time., When applied to online speech recognition, we obtain state-of-the-art results and match the performance of a model using an offline soft attention mechanism., In document summarization experiments where we do not expect monotonic alignments, we show significantly improved performance compared to a baseline monotonic attention-based model.",10,6.111111111111111,12.6
230,"['We present a framework for automatically ordering image patches that enables in-depth analysis of dataset relationship to learnability of a classification task using convolutional neural network.', 'An image patch is a group of pixels residing in a continuous area contained in the sample.', 'Our preliminary experimental results show that an informed smart shuffling of patches at a sample level can expedite training by exposing important features at early stages of training.', 'In addition, we conduct systematic experiments and provide evidence that CNNs generalization capabilities do not correlate with human recognizable features present in training samples.', 'We utilized the framework not only to show that spatial locality of features within samples do not correlate with generalization, but also to expedite convergence while achieving similar generalization performance.', 'Using multiple network architectures and datasets, we show that ordering image regions using mutual information measure between adjacent patches, enables CNNs to converge in a third of the total steps required to train the same network without patch ordering.']","[1, 0, 0, 0, 0, 0]","[0.23255813121795654, 0.11764705181121826, 0.13636362552642822, 0.1860465109348297, 0.1702127605676651, 0.18518517911434174]",SJeI5i0cYQ,['Develop new techniques that rely on patch reordering to enable detailed analysis of data-set relationship to training and generalization performances.'],"['present framework automatically ordering image patch enables indepth analysis dataset relationship learnability classification task using convolutional neural network ', 'image patch group pixel residing continuous area contained sample ', 'preliminary experimental result show informed smart shuffling patch sample level expedite training exposing important feature early stage training ', 'addition  conduct systematic experiment provide evidence cnn  generalization capability correlate human recognizable feature present training sample ', 'utilized framework show spatial locality feature within sample correlate generalization  also expedite convergence achieving similar generalization performance ', 'using multiple network architecture datasets  show ordering image region using mutual information measure adjacent patch  enables cnns converge third total step required train network without patch ordering ']","We present a framework for automatically ordering image patches that enables in-depth analysis of dataset relationship to learnability of a classification task using convolutional neural network., An image patch is a group of pixels residing in a continuous area contained in the sample., Our preliminary experimental results show that an informed smart shuffling of patches at a sample level can expedite training by exposing important features at early stages of training., In addition, we conduct systematic experiments and provide evidence that CNNs generalization capabilities do not correlate with human recognizable features present in training samples., We utilized the framework not only to show that spatial locality of features within samples do not correlate with generalization, but also to expedite convergence while achieving similar generalization performance., Using multiple network architectures and datasets, we show that ordering image regions using mutual information measure between adjacent patches, enables CNNs to converge in a third of the total steps required to train the same network without patch ordering.",10,5.890243902439025,16.4
231,"['Producing agents that can generalize to a wide range of environments is a significant challenge in reinforcement learning.', 'One method for overcoming this issue is domain randomization, whereby at the start of each training episode some parameters of the environment are randomized so that the agent is exposed to many possible variations.', 'However, domain randomization is highly inefficient and may lead to policies with high variance across domains.', ""In this work, we formalize the domain randomization problem, and show that minimizing the policy's Lipschitz constant with respect to the randomization parameters leads to low variance in the learned policies."", 'We propose a method where the agent only needs to be trained on one variation of the environment, and its learned state representations are regularized during training to minimize this constant.', 'We conduct experiments that demonstrate that our technique leads to more efficient and robust learning than standard domain randomization, while achieving equal generalization scores.']","[1, 0, 0, 0, 0, 0]","[0.6285714507102966, 0.1249999925494194, 0.05882352590560913, 0.09090908616781235, 0.1702127605676651, 0.24390242993831635]",H1xSOTVtvH,"['We produce reinforcement learning agents that generalize well to a wide range of environments using a novel regularization technique.', 'The paper introduces the high variance policies challenge in domain randomization for reinforcement learning and mainly focuses on the problem of visual randomization, where the different randomized domains differ only in state space and the underlying rewards and dynamics are the same.', 'To improve the generalization ability of deep RL agents across the tasks with different visual patterns, this paper proposed a simple regularization technique for domain randomization.']","['producing agent generalize wide range environment significant challenge reinforcement learning ', 'one method overcoming issue domain randomization  whereby start training episode parameter environment randomized agent exposed many possible variation ', 'however  domain randomization highly inefficient may lead policy high variance across domain ', 'work  formalize domain randomization problem  show minimizing policy lipschitz constant respect randomization parameter lead low variance learned policy ', 'propose method agent need trained one variation environment  learned state representation regularized training minimize constant ', 'conduct experiment demonstrate technique lead efficient robust learning standard domain randomization  achieving equal generalization score ']","Producing agents that can generalize to a wide range of environments is a significant challenge in reinforcement learning., One method for overcoming this issue is domain randomization, whereby at the start of each training episode some parameters of the environment are randomized so that the agent is exposed to many possible variations., However, domain randomization is highly inefficient and may lead to policies with high variance across domains., In this work, we formalize the domain randomization problem, and show that minimizing the policy's Lipschitz constant with respect to the randomization parameters leads to low variance in the learned policies., We propose a method where the agent only needs to be trained on one variation of the environment, and its learned state representations are regularized during training to minimize this constant., We conduct experiments that demonstrate that our technique leads to more efficient and robust learning than standard domain randomization, while achieving equal generalization scores.",12,5.714285714285714,12.833333333333334
232,"['Claims from the fields of network neuroscience and connectomics suggest that topological models of the brain involving complex networks are of particular use and interest.', 'The field of deep neural networks has mostly left inspiration from these claims out.', 'In this paper, we propose three architectures and use each of them to explore the intersection of network neuroscience and deep learning in an attempt to bridge the gap between the two fields.', 'Using the teachings from network neuroscience and connectomics, we show improvements over the ResNet architecture, we show a possible connection between early training and the spectral properties of the network, and we show the trainability of a DNN based on the neuronal network of C.Elegans.']","[0, 0, 1, 0]","[0.25, 0.1599999964237213, 0.41025641560554504, 0.190476194024086]",HygPD4H22N,['We explore the intersection of network neurosciences and deep learning. '],"['claim field network neuroscience connectomics suggest topological model brain involving complex network particular use interest ', 'field deep neural network mostly left inspiration claim ', 'paper  propose three architecture use explore intersection network neuroscience deep learning attempt bridge gap two field ', 'using teaching network neuroscience connectomics  show improvement resnet architecture  show possible connection early training spectral property network  show trainability dnn based neuronal network celegans ']","Claims from the fields of network neuroscience and connectomics suggest that topological models of the brain involving complex networks are of particular use and interest., The field of deep neural networks has mostly left inspiration from these claims out., In this paper, we propose three architectures and use each of them to explore the intersection of network neuroscience and deep learning in an attempt to bridge the gap between the two fields., Using the teachings from network neuroscience and connectomics, we show improvements over the ResNet architecture, we show a possible connection between early training and the spectral properties of the network, and we show the trainability of a DNN based on the neuronal network of C.Elegans.",8,5.3247863247863245,14.625
233,"['Creating a knowledge base that is accurate, up-to-date and complete remains a significant challenge despite substantial efforts in automated knowledge base construction.  ', 'In this paper, we present Alexandria -- a system for unsupervised, high-precision knowledge base construction.', 'Alexandria uses a probabilistic program to define a process of converting knowledge base facts into unstructured text.  ', 'Using probabilistic inference, we can invert this program and so retrieve facts, schemas and entities from web text.', 'The use of a probabilistic program allows uncertainty in the text to be propagated through to the retrieved facts, which increases accuracy and helps merge facts from multiple sources.', 'Because Alexandria does not require labelled training data, knowledge bases can be constructed with the minimum of manual input.', 'We demonstrate this by constructing a high precision (typically 97\\%+) knowledge base for people from a single seed fact.']","[0, 0, 1, 0, 0, 0, 0]","[0.1860465109348297, 0.42105263471603394, 0.699999988079071, 0.14999999105930328, 0.2800000011920929, 0.0952380895614624, 0.19512194395065308]",rJgHCgc6pX,"['This paper presents a system for unsupervised, high-precision knowledge base construction using a probabilistic program to define a process of converting knowledge base facts into unstructured text.', 'Overview about existing knowledge base that is constructed with a probabilistic model, with the knowledge base construction approach evaluated against other knowledge base approaches YAGO2, NELL, Knowledge Vault, and DeepDive.', 'This paper uses a probabilistic program describing the process by which facts describing entities can be realised in text and large number of web pages, to learn to perform fact extraction about people using a single seed fact.']","['creating knowledge base accurate  uptodate complete remains significant challenge despite substantial effort automated knowledge base construction ', 'paper  present alexandria  system unsupervised  highprecision knowledge base construction ', 'alexandria us probabilistic program define process converting knowledge base fact unstructured text ', 'using probabilistic inference  invert program retrieve fact  schema entity web text ', 'use probabilistic program allows uncertainty text propagated retrieved fact  increase accuracy help merge fact multiple source ', 'alexandria require labelled training data  knowledge base constructed minimum manual input ', 'demonstrate constructing high precision  typically 97    knowledge base people single seed fact ']","Creating a knowledge base that is accurate, up-to-date and complete remains a significant challenge despite substantial efforts in automated knowledge base construction.  , In this paper, we present Alexandria -- a system for unsupervised, high-precision knowledge base construction., Alexandria uses a probabilistic program to define a process of converting knowledge base facts into unstructured text.  , Using probabilistic inference, we can invert this program and so retrieve facts, schemas and entities from web text., The use of a probabilistic program allows uncertainty in the text to be propagated through to the retrieved facts, which increases accuracy and helps merge facts from multiple sources., Because Alexandria does not require labelled training data, knowledge bases can be constructed with the minimum of manual input., We demonstrate this by constructing a high precision (typically 97\%+) knowledge base for people from a single seed fact.",14,5.805755395683454,9.928571428571429
234,"['Recent advances have made it possible to create deep complex-valued neural networks.', 'Despite this progress, many challenging learning tasks have yet to leverage the power of complex representations.', 'Building on recent advances, we propose a new deep complex-valued method for signal retrieval and extraction in the frequency domain.', 'As a case study, we perform audio source separation in the Fourier domain.', 'Our new method takes advantage of the convolution theorem which states that the Fourier transform of two convolved signals is the elementwise product of their Fourier transforms.', 'Our novel method is based on a complex-valued version of Feature-Wise Linear Modulation (FiLM) and serves as the keystone of our proposed signal extraction method.', 'We also introduce a new and explicit amplitude and phase-aware loss, which is scale and time invariant, taking into account the complex-valued components of the spectrogram.', 'Using the Wall Street Journal Dataset, we compared our phase-aware loss to several others that operate both in the time and frequency domains and demonstrate the effectiveness of our proposed signal extraction method and proposed loss.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.0, 0.0833333283662796, 0.1428571343421936, 0.2857142686843872, 0.13333332538604736, 0.06451612710952759, 0.06451612710952759, 0.10810810327529907]",H1x22Xn5Ur,['New Signal Extraction Method in the Fourier Domain'],"['recent advance made possible create deep complexvalued neural network ', 'despite progress  many challenging learning task yet leverage power complex representation ', 'building recent advance  propose new deep complexvalued method signal retrieval extraction frequency domain ', 'case study  perform audio source separation fourier domain ', 'new method take advantage convolution theorem state fourier transform two convolved signal elementwise product fourier transforms ', 'novel method based complexvalued version featurewise linear modulation  film  serf keystone proposed signal extraction method ', 'also introduce new explicit amplitude phaseaware loss  scale time invariant  taking account complexvalued component spectrogram ', 'using wall street journal dataset  compared phaseaware loss several others operate time frequency domain demonstrate effectiveness proposed signal extraction method proposed loss ']","Recent advances have made it possible to create deep complex-valued neural networks., Despite this progress, many challenging learning tasks have yet to leverage the power of complex representations., Building on recent advances, we propose a new deep complex-valued method for signal retrieval and extraction in the frequency domain., As a case study, we perform audio source separation in the Fourier domain., Our new method takes advantage of the convolution theorem which states that the Fourier transform of two convolved signals is the elementwise product of their Fourier transforms., Our novel method is based on a complex-valued version of Feature-Wise Linear Modulation (FiLM) and serves as the keystone of our proposed signal extraction method., We also introduce a new and explicit amplitude and phase-aware loss, which is scale and time invariant, taking into account the complex-valued components of the spectrogram., Using the Wall Street Journal Dataset, we compared our phase-aware loss to several others that operate both in the time and frequency domains and demonstrate the effectiveness of our proposed signal extraction method and proposed loss.",14,5.6,12.5
235,"['We propose an implementation of GNN that predicts and imitates the motion be- haviors from observed swarm trajectory data.', 'The networks ability to capture interaction dynamics in swarms is demonstrated through transfer learning.', 'We finally discuss the inherent availability and challenges in the scalability of GNN, and proposed a method to improve it with layer-wise tuning and mixing of data enabled by padding.']","[1, 0, 0]","[0.3030303120613098, 0.0714285671710968, 0.19999998807907104]",HJeANgBYwr,"['Improve the scalability of graph neural networks on imitation learning and prediction of swarm motion', 'The paper proposes a new time series model for learning a sequence of graphs.', 'This work considers sequence prediction problems in a multi-agent system.']","['propose implementation gnn predicts imitates motion haviors observed swarm trajectory data ', 'network  ability capture interaction dynamic swarm demonstrated transfer learning ', 'finally discus inherent availability challenge scalability gnn  proposed method improve layerwise tuning mixing data enabled padding ']","We propose an implementation of GNN that predicts and imitates the motion be- haviors from observed swarm trajectory data., The networks ability to capture interaction dynamics in swarms is demonstrated through transfer learning., We finally discuss the inherent availability and challenges in the scalability of GNN, and proposed a method to improve it with layer-wise tuning and mixing of data enabled by padding.",4,5.571428571428571,15.75
236,"['Embedding layers are commonly used to map discrete symbols into continuous embedding vectors that reflect their semantic meanings.', 'Despite their effectiveness, the number of parameters in an embedding layer increases linearly with the number of symbols and poses a critical challenge on memory and storage constraints.', 'In this work, we propose a generic and end-to-end learnable compression framework termed differentiable product quantization (DPQ).', 'We present two instantiations of DPQ that leverage different approximation techniques to enable differentiability in end-to-end learning.', 'Our method can readily serve as a drop-in alternative for any existing embedding layer.', 'Empirically, DPQ offers significant compression ratios (14-238x) at negligible or no performance cost on 10 datasets across three different language tasks.']","[0, 0, 1, 0, 0, 0]","[0.09756097197532654, 0.2978723347187042, 0.3499999940395355, 0.25, 0.21621620655059814, 0.1818181723356247]",BJxbOlSKPr,"['We propose a differentiable product quantization framework that can reduce the size of embedding layer in an end-to-end training at no performance cost.', 'This paper works on methods for compressing embedding layers for low memory inference, where compressed embeddings are learned together with the task-specific models in a differentiable end-to-end fashion.']","['embedding layer commonly used map discrete symbol continuous embedding vector reflect semantic meaning ', 'despite effectiveness  number parameter embedding layer increase linearly number symbol pose critical challenge memory storage constraint ', 'work  propose generic endtoend learnable compression framework termed differentiable product quantization  dpq  ', 'present two instantiation dpq leverage different approximation technique enable differentiability endtoend learning ', 'method readily serve dropin alternative existing embedding layer ', 'empirically  dpq offer significant compression ratio  14238x  negligible performance cost 10 datasets across three different language task ']","Embedding layers are commonly used to map discrete symbols into continuous embedding vectors that reflect their semantic meanings., Despite their effectiveness, the number of parameters in an embedding layer increases linearly with the number of symbols and poses a critical challenge on memory and storage constraints., In this work, we propose a generic and end-to-end learnable compression framework termed differentiable product quantization (DPQ)., We present two instantiations of DPQ that leverage different approximation techniques to enable differentiability in end-to-end learning., Our method can readily serve as a drop-in alternative for any existing embedding layer., Empirically, DPQ offers significant compression ratios (14-238x) at negligible or no performance cost on 10 datasets across three different language tasks.",9,6.217391304347826,12.777777777777779
237,"['For multi-valued functions---such as when the conditional distribution on targets given the inputs is multi-modal---standard regression approaches are not always desirable because they provide the conditional mean.', 'Modal regression approaches aim to instead find the conditional mode, but are restricted to nonparametric approaches.', 'Such approaches can be difficult to scale, and make it difficult to benefit from parametric function approximation, like neural networks, which can learn complex relationships between inputs and targets.', 'In this work, we propose a parametric modal regression algorithm, by using the implicit function theorem to develop an objective for learning a joint parameterized function over inputs and targets.', 'We empirically demonstrate on several synthetic problems that our method', '(i) can learn multi-valued functions and produce the conditional modes,', '(ii) scales well to high-dimensional inputs and', '(iii) is even more effective for certain unimodal problems, particularly for high frequency data where the joint function over inputs and targets can better capture the complex relationship between them.', 'We conclude by showing that our method provides small improvements on two regression datasets that have asymmetric distributions over the targets.']","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.09756097197532654, 0.12903225421905518, 0.1428571343421936, 0.2222222238779068, 0.14814814925193787, 0.07407406717538834, 0.1666666567325592, 0.08888888359069824, 0.10810810327529907]",Bkx29TVFPr,"['We introduce a simple and novel modal regression algorithm which is easy to scale to large problems. ', 'The paper proposes an implicit function approach to learning the modes of multimodal regression.', 'The present work proposes a parametric approach to estimate the conditional mode using the Implicit Function Theorem for multi-modal distributions. ']","['multivalued function  conditional distribution target given input multimodal  standard regression approach always desirable provide conditional mean ', 'modal regression approach aim instead find conditional mode  restricted nonparametric approach ', 'approach difficult scale  make difficult benefit parametric function approximation  like neural network  learn complex relationship input target ', 'work  propose parametric modal regression algorithm  using implicit function theorem develop objective learning joint parameterized function input target ', 'empirically demonstrate several synthetic problem method', '  learn multivalued function produce conditional mode ', ' ii  scale well highdimensional input', ' iii  even effective certain unimodal problem  particularly high frequency data joint function input target better capture complex relationship ', 'conclude showing method provides small improvement two regression datasets asymmetric distribution target ']","For multi-valued functions---such as when the conditional distribution on targets given the inputs is multi-modal---standard regression approaches are not always desirable because they provide the conditional mean., Modal regression approaches aim to instead find the conditional mode, but are restricted to nonparametric approaches., Such approaches can be difficult to scale, and make it difficult to benefit from parametric function approximation, like neural networks, which can learn complex relationships between inputs and targets., In this work, we propose a parametric modal regression algorithm, by using the implicit function theorem to develop an objective for learning a joint parameterized function over inputs and targets., We empirically demonstrate on several synthetic problems that our method, (i) can learn multi-valued functions and produce the conditional modes,, (ii) scales well to high-dimensional inputs and, (iii) is even more effective for certain unimodal problems, particularly for high frequency data where the joint function over inputs and targets can better capture the complex relationship between them., We conclude by showing that our method provides small improvements on two regression datasets that have asymmetric distributions over the targets.",16,6.066666666666666,11.25
238,"['Deep reinforcement learning algorithms require large amounts of experience to learn an individual task.', 'While in principle meta-reinforcement learning (meta-RL) algorithms enable agents to learn new skills from small amounts of experience, several major challenges preclude their practicality.', 'Current methods rely heavily on on-policy experience, limiting their sample efficiency.', 'They also lack mechanisms to reason about task uncertainty when adapting to new tasks, limiting their effectiveness in sparse reward problems.', 'In this paper, we address these challenges by developing an off-policy meta-RL algorithm that disentangles task inference and control.', 'In our approach, we perform online probabilistic filtering of latent task variables to infer how to solve a new task from small amounts of experience.', 'This probabilistic interpretation enables posterior sampling for structured and efficient exploration.', 'We demonstrate how to integrate these task variables with off-policy RL algorithms to achieve both meta-training and adaptation efficiency.', 'Our method outperforms prior algorithms in sample efficiency by 20-100X as well as in asymptotic performance on several meta-RL benchmarks.']","[0, 0, 0, 0, 0, 0, 0, 1, 0]","[0.1428571343421936, 0.052631575614213943, 0.0, 0.05882352590560913, 0.3030303120613098, 0.2222222238779068, 0.1599999964237213, 0.3125, 0.1249999925494194]",BJeMeiCVd4,"['Sample efficient meta-RL by combining variational inference of probabilistic task variables with off-policy RL ', 'This paper proposes using off-policy RL during the meta-training time to greatly improve sample efficiency of Meta-RL methods.']","['deep reinforcement learning algorithm require large amount experience learn individual task ', 'principle metareinforcement learning  metarl  algorithm enable agent learn new skill small amount experience  several major challenge preclude practicality ', 'current method rely heavily onpolicy experience  limiting sample efficiency ', 'also lack mechanism reason task uncertainty adapting new task  limiting effectiveness sparse reward problem ', 'paper  address challenge developing offpolicy metarl algorithm disentangles task inference control ', 'approach  perform online probabilistic filtering latent task variable infer solve new task small amount experience ', 'probabilistic interpretation enables posterior sampling structured efficient exploration ', 'demonstrate integrate task variable offpolicy rl algorithm achieve metatraining adaptation efficiency ', 'method outperforms prior algorithm sample efficiency 20100x well asymptotic performance several metarl benchmark ']","Deep reinforcement learning algorithms require large amounts of experience to learn an individual task., While in principle meta-reinforcement learning (meta-RL) algorithms enable agents to learn new skills from small amounts of experience, several major challenges preclude their practicality., Current methods rely heavily on on-policy experience, limiting their sample efficiency., They also lack mechanisms to reason about task uncertainty when adapting to new tasks, limiting their effectiveness in sparse reward problems., In this paper, we address these challenges by developing an off-policy meta-RL algorithm that disentangles task inference and control., In our approach, we perform online probabilistic filtering of latent task variables to infer how to solve a new task from small amounts of experience., This probabilistic interpretation enables posterior sampling for structured and efficient exploration., We demonstrate how to integrate these task variables with off-policy RL algorithms to achieve both meta-training and adaptation efficiency., Our method outperforms prior algorithms in sample efficiency by 20-100X as well as in asymptotic performance on several meta-RL benchmarks.",14,6.25,11.714285714285714
239,"['Knowledge bases, massive collections of facts (RDF triples) on diverse topics, support vital modern applications.', 'However, existing knowledge bases contain very little data compared to the wealth of information on the Web.', 'This is because the industry standard in knowledge base creation and augmentation suffers from a serious bottleneck: they rely on domain experts to identify appropriate web sources to extract data from.', 'Efforts to fully automate knowledge extraction have failed to improve this standard: these automated systems are able to retrieve much more data and from a broader range of sources, but they suffer from very low precision and recall.', 'As a result, these large-scale extractions remain unexploited.', 'In this paper, we present MIDAS, a system that harnesses the results of automated knowledge extraction pipelines to repair the bottleneck in industrial knowledge creation and augmentation processes.', 'MIDAS automates the suggestion of good-quality web sources and describes what to extract with respect to augmenting an existing knowledge base.', 'We make three major contributions.', 'First, we introduce a novel concept, web source slices, to describe the contents of a web source.', 'Second, we define a profit function to quantify the value of a web source slice with respect to augmenting an existing knowledge base.', 'Third, we develop effective and highly-scalable algorithms to derive high-profit web source slices.', 'We demonstrate that MIDAS produces high-profit results and outperforms the baselines significantly on both real-word and synthetic datasets.']","[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.06666666269302368, 0.12903225421905518, 0.3181818127632141, 0.04081632196903229, 0.0, 0.1463414579629898, 0.22857142984867096, 0.0, 0.06896550953388214, 0.1666666567325592, 0.0714285671710968, 0.0624999962747097]",BketCg9p6X,['This paper focuses on identifying high quality web sources for industrial knowledge base augmentation pipeline.'],"['knowledge base  massive collection fact  rdf triple  diverse topic  support vital modern application ', 'however  existing knowledge base contain little data compared wealth information web ', 'industry standard knowledge base creation augmentation suffers serious bottleneck  rely domain expert identify appropriate web source extract data ', 'effort fully automate knowledge extraction failed improve standard  automated system able retrieve much data broader range source  suffer low precision recall ', 'result  largescale extraction remain unexploited ', 'paper  present midas  system harness result automated knowledge extraction pipeline repair bottleneck industrial knowledge creation augmentation process ', 'midas automates suggestion goodquality web source describes extract respect augmenting existing knowledge base ', 'make three major contribution ', 'first  introduce novel concept  web source slice  describe content web source ', 'second  define profit function quantify value web source slice respect augmenting existing knowledge base ', 'third  develop effective highlyscalable algorithm derive highprofit web source slice ', 'demonstrate midas produce highprofit result outperforms baseline significantly realword synthetic datasets ']","Knowledge bases, massive collections of facts (RDF triples) on diverse topics, support vital modern applications., However, existing knowledge bases contain very little data compared to the wealth of information on the Web., This is because the industry standard in knowledge base creation and augmentation suffers from a serious bottleneck: they rely on domain experts to identify appropriate web sources to extract data from., Efforts to fully automate knowledge extraction have failed to improve this standard: these automated systems are able to retrieve much more data and from a broader range of sources, but they suffer from very low precision and recall., As a result, these large-scale extractions remain unexploited., In this paper, we present MIDAS, a system that harnesses the results of automated knowledge extraction pipelines to repair the bottleneck in industrial knowledge creation and augmentation processes., MIDAS automates the suggestion of good-quality web sources and describes what to extract with respect to augmenting an existing knowledge base., We make three major contributions., First, we introduce a novel concept, web source slices, to describe the contents of a web source., Second, we define a profit function to quantify the value of a web source slice with respect to augmenting an existing knowledge base., Third, we develop effective and highly-scalable algorithms to derive high-profit web source slices., We demonstrate that MIDAS produces high-profit results and outperforms the baselines significantly on both real-word and synthetic datasets.",24,5.67948717948718,9.75
240,"['We explore the match prediction problem where one seeks to estimate the likelihood of a group of M items preferred over another, based on partial group comparison data.', 'Challenges arise in practice.', 'As existing state-of-the-art algorithms are tailored to certain statistical models, we have different best algorithms across distinct scenarios.', 'Worse yet, we have no prior knowledge on the underlying model for a given scenario.', 'These call for a unified approach that can be universally applied to a wide range of scenarios and achieve consistently high performances.', 'To this end, we incorporate deep learning architectures so as to reflect the key structural features that most state-of-the-art algorithms, some of which are optimal in certain settings, share in common.', 'This enables us to infer hidden models underlying a given dataset, which govern in-group interactions and statistical patterns of comparisons, and hence to devise the best algorithm tailored to the dataset at hand.', 'Through extensive experiments on synthetic and real-world datasets, we evaluate our framework in comparison to state-of-the-art algorithms.', 'It turns out that our framework consistently leads to the best performance across all datasets in terms of cross entropy loss and prediction accuracy, while the state-of-the-art algorithms suffer from inconsistent performances across different datasets.', 'Furthermore, we show that it can be easily extended to attain satisfactory performances in rank aggregation tasks, suggesting that it can be adaptable for other tasks as well.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.8727272748947144, 0.05882352590560913, 0.04255318641662598, 0.13333332538604736, 0.11764705181121826, 0.13333332538604736, 0.1355932205915451, 0.1702127605676651, 0.16129031777381897, 0.07407406717538834]",BJxYUaVtPB,"['We investigate the merits of employing neural networks in the match prediction problem where one seeks to estimate the likelihood of a group of M items preferred over another, based on partial group comparison data.', 'This paper proposes a deep neural network solution to the set ranking problem and designs a architecture for this task inspired by previous manually designed algorithms.', 'This paper provides a technique to solve the match prediction problem using a deep learning architecture.']","['explore match prediction problem one seek estimate likelihood group item preferred another  based partial group comparison data ', 'challenge arise practice ', 'existing stateoftheart algorithm tailored certain statistical model  different best algorithm across distinct scenario ', 'worse yet  prior knowledge underlying model given scenario ', 'call unified approach universally applied wide range scenario achieve consistently high performance ', 'end  incorporate deep learning architecture reflect key structural feature stateoftheart algorithm  optimal certain setting  share common ', 'enables u infer hidden model underlying given dataset  govern ingroup interaction statistical pattern comparison  hence devise best algorithm tailored dataset hand ', 'extensive experiment synthetic realworld datasets  evaluate framework comparison stateoftheart algorithm ', 'turn framework consistently lead best performance across datasets term cross entropy loss prediction accuracy  stateoftheart algorithm suffer inconsistent performance across different datasets ', 'furthermore  show easily extended attain satisfactory performance rank aggregation task  suggesting adaptable task well ']","We explore the match prediction problem where one seeks to estimate the likelihood of a group of M items preferred over another, based on partial group comparison data., Challenges arise in practice., As existing state-of-the-art algorithms are tailored to certain statistical models, we have different best algorithms across distinct scenarios., Worse yet, we have no prior knowledge on the underlying model for a given scenario., These call for a unified approach that can be universally applied to a wide range of scenarios and achieve consistently high performances., To this end, we incorporate deep learning architectures so as to reflect the key structural features that most state-of-the-art algorithms, some of which are optimal in certain settings, share in common., This enables us to infer hidden models underlying a given dataset, which govern in-group interactions and statistical patterns of comparisons, and hence to devise the best algorithm tailored to the dataset at hand., Through extensive experiments on synthetic and real-world datasets, we evaluate our framework in comparison to state-of-the-art algorithms., It turns out that our framework consistently leads to the best performance across all datasets in terms of cross entropy loss and prediction accuracy, while the state-of-the-art algorithms suffer from inconsistent performances across different datasets., Furthermore, we show that it can be easily extended to attain satisfactory performances in rank aggregation tasks, suggesting that it can be adaptable for other tasks as well.",22,5.683982683982684,10.5
241,"['Recurrent Neural Networks (RNNs) are designed to handle sequential data but suffer from vanishing or exploding gradients.  ', 'Recent work on Unitary Recurrent Neural Networks (uRNNs) have been used to address this issue and in some cases, exceed the capabilities of Long Short-Term Memory networks (LSTMs).  ', 'We propose a simpler and novel update scheme to maintain orthogonal recurrent weight matrices without using complex valued matrices.', 'This is done by parametrizing with a skew-symmetric matrix using the Cayley transform.', 'Such a parametrization is unable to represent matrices with negative one eigenvalues, but this limitation is overcome by scaling the recurrent weight matrix by a diagonal matrix consisting of ones and negative ones.  ', 'The proposed training scheme involves a straightforward gradient calculation and update step.', 'In several experiments, the proposed scaled Cayley orthogonal recurrent neural network (scoRNN) achieves superior results with fewer trainable parameters than other unitary RNNs.']","[0, 0, 1, 0, 0, 0, 0]","[0.06666666269302368, 0.09756097197532654, 0.5333333015441895, 0.07999999821186066, 0.25, 0.0833333283662796, 0.11428570747375488]",HyEi7bWR-,"['A novel approach to maintain orthogonal recurrent weight matrices in a RNN.', 'Introduces a scheme for learning the recurrent parameter matrix in a neural network that uses the Cayley transform and a scaling weight matrix. ', 'This paper suggests an RNN reparametrization of the recurrent weights with a skew-symmetric matrix using Cayley transform to keep the recurrent weight matrix orthogonal.', 'Novel parametrization of RNNs allows representing orthogonal weight matrices relatively easily.']","['recurrent neural network  rnns  designed handle sequential data suffer vanishing exploding gradient ', 'recent work unitary recurrent neural network  urnns  used address issue case  exceed capability long shortterm memory network  lstms  ', 'propose simpler novel update scheme maintain orthogonal recurrent weight matrix without using complex valued matrix ', 'done parametrizing skewsymmetric matrix using cayley transform ', 'parametrization unable represent matrix negative one eigenvalue  limitation overcome scaling recurrent weight matrix diagonal matrix consisting one negative one ', 'proposed training scheme involves straightforward gradient calculation update step ', 'several experiment  proposed scaled cayley orthogonal recurrent neural network  scornn  achieves superior result fewer trainable parameter unitary rnns ']","Recurrent Neural Networks (RNNs) are designed to handle sequential data but suffer from vanishing or exploding gradients.  , Recent work on Unitary Recurrent Neural Networks (uRNNs) have been used to address this issue and in some cases, exceed the capabilities of Long Short-Term Memory networks (LSTMs).  , We propose a simpler and novel update scheme to maintain orthogonal recurrent weight matrices without using complex valued matrices., This is done by parametrizing with a skew-symmetric matrix using the Cayley transform., Such a parametrization is unable to represent matrices with negative one eigenvalues, but this limitation is overcome by scaling the recurrent weight matrix by a diagonal matrix consisting of ones and negative ones.  , The proposed training scheme involves a straightforward gradient calculation and update step., In several experiments, the proposed scaled Cayley orthogonal recurrent neural network (scoRNN) achieves superior results with fewer trainable parameters than other unitary RNNs.",10,5.958620689655173,14.5
242,"['A large number of natural language processing tasks exist to analyze syntax, semantics, and information content of human language.', 'These seemingly very different tasks are usually solved by specially designed architectures.', 'In this paper, we provide the simple insight that a great variety of tasks can be represented in a single unified format consisting of labeling spans and relations between spans, thus a single task-independent model can be used across different tasks.', 'We perform extensive experiments to test this insight on 10 disparate tasks as broad as dependency parsing (syntax), semantic role labeling (semantics), relation extraction (information content), aspect based sentiment analysis (sentiment), and many others, achieving comparable performance as state-of-the-art specialized models.', 'We further demonstrate benefits in multi-task learning.', 'We convert these datasets into a unified format to build a benchmark, which provides a holistic testbed for evaluating future models for generalized natural language analysis.']","[0, 0, 1, 0, 0, 0]","[0.2631579041481018, 0.12121211737394333, 0.3636363446712494, 0.13333332538604736, 0.1428571343421936, 0.3636363446712494]",B1x_K04YwS,"['We use a single model to solve a great variety of natural language analysis tasks by formulating them in a unified span-relation format.', 'This paper generalizes a wide range of natural language processing tasks as a single span-based framework and proposes a general architecture to solve all these problems.', 'This work presents a unified formulation of various phrase and token level NLP tasks.']","['large number natural language processing task exist analyze syntax  semantics  information content human language ', 'seemingly different task usually solved specially designed architecture ', 'paper  provide simple insight great variety task represented single unified format consisting labeling span relation span  thus single taskindependent model used across different task ', 'perform extensive experiment test insight 10 disparate task broad dependency parsing  syntax   semantic role labeling  semantics   relation extraction  information content   aspect based sentiment analysis  sentiment   many others  achieving comparable performance stateoftheart specialized model ', 'demonstrate benefit multitask learning ', 'convert datasets unified format build benchmark  provides holistic testbed evaluating future model generalized natural language analysis ']","A large number of natural language processing tasks exist to analyze syntax, semantics, and information content of human language., These seemingly very different tasks are usually solved by specially designed architectures., In this paper, we provide the simple insight that a great variety of tasks can be represented in a single unified format consisting of labeling spans and relations between spans, thus a single task-independent model can be used across different tasks., We perform extensive experiments to test this insight on 10 disparate tasks as broad as dependency parsing (syntax), semantic role labeling (semantics), relation extraction (information content), aspect based sentiment analysis (sentiment), and many others, achieving comparable performance as state-of-the-art specialized models., We further demonstrate benefits in multi-task learning., We convert these datasets into a unified format to build a benchmark, which provides a holistic testbed for evaluating future models for generalized natural language analysis.",16,6.0479452054794525,9.125
243,"['Large matrix inversions have often been cited as a major impediment to scaling Gaussian process (GP) models.', 'With the use of GPs as building blocks for ever more sophisticated Bayesian deep learning models, removing these impediments is a necessary step for achieving large scale results.', 'We present a variational approximation for a wide range of GP models that does not require a matrix inverse to be performed at each optimisation step.', 'Our bound instead directly parameterises a free matrix, which is an additional variational parameter.', 'At the local maxima of the bound, this matrix is equal to the matrix inverse.', 'We prove that our bound gives the same guarantees as earlier variational approximations.', 'We demonstrate some beneficial properties of the bound experimentally, although significant wall clock time speed improvements will require future improvements in optimisation and implementation.']","[0, 0, 0, 0, 0, 1, 0]","[0.17777776718139648, 0.145454540848732, 0.38461539149284363, 0.1428571343421936, 0.09999999403953552, 0.4390243887901306, 0.11764705181121826]",rklEqJhNFH,"['We present a variational lower bound for GP models that can be optimised without computing expensive matrix operations like inverses, while providing the same guarantees as existing variational approximations.']","['large matrix inversion often cited major impediment scaling gaussian process  gp  model ', 'use gps building block ever sophisticated bayesian deep learning model  removing impediment necessary step achieving large scale result ', 'present variational approximation wide range gp model require matrix inverse performed optimisation step ', 'bound instead directly parameterises free matrix  additional variational parameter ', 'local maximum bound  matrix equal matrix inverse ', 'prove bound give guarantee earlier variational approximation ', 'demonstrate beneficial property bound experimentally  although significant wall clock time speed improvement require future improvement optimisation implementation ']","Large matrix inversions have often been cited as a major impediment to scaling Gaussian process (GP) models., With the use of GPs as building blocks for ever more sophisticated Bayesian deep learning models, removing these impediments is a necessary step for achieving large scale results., We present a variational approximation for a wide range of GP models that does not require a matrix inverse to be performed at each optimisation step., Our bound instead directly parameterises a free matrix, which is an additional variational parameter., At the local maxima of the bound, this matrix is equal to the matrix inverse., We prove that our bound gives the same guarantees as earlier variational approximations., We demonstrate some beneficial properties of the bound experimentally, although significant wall clock time speed improvements will require future improvements in optimisation and implementation.",11,5.576642335766423,12.454545454545455
244,"['It has been shown that using geometric spaces with non-zero curvature instead of plain Euclidean spaces with zero curvature improves performance on a range of Machine Learning tasks for learning representations.', 'Recent work has leveraged these geometries to learn latent variable models like Variational Autoencoders (VAEs) in spherical and hyperbolic spaces with constant curvature.', 'While these approaches work well on particular kinds of data that they were designed for e.g.~tree-like data for a hyperbolic VAE, there exists no generic approach unifying all three models.', 'We develop a Mixed-curvature Variational Autoencoder, an efficient way to train a VAE whose latent space is a product of constant curvature Riemannian manifolds, where the per-component curvature can be learned.', 'This generalizes the Euclidean VAE to curved latent spaces, as the model essentially reduces to the Euclidean VAE if curvatures of all latent space components go to 0.']","[0, 1, 0, 0, 0]","[0.21276594698429108, 0.3255814015865326, 0.07999999821186066, 0.25, 0.1463414579629898]",S1g6xeSKDS,"['Variational Autoencoders with latent spaces modeled as products of constant curvature Riemannian manifolds improve on image reconstruction over single-manifold variants.', 'This paper introduces a general formulation of the notion of a VAE with a latent space composed by a curved manifold.', 'This paper is about developing VAEs in non-Euclidean spaces.']","['shown using geometric space nonzero curvature instead plain euclidean space zero curvature improves performance range machine learning task learning representation ', 'recent work leveraged geometry learn latent variable model like variational autoencoders  vaes  spherical hyperbolic space constant curvature ', 'approach work well particular kind data designed egtreelike data hyperbolic vae  exists generic approach unifying three model ', 'develop mixedcurvature variational autoencoder  efficient way train vae whose latent space product constant curvature riemannian manifold  percomponent curvature learned ', 'generalizes euclidean vae curved latent space  model essentially reduces euclidean vae curvature latent space component go 0 ']","It has been shown that using geometric spaces with non-zero curvature instead of plain Euclidean spaces with zero curvature improves performance on a range of Machine Learning tasks for learning representations., Recent work has leveraged these geometries to learn latent variable models like Variational Autoencoders (VAEs) in spherical and hyperbolic spaces with constant curvature., While these approaches work well on particular kinds of data that they were designed for e.g.~tree-like data for a hyperbolic VAE, there exists no generic approach unifying all three models., We develop a Mixed-curvature Variational Autoencoder, an efficient way to train a VAE whose latent space is a product of constant curvature Riemannian manifolds, where the per-component curvature can be learned., This generalizes the Euclidean VAE to curved latent spaces, as the model essentially reduces to the Euclidean VAE if curvatures of all latent space components go to 0.",9,5.65034965034965,15.88888888888889
245,"['Machine learning algorithms for generating molecular structures offer a promising new approach to drug discovery.', 'We cast molecular optimization as a translation problem, where the goal is to map an input compound to a target compound with improved biochemical properties.', 'Remarkably, we observe that when generated molecules are iteratively fed back into the translator, molecular compound attributes improve with each step.', 'We show that this finding is invariant to the choice of translation model, making this a ""black box"" algorithm.', 'We call this method Black Box Recursive Translation (BBRT), a new inference method for molecular property optimization.', 'This simple, powerful technique operates strictly on the inputs and outputs of any translation model.', 'We obtain new state-of-the-art results for molecular property optimization tasks using our simple drop-in replacement with well-known sequence and graph-based models.', 'Our method provides a significant boost in performance relative to its non-recursive peers with just a simple ""``for"" loop.', 'Further, BBRT is highly interpretable, allowing users to map the evolution of newly discovered compounds from known starting points.']","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.13793103396892548, 0.2222222238779068, 0.0, 0.3125, 0.2666666507720947, 0.13793103396892548, 0.22857142984867096, 0.0624999962747097, 0.12121211737394333]",rJxok1BYPr,"['We introduce a black box algorithm for repeated optimization of compounds using a translation framework.', 'The authors frame molecule optimization as a sequence-to-sequence problem, and extend existing methods for improving molecules, showing that it is beneficial for optimizing logP but not QED.', 'The paper builds on existing translation models developed for molecular optimization, making an iterative use of sequence to sequence or graph to graph translation models.']","['machine learning algorithm generating molecular structure offer promising new approach drug discovery ', 'cast molecular optimization translation problem  goal map input compound target compound improved biochemical property ', 'remarkably  observe generated molecule iteratively fed back translator  molecular compound attribute improve step ', 'show finding invariant choice translation model  making  black box  algorithm ', 'call method black box recursive translation  bbrt   new inference method molecular property optimization ', 'simple  powerful technique operates strictly input output translation model ', 'obtain new stateoftheart result molecular property optimization task using simple dropin replacement wellknown sequence graphbased model ', 'method provides significant boost performance relative nonrecursive peer simple    loop ', ' bbrt highly interpretable  allowing user map evolution newly discovered compound known starting point ']","Machine learning algorithms for generating molecular structures offer a promising new approach to drug discovery., We cast molecular optimization as a translation problem, where the goal is to map an input compound to a target compound with improved biochemical properties., Remarkably, we observe that when generated molecules are iteratively fed back into the translator, molecular compound attributes improve with each step., We show that this finding is invariant to the choice of translation model, making this a ""black box"" algorithm., We call this method Black Box Recursive Translation (BBRT), a new inference method for molecular property optimization., This simple, powerful technique operates strictly on the inputs and outputs of any translation model., We obtain new state-of-the-art results for molecular property optimization tasks using our simple drop-in replacement with well-known sequence and graph-based models., Our method provides a significant boost in performance relative to its non-recursive peers with just a simple ""``for"" loop., Further, BBRT is highly interpretable, allowing users to map the evolution of newly discovered compounds from known starting points.",17,5.87719298245614,10.058823529411764
246,"['Deep Neural Networks (DNNs) are increasingly deployed in cloud servers and autonomous agents due to their superior performance.', 'The deployed DNN is either leveraged in a white-box setting (model internals are publicly known) or a black-box setting (only model outputs are known) depending on the application.', 'A practical concern in the rush to adopt DNNs is protecting the models against Intellectual Property (IP) infringement.', 'We propose BlackMarks, the first end-to-end multi-bit watermarking framework that is applicable in the black-box scenario.', 'BlackMarks takes the pre-trained unmarked model and the owners binary signature as inputs.', 'The output is the corresponding marked model with specific keys that can be later used to trigger the embedded watermark.', 'To do so, BlackMarks first designs a model-dependent encoding scheme that maps all possible classes in the task to bit 0 and bit 1.', 'Given the owners watermark signature (a binary string), a set of key image and label pairs is designed using targeted adversarial attacks.', 'The watermark (WM) is then encoded in the distribution of output activations of the DNN by fine-tuning the model with a WM-specific regularized loss.', 'To extract the WM, BlackMarks queries the model with the WM key images and decodes the owners signature from the corresponding predictions using the designed encoding scheme.', 'We perform a comprehensive evaluation of BlackMarks performance on MNIST, CIFAR-10, ImageNet datasets and corroborate its effectiveness and robustness.', 'BlackMarks preserves the functionality of the original DNN and incurs negligible WM embedding overhead as low as 2.054%.']","[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]","[0.05882352590560913, 0.14999999105930328, 0.060606054961681366, 0.32258063554763794, 0.2142857164144516, 0.05714285373687744, 0.1538461446762085, 0.2631579041481018, 0.1621621549129486, 0.21052631735801697, 0.11764705181121826, 0.3030303120613098]",S1MeM2RcFm,"['Proposing the first watermarking framework for multi-bit signature embedding and extraction using the outputs of the DNN. ', 'Proposes a method for multi-bit watermarking of neural networks in a black-box setting and demonstrate that the predictions of existing models can carry a multi-bit string that can later be used to verify ownership.', 'The paper proposes an approach for model watermarking where the watermark is a bit string embedded in the model as part of a fine-tuning procedure']","['deep neural network  dnns  increasingly deployed cloud server autonomous agent due superior performance ', 'deployed dnn either leveraged whitebox setting  model internals publicly known  blackbox setting  model output known  depending application ', 'practical concern rush adopt dnns protecting model intellectual property  ip  infringement ', 'propose blackmarks  first endtoend multibit watermarking framework applicable blackbox scenario ', 'blackmarks take pretrained unmarked model owner  binary signature input ', 'output corresponding marked model specific key later used trigger embedded watermark ', ' blackmarks first design modeldependent encoding scheme map possible class task bit  0  bit  1  ', 'given owner  watermark signature  binary string   set key image label pair designed using targeted adversarial attack ', 'watermark  wm  encoded distribution output activation dnn finetuning model wmspecific regularized loss ', 'extract wm  blackmarks query model wm key image decodes owner  signature corresponding prediction using designed encoding scheme ', 'perform comprehensive evaluation blackmarks  performance mnist  cifar10  imagenet datasets corroborate effectiveness robustness ', 'blackmarks preserve functionality original dnn incurs negligible wm embedding overhead low 2054  ']","Deep Neural Networks (DNNs) are increasingly deployed in cloud servers and autonomous agents due to their superior performance., The deployed DNN is either leveraged in a white-box setting (model internals are publicly known) or a black-box setting (only model outputs are known) depending on the application., A practical concern in the rush to adopt DNNs is protecting the models against Intellectual Property (IP) infringement., We propose BlackMarks, the first end-to-end multi-bit watermarking framework that is applicable in the black-box scenario., BlackMarks takes the pre-trained unmarked model and the owners binary signature as inputs., The output is the corresponding marked model with specific keys that can be later used to trigger the embedded watermark., To do so, BlackMarks first designs a model-dependent encoding scheme that maps all possible classes in the task to bit 0 and bit 1., Given the owners watermark signature (a binary string), a set of key image and label pairs is designed using targeted adversarial attacks., The watermark (WM) is then encoded in the distribution of output activations of the DNN by fine-tuning the model with a WM-specific regularized loss., To extract the WM, BlackMarks queries the model with the WM key images and decodes the owners signature from the corresponding predictions using the designed encoding scheme., We perform a comprehensive evaluation of BlackMarks performance on MNIST, CIFAR-10, ImageNet datasets and corroborate its effectiveness and robustness., BlackMarks preserves the functionality of the original DNN and incurs negligible WM embedding overhead as low as 2.054%.",18,5.623481781376518,13.722222222222221
247,"['Adversarial training provides a principled approach for training robust neural networks.', 'From an optimization perspective, the adversarial training is essentially solving a minmax robust optimization problem.', 'The outer minimization is trying to learn a robust classifier, while the inner maximization is trying to generate adversarial samples.', 'Unfortunately, such a minmax problem is very difficult to solve due to the lack of convex-concave structure.', 'This work proposes a new adversarial training method based on a general learning-to-learn framework.', 'Specifically, instead of applying the existing hand-design algorithms for the inner problem, we learn an optimizer, which is parametrized as a convolutional neural network.', 'At the same time, a robust classifier is learned to defense the adversarial attack generated by the learned optimizer.', 'From the perspective of generative learning, our proposed method can be viewed as learning a deep generative model for generating adversarial samples, which is adaptive to the robust classification.', 'Our experiments demonstrate that our proposed method significantly outperforms existing adversarial training methods on CIFAR-10 and CIFAR-100 datasets.']","[0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.0, 0.0, 0.1538461446762085, 0.07999999821186066, 0.0, 0.0624999962747097, 0.07999999821186066, 0.0555555522441864, 0.0]",H1gHELLK_V,"[""Don't know how to optimize? Then just learn to optimize!"", 'This paper proposes a way to train image classification models to be resistant to L-infinity perturbation attacks.', 'This paper proposes using the learning-to-learn framework to learn an attacker.']","['adversarial training provides principled approach training robust neural network ', 'optimization perspective  adversarial training essentially solving minmax robust optimization problem ', 'outer minimization trying learn robust classifier  inner maximization trying generate adversarial sample ', 'unfortunately  minmax problem difficult solve due lack convexconcave structure ', 'work proposes new adversarial training method based general learningtolearn framework ', 'specifically  instead applying existing handdesign algorithm inner problem  learn optimizer  parametrized convolutional neural network ', 'time  robust classifier learned defense adversarial attack generated learned optimizer ', 'perspective generative learning  proposed method viewed learning deep generative model generating adversarial sample  adaptive robust classification ', 'experiment demonstrate proposed method significantly outperforms existing adversarial training method cifar10 cifar100 datasets ']","Adversarial training provides a principled approach for training robust neural networks., From an optimization perspective, the adversarial training is essentially solving a minmax robust optimization problem., The outer minimization is trying to learn a robust classifier, while the inner maximization is trying to generate adversarial samples., Unfortunately, such a minmax problem is very difficult to solve due to the lack of convex-concave structure., This work proposes a new adversarial training method based on a general learning-to-learn framework., Specifically, instead of applying the existing hand-design algorithms for the inner problem, we learn an optimizer, which is parametrized as a convolutional neural network., At the same time, a robust classifier is learned to defense the adversarial attack generated by the learned optimizer., From the perspective of generative learning, our proposed method can be viewed as learning a deep generative model for generating adversarial samples, which is adaptive to the robust classification., Our experiments demonstrate that our proposed method significantly outperforms existing adversarial training methods on CIFAR-10 and CIFAR-100 datasets.",18,6.119760479041916,9.277777777777779
248,"['In this work we introduce a new framework for performing temporal predictions\n', 'in the presence of uncertainty.', 'It is based on a simple idea of disentangling com-\n', 'ponents of the future state which are predictable from those which are inherently\n', 'unpredictable, and encoding the unpredictable components into a low-dimensional\n', 'latent variable which is fed into the forward model.', 'Our method uses a simple su-\n', 'pervised training objective which is fast and easy to train.', 'We evaluate it in the\n', 'context of video prediction on multiple datasets and show that it is able to consi-\n', 'tently generate diverse predictions without the need for alternating minimization\n', 'over a latent space or adversarial training.']","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.07692307233810425, 0.10526315122842789, 0.0833333283662796, 0.0, 0.08695651590824127, 0.0, 0.20000000298023224, 0.3333333432674408, 0.10526315122842789, 0.20689654350280762, 0.0833333283662796, 0.0]",HJIhGXWCZ,"['A simple and easy to train method for multimodal prediction in time series. ', 'This paper introduces a times-series prediction model that that learns a deterministic mapping and trains another net to predict future frames given the input and residual error from the first network.', 'The paper proposes a model for prediction under uncertainty where they separate out deterministic component prediction and uncertain component prediction.']","['work introduce new framework performing temporal prediction', 'presence uncertainty ', 'based simple idea disentangling com', 'ponents future state predictable inherently', 'unpredictable  encoding unpredictable component lowdimensional', 'latent variable fed forward model ', 'method us simple su', 'pervised training objective fast easy train ', 'evaluate', 'context video prediction multiple datasets show able consi', 'tently generate diverse prediction without need alternating minimization', 'latent space adversarial training ']","In this work we introduce a new framework for performing temporal predictions
, in the presence of uncertainty., It is based on a simple idea of disentangling com-
, ponents of the future state which are predictable from those which are inherently
, unpredictable, and encoding the unpredictable components into a low-dimensional
, latent variable which is fed into the forward model., Our method uses a simple su-
, pervised training objective which is fast and easy to train., We evaluate it in the
, context of video prediction on multiple datasets and show that it is able to consi-
, tently generate diverse predictions without the need for alternating minimization
, over a latent space or adversarial training.",13,5.288288288288288,8.538461538461538
249,"['Conducting reinforcement-learning experiments can be a complex and timely process.', 'A full experimental pipeline will typically consist of a simulation of an environment, an implementation of one or many learning algorithms, a variety of additional components designed to facilitate the agent-environment interplay, and any requisite analysis, plotting, and logging thereof.', 'In light of this complexity, this paper introduces simple rl, a new open source library for carrying out reinforcement learning experiments in Python 2 and 3 with a focus on simplicity.', 'The goal of simple_rl is to support seamless, reproducible methods for running reinforcement learning experiments.', 'This paper gives an overview  of the core design philosophy of the package, how it differs from existing libraries, and showcases its central features.']","[0, 0, 1, 0, 0]","[0.17142856121063232, 0.10169491171836853, 0.8148148059844971, 0.19999998807907104, 0.12765957415103912]",S1xkr2LTIN,"['This paper introduces and motivates simple_rl, a new open source library for carrying out reinforcement learning experiments in Python 2 and 3 with a focus on simplicity.']","['conducting reinforcementlearning experiment complex timely process ', 'full experimental pipeline typically consist simulation environment  implementation one many learning algorithm  variety additional component designed facilitate agentenvironment interplay  requisite analysis  plotting  logging thereof ', 'light complexity  paper introduces simple rl  new open source library carrying reinforcement learning experiment python 2 3 focus simplicity ', 'goal simplerl support seamless  reproducible method running reinforcement learning experiment ', 'paper give overview core design philosophy package  differs existing library  showcase central feature ']","Conducting reinforcement-learning experiments can be a complex and timely process., A full experimental pipeline will typically consist of a simulation of an environment, an implementation of one or many learning algorithms, a variety of additional components designed to facilitate the agent-environment interplay, and any requisite analysis, plotting, and logging thereof., In light of this complexity, this paper introduces simple rl, a new open source library for carrying out reinforcement learning experiments in Python 2 and 3 with a focus on simplicity., The goal of simple_rl is to support seamless, reproducible methods for running reinforcement learning experiments., This paper gives an overview  of the core design philosophy of the package, how it differs from existing libraries, and showcases its central features.",15,5.8,8.0
250,"['Wasserstein GAN(WGAN) is a model that minimizes the Wasserstein distance between a data distribution and sample distribution.', 'Recent studies have proposed stabilizing the training process for the WGAN and implementing the Lipschitz constraint.', 'In this study, we prove the local stability of optimizing the simple gradient penalty $\\mu$-WGAN(SGP $\\mu$-WGAN) under suitable assumptions regarding the equilibrium and penalty measure $\\mu$.', 'The measure valued differentiation concept is employed to deal with the derivative of the penalty terms, which is helpful for handling abstract singular measures with lower dimensional support.', 'Based on this analysis, we claim that penalizing the data manifold or sample manifold is the key to regularizing the original WGAN with a gradient penalty.', 'Experimental results obtained with unintuitive penalty measures that satisfy our assumptions are also provided to support our theoretical results.']","[0, 0, 0, 1, 0, 0]","[0.0624999962747097, 0.0, 0.2926829159259796, 0.3255814015865326, 0.19512194395065308, 0.11428570747375488]",H1ecDoR5Y7,"['This paper deals with stability of simple gradient penalty $\\mu$-WGAN optimization by introducing a concept of measure valued differentiation.', 'WGAN with a squared zero centered gradient penalty term w.r.t. to a general measure is studied.', 'Characterizes the convergence of gradient penalized Wasserstein GAN.']","['wasserstein gan  wgan  model minimizes wasserstein distance data distribution sample distribution ', 'recent study proposed stabilizing training process wgan implementing lipschitz constraint ', 'study  prove local stability optimizing simple gradient penalty  mu  wgan  sgp  mu  wgan  suitable assumption regarding equilibrium penalty measure  mu  ', 'measure valued differentiation concept employed deal derivative penalty term  helpful handling abstract singular measure lower dimensional support ', 'based analysis  claim penalizing data manifold sample manifold key regularizing original wgan gradient penalty ', 'experimental result obtained unintuitive penalty measure satisfy assumption also provided support theoretical result ']","Wasserstein GAN(WGAN) is a model that minimizes the Wasserstein distance between a data distribution and sample distribution., Recent studies have proposed stabilizing the training process for the WGAN and implementing the Lipschitz constraint., In this study, we prove the local stability of optimizing the simple gradient penalty $\mu$-WGAN(SGP $\mu$-WGAN) under suitable assumptions regarding the equilibrium and penalty measure $\mu$., The measure valued differentiation concept is employed to deal with the derivative of the penalty terms, which is helpful for handling abstract singular measures with lower dimensional support., Based on this analysis, we claim that penalizing the data manifold or sample manifold is the key to regularizing the original WGAN with a gradient penalty., Experimental results obtained with unintuitive penalty measures that satisfy our assumptions are also provided to support our theoretical results.",9,6.053030303030303,14.666666666666666
251,"['We present Random Partition Relaxation (RPR), a method for strong quantization of the parameters of convolutional neural networks to binary (+1/-1) and ternary (+1/0/-1) values.', 'Starting from a pretrained model, we first quantize the weights and then relax random partitions of them to their continuous values for retraining before quantizing them again and switching to another weight partition for further adaptation.  ', 'We empirically evaluate the performance of RPR with ResNet-18, ResNet-50 and GoogLeNet on the ImageNet classification task for binary and ternary weight networks.', 'We show accuracies beyond the state-of-the-art for binary- and ternary-weight GoogLeNet and competitive performance for ResNet-18 and ResNet-50 using a SGD-based training method that can easily be integrated into existing frameworks.']","[0, 0, 1, 0]","[0.3414634168148041, 0.19999998807907104, 0.42105263471603394, 0.17777776718139648]",S1lvWeBFwB,"['State-of-the-art training method for binary and ternary weight networks based on alternating optimization of randomly relaxed weight partitions', 'The paper proposes a new training scheme of optimizing a ternary neural network.', 'Authors propose RPR, a way to randomly partition and quantize weights and train the remaining parameters followed by relaxation in alternate cycles to train quantized models.']","['present random partition relaxation  rpr   method strong quantization parameter convolutional neural network binary  11  ternary  101  value ', 'starting pretrained model  first quantize weight relax random partition continuous value retraining quantizing switching another weight partition adaptation ', 'empirically evaluate performance rpr resnet18  resnet50 googlenet imagenet classification task binary ternary weight network ', 'show accuracy beyond stateoftheart binary ternaryweight googlenet competitive performance resnet18 resnet50 using sgdbased training method easily integrated existing framework ']","We present Random Partition Relaxation (RPR), a method for strong quantization of the parameters of convolutional neural networks to binary (+1/-1) and ternary (+1/0/-1) values., Starting from a pretrained model, we first quantize the weights and then relax random partitions of them to their continuous values for retraining before quantizing them again and switching to another weight partition for further adaptation.  , We empirically evaluate the performance of RPR with ResNet-18, ResNet-50 and GoogLeNet on the ImageNet classification task for binary and ternary weight networks., We show accuracies beyond the state-of-the-art for binary- and ternary-weight GoogLeNet and competitive performance for ResNet-18 and ResNet-50 using a SGD-based training method that can easily be integrated into existing frameworks.",7,6.078260869565217,16.428571428571427
252,"['Learning long-term dependencies is a key long-standing challenge of recurrent neural networks (RNNs).', 'Hierarchical recurrent neural networks (HRNNs) have been considered a promising approach as long-term dependencies are resolved through shortcuts up and down the hierarchy.', 'Yet, the memory requirements of Truncated Backpropagation Through Time (TBPTT) still prevent training them on very long sequences.', 'In this paper, we empirically show that in (deep) HRNNs, propagating gradients back from higher to lower levels can be replaced by locally computable losses, without harming the learning capability of the network, over a wide range of tasks.', 'This decoupling by local losses reduces the memory requirements of training by a factor exponential in the depth of the hierarchy in comparison to standard TBPTT.']","[0, 0, 0, 1, 0]","[0.0, 0.04347825422883034, 0.09756097197532654, 0.2666666507720947, 0.1818181723356247]",S1lNWertDr,"[""We replace some gradients paths in hierarchical RNN's by an auxiliary loss. We show that this can reduce the memory cost while preserving performance."", 'The paper introduces a hierarchical RNN architecture that could be trained more memory efficiently.', 'The proposed paper suggests to decouple the different layers of hierarchy in RNN using auxiliary losses.']","['learning longterm dependency key longstanding challenge recurrent neural network  rnns  ', 'hierarchical recurrent neural network  hrnns  considered promising approach longterm dependency resolved shortcut hierarchy ', 'yet  memory requirement truncated backpropagation time  tbptt  still prevent training long sequence ', 'paper  empirically show  deep  hrnns  propagating gradient back higher lower level replaced locally computable loss  without harming learning capability network  wide range task ', 'decoupling local loss reduces memory requirement training factor exponential depth hierarchy comparison standard tbptt ']","Learning long-term dependencies is a key long-standing challenge of recurrent neural networks (RNNs)., Hierarchical recurrent neural networks (HRNNs) have been considered a promising approach as long-term dependencies are resolved through shortcuts up and down the hierarchy., Yet, the memory requirements of Truncated Backpropagation Through Time (TBPTT) still prevent training them on very long sequences., In this paper, we empirically show that in (deep) HRNNs, propagating gradients back from higher to lower levels can be replaced by locally computable losses, without harming the learning capability of the network, over a wide range of tasks., This decoupling by local losses reduces the memory requirements of training by a factor exponential in the depth of the hierarchy in comparison to standard TBPTT.",10,5.773109243697479,11.9
253,"['In a typical deep learning approach to a computer vision task, Convolutional Neural Networks (CNNs) are used to extract features at varying levels of abstraction from an image and compress a high dimensional input into a lower dimensional decision space through a series of transformations.', 'In this paper, we investigate how a class of input images is eventually compressed over the course of these transformations.', 'In particular, we use singular value decomposition to analyze the relevant variations in feature space.', 'These variations are formalized as the effective dimension of the embedding.', 'We consider how the effective dimension varies across layers within class.', 'We show that across datasets and architectures, the effective dimension of a class increases before decreasing further into the network, suggesting some sort of initial whitening transformation.', 'Further, the decrease rate of the effective dimension deeper in the network corresponds with training performance of the model.']","[0, 0, 0, 0, 0, 1, 0]","[0.13793103396892548, 0.10256409645080566, 0.0, 0.06666666269302368, 0.0, 0.2222222238779068, 0.05714285373687744]",HJGsj13qTE,['Neural networks that do a good job of classification project points into more spherical shapes before compressing them into fewer dimensions.'],"['typical deep learning approach computer vision task  convolutional neural network  cnns  used extract feature varying level abstraction image compress high dimensional input lower dimensional decision space series transformation ', 'paper  investigate class input image eventually compressed course transformation ', 'particular  use singular value decomposition analyze relevant variation feature space ', 'variation formalized effective dimension embedding ', 'consider effective dimension varies across layer within class ', 'show across datasets architecture  effective dimension class increase decreasing network  suggesting sort initial whitening transformation ', ' decrease rate effective dimension deeper network corresponds training performance model ']","In a typical deep learning approach to a computer vision task, Convolutional Neural Networks (CNNs) are used to extract features at varying levels of abstraction from an image and compress a high dimensional input into a lower dimensional decision space through a series of transformations., In this paper, we investigate how a class of input images is eventually compressed over the course of these transformations., In particular, we use singular value decomposition to analyze the relevant variations in feature space., These variations are formalized as the effective dimension of the embedding., We consider how the effective dimension varies across layers within class., We show that across datasets and architectures, the effective dimension of a class increases before decreasing further into the network, suggesting some sort of initial whitening transformation., Further, the decrease rate of the effective dimension deeper in the network corresponds with training performance of the model.",13,5.6824324324324325,11.384615384615385
254,"['Deep learning methods have achieved high performance in sound recognition tasks.', 'Deciding how to feed the training data is important for further performance improvement.', 'We propose a novel learning method for deep sound recognition: Between-Class learning (BC learning).', 'Our strategy is to learn a discriminative feature space by recognizing the between-class sounds as between-class sounds.', 'We generate between-class sounds by mixing two sounds belonging to different classes with a random ratio.', 'We then input the mixed sound to the model and train the model to output the mixing ratio.', 'The advantages of BC learning are not limited only to the increase in variation of the training data; BC learning leads to an enlargement of Fishers criterion in the feature space and a regularization of the positional relationship among the feature distributions of the classes.', 'The experimental results show that BC learning improves the performance on various sound recognition networks, datasets, and data augmentation schemes, in which BC learning proves to be always beneficial.', 'Furthermore, we construct a new deep sound recognition network (EnvNet-v2) and train it with BC learning.', 'As a result, we achieved a performance surpasses the human level.']","[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.260869562625885, 0.07999999821186066, 0.6399999856948853, 0.0, 0.07407406717538834, 0.1599999964237213, 0.1395348757505417, 0.20512820780277252, 0.3571428656578064, 0.0]",B1Gi6LeRZ,"['We propose an novel learning method for deep sound recognition named BC learning.', 'Authors defined a new learning task that requires a DNN to predict mixing ratio between sounds from two different classes to increase discriminitive power of the final learned network.', 'Proposes a method to improve the performance of a generic learning method by generating ""in between class"" training samples and presents the basic intuition and necessity of the proposed technique.']","['deep learning method achieved high performance sound recognition task ', 'deciding feed training data important performance improvement ', 'propose novel learning method deep sound recognition  betweenclass learning  bc learning  ', 'strategy learn discriminative feature space recognizing betweenclass sound betweenclass sound ', 'generate betweenclass sound mixing two sound belonging different class random ratio ', 'input mixed sound model train model output mixing ratio ', 'advantage bc learning limited increase variation training data  bc learning lead enlargement fisher  criterion feature space regularization positional relationship among feature distribution class ', 'experimental result show bc learning improves performance various sound recognition network  datasets  data augmentation scheme  bc learning prof always beneficial ', 'furthermore  construct new deep sound recognition network  envnetv2  train bc learning ', 'result  achieved performance surpasses human level ']","Deep learning methods have achieved high performance in sound recognition tasks., Deciding how to feed the training data is important for further performance improvement., We propose a novel learning method for deep sound recognition: Between-Class learning (BC learning)., Our strategy is to learn a discriminative feature space by recognizing the between-class sounds as between-class sounds., We generate between-class sounds by mixing two sounds belonging to different classes with a random ratio., We then input the mixed sound to the model and train the model to output the mixing ratio., The advantages of BC learning are not limited only to the increase in variation of the training data; BC learning leads to an enlargement of Fishers criterion in the feature space and a regularization of the positional relationship among the feature distributions of the classes., The experimental results show that BC learning improves the performance on various sound recognition networks, datasets, and data augmentation schemes, in which BC learning proves to be always beneficial., Furthermore, we construct a new deep sound recognition network (EnvNet-v2) and train it with BC learning., As a result, we achieved a performance surpasses the human level.",15,5.536842105263158,12.666666666666666
255,"['Spatiotemporal forecasting has become an increasingly important prediction task in machine learning and statistics due to its vast applications, such as climate modeling, traffic prediction, video caching predictions, and so on.', 'While numerous studies have been conducted, most existing works assume that the data from different sources or across different locations are equally reliable.', 'Due to cost, accessibility, or other factors, it is inevitable that the data quality could vary, which introduces significant biases into the model and leads to unreliable prediction results.', 'The problem could be exacerbated in black-box prediction models, such as deep neural networks.', 'In this paper, we propose a novel solution that can automatically infer data quality levels of different sources through local variations of spatiotemporal signals without explicit labels.', 'Furthermore, we integrate the estimate of data quality level with graph convolutional networks to exploit their efficient structures.', 'We evaluate our proposed method on forecasting temperatures in Los Angeles.']","[0, 0, 0, 0, 1, 0, 0]","[0.0416666604578495, 0.14999999105930328, 0.17777776718139648, 0.0, 0.3636363446712494, 0.2222222238779068, 0.20689654350280762]",ByJIWUnpW,"['We propose a method that infers the time-varying data quality level for spatiotemporal forecasting without explicitly assigned labels.', 'Introduces a new definition of data quality that relies on the notion of local variation defined in (Zhou and Scholkopf) and extends it to multiple heterogenous data sources.', 'This work proposed a new way to evaluate the quality of different data sources with the time-vary graph model, with the quality level used as a regularization term in the objective function']","['spatiotemporal forecasting become increasingly important prediction task machine learning statistic due vast application  climate modeling  traffic prediction  video caching prediction  ', 'numerous study conducted  existing work assume data different source across different location equally reliable ', 'due cost  accessibility  factor  inevitable data quality could vary  introduces significant bias model lead unreliable prediction result ', 'problem could exacerbated blackbox prediction model  deep neural network ', 'paper  propose novel solution automatically infer data quality level different source local variation spatiotemporal signal without explicit label ', 'furthermore  integrate estimate data quality level graph convolutional network exploit efficient structure ', 'evaluate proposed method forecasting temperature los angeles ']","Spatiotemporal forecasting has become an increasingly important prediction task in machine learning and statistics due to its vast applications, such as climate modeling, traffic prediction, video caching predictions, and so on., While numerous studies have been conducted, most existing works assume that the data from different sources or across different locations are equally reliable., Due to cost, accessibility, or other factors, it is inevitable that the data quality could vary, which introduces significant biases into the model and leads to unreliable prediction results., The problem could be exacerbated in black-box prediction models, such as deep neural networks., In this paper, we propose a novel solution that can automatically infer data quality levels of different sources through local variations of spatiotemporal signals without explicit labels., Furthermore, we integrate the estimate of data quality level with graph convolutional networks to exploit their efficient structures., We evaluate our proposed method on forecasting temperatures in Los Angeles.",19,5.947712418300654,8.052631578947368
256,"['Human perception of 3D shapes goes beyond reconstructing them as a set of points or a composition of geometric primitives: we also effortlessly understand higher-level shape structure such as the repetition and reflective symmetry of object parts.', 'In contrast, recent advances in 3D shape sensing focus more on low-level geometry but less on these higher-level relationships.', 'In this paper, we propose 3D shape programs, integrating bottom-up recognition systems with top-down, symbolic program structure to capture both low-level geometry and high-level structural priors for 3D shapes.', 'Because there are no annotations of shape programs for real shapes, we develop neural modules that not only learn to infer 3D shape programs from raw, unannotated shapes, but also to execute these programs for shape reconstruction.', 'After initial bootstrapping, our end-to-end differentiable model learns 3D shape programs by reconstructing shapes in a self-supervised manner.', 'Experiments demonstrate that our model accurately infers and executes 3D shape programs for highly complex shapes from various categories.', 'It can also be integrated with an image-to-shape module to infer 3D shape programs directly from an RGB image, leading to 3D shape reconstructions that are both more accurate and more physically plausible.']","[0, 0, 0, 0, 1, 0, 0]","[0.19607841968536377, 0.10810810327529907, 0.2978723347187042, 0.2448979616165161, 0.37837836146354675, 0.31578946113586426, 0.25531914830207825]",rylNH20qFQ,"['We propose 3D shape programs, a structured, compositional shape representation. Our model learns to infer and execute shape programs to explain 3D shapes.', 'An approach to infer shape programs given 3D models, with architecture consisting of a recurrent network that encodes a 3D shape and outputs instructions, and a second module that renders the program to 3D.', 'This paper introduces a high-level semantic description for 3D shapes, given by the ShapeProgram.']","['human perception 3d shape go beyond reconstructing set point composition geometric primitive  also effortlessly understand higherlevel shape structure repetition reflective symmetry object part ', 'contrast  recent advance 3d shape sensing focus lowlevel geometry le higherlevel relationship ', 'paper  propose 3d shape program  integrating bottomup recognition system topdown  symbolic program structure capture lowlevel geometry highlevel structural prior 3d shape ', 'annotation shape program real shape  develop neural module learn infer 3d shape program raw  unannotated shape  also execute program shape reconstruction ', 'initial bootstrapping  endtoend differentiable model learns 3d shape program reconstructing shape selfsupervised manner ', 'experiment demonstrate model accurately infers executes 3d shape program highly complex shape various category ', 'also integrated imagetoshape module infer 3d shape program directly rgb image  leading 3d shape reconstruction accurate physically plausible ']","Human perception of 3D shapes goes beyond reconstructing them as a set of points or a composition of geometric primitives: we also effortlessly understand higher-level shape structure such as the repetition and reflective symmetry of object parts., In contrast, recent advances in 3D shape sensing focus more on low-level geometry but less on these higher-level relationships., In this paper, we propose 3D shape programs, integrating bottom-up recognition systems with top-down, symbolic program structure to capture both low-level geometry and high-level structural priors for 3D shapes., Because there are no annotations of shape programs for real shapes, we develop neural modules that not only learn to infer 3D shape programs from raw, unannotated shapes, but also to execute these programs for shape reconstruction., After initial bootstrapping, our end-to-end differentiable model learns 3D shape programs by reconstructing shapes in a self-supervised manner., Experiments demonstrate that our model accurately infers and executes 3D shape programs for highly complex shapes from various categories., It can also be integrated with an image-to-shape module to infer 3D shape programs directly from an RGB image, leading to 3D shape reconstructions that are both more accurate and more physically plausible.",16,5.770833333333333,12.0
257,"['Deep Reinforcement Learning (Deep RL) has been receiving increasingly more attention  thanks to its encouraging performance on a variety of control tasks.', 'Yet, conventional regularization techniques in training neural networks (e.g., $L_2$ regularization, dropout) have been largely ignored in RL methods, possibly because agents are typically trained and evaluated in the same environment.', 'In this work, we present the first comprehensive study of regularization techniques with multiple policy optimization algorithms on continuous control tasks.', 'Interestingly, we find conventional regularization techniques on the policy networks can often bring large improvement on the task performance, and the improvement is typically more significant when the task is more difficult.', 'We also compare with the widely used entropy regularization and find $L_2$ regularization is generally better.', 'Our findings are further confirmed to be robust against the choice of training hyperparameters.', 'We also study the effects of regularizing different components and find that only regularizing the policy network is typically enough.', 'We hope our study provides guidance for future practices in regularizing policy optimization algorithms.']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.04255318641662598, 0.4285714328289032, 0.1304347813129425, 0.16326530277729034, 0.09999999403953552, 0.05128204822540283, 0.1395348757505417, 0.20512820780277252]",B1lqDertwr,"['We show that conventional regularization methods (e.g., $L_2$, dropout), which have been largely ignored in RL methods, can be very effective in policy optimization.', 'The authors study a set of existing direct policy optimization methods in the field of reinforcement learning and provide a detailed investigation on the effect of regulations on the performance and behavior of agents following these methods.', 'This paper provides a study on the effect of regularization on performance in training environments in policy optimization methods in multiple continuous control tasks.']","['deep reinforcement learning  deep rl  receiving increasingly attention thanks encouraging performance variety control task ', 'yet  conventional regularization technique training neural network  eg   l2  regularization  dropout  largely ignored rl method  possibly agent typically trained evaluated environment ', 'work  present first comprehensive study regularization technique multiple policy optimization algorithm continuous control task ', 'interestingly  find conventional regularization technique policy network often bring large improvement task performance  improvement typically significant task difficult ', 'also compare widely used entropy regularization find  l2  regularization generally better ', 'finding confirmed robust choice training hyperparameters ', 'also study effect regularizing different component find regularizing policy network typically enough ', 'hope study provides guidance future practice regularizing policy optimization algorithm ']","Deep Reinforcement Learning (Deep RL) has been receiving increasingly more attention  thanks to its encouraging performance on a variety of control tasks., Yet, conventional regularization techniques in training neural networks (e.g., $L_2$ regularization, dropout) have been largely ignored in RL methods, possibly because agents are typically trained and evaluated in the same environment., In this work, we present the first comprehensive study of regularization techniques with multiple policy optimization algorithms on continuous control tasks., Interestingly, we find conventional regularization techniques on the policy networks can often bring large improvement on the task performance, and the improvement is typically more significant when the task is more difficult., We also compare with the widely used entropy regularization and find $L_2$ regularization is generally better., Our findings are further confirmed to be robust against the choice of training hyperparameters., We also study the effects of regularizing different components and find that only regularizing the policy network is typically enough., We hope our study provides guidance for future practices in regularizing policy optimization algorithms.",15,6.147058823529412,11.333333333333334
258,"['We introduce FigureQA, a visual reasoning corpus of over one million question-answer pairs grounded in over 100,000 images.', 'The images are synthetic, scientific-style figures from five classes: line plots, dot-line plots, vertical and horizontal bar graphs, and pie charts.', 'We formulate our reasoning task by generating questions from 15 templates; questions concern various relationships between plot elements and examine characteristics like the maximum, the minimum, area-under-the-curve, smoothness, and intersection.', 'To resolve, such questions often require reference to multiple plot elements and synthesis of information distributed spatially throughout a figure.', 'To facilitate the training of machine learning systems, the corpus also includes side data that can be used to formulate auxiliary objectives.', 'In particular, we provide the numerical data used to generate each figure as well as bounding-box annotations for all plot elements.', 'We study the proposed visual reasoning task by training several models, including the recently proposed Relation Network as strong baseline.', 'Preliminary results indicate that the task poses a significant machine learning challenge.', 'We envision FigureQA as a first step towards developing models that can intuitively recognize patterns from visual representations of data.']","[0, 0, 0, 0, 0, 0, 0, 0, 1]","[0.25641024112701416, 0.04878048226237297, 0.08163265138864517, 0.0952380895614624, 0.1860465109348297, 0.0952380895614624, 0.14999999105930328, 0.11764705181121826, 0.8571428656578064]",SyunbfbAb,"['We present a question-answering dataset, FigureQA, as a first step towards developing models that can intuitively recognize patterns from visual representations of data.', 'This paper introduces a dataset of templated question answering on figures, involving reasoning about figure elements.', 'The paper introduces a new visual reasoning dataset called Figure-QA which consists of 140K figure images and 1.55M QA pairs, which can help in developing models that can extract useful information from visual representations of data.']","['introduce figureqa  visual reasoning corpus one million questionanswer pair grounded 100000 image ', 'image synthetic  scientificstyle figure five class  line plot  dotline plot  vertical horizontal bar graph  pie chart ', 'formulate reasoning task generating question 15 template  question concern various relationship plot element examine characteristic like maximum  minimum  areaunderthecurve  smoothness  intersection ', 'resolve  question often require reference multiple plot element synthesis information distributed spatially throughout figure ', 'facilitate training machine learning system  corpus also includes side data used formulate auxiliary objective ', 'particular  provide numerical data used generate figure well boundingbox annotation plot element ', 'study proposed visual reasoning task training several model  including recently proposed relation network strong baseline ', 'preliminary result indicate task pose significant machine learning challenge ', 'envision figureqa first step towards developing model intuitively recognize pattern visual representation data ']","We introduce FigureQA, a visual reasoning corpus of over one million question-answer pairs grounded in over 100,000 images., The images are synthetic, scientific-style figures from five classes: line plots, dot-line plots, vertical and horizontal bar graphs, and pie charts., We formulate our reasoning task by generating questions from 15 templates; questions concern various relationships between plot elements and examine characteristics like the maximum, the minimum, area-under-the-curve, smoothness, and intersection., To resolve, such questions often require reference to multiple plot elements and synthesis of information distributed spatially throughout a figure., To facilitate the training of machine learning systems, the corpus also includes side data that can be used to formulate auxiliary objectives., In particular, we provide the numerical data used to generate each figure as well as bounding-box annotations for all plot elements., We study the proposed visual reasoning task by training several models, including the recently proposed Relation Network as strong baseline., Preliminary results indicate that the task poses a significant machine learning challenge., We envision FigureQA as a first step towards developing models that can intuitively recognize patterns from visual representations of data.",22,6.0978260869565215,8.363636363636363
259,"['In this paper, I discuss some varieties of explanation that can arise\n', 'in intelligent agents.', 'I distinguish between process accounts, which\n', 'address the detailed decisions made during heuristic search, and\n', 'preference accounts, which clarify the ordering of alternatives\n', 'independent of how they were generated.', 'I also hypothesize \n', 'which types of users will appreciate which types of explanation.\n', 'In addition, I discuss three facets of multi-step decision making\n', '-- conceptual inference, plan generation, and plan execution --\n', 'in which explanations can arise.', 'I also consider alternative ways\n', 'to present questions to agents and for them provide their answers.\n']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.3333333432674408, 0.0952380895614624, 0.0, 0.07407406717538834, 0.07692307233810425, 0.0833333283662796, 0.0, 0.307692289352417, 0.0714285671710968, 0.07999999821186066, 0.260869562625885, 0.0, 0.13793103396892548]",rkg7Va3Xq4,"['This position paper analyzes different types of self explanation that can arise in planning and related systems. ', 'Discusses different aspects of explanations, particularly in the context of sequential decision making. ']","['paper  discus variety explanation arise', 'intelligent agent ', 'distinguish process account ', 'address detailed decision made heuristic search ', 'preference account  clarify ordering alternative', 'independent generated ', 'also hypothesize', 'type user appreciate type explanation ', 'addition  discus three facet multistep decision making', ' conceptual inference  plan generation  plan execution ', 'explanation arise ', 'also consider alternative way', 'present question agent provide answer ']","In this paper, I discuss some varieties of explanation that can arise
, in intelligent agents., I distinguish between process accounts, which
, address the detailed decisions made during heuristic search, and
, preference accounts, which clarify the ordering of alternatives
, independent of how they were generated., I also hypothesize 
, which types of users will appreciate which types of explanation.
, In addition, I discuss three facets of multi-step decision making
, -- conceptual inference, plan generation, and plan execution --
, in which explanations can arise., I also consider alternative ways
, to present questions to agents and for them provide their answers.
",20,5.680412371134021,4.85
260,"['Generative deep learning has sparked a new wave of Super-Resolution (SR) algorithms that enhance single images with impressive aesthetic results, albeit with imaginary details.', 'Multi-frame Super-Resolution (MFSR) offers a more grounded approach to the ill-posed problem, by conditioning on multiple low-resolution views.', 'This is important for satellite monitoring of human impact on the planet -- from deforestation, to human rights violations -- that depend on reliable imagery.', 'To this end, we present HighRes-net, the first deep learning approach to MFSR that learns its sub-tasks in an end-to-end fashion:', '(i) co-registration,', '(ii) fusion,', '(iii) up-sampling, and', '(iv) registration-at-the-loss.', 'Co-registration of low-res views is learned implicitly through a reference-frame channel, with no explicit registration mechanism.', 'We learn a global fusion operator that is applied recursively on an arbitrary number of low-res pairs.', 'We introduce a registered loss, by learning to align the SR output to a ground-truth through ShiftNet.', 'We show that by learning deep representations of multiple views, we can super-resolve low-resolution signals and enhance Earth observation data at scale.', ""Our approach recently topped the European Space Agency's MFSR competition on real-world satellite imagery.""]","[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.10526315122842789, 0.12121211737394333, 0.05405404791235924, 0.5, 0.0, 0.0, 0.0624999962747097, 0.13333332538604736, 0.10810810327529907, 0.13793103396892548]",HJxJ2h4tPr,"['The first deep learning approach to MFSR to solve registration, fusion, up-sampling in an end-to-end manner.', ""This paper proposes an end-to-end multi-frame super-resolution algorithm, that relies on a pair-wise co-registrations and fusing blocks (convolutional residual blocks), embedded in a encoder-decoder network 'HighRes-net' that estimates the super-resolution image."", 'This paper proposes a framework including recursive fusion to co-registration loss to solve the problem of super-resolution results and high-resolution labels not being pixel aligned.']","['generative deep learning sparked new wave superresolution  sr  algorithm enhance single image impressive aesthetic result  albeit imaginary detail ', 'multiframe superresolution  mfsr  offer grounded approach illposed problem  conditioning multiple lowresolution view ', 'important satellite monitoring human impact planet  deforestation  human right violation  depend reliable imagery ', 'end  present highresnet  first deep learning approach mfsr learns subtasks endtoend fashion ', '  coregistration ', ' ii  fusion ', ' iii  upsampling ', ' iv  registrationattheloss ', 'coregistration lowres view learned implicitly referenceframe channel  explicit registration mechanism ', 'learn global fusion operator applied recursively arbitrary number lowres pair ', 'introduce registered loss  learning align sr output groundtruth shiftnet ', 'show learning deep representation multiple view  superresolve lowresolution signal enhance earth observation data scale ', 'approach recently topped european space agency mfsr competition realworld satellite imagery ']","Generative deep learning has sparked a new wave of Super-Resolution (SR) algorithms that enhance single images with impressive aesthetic results, albeit with imaginary details., Multi-frame Super-Resolution (MFSR) offers a more grounded approach to the ill-posed problem, by conditioning on multiple low-resolution views., This is important for satellite monitoring of human impact on the planet -- from deforestation, to human rights violations -- that depend on reliable imagery., To this end, we present HighRes-net, the first deep learning approach to MFSR that learns its sub-tasks in an end-to-end fashion:, (i) co-registration,, (ii) fusion,, (iii) up-sampling, and, (iv) registration-at-the-loss., Co-registration of low-res views is learned implicitly through a reference-frame channel, with no explicit registration mechanism., We learn a global fusion operator that is applied recursively on an arbitrary number of low-res pairs., We introduce a registered loss, by learning to align the SR output to a ground-truth through ShiftNet., We show that by learning deep representations of multiple views, we can super-resolve low-resolution signals and enhance Earth observation data at scale., Our approach recently topped the European Space Agency's MFSR competition on real-world satellite imagery.",22,6.032786885245901,8.318181818181818
261,"['Large mini-batch parallel SGD is commonly used for distributed training of deep networks.', 'Approaches that use tightly-coupled exact distributed averaging based on AllReduce are sensitive to slow nodes and high-latency communication.', 'In this work we show the applicability of Stochastic Gradient Push (SGP) for distributed training.', 'SGP uses a gossip algorithm called PushSum for approximate distributed averaging, allowing for much more loosely coupled communications which can be beneficial in high-latency or high-variability scenarios.', 'The tradeoff is that approximate distributed averaging injects additional noise in the gradient which can affect the train and test accuracies.', 'We prove that SGP converges to a stationary point of smooth, non-convex objective functions.', 'Furthermore, we validate empirically the potential of SGP.', 'For example, using 32 nodes with 8 GPUs per node to train ResNet-50 on ImageNet, where nodes communicate over 10Gbps Ethernet, SGP completes 90 epochs in around 1.5 hours while AllReduce SGD takes over 5 hours, and the top-1 validation accuracy of SGP remains within 1.2% of that obtained using AllReduce SGD.']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.20689654350280762, 0.3529411852359772, 0.19354838132858276, 0.1428571343421936, 0.1666666567325592, 0.06666666269302368, 0.0833333283662796, 0.13114753365516663]",HkgSk2A9Y7,"['For distributed training over high-latency networks, use gossip-based approximate distributed averaging instead of exact distribute averaging like AllReduce.', 'The authors propose using gossip algorithms as a general method of computing approximate average over a set of workers approximately', 'The paper proves the convergence of SGP for nonconvex smooth functions and shows the SGP can achieve a significant speed-up in the low-latency environment without sacrificing too much predictive performance. ']","['large minibatch parallel sgd commonly used distributed training deep network ', 'approach use tightlycoupled exact distributed averaging based allreduce sensitive slow node highlatency communication ', 'work show applicability stochastic gradient push  sgp  distributed training ', 'sgp us gossip algorithm called pushsum approximate distributed averaging  allowing much loosely coupled communication beneficial highlatency highvariability scenario ', 'tradeoff approximate distributed averaging injects additional noise gradient affect train test accuracy ', 'prove sgp converges stationary point smooth  nonconvex objective function ', 'furthermore  validate empirically potential sgp ', 'example  using 32 node 8 gpus per node train resnet50 imagenet  node communicate 10gbps ethernet  sgp completes 90 epoch around 15 hour allreduce sgd take 5 hour  top1 validation accuracy sgp remains within 12  obtained using allreduce sgd ']","Large mini-batch parallel SGD is commonly used for distributed training of deep networks., Approaches that use tightly-coupled exact distributed averaging based on AllReduce are sensitive to slow nodes and high-latency communication., In this work we show the applicability of Stochastic Gradient Push (SGP) for distributed training., SGP uses a gossip algorithm called PushSum for approximate distributed averaging, allowing for much more loosely coupled communications which can be beneficial in high-latency or high-variability scenarios., The tradeoff is that approximate distributed averaging injects additional noise in the gradient which can affect the train and test accuracies., We prove that SGP converges to a stationary point of smooth, non-convex objective functions., Furthermore, we validate empirically the potential of SGP., For example, using 32 nodes with 8 GPUs per node to train ResNet-50 on ImageNet, where nodes communicate over 10Gbps Ethernet, SGP completes 90 epochs in around 1.5 hours while AllReduce SGD takes over 5 hours, and the top-1 validation accuracy of SGP remains within 1.2% of that obtained using AllReduce SGD.",15,5.773809523809524,11.2
262,"['In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq) neural network conversation model to a multi-turn dialogue scenario by modifying the state-of-the-art hredGAN architecture to simultaneously capture utterance attributes such as speaker identity, dialogue topic, speaker sentiments and so on.', 'The proposed system, phredGAN has a persona-based HRED generator (PHRED) and a conditional discriminator.', 'We also explore two approaches to accomplish the conditional discriminator: (1) $phredGAN_a$, a system that passes the attribute representation as an additional input into a traditional adversarial discriminator, and (2) $phredGAN_d$, a dual discriminator system which in addition to the adversarial discriminator, collaboratively predicts the attribute(s) that generated the input utterance.', 'To demonstrate the superior performance of phredGAN over the persona SeqSeq model, we experiment with two conversational datasets, the Ubuntu Dialogue Corpus (UDC) and TV series transcripts from the Big Bang Theory and Friends.', 'Performance comparison is made with respect to a variety of quantitative measures as well as crowd-sourced human evaluation.', 'We also explore the trade-offs from using either variant of $phredGAN$ on datasets with many but weak attribute modalities (such as with Big Bang Theory and Friends) and ones with few but strong attribute modalities (customer-agent interactions in Ubuntu dataset).']","[0, 0, 0, 1, 0, 0]","[0.08163265138864517, 0.0, 0.07692307233810425, 0.09302324801683426, 0.06666666269302368, 0.04255318641662598]",rkeYUsRqKQ,"['This paper develops an adversarial learning framework for neural conversation models with persona', 'This paper proposes an extension to hredGAN to simultaneously learn a set of attribute embeddings that represent the persona of each speaker and generate persona-based responses']","['paper  extend personabased sequencetosequence  seq2seq  neural network conversation model multiturn dialogue scenario modifying stateoftheart hredgan architecture simultaneously capture utterance attribute speaker identity  dialogue topic  speaker sentiment ', 'proposed system  phredgan personabased hred generator  phred  conditional discriminator ', 'also explore two approach accomplish conditional discriminator   1   phredgana   system pass attribute representation additional input traditional adversarial discriminator   2   phredgand   dual discriminator system addition adversarial discriminator  collaboratively predicts attribute   generated input utterance ', 'demonstrate superior performance phredgan persona seqseq model  experiment two conversational datasets  ubuntu dialogue corpus  udc  tv series transcript big bang theory friend ', 'performance comparison made respect variety quantitative measure well crowdsourced human evaluation ', 'also explore tradeoff using either variant  phredgan  datasets many weak attribute modality  big bang theory friend  one strong attribute modality  customeragent interaction ubuntu dataset  ']","In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq) neural network conversation model to a multi-turn dialogue scenario by modifying the state-of-the-art hredGAN architecture to simultaneously capture utterance attributes such as speaker identity, dialogue topic, speaker sentiments and so on., The proposed system, phredGAN has a persona-based HRED generator (PHRED) and a conditional discriminator., We also explore two approaches to accomplish the conditional discriminator: (1) $phredGAN_a$, a system that passes the attribute representation as an additional input into a traditional adversarial discriminator, and (2) $phredGAN_d$, a dual discriminator system which in addition to the adversarial discriminator, collaboratively predicts the attribute(s) that generated the input utterance., To demonstrate the superior performance of phredGAN over the persona SeqSeq model, we experiment with two conversational datasets, the Ubuntu Dialogue Corpus (UDC) and TV series transcripts from the Big Bang Theory and Friends., Performance comparison is made with respect to a variety of quantitative measures as well as crowd-sourced human evaluation., We also explore the trade-offs from using either variant of $phredGAN$ on datasets with many but weak attribute modalities (such as with Big Bang Theory and Friends) and ones with few but strong attribute modalities (customer-agent interactions in Ubuntu dataset).",16,6.223350253807107,12.3125
263,"['We introduce bio-inspired artificial neural networks consisting of neurons that are additionally characterized by spatial positions.', 'To simulate properties of biological systems we add the costs penalizing long connections and the proximity of neurons in a two-dimensional space.', 'Our experiments show that in the case where the network performs two different tasks, the neurons naturally split into clusters, where each cluster is responsible for processing a different task.', 'This behavior not only corresponds to the biological systems, but also allows for further insight into interpretability or continual learning.']","[1, 0, 0, 0]","[0.3243243098258972, 0.24390242993831635, 0.21276594698429108, 0.04878048226237297]",SyxTQ7K88S,"['Bio-inspired artificial neural networks, consisting of neurons positioned in a two-dimensional space, are capable of forming independent groups for performing different tasks.']","['introduce bioinspired artificial neural network consisting neuron additionally characterized spatial position ', 'simulate property biological system add cost penalizing long connection proximity neuron twodimensional space ', 'experiment show case network performs two different task  neuron naturally split cluster  cluster responsible processing different task ', 'behavior corresponds biological system  also allows insight interpretability continual learning ']","We introduce bio-inspired artificial neural networks consisting of neurons that are additionally characterized by spatial positions., To simulate properties of biological systems we add the costs penalizing long connections and the proximity of neurons in a two-dimensional space., Our experiments show that in the case where the network performs two different tasks, the neurons naturally split into clusters, where each cluster is responsible for processing a different task., This behavior not only corresponds to the biological systems, but also allows for further insight into interpretability or continual learning.",7,6.0,12.571428571428571
264,"['The transformer has become a central model for many NLP tasks from translation to language modeling to representation learning.', 'Its success demonstrates the effectiveness of stacked attention as a replacement for recurrence for many tasks.', 'In theory attention also offers more insights into the models internal decisions; however, in practice when stacked it quickly becomes nearly as fully-connected as recurrent models.', 'In this work, we propose an alternative transformer architecture, discrete transformer, with the goal of better separating out internal model decisions.', 'The model uses hard attention to ensure that each step only depends on a fixed context.', 'Additionally, the model uses a separate syntactic controller to separate out network structure from decision making.', 'Finally we show that this approach can be further sparsified with direct regularization.', 'Empirically, this approach is able to maintain the same level of performance on several datasets, while discretizing reasoning decisions over the data.']","[0, 0, 0, 0, 1, 0, 0, 0]","[0.17142856121063232, 0.1249999925494194, 0.0476190410554409, 0.052631575614213943, 0.8484848141670227, 0.1875, 0.06666666269302368, 0.10526315122842789]",BygdR0VKDr,"['Discrete transformer which uses hard attention to ensure that each step only depends on a fixed context.', 'This paper presents modifications to the standard transformer architecture with the goal of improving interpretability while retaining performance in NLP tasks.', 'This paper proposes three Discrete Transformers: a discrete and stochastic Gumbel-softmax based attention module, a two-stream syntactic and semantic transformer, and sparsity regularization.']","['transformer become central model many nlp task translation language modeling representation learning ', 'success demonstrates effectiveness stacked attention replacement recurrence many task ', 'theory attention also offer insight model  internal decision  however  practice stacked quickly becomes nearly fullyconnected recurrent model ', 'work  propose alternative transformer architecture  discrete transformer  goal better separating internal model decision ', 'model us hard attention ensure step depends fixed context ', 'additionally  model us separate  syntactic  controller separate network structure decision making ', 'finally show approach sparsified direct regularization ', 'empirically  approach able maintain level performance several datasets  discretizing reasoning decision data ']","The transformer has become a central model for many NLP tasks from translation to language modeling to representation learning., Its success demonstrates the effectiveness of stacked attention as a replacement for recurrence for many tasks., In theory attention also offers more insights into the models internal decisions; however, in practice when stacked it quickly becomes nearly as fully-connected as recurrent models., In this work, we propose an alternative transformer architecture, discrete transformer, with the goal of better separating out internal model decisions., The model uses hard attention to ensure that each step only depends on a fixed context., Additionally, the model uses a separate syntactic controller to separate out network structure from decision making., Finally we show that this approach can be further sparsified with direct regularization., Empirically, this approach is able to maintain the same level of performance on several datasets, while discretizing reasoning decisions over the data.",15,5.825503355704698,9.933333333333334
265,"['Deep predictive coding networks are neuroscience-inspired unsupervised learning models that learn to predict future sensory states.', 'We build upon the PredNet implementation by Lotter, Kreiman, and Cox (2016) to investigate if predictive coding representations are useful to predict brain activity in the visual cortex.', 'We use representational similarity analysis (RSA) to compare PredNet representations to functional magnetic resonance imaging (fMRI) and magnetoencephalography (MEG) data from the Algonauts Project (Cichy et al., 2019).', 'In contrast to previous findings in the literature (Khaligh-Razavi & Kriegeskorte, 2014), we report empirical data suggesting that unsupervised models trained to predict frames of videos without further fine-tuning may outperform supervised image classification baselines in terms of correlation to spatial (fMRI) and temporal (MEG) data.']","[1, 0, 0, 0]","[0.2857142686843872, 0.2666666507720947, 0.1702127605676651, 0.23333333432674408]",HJgiVXY88r,['We show empirical evidence that predictive coding models yield representations more correlated to brain data than supervised image recognition models.'],"['deep predictive coding network neuroscienceinspired unsupervised learning model learn predict future sensory state ', 'build upon prednet implementation lotter  kreiman  cox  2016  investigate predictive coding representation useful predict brain activity visual cortex ', 'use representational similarity analysis  rsa  compare prednet representation functional magnetic resonance imaging  fmri  magnetoencephalography  meg  data algonauts project  cichy et al  2019  ', 'contrast previous finding literature  khalighrazavi  kriegeskorte  2014   report empirical data suggesting unsupervised model trained predict frame video without finetuning may outperform supervised image classification baseline term correlation spatial  fmri  temporal  meg  data ']","Deep predictive coding networks are neuroscience-inspired unsupervised learning models that learn to predict future sensory states., We build upon the PredNet implementation by Lotter, Kreiman, and Cox (2016) to investigate if predictive coding representations are useful to predict brain activity in the visual cortex., We use representational similarity analysis (RSA) to compare PredNet representations to functional magnetic resonance imaging (fMRI) and magnetoencephalography (MEG) data from the Algonauts Project (Cichy et al., 2019)., In contrast to previous findings in the literature (Khaligh-Razavi & Kriegeskorte, 2014), we report empirical data suggesting that unsupervised models trained to predict frames of videos without further fine-tuning may outperform supervised image classification baselines in terms of correlation to spatial (fMRI) and temporal (MEG) data.",9,6.398305084745763,13.11111111111111
266,"['The incorporation of prior knowledge into learning is essential in achieving good performance based on small noisy samples.', 'Such knowledge is often incorporated through the availability of related data arising from domains and tasks similar to the one of current interest.', 'Ideally one would like to allow both the data for the current task and for previous related tasks to self-organize the learning system in such a way that commonalities and differences between the tasks are learned in a data-driven fashion.', 'We develop a framework for learning multiple tasks simultaneously, based on sharing features that are common to all tasks, achieved through the use of a modular deep feedforward neural network consisting of shared branches, dealing with the common features of all tasks, and private branches, learning the specific unique aspects of each task.', 'Once an appropriate weight sharing architecture has been established, learning takes place through standard algorithms for feedforward networks, e.g., stochastic gradient descent and its variations.', 'The method deals with meta-learning (such as domain adaptation, transfer and multi-task learning) in a unified fashion, and can easily deal with data arising from different types of sources.', 'Numerical experiments demonstrate the effectiveness of learning in domain adaptation and transfer learning setups, and provide evidence for the flexible and task-oriented representations arising in the network.']","[0, 0, 0, 0, 0, 0, 1]","[0.11428570747375488, 0.10526315122842789, 0.1249999925494194, 0.24137930572032928, 0.13636362552642822, 0.22727271914482117, 0.2631579041481018]",S1tWRJ-R-,"['A generic framework for handling transfer and multi-task learning using pairs of autoencoders with task-specific and shared weights.', 'Proposes a generic framework for end-to-end transfer learning / domain adaptation with deep neural networks. ', 'This paper proposes a model for allowing deep neural network architectures to share parameters across different datasets, and applies it to transfer learning.', 'The paper focuses on learning common features from multiple domains data and ends up with a general architecture for multi-task, semi-supervised and transfer learning']","['incorporation prior knowledge learning essential achieving good performance based small noisy sample ', 'knowledge often incorporated availability related data arising domain task similar one current interest ', 'ideally one would like allow data current task previous related task selforganize learning system way commonality difference task learned datadriven fashion ', 'develop framework learning multiple task simultaneously  based sharing feature common task  achieved use modular deep feedforward neural network consisting shared branch  dealing common feature task  private branch  learning specific unique aspect task ', 'appropriate weight sharing architecture established  learning take place standard algorithm feedforward network  eg  stochastic gradient descent variation ', 'method deal metalearning  domain adaptation  transfer multitask learning  unified fashion  easily deal data arising different type source ', 'numerical experiment demonstrate effectiveness learning domain adaptation transfer learning setup  provide evidence flexible taskoriented representation arising network ']","The incorporation of prior knowledge into learning is essential in achieving good performance based on small noisy samples., Such knowledge is often incorporated through the availability of related data arising from domains and tasks similar to the one of current interest., Ideally one would like to allow both the data for the current task and for previous related tasks to self-organize the learning system in such a way that commonalities and differences between the tasks are learned in a data-driven fashion., We develop a framework for learning multiple tasks simultaneously, based on sharing features that are common to all tasks, achieved through the use of a modular deep feedforward neural network consisting of shared branches, dealing with the common features of all tasks, and private branches, learning the specific unique aspects of each task., Once an appropriate weight sharing architecture has been established, learning takes place through standard algorithms for feedforward networks, e.g., stochastic gradient descent and its variations., The method deals with meta-learning (such as domain adaptation, transfer and multi-task learning) in a unified fashion, and can easily deal with data arising from different types of sources., Numerical experiments demonstrate the effectiveness of learning in domain adaptation and transfer learning setups, and provide evidence for the flexible and task-oriented representations arising in the network.",18,5.730232558139535,11.944444444444445
267,"['Deep neural networks and decision trees operate on largely separate paradigms; typically, the former performs representation learning with pre-specified architectures, while the latter is characterised by learning hierarchies over pre-specified features with data-driven architectures.', 'We unite the two via adaptive neural trees (ANTs), a model that incorporates representation learning into edges, routing functions and leaf nodes of a decision tree, along with a backpropagation-based training algorithm that adaptively grows the architecture from primitive modules (e.g., convolutional layers).', 'ANTs allow increased interpretability via hierarchical clustering, e.g., learning meaningful class associations, such as separating natural vs. man-made objects.', 'We demonstrate this on classification and regression tasks, achieving over 99% and 90% accuracy on the MNIST and CIFAR-10 datasets, and outperforming standard neural networks, random forests and gradient boosted trees on the SARCOS dataset.', 'Furthermore, ANT optimisation naturally adapts the architecture to the size and complexity of the training data.']","[0, 1, 0, 0, 0]","[0.23333333432674408, 0.28169015049934387, 0.0, 0.27586206793785095, 0.1818181723356247]",ByN7Yo05YX,"['We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.', 'The authors proposed a new model, Adaptive Neural Trees, by combining the representation learning and gradient optimization of neural networks with architecture learning of decision trees', 'This paper proposes the Adaptive Neural Trees approach to combine the two learning paradigms of deep neural nets and decision trees']","['deep neural network decision tree operate largely separate paradigm  typically  former performs representation learning prespecified architecture  latter characterised learning hierarchy prespecified feature datadriven architecture ', 'unite two via adaptive neural tree  ant   model incorporates representation learning edge  routing function leaf node decision tree  along backpropagationbased training algorithm adaptively grows architecture primitive module  eg  convolutional layer  ', 'ant allow increased interpretability via hierarchical clustering  eg  learning meaningful class association  separating natural v manmade object ', 'demonstrate classification regression task  achieving 99  90  accuracy mnist cifar10 datasets  outperforming standard neural network  random forest gradient boosted tree sarcos dataset ', 'furthermore  ant optimisation naturally adapts architecture size complexity training data ']","Deep neural networks and decision trees operate on largely separate paradigms; typically, the former performs representation learning with pre-specified architectures, while the latter is characterised by learning hierarchies over pre-specified features with data-driven architectures., We unite the two via adaptive neural trees (ANTs), a model that incorporates representation learning into edges, routing functions and leaf nodes of a decision tree, along with a backpropagation-based training algorithm that adaptively grows the architecture from primitive modules (e.g., convolutional layers)., ANTs allow increased interpretability via hierarchical clustering, e.g., learning meaningful class associations, such as separating natural vs. man-made objects., We demonstrate this on classification and regression tasks, achieving over 99% and 90% accuracy on the MNIST and CIFAR-10 datasets, and outperforming standard neural networks, random forests and gradient boosted trees on the SARCOS dataset., Furthermore, ANT optimisation naturally adapts the architecture to the size and complexity of the training data.",18,6.489795918367347,8.166666666666666
268,"['While natural language processing systems often focus on a single language, multilingual transfer learning has the potential to improve performance, especially for low-resource languages. \n', 'We introduce XLDA, cross-lingual data augmentation, a method that replaces a segment of the input text with its translation in another language.', 'XLDA enhances performance of all 14 tested languages of the cross-lingual natural language inference (XNLI) benchmark.', 'With improvements of up to 4.8, training with XLDA achieves state-of-the-art performance for Greek, Turkish, and Urdu.', 'XLDA is in contrast to, and performs markedly better than, a more naive approach that aggregates examples in various languages in a way that each example is solely in one language.', 'On the SQuAD question answering task, we see that XLDA provides a 1.0 performance increase on the English evaluation set.', 'Comprehensive experiments suggest that most languages are effective as cross-lingual augmentors, that XLDA is robust to a wide range of translation quality, and that XLDA is even more effective for randomly initialized models than for pretrained models.']","[0, 0, 1, 0, 0, 0, 0]","[0.1111111044883728, 0.25, 0.307692289352417, 0.20689654350280762, 0.0, 0.12903225421905518, 0.09756097197532654]",BJgAf6Etwr,"['Translating portions of the input during training can improve cross-lingual performance.', 'The paper proposes a cross-lingual data augmentation method to improve the language inference and question answering tasks.', 'This paper proposes to augment crosslingual data with heuristic swaps using aligned translations, like bilingual humans do in code-switching.']","['natural language processing system often focus single language  multilingual transfer learning potential improve performance  especially lowresource language ', 'introduce xlda  crosslingual data augmentation  method replaces segment input text translation another language ', 'xlda enhances performance 14 tested language crosslingual natural language inference  xnli  benchmark ', 'improvement 48  training xlda achieves stateoftheart performance greek  turkish  urdu ', 'xlda contrast  performs markedly better  naive approach aggregate example various language way example solely one language ', 'squad question answering task  see xlda provides 10 performance increase english evaluation set ', 'comprehensive experiment suggest language effective crosslingual augmentors  xlda robust wide range translation quality  xlda even effective randomly initialized model pretrained model ']","While natural language processing systems often focus on a single language, multilingual transfer learning has the potential to improve performance, especially for low-resource languages. 
, We introduce XLDA, cross-lingual data augmentation, a method that replaces a segment of the input text with its translation in another language., XLDA enhances performance of all 14 tested languages of the cross-lingual natural language inference (XNLI) benchmark., With improvements of up to 4.8, training with XLDA achieves state-of-the-art performance for Greek, Turkish, and Urdu., XLDA is in contrast to, and performs markedly better than, a more naive approach that aggregates examples in various languages in a way that each example is solely in one language., On the SQuAD question answering task, we see that XLDA provides a 1.0 performance increase on the English evaluation set., Comprehensive experiments suggest that most languages are effective as cross-lingual augmentors, that XLDA is robust to a wide range of translation quality, and that XLDA is even more effective for randomly initialized models than for pretrained models.",19,5.682634730538922,8.789473684210526
269,"['Training conditional generative latent-variable models is challenging in scenarios where the conditioning signal is very strong and the decoder is expressive enough to generate a plausible output given only the condition; the generative model tends to ignore the latent variable, suffering from posterior collapse.', ' We find, and empirically show, that one of the major reasons behind posterior collapse is rooted in the way that generative models are conditioned, i.e., through concatenation of the latent variable and the condition', '. To mitigate this problem, we propose to explicitly make the latent variables depend on the condition by unifying the conditioning and latent variable sampling, thus coupling them so as to prevent the model from discarding the root of variations', '. To achieve this, we develop a conditional Variational Autoencoder architecture that learns a distribution not only of the latent variables, but also of the condition, the latter acting as prior on the former', '. Our experiments on the challenging tasks of conditional human motion prediction and image captioning demonstrate the effectiveness of our approach at avoiding posterior collapse', '. Video results of our approach are anonymously provided in http://bit.ly/iclr2020']","[1, 0, 0, 0, 0, 0]","[0.5846154093742371, 0.20338982343673706, 0.16129031777381897, 0.14035087823867798, 0.15686273574829102, 0.04999999701976776]",rJlHea4Kvr,"['We propose a conditional variational autoencoder framework that mitigates the posterior collapse in scenarios where the conditioning signal strong enough for an expressive decoder to generate a plausible output from it.', 'This paper considers strongly conditioned generative models, and proposes an objective function and a parameterisation of the variational distribution such that latent variables explicitly depend on input conditions.', 'This paper argues that when the decoder is conditioned on the concatenation of latent variables and auxiliary information, then posterior collapse is more likely than in vanilla VAE.']","['training conditional generative latentvariable model challenging scenario conditioning signal strong decoder expressive enough generate plausible output given condition  generative model tends ignore latent variable  suffering posterior collapse ', 'find  empirically show  one major reason behind posterior collapse rooted way generative model conditioned  ie  concatenation latent variable condition', ' mitigate problem  propose explicitly make latent variable depend condition unifying conditioning latent variable sampling  thus coupling prevent model discarding root variation', ' achieve  develop conditional variational autoencoder architecture learns distribution latent variable  also condition  latter acting prior former', ' experiment challenging task conditional human motion prediction image captioning demonstrate effectiveness approach avoiding posterior collapse', ' video result approach anonymously provided http  bitlyiclr2020']","Training conditional generative latent-variable models is challenging in scenarios where the conditioning signal is very strong and the decoder is expressive enough to generate a plausible output given only the condition; the generative model tends to ignore the latent variable, suffering from posterior collapse.,  We find, and empirically show, that one of the major reasons behind posterior collapse is rooted in the way that generative models are conditioned, i.e., through concatenation of the latent variable and the condition, . To mitigate this problem, we propose to explicitly make the latent variables depend on the condition by unifying the conditioning and latent variable sampling, thus coupling them so as to prevent the model from discarding the root of variations, . To achieve this, we develop a conditional Variational Autoencoder architecture that learns a distribution not only of the latent variables, but also of the condition, the latter acting as prior on the former, . Our experiments on the challenging tasks of conditional human motion prediction and image captioning demonstrate the effectiveness of our approach at avoiding posterior collapse, . Video results of our approach are anonymously provided in http://bit.ly/iclr2020",16,5.6063829787234045,9.4
270,"['We propose a study of the stability of several few-shot learning algorithms subject to variations in the hyper-parameters and optimization schemes while controlling the random seed.  ', 'We propose a methodology for testing for statistical differences in model performances under several replications.', 'To study this specific design, we attempt to reproduce results from three prominent papers: Matching Nets, Prototypical Networks, and TADAM.', 'We analyze on the miniImagenet dataset on the standard classification task in the 5-ways, 5-shots learning setting at test time.', 'We find that the selected implementations exhibit stability across random seed, and repeats.']","[1, 0, 0, 0, 0]","[0.978723406791687, 0.2702702581882477, 0.1395348757505417, 0.19999998807907104, 0.277777761220932]",B1g-SnUaUN,"['We propose a study of the stability of several few-shot learning algorithms subject to variations in the hyper-parameters and optimization schemes while controlling the random seed.', 'This paper studies reproducibility for few-shot learning.']","['propose study stability several fewshot learning algorithm subject variation hyperparameters optimization scheme controlling random seed ', 'propose methodology testing statistical difference model performance several replication ', 'study specific design  attempt reproduce result three prominent paper  matching net  prototypical network  tadam ', 'analyze miniimagenet dataset standard classification task 5ways  5shots learning setting test time ', 'find selected implementation exhibit stability across random seed  repeat ']","We propose a study of the stability of several few-shot learning algorithms subject to variations in the hyper-parameters and optimization schemes while controlling the random seed.  , We propose a methodology for testing for statistical differences in model performances under several replications., To study this specific design, we attempt to reproduce results from three prominent papers: Matching Nets, Prototypical Networks, and TADAM., We analyze on the miniImagenet dataset on the standard classification task in the 5-ways, 5-shots learning setting at test time., We find that the selected implementations exhibit stability across random seed, and repeats.",10,5.968085106382978,9.4
271,"['We study the problem of representation learning in goal-conditioned hierarchical reinforcement learning.', 'In such hierarchical structures, a higher-level controller solves tasks by iteratively communicating goals which a lower-level policy is trained to reach.', 'Accordingly, the choice of representation -- the mapping of observation space to goal space -- is crucial.', 'To study this problem, we develop a notion of sub-optimality of a representation, defined in terms of expected reward of the optimal hierarchical policy using this representation.', 'We derive expressions which bound the sub-optimality and show how these expressions can be translated to representation learning objectives which may be optimized in practice.', 'Results on a number of difficult continuous-control tasks show that our approach to representation learning yields qualitatively better representations as well as quantitatively better hierarchical policies, compared to existing methods.']","[1, 0, 0, 0, 0, 0]","[0.48275861144065857, 0.15789473056793213, 0.19354838132858276, 0.29999998211860657, 0.3499999940395355, 0.31111109256744385]",H1emus0qF7,"['We translate a bound on sub-optimality of representations to a practical training objective in the context of hierarchical reinforcement learning.', 'The authors proposes a novel approach in learning a representation for HRL and state an intriguing connection between representation learning and bounding the sub-optimality which results in a gradient based algorithm', 'This paper proposes a way to handle sub-optimality in the context of learning representations which refer to the sub-optimality of hierarchical polity with respect to the task reward.']","['study problem representation learning goalconditioned hierarchical reinforcement learning ', 'hierarchical structure  higherlevel controller solves task iteratively communicating goal lowerlevel policy trained reach ', 'accordingly  choice representation  mapping observation space goal space  crucial ', 'study problem  develop notion suboptimality representation  defined term expected reward optimal hierarchical policy using representation ', 'derive expression bound suboptimality show expression translated representation learning objective may optimized practice ', 'result number difficult continuouscontrol task show approach representation learning yield qualitatively better representation well quantitatively better hierarchical policy  compared existing method ']","We study the problem of representation learning in goal-conditioned hierarchical reinforcement learning., In such hierarchical structures, a higher-level controller solves tasks by iteratively communicating goals which a lower-level policy is trained to reach., Accordingly, the choice of representation -- the mapping of observation space to goal space -- is crucial., To study this problem, we develop a notion of sub-optimality of a representation, defined in terms of expected reward of the optimal hierarchical policy using this representation., We derive expressions which bound the sub-optimality and show how these expressions can be translated to representation learning objectives which may be optimized in practice., Results on a number of difficult continuous-control tasks show that our approach to representation learning yields qualitatively better representations as well as quantitatively better hierarchical policies, compared to existing methods.",11,6.242424242424242,12.0
272,"['Heuristic search research often deals with finding algorithms for offline planning which aim to minimize the number of expanded nodes or planning time.', 'In online planning, algorithms for real-time search or deadline-aware search have been considered before.', ""However, in this paper, we are interested in the problem of {\\em situated temporal planning} in which an agent's plan can depend on exogenous events in the external world, and thus it becomes important to take the passage of time into account during the planning process.  \n"", 'Previous work on situated temporal planning has proposed simple pruning strategies, as well as complex schemes for a simplified version of the associated metareasoning problem. \n', 'In this paper, we propose a simple metareasoning technique,  called the crude greedy scheme, which can be applied in a situated temporal planner.', 'Our empirical evaluation shows that the crude greedy scheme outperforms standard heuristic search based on cost-to-go estimates.']","[0, 0, 0, 0, 1, 0]","[0.0, 0.0, 0.043478257954120636, 0.06451612710952759, 0.1428571343421936, 0.0]",rkxwVZPpPV,"['Metareasoning in a Situated Temporal Planner', 'This paper addresses the problem of situated temporal planning, proposing a further simplification on  greedy strategies previously proposed by Shperberg.']","['heuristic search research often deal finding algorithm offline planning aim minimize number expanded node planning time ', 'online planning  algorithm realtime search deadlineaware search considered ', 'however  paper  interested problem  em situated temporal planning  agent plan depend exogenous event external world  thus becomes important take passage time account planning process ', 'previous work situated temporal planning proposed simple pruning strategy  well complex scheme simplified version associated metareasoning problem ', 'paper  propose simple metareasoning technique  called crude greedy scheme  applied situated temporal planner ', 'empirical evaluation show crude greedy scheme outperforms standard heuristic search based costtogo estimate ']","Heuristic search research often deals with finding algorithms for offline planning which aim to minimize the number of expanded nodes or planning time., In online planning, algorithms for real-time search or deadline-aware search have been considered before., However, in this paper, we are interested in the problem of {\em situated temporal planning} in which an agent's plan can depend on exogenous events in the external world, and thus it becomes important to take the passage of time into account during the planning process.  
, Previous work on situated temporal planning has proposed simple pruning strategies, as well as complex schemes for a simplified version of the associated metareasoning problem. 
, In this paper, we propose a simple metareasoning technique,  called the crude greedy scheme, which can be applied in a situated temporal planner., Our empirical evaluation shows that the crude greedy scheme outperforms standard heuristic search based on cost-to-go estimates.",14,5.574324324324325,10.571428571428571
273,"['Neural networks are vulnerable to small adversarial perturbations.', 'Existing literature largely focused on understanding and mitigating the vulnerability of learned models.', 'In this paper, we demonstrate an intriguing phenomenon about the most popular robust training method in the literature, adversarial training: Adversarial robustness, unlike clean accuracy, is sensitive to the input data distribution.', 'Even a semantics-preserving transformations on the input data distribution can cause a significantly different robustness for the adversarial trained model that is both trained and evaluated on the new distribution.', 'Our discovery of such sensitivity on data distribution is based on a study which disentangles the behaviors of clean accuracy and robust accuracy of the Bayes classifier.', 'Empirical investigations further confirm our finding.', 'We construct semantically-identical variants for MNIST and CIFAR10 respectively, and show that standardly trained models achieve comparable clean accuracies on them, but adversarially trained models achieve significantly different robustness accuracies.', 'This counter-intuitive phenomenon indicates that input data distribution alone can affect the adversarial robustness of trained neural networks, not necessarily the tasks themselves.', 'Lastly, we discuss the practical implications on evaluating adversarial robustness, and make initial attempts to understand this complex phenomenon.']","[0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.12903225421905518, 0.1666666567325592, 0.18867923319339752, 0.12765957415103912, 0.17777776718139648, 0.0, 0.0833333283662796, 0.13333332538604736, 0.0952380895614624]",S1xNEhR9KX,"['Robustness performance of PGD trained models are sensitive to semantics-preserving transformation of image datasets, which implies the trickiness of evaluation of robust learning algorithms in practice.', 'Paper clarifies the difference between clean and robust accuracy and shows that changing the marginal distribution of the input data P(x) while preserving its semantic P(y|x) affects the robustness of the model.', 'This paper investigates the origin of the lack of robustness of classifiers to perturbations of adversarial inputs under l-inf bounded perturbations.']","['neural network vulnerable small adversarial perturbation ', 'existing literature largely focused understanding mitigating vulnerability learned model ', 'paper  demonstrate intriguing phenomenon popular robust training method literature  adversarial training  adversarial robustness  unlike clean accuracy  sensitive input data distribution ', 'even semanticspreserving transformation input data distribution cause significantly different robustness adversarial trained model trained evaluated new distribution ', 'discovery sensitivity data distribution based study disentangles behavior clean accuracy robust accuracy bayes classifier ', 'empirical investigation confirm finding ', 'construct semanticallyidentical variant mnist cifar10 respectively  show standardly trained model achieve comparable clean accuracy  adversarially trained model achieve significantly different robustness accuracy ', 'counterintuitive phenomenon indicates input data distribution alone affect adversarial robustness trained neural network  necessarily task ', 'lastly  discus practical implication evaluating adversarial robustness  make initial attempt understand complex phenomenon ']","Neural networks are vulnerable to small adversarial perturbations., Existing literature largely focused on understanding and mitigating the vulnerability of learned models., In this paper, we demonstrate an intriguing phenomenon about the most popular robust training method in the literature, adversarial training: Adversarial robustness, unlike clean accuracy, is sensitive to the input data distribution., Even a semantics-preserving transformations on the input data distribution can cause a significantly different robustness for the adversarial trained model that is both trained and evaluated on the new distribution., Our discovery of such sensitivity on data distribution is based on a study which disentangles the behaviors of clean accuracy and robust accuracy of the Bayes classifier., Empirical investigations further confirm our finding., We construct semantically-identical variants for MNIST and CIFAR10 respectively, and show that standardly trained models achieve comparable clean accuracies on them, but adversarially trained models achieve significantly different robustness accuracies., This counter-intuitive phenomenon indicates that input data distribution alone can affect the adversarial robustness of trained neural networks, not necessarily the tasks themselves., Lastly, we discuss the practical implications on evaluating adversarial robustness, and make initial attempts to understand this complex phenomenon.",18,6.574468085106383,10.444444444444445
274,"[' Many tasks in natural language processing involve comparing two sentences to compute some notion of relevance, entailment, or similarity.', 'Typically this comparison is done either at the word level or at the sentence level, with no attempt to leverage the inherent structure of the sentence.', 'When sentence structure is used for comparison, it is obtained during a non-differentiable pre-processing step, leading to propagation of errors.', 'We introduce a model of structured alignments between sentences, showing how to compare two sentences by matching their latent structures.', 'Using a structured attention mechanism, our model matches possible spans in the first sentence to possible spans in the second sentence, simultaneously discovering the tree structure of each sentence and performing a comparison, in a model that is fully differentiable and is trained only on the comparison objective.', 'We evaluate this model on two sentence comparison tasks: the Stanford natural language inference dataset and the TREC-QA dataset.', 'We find that comparing spans results in superior performance to comparing words individually, and that the learned trees are consistent with actual linguistic structures.']","[0, 0, 0, 1, 0, 0, 0]","[0.10256409645080566, 0.1463414579629898, 0.10256409645080566, 0.29999998211860657, 0.145454540848732, 0.05405404791235924, 0.1428571343421936]",Byht0GbRZ,"['Matching sentences by learning the latent constituency tree structures with a variant of the inside-outside algorithm embedded as a neural network layer.', 'This paper introduces a structured attention mechanisms to compute alignment scores among all possible spans in two given sentences', 'This paper proposes a model of structured alignments between sentences as a means of comparing sentences by matching their latent structures.']","['many task natural language processing involve comparing two sentence compute notion relevance  entailment  similarity ', 'typically comparison done either word level sentence level  attempt leverage inherent structure sentence ', 'sentence structure used comparison  obtained nondifferentiable preprocessing step  leading propagation error ', 'introduce model structured alignment sentence  showing compare two sentence matching latent structure ', 'using structured attention mechanism  model match possible span first sentence possible span second sentence  simultaneously discovering tree structure sentence performing comparison  model fully differentiable trained comparison objective ', 'evaluate model two sentence comparison task  stanford natural language inference dataset trecqa dataset ', 'find comparing span result superior performance comparing word individually  learned tree consistent actual linguistic structure ']"," Many tasks in natural language processing involve comparing two sentences to compute some notion of relevance, entailment, or similarity., Typically this comparison is done either at the word level or at the sentence level, with no attempt to leverage the inherent structure of the sentence., When sentence structure is used for comparison, it is obtained during a non-differentiable pre-processing step, leading to propagation of errors., We introduce a model of structured alignments between sentences, showing how to compare two sentences by matching their latent structures., Using a structured attention mechanism, our model matches possible spans in the first sentence to possible spans in the second sentence, simultaneously discovering the tree structure of each sentence and performing a comparison, in a model that is fully differentiable and is trained only on the comparison objective., We evaluate this model on two sentence comparison tasks: the Stanford natural language inference dataset and the TREC-QA dataset., We find that comparing spans results in superior performance to comparing words individually, and that the learned trees are consistent with actual linguistic structures.",17,5.732954545454546,10.352941176470589
275,"['Learning disentangled representation from any unlabelled data is a non-trivial problem.', 'In this paper we propose Information Maximising Autoencoder (InfoAE) where the encoder learns powerful disentangled representation through maximizing the mutual information between the representation and given information in an unsupervised fashion.', 'We have evaluated our model on MNIST dataset and achieved approximately 98.9 % test accuracy while using complete unsupervised training.']","[0, 1, 0]","[0.1111111044883728, 0.23529411852359772, 0.0714285671710968]",BJxt7NmlON,"['Learn disentangle representation in an unsupervised manner.', 'The authors present a framework in which an auto encoder (E, D) is regularized such that its latent representation to share mutual information with a generated latent space representation.']","['learning disentangled representation unlabelled data nontrivial problem ', 'paper propose information maximising autoencoder  infoae  encoder learns powerful disentangled representation maximizing mutual information representation given information unsupervised fashion ', 'evaluated model mnist dataset achieved approximately 989  test accuracy using complete unsupervised training ']","Learning disentangled representation from any unlabelled data is a non-trivial problem., In this paper we propose Information Maximising Autoencoder (InfoAE) where the encoder learns powerful disentangled representation through maximizing the mutual information between the representation and given information in an unsupervised fashion., We have evaluated our model on MNIST dataset and achieved approximately 98.9 % test accuracy while using complete unsupervised training.",3,6.661290322580645,20.666666666666668
276,"['Effective training of neural networks requires much data.', 'In the low-data regime,\n', 'parameters are underdetermined, and learnt networks generalise poorly.', 'Data\n', 'Augmentation (Krizhevsky et al., 2012) alleviates this by using existing data\n', 'more effectively.', 'However standard data augmentation produces only limited\n', 'plausible alternative data.', 'Given there is potential to generate a much broader set\n', 'of augmentations, we design and train a generative model to do data augmentation.\n', 'The model, based on image conditional Generative Adversarial Networks, takes\n', 'data from a source domain and learns to take any data item and generalise it\n', 'to generate other within-class data items.', 'As this generative process does not\n', 'depend on the classes themselves, it can be applied to novel unseen classes of data.\n', 'We show that a Data Augmentation Generative Adversarial Network (DAGAN)\n', 'augments standard vanilla classifiers well.', 'We also show a DAGAN can enhance\n', 'few-shot learning systems such as Matching Networks.', 'We demonstrate these\n', 'approaches on Omniglot, on EMNIST having learnt the DAGAN on Omniglot, and\n', 'VGG-Face data.', 'In our experiments we can see over 13% increase in accuracy in\n', 'the low-data regime experiments in Omniglot (from 69% to 82%), EMNIST (73.9%\n', 'to 76%) and VGG-Face (4.5% to 12%); in Matching Networks for Omniglot we\n', 'observe an increase of 0.5% (from 96.9% to 97.4%) and an increase of 1.8% in\n', 'EMNIST (from 59.5% to 61.3%).']","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.17142856121063232, 0.0, 0.11428570747375488, 0.05128204822540283, 0.05882352590560913, 0.06666666269302368, 0.10810810327529907, 0.19512194395065308, 0.054054051637649536, 0.14999999105930328, 0.1818181723356247, 0.0, 0.1428571343421936, 0.0, 0.0624999962747097, 0.05882352590560913, 0.23529411852359772, 0.0, 0.0555555522441864, 0.0, 0.04999999701976776, 0.09999999403953552, 0.1395348757505417, 0.05882352590560913]",S1Auv-WRZ,"['Conditional GANs trained to generate data augmented samples of their conditional inputs used to enhance vanilla classification and one shot learning systems such as matching networks and pixel distance', 'The authors propose a method to conduct data augmentation where the cross-class transformations are mapped to a low dimensional latent space using conditional GAN']","['effective training neural network requires much data ', 'lowdata regime ', 'parameter underdetermined  learnt network generalise poorly ', 'data', 'augmentation  krizhevsky et al  2012  alleviates using existing data', 'effectively ', 'however standard data augmentation produce limited', 'plausible alternative data ', 'given potential generate much broader set', 'augmentation  design train generative model data augmentation ', 'model  based image conditional generative adversarial network  take', 'data source domain learns take data item generalise', 'generate withinclass data item ', 'generative process', 'depend class  applied novel unseen class data ', 'show data augmentation generative adversarial network  dagan ', 'augments standard vanilla classifier well ', 'also show dagan enhance', 'fewshot learning system matching network ', 'demonstrate', 'approach omniglot  emnist learnt dagan omniglot ', 'vggface data ', 'experiment see 13  increase accuracy', 'lowdata regime experiment omniglot  69  82    emnist  739 ', '76   vggface  45  12    matching network omniglot', 'observe increase 05   969  974   increase 18 ', 'emnist  595  613   ']","Effective training of neural networks requires much data., In the low-data regime,
, parameters are underdetermined, and learnt networks generalise poorly., Data
, Augmentation (Krizhevsky et al., 2012) alleviates this by using existing data
, more effectively., However standard data augmentation produces only limited
, plausible alternative data., Given there is potential to generate a much broader set
, of augmentations, we design and train a generative model to do data augmentation.
, The model, based on image conditional Generative Adversarial Networks, takes
, data from a source domain and learns to take any data item and generalise it
, to generate other within-class data items., As this generative process does not
, depend on the classes themselves, it can be applied to novel unseen classes of data.
, We show that a Data Augmentation Generative Adversarial Network (DAGAN)
, augments standard vanilla classifiers well., We also show a DAGAN can enhance
, few-shot learning systems such as Matching Networks., We demonstrate these
, approaches on Omniglot, on EMNIST having learnt the DAGAN on Omniglot, and
, VGG-Face data., In our experiments we can see over 13% increase in accuracy in
, the low-data regime experiments in Omniglot (from 69% to 82%), EMNIST (73.9%
, to 76%) and VGG-Face (4.5% to 12%); in Matching Networks for Omniglot we
, observe an increase of 0.5% (from 96.9% to 97.4%) and an increase of 1.8% in
, EMNIST (from 59.5% to 61.3%).",36,5.391891891891892,6.166666666666667
277,"['Answering questions about data can require understanding what parts of an input X influence the response Y. Finding such an understanding can be built by testing relationships between variables through a machine learning model.', 'For example, conditional randomization tests help determine whether a variable relates to the response given the rest of the variables.', 'However, randomization tests require users to specify test statistics.', 'We formalize a class of proper test statistics that are guaranteed to select a feature when it provides information about the response even when the rest of the features are known.', 'We show that f-divergences provide a broad class of proper test statistics.', 'In the class of f-divergences, the KL-divergence yields an easy-to-compute proper test statistic that relates to the AMI.', 'Questions of feature importance can be asked at the level of an individual sample.  ', 'We show that estimators from the same AMI test can also be used to find important features in a particular instance.', 'We provide an example to show that perfect predictive models are insufficient for instance-wise feature selection.', 'We evaluate our method on several simulation experiments, on a genomic dataset, a clinical dataset for hospital readmission, and on a subset of classes in ImageNet.', 'Our method outperforms several baselines in various simulated datasets, is able to identify biologically significant genes, can select the most important predictors of a hospital readmission event, and is able to identify distinguishing features in an image-classification task.']","[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]","[0.06896550953388214, 0.08888888359069824, 0.0555555522441864, 0.1538461446762085, 0.10256409645080566, 0.04651162400841713, 0.04878048226237297, 0.1249999925494194, 0.1860465109348297, 0.2448979616165161, 0.19999998807907104]",HJg_tkBtwS,"['We develop a simple regression-based model-agnostic feature selection method to interpret data generating processes with FDR control, and outperform several popular baselines on several simulated, medical, and image datasets.', 'This paper proposes a practical improvement of the conditional randomization test and a new test statistic, proves f-divergence is one possible choice, and shows that KL-divergence cancels out some conditional distributions.', 'This paper addresses the problem of finding useful features in an input that are dependent on a response variable even when conditioning on all other input variables.', 'A model agnostic method to provide interpretation on the influence of input features on the response of a machine level model down to instance level, and proper test statistics for model agnostic feature selection.']","['answering question data require understanding part input x influence response  finding understanding built testing relationship variable machine learning model ', 'example  conditional randomization test help determine whether variable relates response given rest variable ', 'however  randomization test require user specify test statistic ', 'formalize class proper test statistic guaranteed select feature provides information response even rest feature known ', 'show fdivergences provide broad class proper test statistic ', 'class fdivergences  kldivergence yield easytocompute proper test statistic relates ami ', 'question feature importance asked level individual sample ', 'show estimator ami test also used find important feature particular instance ', 'provide example show perfect predictive model insufficient instancewise feature selection ', 'evaluate method several simulation experiment  genomic dataset  clinical dataset hospital readmission  subset class imagenet ', 'method outperforms several baseline various simulated datasets  able identify biologically significant gene  select important predictor hospital readmission event  able identify distinguishing feature imageclassification task ']","Answering questions about data can require understanding what parts of an input X influence the response Y. Finding such an understanding can be built by testing relationships between variables through a machine learning model., For example, conditional randomization tests help determine whether a variable relates to the response given the rest of the variables., However, randomization tests require users to specify test statistics., We formalize a class of proper test statistics that are guaranteed to select a feature when it provides information about the response even when the rest of the features are known., We show that f-divergences provide a broad class of proper test statistics., In the class of f-divergences, the KL-divergence yields an easy-to-compute proper test statistic that relates to the AMI., Questions of feature importance can be asked at the level of an individual sample.  , We show that estimators from the same AMI test can also be used to find important features in a particular instance., We provide an example to show that perfect predictive models are insufficient for instance-wise feature selection., We evaluate our method on several simulation experiments, on a genomic dataset, a clinical dataset for hospital readmission, and on a subset of classes in ImageNet., Our method outperforms several baselines in various simulated datasets, is able to identify biologically significant genes, can select the most important predictors of a hospital readmission event, and is able to identify distinguishing features in an image-classification task.",20,5.543933054393306,11.380952380952381
278,"['Supervised learning depends on annotated examples, which are taken to be the ground truth.', 'But these labels often come from noisy crowdsourcing platforms, like Amazon Mechanical Turk.', 'Practitioners typically collect multiple labels per example and aggregate the results to mitigate noise (the classic crowdsourcing problem).', 'Given a fixed annotation budget and unlimited unlabeled data, redundant annotation comes at the expense of fewer labeled examples.', 'This raises two fundamental questions: (1) How can we best learn from noisy workers?', '(2) How should we allocate our labeling budget to maximize the performance of a classifier?', 'We propose a new algorithm for jointly modeling labels and worker quality from noisy crowd-sourced data.', 'The alternating minimization proceeds in rounds, estimating worker quality from disagreement with the current model and then updating the model by optimizing a loss function that accounts for the current estimate of worker quality.', 'Unlike previous approaches, even with only one annotation per example, our algorithm can estimate worker quality.', ""We establish a generalization error bound for models learned with our algorithm and establish theoretically that it's better to label many examples once (vs less multiply) when worker quality exceeds a threshold."", ""Experiments conducted on both ImageNet (with simulated noisy workers) and MS-COCO (using the real crowdsourced labels) confirm our algorithm's benefits.""]","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.07999999821186066, 0.1666666567325592, 0.0, 0.06896550953388214, 0.1599999964237213, 0.07692307233810425, 0.37037035822868347, 0.20512820780277252, 0.0, 0.09756097197532654, 0.12903225421905518]",H1sUHgb0Z,"['A new approach for learning a model from noisy crowdsourced annotations.', ""This paper proposes a method for learning from noisy labels, focusing on the case when data isn't redundantly labeled with theoretical and experimental validation"", 'This paper focuses on the learning-from-crowds problem, where jointly updating the classifier weights and the confusion matrices of workers can help on the estimation problem with rare crowdsourced labels.', 'Proposes a supervised learning algorithm for modeling label and worker quality and utilizes algorithm to study how much redundancy is required in crowdsourcing and whether low redundancy with abundant noise examples lead to better labels.']","['supervised learning depends annotated example  taken ground truth ', 'label often come noisy crowdsourcing platform  like amazon mechanical turk ', 'practitioner typically collect multiple label per example aggregate result mitigate noise  classic crowdsourcing problem  ', 'given fixed annotation budget unlimited unlabeled data  redundant annotation come expense fewer labeled example ', 'raise two fundamental question   1  best learn noisy worker ', ' 2  allocate labeling budget maximize performance classifier ', 'propose new algorithm jointly modeling label worker quality noisy crowdsourced data ', 'alternating minimization proceeds round  estimating worker quality disagreement current model updating model optimizing loss function account current estimate worker quality ', 'unlike previous approach  even one annotation per example  algorithm estimate worker quality ', 'establish generalization error bound model learned algorithm establish theoretically better label many example  v le multiply  worker quality exceeds threshold ', 'experiment conducted imagenet  simulated noisy worker  mscoco  using real crowdsourced label  confirm algorithm benefit ']","Supervised learning depends on annotated examples, which are taken to be the ground truth., But these labels often come from noisy crowdsourcing platforms, like Amazon Mechanical Turk., Practitioners typically collect multiple labels per example and aggregate the results to mitigate noise (the classic crowdsourcing problem)., Given a fixed annotation budget and unlimited unlabeled data, redundant annotation comes at the expense of fewer labeled examples., This raises two fundamental questions: (1) How can we best learn from noisy workers?, (2) How should we allocate our labeling budget to maximize the performance of a classifier?, We propose a new algorithm for jointly modeling labels and worker quality from noisy crowd-sourced data., The alternating minimization proceeds in rounds, estimating worker quality from disagreement with the current model and then updating the model by optimizing a loss function that accounts for the current estimate of worker quality., Unlike previous approaches, even with only one annotation per example, our algorithm can estimate worker quality., We establish a generalization error bound for models learned with our algorithm and establish theoretically that it's better to label many examples once (vs less multiply) when worker quality exceeds a threshold., Experiments conducted on both ImageNet (with simulated noisy workers) and MS-COCO (using the real crowdsourced labels) confirm our algorithm's benefits.",17,5.843601895734597,12.411764705882353
279,"['Neural networks make mistakes.', 'The reason why a mistake is made often remains a mystery.', 'As such neural networks often are considered a black box.', 'It would be useful to have a method that can give an explanation that is intuitive to a user as to why an image is misclassified.', 'In this paper we develop a method for explaining the mistakes of a classifier model by visually showing what must be added to an image such that it is correctly classified.', 'Our work combines the fields of adversarial examples, generative modeling and a correction technique based on difference target propagation to create an technique that creates explanations of why an image is misclassified.', 'In this paper we explain our method and demonstrate it on MNIST and CelebA.', 'This approach could aid in demystifying neural networks for a user.\n']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.0, 0.1818181723356247, 0.1818181723356247, 0.3125, 0.2380952388048172, 0.2926829159259796, 0.0, 0.1666666567325592]",S1EzRgb0W,"['New way of explaining why a neural network has misclassified an image', 'This paper proposes a method for explaining the classification mistakes of neural networks. ', 'Aims to better understand the classification of neural networks and explores the latent space of a variational auto encoder and considers the perturbations of the latent space in order to obtain the correct classification.']","['neural network make mistake ', 'reason mistake made often remains mystery ', 'neural network often considered black box ', 'would useful method give explanation intuitive user image misclassified ', 'paper develop method explaining mistake classifier model visually showing must added image correctly classified ', 'work combine field adversarial example  generative modeling correction technique based difference target propagation create technique creates explanation image misclassified ', 'paper explain method demonstrate mnist celeba ', 'approach could aid demystifying neural network user ']","Neural networks make mistakes., The reason why a mistake is made often remains a mystery., As such neural networks often are considered a black box., It would be useful to have a method that can give an explanation that is intuitive to a user as to why an image is misclassified., In this paper we develop a method for explaining the mistakes of a classifier model by visually showing what must be added to an image such that it is correctly classified., Our work combines the fields of adversarial examples, generative modeling and a correction technique based on difference target propagation to create an technique that creates explanations of why an image is misclassified., In this paper we explain our method and demonstrate it on MNIST and CelebA., This approach could aid in demystifying neural networks for a user.
",9,4.870503597122302,15.444444444444445
280,"['In the context of multi-task learning, neural networks with branched architectures have often been employed to jointly tackle the tasks at hand.', 'Such ramified networks typically start with a number of shared layers, after which different tasks branch out into their own sequence of layers.', 'Understandably, as the number of possible network configurations is combinatorially large, deciding what layers to share and where to branch out becomes cumbersome.', 'Prior works have either relied on ad hoc methods to determine the level of layer sharing, which is suboptimal, or utilized neural architecture search techniques to establish the network design, which is considerably expensive.', ""In this paper, we go beyond these limitations and propose a principled approach to automatically construct branched multi-task networks, by leveraging the employed tasks' affinities."", 'Given a specific budget, i.e. number of learnable parameters, the proposed approach generates architectures, in which shallow layers are task-agnostic, whereas deeper ones gradually grow more task-specific.', 'Extensive experimental analysis across numerous, diverse multi-tasking datasets shows that, for a given budget, our method consistently yields networks with the highest performance, while for a certain performance threshold it requires the least amount of learnable parameters.']","[0, 0, 0, 0, 0, 0, 1]","[0.307692289352417, 0.14999999105930328, 0.09999999403953552, 0.1249999925494194, 0.1395348757505417, 0.08695651590824127, 0.38461539149284363]",HJxhUpVKDr,"['A method for the automated construction of branched multi-task networks with strong experimental evaluation on diverse multi-tasking datasets.', 'This paper proposes a novel soft parameter sharing Multi-task Learning framework based on a tree-like structure.', 'This paper presents a method to infer multi-task networks architecture to determine which part of the network should be shared among different tasks.']","['context multitask learning  neural network branched architecture often employed jointly tackle task hand ', 'ramified network typically start number shared layer  different task branch sequence layer ', 'understandably  number possible network configuration combinatorially large  deciding layer share branch becomes cumbersome ', 'prior work either relied ad hoc method determine level layer sharing  suboptimal  utilized neural architecture search technique establish network design  considerably expensive ', 'paper  go beyond limitation propose principled approach automatically construct branched multitask network  leveraging employed task  affinity ', 'given specific budget  ie  number learnable parameter  proposed approach generates architecture  shallow layer taskagnostic  whereas deeper one gradually grow taskspecific ', 'extensive experimental analysis across numerous  diverse multitasking datasets show  given budget  method consistently yield network highest performance  certain performance threshold requires least amount learnable parameter ']","In the context of multi-task learning, neural networks with branched architectures have often been employed to jointly tackle the tasks at hand., Such ramified networks typically start with a number of shared layers, after which different tasks branch out into their own sequence of layers., Understandably, as the number of possible network configurations is combinatorially large, deciding what layers to share and where to branch out becomes cumbersome., Prior works have either relied on ad hoc methods to determine the level of layer sharing, which is suboptimal, or utilized neural architecture search techniques to establish the network design, which is considerably expensive., In this paper, we go beyond these limitations and propose a principled approach to automatically construct branched multi-task networks, by leveraging the employed tasks' affinities., Given a specific budget, i.e. number of learnable parameters, the proposed approach generates architectures, in which shallow layers are task-agnostic, whereas deeper ones gradually grow more task-specific., Extensive experimental analysis across numerous, diverse multi-tasking datasets shows that, for a given budget, our method consistently yields networks with the highest performance, while for a certain performance threshold it requires the least amount of learnable parameters.",24,5.979057591623037,7.64
281,"['Typical recent neural network designs are primarily convolutional layers, but the tricks enabling structured efficient linear layers (SELLs) have not yet been adapted to the convolutional setting.', 'We present a method to express the weight tensor in a convolutional layer using diagonal matrices, discrete cosine transforms (DCTs) and permutations that can be optimised using standard stochastic gradient methods.', 'A network composed of such structured efficient convolutional layers (SECL) outperforms existing low-rank networks and demonstrates competitive computational efficiency.']","[0, 1, 0]","[0.21739129722118378, 0.2800000011920929, 0.19999998807907104]",rygwBRgYs7,"[""It's possible to substitute the weight matrix in a convolutional layer to train it as a structured efficient layer; performing as well as low-rank decomposition."", 'This work applies previous Structured Efficient Linear Layers to conv layers and proposes Structured Efficient Convolutional Layers as substitution of original conv layers.']","['typical recent neural network design primarily convolutional layer  trick enabling structured efficient linear layer  sell  yet adapted convolutional setting ', 'present method express weight tensor convolutional layer using diagonal matrix  discrete cosine transforms  dcts  permutation optimised using standard stochastic gradient method ', 'network composed structured efficient convolutional layer  secl  outperforms existing lowrank network demonstrates competitive computational efficiency ']","Typical recent neural network designs are primarily convolutional layers, but the tricks enabling structured efficient linear layers (SELLs) have not yet been adapted to the convolutional setting., We present a method to express the weight tensor in a convolutional layer using diagonal matrices, discrete cosine transforms (DCTs) and permutations that can be optimised using standard stochastic gradient methods., A network composed of such structured efficient convolutional layers (SECL) outperforms existing low-rank networks and demonstrates competitive computational efficiency.",5,6.545454545454546,15.4
282,"['Blind document deblurring is a fundamental task in the field of document processing and restoration, having wide enhancement applications in optical character recognition systems, forensics, etc.', 'Since this problem is highly ill-posed, supervised and unsupervised learning methods are well suited for this application.', 'Using various techniques, extensive work has been done on natural-scene deblurring.', 'However, these extracted features are not suitable for document images.', 'We present SVDocNet, an end-to-end trainable U-Net based spatial recurrent neural network (RNN) for blind document deblurring where the weights of the RNNs are determined by different convolutional neural networks (CNNs).', 'This network achieves state of the art performance in terms of both quantitative measures and qualitative results.']","[0, 0, 0, 0, 1, 0]","[0.09756097197532654, 0.060606054961681366, 0.0714285671710968, 0.14814814925193787, 0.739130437374115, 0.060606054961681366]",Hyx3f65qLS,"['We present SVDocNet, an end-to-end trainable U-Net based spatial recurrent neural network (RNN) for blind document deblurring.']","['blind document deblurring fundamental task field document processing restoration  wide enhancement application optical character recognition system  forensics  etc ', 'since problem highly illposed  supervised unsupervised learning method well suited application ', 'using various technique  extensive work done naturalscene deblurring ', 'however  extracted feature suitable document image ', 'present svdocnet  endtoend trainable unet based spatial recurrent neural network  rnn  blind document deblurring weight rnns determined different convolutional neural network  cnns  ', 'network achieves state art performance term quantitative measure qualitative result ']","Blind document deblurring is a fundamental task in the field of document processing and restoration, having wide enhancement applications in optical character recognition systems, forensics, etc., Since this problem is highly ill-posed, supervised and unsupervised learning methods are well suited for this application., Using various techniques, extensive work has been done on natural-scene deblurring., However, these extracted features are not suitable for document images., We present SVDocNet, an end-to-end trainable U-Net based spatial recurrent neural network (RNN) for blind document deblurring where the weights of the RNNs are determined by different convolutional neural networks (CNNs)., This network achieves state of the art performance in terms of both quantitative measures and qualitative results.",13,6.1875,8.615384615384615
283,"['In contrast to the monolithic deep architectures used in deep learning today for computer vision, the visual cortex processes retinal images via two functionally distinct but interconnected networks: the ventral pathway for processing object-related information and the dorsal pathway for processing motion and transformations.', 'Inspired by this cortical division of labor and properties of the magno- and parvocellular systems, we explore an unsupervised approach to feature learning that jointly learns object features and their transformations from natural videos.', 'We propose a new convolutional bilinear sparse coding model that (1) allows independent feature transformations and (2) is capable of processing large images.', 'Our learning procedure leverages smooth motion in natural videos.', 'Our results show that our model can learn groups of features and their transformations directly from natural videos in a completely unsupervised manner.', 'The learned ""dynamic filters"" exhibit certain equivariance properties, resemble cortical spatiotemporal filters, and capture the statistics of transitions between video frames.', 'Our model can be viewed as one of the first approaches to demonstrate unsupervised learning of primary ""capsules"" (proposed by Hinton and colleagues for supervised learning) and has strong connections to the Lie group approach to visual perception.']","[0, 0, 1, 0, 0, 0, 0]","[0.0833333283662796, 0.09090908616781235, 0.277777761220932, 0.0, 0.1111111044883728, 0.11764705181121826, 0.08695651590824127]",BkxsVXtLUr,['We extend bilinear sparse coding and leverage video sequences to learn dynamic filters.'],"['contrast monolithic deep architecture used deep learning today computer vision  visual cortex process retinal image via two functionally distinct interconnected network  ventral pathway processing objectrelated information dorsal pathway processing motion transformation ', 'inspired cortical division labor property magno parvocellular system  explore unsupervised approach feature learning jointly learns object feature transformation natural video ', 'propose new convolutional bilinear sparse coding model  1  allows independent feature transformation  2  capable processing large image ', 'learning procedure leverage smooth motion natural video ', 'result show model learn group feature transformation directly natural video completely unsupervised manner ', 'learned  dynamic filter  exhibit certain equivariance property  resemble cortical spatiotemporal filter  capture statistic transition video frame ', 'model viewed one first approach demonstrate unsupervised learning primary  capsule   proposed hinton colleague supervised learning  strong connection lie group approach visual perception ']","In contrast to the monolithic deep architectures used in deep learning today for computer vision, the visual cortex processes retinal images via two functionally distinct but interconnected networks: the ventral pathway for processing object-related information and the dorsal pathway for processing motion and transformations., Inspired by this cortical division of labor and properties of the magno- and parvocellular systems, we explore an unsupervised approach to feature learning that jointly learns object features and their transformations from natural videos., We propose a new convolutional bilinear sparse coding model that (1) allows independent feature transformations and (2) is capable of processing large images., Our learning procedure leverages smooth motion in natural videos., Our results show that our model can learn groups of features and their transformations directly from natural videos in a completely unsupervised manner., The learned ""dynamic filters"" exhibit certain equivariance properties, resemble cortical spatiotemporal filters, and capture the statistics of transitions between video frames., Our model can be viewed as one of the first approaches to demonstrate unsupervised learning of primary ""capsules"" (proposed by Hinton and colleagues for supervised learning) and has strong connections to the Lie group approach to visual perception.",11,6.119791666666667,17.454545454545453
284,"[' Conventional out-of-distribution (OOD) detection schemes based on variational autoencoder or Random Network Distillation (RND) are known to assign lower uncertainty to the OOD data than the target distribution.', 'In this work, we discover that such conventional novelty detection schemes are also vulnerable to the blurred images.', 'Based on the observation, we construct a novel RND-based OOD detector, SVD-RND, that utilizes blurred images during training.', 'Our detector is simple, efficient in test time, and outperforms baseline OOD detectors in various domains.', 'Further results show that SVD-RND learns a better target distribution representation than the baselines.', 'Finally, SVD-RND combined with geometric transform achieves near-perfect detection accuracy in CelebA domain.']","[0, 0, 0, 1, 0, 0]","[0.0833333283662796, 0.19999998807907104, 0.29999998211860657, 0.3243243098258972, 0.1111111044883728, 0.11428570747375488]",ByeNra4FDB,"['We propose a novel OOD detector that employ blurred images as adversarial examples . Our model achieve significant OOD detection performance in various domains.', 'This paper presents the idea to use blurred images as regularizing examples to improve out-of-distribution detection performance based on Random Network Distillation.', 'This paper tackles out-of-data distribution by leveraging RND applied to data augmentations by training a model to match the outputs of a random network with an augmentation as input.']","['conventional outofdistribution  ood  detection scheme based variational autoencoder random network distillation  rnd  known assign lower uncertainty ood data target distribution ', 'work  discover conventional novelty detection scheme also vulnerable blurred image ', 'based observation  construct novel rndbased ood detector  svdrnd  utilizes blurred image training ', 'detector simple  efficient test time  outperforms baseline ood detector various domain ', 'result show svdrnd learns better target distribution representation baseline ', 'finally  svdrnd combined geometric transform achieves nearperfect detection accuracy celeba domain ']"," Conventional out-of-distribution (OOD) detection schemes based on variational autoencoder or Random Network Distillation (RND) are known to assign lower uncertainty to the OOD data than the target distribution., In this work, we discover that such conventional novelty detection schemes are also vulnerable to the blurred images., Based on the observation, we construct a novel RND-based OOD detector, SVD-RND, that utilizes blurred images during training., Our detector is simple, efficient in test time, and outperforms baseline OOD detectors in various domains., Further results show that SVD-RND learns a better target distribution representation than the baselines., Finally, SVD-RND combined with geometric transform achieves near-perfect detection accuracy in CelebA domain.",13,6.196261682242991,8.23076923076923
285,"['Training large deep neural networks on massive datasets is \xa0computationally very challenging.', 'There has been recent surge in interest in using large batch stochastic optimization methods to tackle this issue.', 'The most prominent algorithm in this line of research is LARS, which by \xa0employing layerwise adaptive learning rates trains ResNet on ImageNet in a few minutes.', 'However, LARS performs poorly for attention models like BERT, indicating that its performance gains are not consistent across tasks.', 'In this paper, we first study a principled layerwise adaptation strategy to accelerate training of deep neural networks using large mini-batches.', 'Using this strategy, we develop a new layerwise adaptive large batch optimization technique called LAMB; we then provide convergence analysis of LAMB as well as LARS, showing convergence to a stationary point in general nonconvex settings.', 'Our empirical results demonstrate the superior performance of LAMB across various tasks such as BERT and ResNet-50 training with very little hyperparameter tuning.', 'In particular, for BERT training, our optimizer enables use of very large batch sizes of 32868 without any degradation of performance. \xa0', 'By increasing the batch size to the memory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to just 76 minutes (Table 1).']","[0, 0, 0, 0, 0, 0, 0, 1, 0]","[0.0, 0.0, 0.0, 0.0714285671710968, 0.06666666269302368, 0.04878048598766327, 0.1249999925494194, 0.13793103396892548, 0.05714285373687744]",Syx4wnEtvH,"['A fast optimizer for general applications and large-batch training.', 'In this paper, the authors made a study on large-batch training for the BERT, and successfully trained a BERT model in 76 minutes.', 'This paper develops a layerwise adaptation strategy that allows training BERT models with large 32k mini-batches vs baseline 512.']","['training large deep neural network massive datasets computationally challenging ', 'recent surge interest using large batch stochastic optimization method tackle issue ', 'prominent algorithm line research lars  employing layerwise adaptive learning rate train resnet imagenet minute ', 'however  lars performs poorly attention model like bert  indicating performance gain consistent across task ', 'paper  first study principled layerwise adaptation strategy accelerate training deep neural network using large minibatches ', 'using strategy  develop new layerwise adaptive large batch optimization technique called lamb  provide convergence analysis lamb well lars  showing convergence stationary point general nonconvex setting ', 'empirical result demonstrate superior performance lamb across various task bert resnet50 training little hyperparameter tuning ', 'particular  bert training  optimizer enables use large batch size 32868 without degradation performance ', 'increasing batch size memory limit tpuv3 pod  bert training time reduced 3 day 76 minute  table 1  ']","Training large deep neural networks on massive datasets is computationally very challenging., There has been recent surge in interest in using large batch stochastic optimization methods to tackle this issue., The most prominent algorithm in this line of research is LARS, which by employing layerwise adaptive learning rates trains ResNet on ImageNet in a few minutes., However, LARS performs poorly for attention models like BERT, indicating that its performance gains are not consistent across tasks., In this paper, we first study a principled layerwise adaptation strategy to accelerate training of deep neural networks using large mini-batches., Using this strategy, we develop a new layerwise adaptive large batch optimization technique called LAMB; we then provide convergence analysis of LAMB as well as LARS, showing convergence to a stationary point in general nonconvex settings., Our empirical results demonstrate the superior performance of LAMB across various tasks such as BERT and ResNet-50 training with very little hyperparameter tuning., In particular, for BERT training, our optimizer enables use of very large batch sizes of 32868 without any degradation of performance. , By increasing the batch size to the memory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to just 76 minutes (Table 1).",18,5.46078431372549,11.333333333333334
286,"['Model-agnostic meta-learning (MAML) is known as a powerful meta-learning method.', 'However, MAML is notorious for being hard to train because of the existence of two learning rates.', 'Therefore, in this paper, we derive the conditions that inner learning rate $\\alpha$ and meta-learning rate $\\beta$ must satisfy for MAML to converge to minima with some simplifications.', 'We find that the upper bound of $\\beta$ depends on $ \\alpha$, in contrast to the case of using the normal gradient descent method.', 'Moreover, we show that the threshold of $\\beta$ increases as $\\alpha$ approaches its own upper bound.', 'This result is verified by experiments on various few-shot tasks and architectures; specifically, we perform sinusoid regression and classification of Omniglot and MiniImagenet datasets with a multilayer perceptron and a convolutional neural network.', 'Based on this outcome, we present a guideline for determining the learning rates: first, search for the largest possible $\\alpha$; next, tune $\\beta$ based on the chosen value of $\\alpha$.']","[0, 1, 0, 0, 0, 0, 0]","[0.0952380895614624, 0.3571428656578064, 0.21052631735801697, 0.24242423474788666, 0.1428571343421936, 0.04878048226237297, 0.15789473056793213]",r1e8qpVKPS,"['We analyzed the role of two learning rates in model-agnostic meta-learning in convergence.', 'The authors tackled the optimization instability problem in MAML by investigating the two learning rates.', 'This paper studies a method to help tune the two learning rates used in the MAML training algorithm.']","['modelagnostic metalearning  maml  known powerful metalearning method ', 'however  maml notorious hard train existence two learning rate ', 'therefore  paper  derive condition inner learning rate  alpha  metalearning rate  beta  must satisfy maml converge minimum simplification ', 'find upper bound  beta  depends  alpha   contrast case using normal gradient descent method ', 'moreover  show threshold  beta  increase  alpha  approach upper bound ', 'result verified experiment various fewshot task architecture  specifically  perform sinusoid regression classification omniglot miniimagenet datasets multilayer perceptron convolutional neural network ', 'based outcome  present guideline determining learning rate  first  search largest possible  alpha   next  tune  beta  based chosen value  alpha  ']","Model-agnostic meta-learning (MAML) is known as a powerful meta-learning method., However, MAML is notorious for being hard to train because of the existence of two learning rates., Therefore, in this paper, we derive the conditions that inner learning rate $\alpha$ and meta-learning rate $\beta$ must satisfy for MAML to converge to minima with some simplifications., We find that the upper bound of $\beta$ depends on $ \alpha$, in contrast to the case of using the normal gradient descent method., Moreover, we show that the threshold of $\beta$ increases as $\alpha$ approaches its own upper bound., This result is verified by experiments on various few-shot tasks and architectures; specifically, we perform sinusoid regression and classification of Omniglot and MiniImagenet datasets with a multilayer perceptron and a convolutional neural network., Based on this outcome, we present a guideline for determining the learning rates: first, search for the largest possible $\alpha$; next, tune $\beta$ based on the chosen value of $\alpha$.",16,5.525316455696203,9.875
287,"['We present a neural framework for learning associations between interrelated groups of words such as the ones found in Subject-Verb-Object (SVO) structures.', 'Our model induces a joint function-specific word vector space, where vectors of e.g. plausible SVO compositions lie close together.', 'The model retains information about word group membership even in the joint space, and can thereby effectively be applied to a number of tasks reasoning over the SVO structure.', 'We show the robustness and versatility of the proposed framework by reporting state-of-the-art results on the tasks of estimating selectional preference (i.e., thematic fit) and event similarity.', 'The results indicate that the combinations of representations learned with our task-independent model outperform task-specific architectures from prior work, while reducing the number of parameters by up to 95%.', 'The proposed framework is versatile and holds promise to support learning function-specific representations beyond the SVO structures.']","[1, 0, 0, 0, 0, 0]","[0.5454545617103577, 0.12903225421905518, 0.10256409645080566, 0.0555555522441864, 0.10526315122842789, 0.0714285671710968]",BkgL7kBtDH,"['Task-independent neural model for learning associations between interrelated groups of words.', 'The paper proposed a method for training function-specific word vectors, in which each word is represented with three vectors each in a different category (Subject-Verb-Object).', 'This paper proposes a neural network to learn function-specific work representations and demonstrates the advantage over alternatives.']","['present neural framework learning association interrelated group word one found subjectverbobject  svo  structure ', 'model induces joint functionspecific word vector space  vector eg  plausible svo composition lie close together ', 'model retains information word group membership even joint space  thereby effectively applied number task reasoning svo structure ', 'show robustness versatility proposed framework reporting stateoftheart result task estimating selectional preference  ie  thematic fit  event similarity ', 'result indicate combination representation learned taskindependent model outperform taskspecific architecture prior work  reducing number parameter 95  ', 'proposed framework versatile hold promise support learning functionspecific representation beyond svo structure ']","We present a neural framework for learning associations between interrelated groups of words such as the ones found in Subject-Verb-Object (SVO) structures., Our model induces a joint function-specific word vector space, where vectors of e.g. plausible SVO compositions lie close together., The model retains information about word group membership even in the joint space, and can thereby effectively be applied to a number of tasks reasoning over the SVO structure., We show the robustness and versatility of the proposed framework by reporting state-of-the-art results on the tasks of estimating selectional preference (i.e., thematic fit) and event similarity., The results indicate that the combinations of representations learned with our task-independent model outperform task-specific architectures from prior work, while reducing the number of parameters by up to 95%., The proposed framework is versatile and holds promise to support learning function-specific representations beyond the SVO structures.",10,6.027972027972028,13.0
288,"['The fabrication of semiconductor involves etching process to remove selected areas from wafers.', 'However, the measurement of etched structure in micro-graph heavily relies on time-consuming manual routines.', 'Traditional image processing usually demands on large number of annotated data and the performance is still poor.', 'We treat this challenge as segmentation problem and use deep learning approach to detect masks of objects in etched structure of wafer.', 'Then, we use simple image processing to carry out automatic measurement on the objects.', 'We attempt Generative Adversarial Network (GAN) to generate more data to overcome the problem of very limited dataset.', 'We download 10 SEM (Scanning Electron Microscope) images of 4 types from Internet, based on which we carry out our experiments.', 'Our deep learning based method demonstrates superiority over image processing approach with  mean accuracy reaching over 96% for the measurements, compared with the ground truth.', 'To the best of our knowledge, it is the first time that deep learning has been applied in semiconductor industry for automatic measurement.']","[0, 0, 0, 0, 0, 0, 0, 0, 1]","[0.2142857164144516, 0.20689654350280762, 0.0624999962747097, 0.277777761220932, 0.3448275923728943, 0.1249999925494194, 0.277777761220932, 0.1621621549129486, 0.4324324131011963]",SJPO7JMyG,['Using deep learning method to carry out automatic measurement of SEM images in semiconductor industry'],"['fabrication semiconductor involves etching process remove selected area wafer ', 'however  measurement etched structure micrograph heavily relies timeconsuming manual routine ', 'traditional image processing usually demand large number annotated data performance still poor ', 'treat challenge segmentation problem use deep learning approach detect mask object etched structure wafer ', ' use simple image processing carry automatic measurement object ', 'attempt generative adversarial network  gan  generate data overcome problem limited dataset ', 'download 10 sem  scanning electron microscope  image 4 type internet  based carry experiment ', 'deep learning based method demonstrates superiority image processing approach mean accuracy reaching 96  measurement  compared ground truth ', 'best knowledge  first time deep learning applied semiconductor industry automatic measurement ']","The fabrication of semiconductor involves etching process to remove selected areas from wafers., However, the measurement of etched structure in micro-graph heavily relies on time-consuming manual routines., Traditional image processing usually demands on large number of annotated data and the performance is still poor., We treat this challenge as segmentation problem and use deep learning approach to detect masks of objects in etched structure of wafer., Then, we use simple image processing to carry out automatic measurement on the objects., We attempt Generative Adversarial Network (GAN) to generate more data to overcome the problem of very limited dataset., We download 10 SEM (Scanning Electron Microscope) images of 4 types from Internet, based on which we carry out our experiments., Our deep learning based method demonstrates superiority over image processing approach with  mean accuracy reaching over 96% for the measurements, compared with the ground truth., To the best of our knowledge, it is the first time that deep learning has been applied in semiconductor industry for automatic measurement.",14,5.610778443113772,11.928571428571429
289,"['Generating and scheduling activities is particularly challenging\n', 'when considering both consumptive resources and\n', 'complex resource interactions such as time-dependent resource\n', 'usage.We present three methods of determining valid\n', 'temporal placement intervals for an activity in a temporally\n', 'grounded plan in the presence of such constraints.', 'We introduce\n', 'the Max Duration and Probe algorithms which are\n', 'sound, but incomplete, and the Linear algorithm which is\n', 'sound and complete for linear rate resource consumption.\n', 'We apply these techniques to the problem of scheduling\n', 'awakes for a planetary rover where the awake durations\n', 'are affected by existing activities.', 'We demonstrate how the\n', 'Probe algorithm performs competitively with the Linear algorithm\n', 'given an advantageous problem space and well-defined\n', 'heuristics.', 'We show that the Probe and Linear algorithms\n', 'outperform the Max Duration algorithm empirically.\n', 'We then empirically present the runtime differences between\n', 'the three algorithms.', 'The Probe algorithm is currently base-lined\n', 'for use in the onboard scheduler for NASAs next planetary\n', 'rover, the Mars 2020 rover.']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.1599999964237213, 0.25, 0.0, 0.23076923191547394, 0.07407406717538834, 0.307692289352417, 0.1538461446762085, 0.14814814925193787, 0.07407406717538834, 0.2222222238779068, 0.07407406717538834, 0.08695651590824127, 0.09090908616781235, 0.07999999821186066, 0.07999999821186066, 0.1538461446762085, 0.07999999821186066, 0.07692307233810425, 0.190476194024086, 0.0, 0.14814814925193787, 0.08695651590824127]",rJl7N-9ctN,"['This paper describes and analyzes three methods to schedule non-fixed duration activities in the presence of consumptive resources.', 'The paper presents three approaches for on-board scheduling of activities in a planetary rover under reservoir resource constraints.']","['generating scheduling activity particularly challenging', 'considering consumptive resource', 'complex resource interaction timedependent resource', 'usagewe present three method determining valid', 'temporal placement interval activity temporally', 'grounded plan presence constraint ', 'introduce', 'max duration probe algorithm', 'sound  incomplete  linear algorithm', 'sound complete linear rate resource consumption ', 'apply technique problem scheduling', 'awakes planetary rover awake duration', 'affected existing activity ', 'demonstrate', 'probe algorithm performs competitively linear algorithm', 'given advantageous problem space welldefined', 'heuristic ', 'show probe linear algorithm', 'outperform max duration algorithm empirically ', 'empirically present runtime difference', 'three algorithm ', 'probe algorithm currently baselined', 'use onboard scheduler nasa  next planetary', 'rover  mar 2020 rover ']","Generating and scheduling activities is particularly challenging
, when considering both consumptive resources and
, complex resource interactions such as time-dependent resource
, usage.We present three methods of determining valid
, temporal placement intervals for an activity in a temporally
, grounded plan in the presence of such constraints., We introduce
, the Max Duration and Probe algorithms which are
, sound, but incomplete, and the Linear algorithm which is
, sound and complete for linear rate resource consumption.
, We apply these techniques to the problem of scheduling
, awakes for a planetary rover where the awake durations
, are affected by existing activities., We demonstrate how the
, Probe algorithm performs competitively with the Linear algorithm
, given an advantageous problem space and well-defined
, heuristics., We show that the Probe and Linear algorithms
, outperform the Max Duration algorithm empirically.
, We then empirically present the runtime differences between
, the three algorithms., The Probe algorithm is currently base-lined
, for use in the onboard scheduler for NASAs next planetary
, rover, the Mars 2020 rover.",27,6.0,5.925925925925926
290,"['A disentangled representation of a data set should be capable of recovering the underlying factors that generated it.', 'One question that arises is whether using Euclidean space for latent variable models can produce a disentangled representation when the underlying generating factors have a certain geometrical structure.', 'Take for example the images of a car seen from different angles.', 'The angle has a periodic structure but a 1-dimensional representation would fail to capture this topology.', 'How can we address this problem?', 'The submissions presented for the first stage of the  NeurIPS2019 Disentanglement Challenge consist of a Diffusion Variational Autoencoder ($\\Delta$VAE) with a hyperspherical latent space which can for example recover periodic true factors.', 'The training of the $\\Delta$VAE is enhanced by incorporating a modified version of the Evidence Lower Bound (ELBO) for tailoring the encoding capacity of the posterior approximate.']","[0, 0, 0, 0, 0, 1, 0]","[0.06896550953388214, 0.0, 0.0833333283662796, 0.07407406717538834, 0.0, 0.25, 0.05882352590560913]",SylFDSU6Sr,['Description of submission to NeurIPS2019 Disentanglement Challenge based on hyperspherical variational autoencoders'],"['disentangled representation data set capable recovering underlying factor generated ', 'one question arises whether using euclidean space latent variable model produce disentangled representation underlying generating factor certain geometrical structure ', 'take example image car seen different angle ', 'angle periodic structure 1dimensional representation would fail capture topology ', 'address problem ', 'submission presented first stage neurips2019 disentanglement challenge consist diffusion variational autoencoder   delta  vae  hyperspherical latent space example recover periodic true factor ', 'training  delta  vae enhanced incorporating modified version evidence lower bound  elbo  tailoring encoding capacity posterior approximate ']","A disentangled representation of a data set should be capable of recovering the underlying factors that generated it., One question that arises is whether using Euclidean space for latent variable models can produce a disentangled representation when the underlying generating factors have a certain geometrical structure., Take for example the images of a car seen from different angles., The angle has a periodic structure but a 1-dimensional representation would fail to capture this topology., How can we address this problem?, The submissions presented for the first stage of the  NeurIPS2019 Disentanglement Challenge consist of a Diffusion Variational Autoencoder ($\Delta$VAE) with a hyperspherical latent space which can for example recover periodic true factors., The training of the $\Delta$VAE is enhanced by incorporating a modified version of the Evidence Lower Bound (ELBO) for tailoring the encoding capacity of the posterior approximate.",7,5.820143884892087,19.857142857142858
291,"['Anomaly detection, finding patterns that substantially deviate from those seen previously, is one of the fundamental problems of artificial intelligence.', 'Recently, classification-based methods were shown to achieve superior results on this task.', 'In this work, we present a unifying view and propose an open-set method to relax current generalization assumptions.', 'Furthermore, we extend the applicability of transformation-based methods to non-image data using random affine transformations.', 'Our method is shown to obtain state-of-the-art accuracy and is applicable to broad data types.', 'The strong performance of our method is extensively validated on multiple datasets from different domains.']","[0, 0, 0, 1, 0, 0]","[0.0, 0.0833333283662796, 0.06666666269302368, 0.2222222238779068, 0.1599999964237213, 0.0]",H1lK_lBtvS,"['An anomaly detection that:  uses random-transformation classification for generalizing to non-image data.', 'This paper proposes a deep method for anomaly detection that unifies recent deep one-class classification and transformation-based classification approaches.', 'This paper proposes an approach to classification-based anomaly detection for general data by using the affine transformation y = Wx+b.']","['anomaly detection  finding pattern substantially deviate seen previously  one fundamental problem artificial intelligence ', 'recently  classificationbased method shown achieve superior result task ', 'work  present unifying view propose openset method relax current generalization assumption ', 'furthermore  extend applicability transformationbased method nonimage data using random affine transformation ', 'method shown obtain stateoftheart accuracy applicable broad data type ', 'strong performance method extensively validated multiple datasets different domain ']","Anomaly detection, finding patterns that substantially deviate from those seen previously, is one of the fundamental problems of artificial intelligence., Recently, classification-based methods were shown to achieve superior results on this task., In this work, we present a unifying view and propose an open-set method to relax current generalization assumptions., Furthermore, we extend the applicability of transformation-based methods to non-image data using random affine transformations., Our method is shown to obtain state-of-the-art accuracy and is applicable to broad data types., The strong performance of our method is extensively validated on multiple datasets from different domains.",11,6.242105263157895,8.636363636363637
292,"['Recent improvements in large-scale language models have driven progress on automatic generation of syntactically and semantically consistent text for many real-world applications.', 'Many of these advances leverage the availability of large corpora.', 'While training on such corpora encourages the model to understand long-range dependencies in text, it can also result in the models internalizing the social biases present in the corpora.', 'This paper aims to quantify and reduce biases exhibited by language models.', 'Given a conditioning context (e.g. a writing prompt) and a language model, we analyze if (and how) the sentiment of the generated text is affected by changes in values of sensitive attributes (e.g. country names, occupations, genders, etc.) in the conditioning context, a.k.a. counterfactual evaluation.', 'We quantify these biases by adapting individual and group fairness metrics from the fair machine learning literature.', 'Extensive evaluation on two different corpora (news articles and Wikipedia) shows that state-of-the-art Transformer-based language models exhibit biases learned from data.', 'We propose embedding-similarity and sentiment-similarity regularization methods that improve both individual and group fairness metrics without sacrificing perplexity and semantic similarity---a positive step toward development and deployment of fairer language models for real-world applications.']","[1, 0, 0, 0, 0, 0, 0, 0]","[0.3333333432674408, 0.08695651590824127, 0.1621621549129486, 0.307692289352417, 0.22641509771347046, 0.12903225421905518, 0.2857142686843872, 0.17777776718139648]",S1l2IyrYPr,"['We reduce sentiment biases based on counterfactual evaluation of text generation using language models.', 'This paper measures sentiment bias in language models as reflected by text generated by the models, and adds other objective terms to the usual language modeling objective to reduce bias.', 'This paper proposes to evaluate bias in pre-trained language models by using a fixed sentiment system and tests several different prefix templates.', 'A method based on semantic simiilarity and a method based on sentiment similarity to debias the neural language models trained from large datasets.']","['recent improvement largescale language model driven progress automatic generation syntactically semantically consistent text many realworld application ', 'many advance leverage availability large corpus ', 'training corpus encourages model understand longrange dependency text  also result model internalizing social bias present corpus ', 'paper aim quantify reduce bias exhibited language model ', 'given conditioning context  eg  writing prompt  language model  analyze   sentiment generated text affected change value sensitive attribute  eg  country name  occupation  gender  etc   conditioning context  aka  counterfactual evaluation ', 'quantify bias adapting individual group fairness metric fair machine learning literature ', 'extensive evaluation two different corpus  news article wikipedia  show stateoftheart transformerbased language model exhibit bias learned data ', 'propose embeddingsimilarity sentimentsimilarity regularization method improve individual group fairness metric without sacrificing perplexity semantic similarity  positive step toward development deployment fairer language model realworld application ']","Recent improvements in large-scale language models have driven progress on automatic generation of syntactically and semantically consistent text for many real-world applications., Many of these advances leverage the availability of large corpora., While training on such corpora encourages the model to understand long-range dependencies in text, it can also result in the models internalizing the social biases present in the corpora., This paper aims to quantify and reduce biases exhibited by language models., Given a conditioning context (e.g. a writing prompt) and a language model, we analyze if (and how) the sentiment of the generated text is affected by changes in values of sensitive attributes (e.g. country names, occupations, genders, etc.) in the conditioning context, a.k.a. counterfactual evaluation., We quantify these biases by adapting individual and group fairness metrics from the fair machine learning literature., Extensive evaluation on two different corpora (news articles and Wikipedia) shows that state-of-the-art Transformer-based language models exhibit biases learned from data., We propose embedding-similarity and sentiment-similarity regularization methods that improve both individual and group fairness metrics without sacrificing perplexity and semantic similarity---a positive step toward development and deployment of fairer language models for real-world applications.",14,6.352631578947369,10.555555555555555
293,"['Topic modeling of text documents is one of the most important tasks in representation learning.', 'In this work, we propose iTM-VAE, which is a Bayesian nonparametric (BNP) topic model with variational auto-encoders.', 'On one hand, as a BNP topic model, iTM-VAE potentially has infinite topics and can adapt the topic number to data automatically.', 'On the other hand, different with the other BNP topic models, the inference of iTM-VAE is modeled by neural networks, which has rich representation capacity and can be computed in a simple feed-forward manner.', 'Two variants of iTM-VAE are also proposed in this paper, where iTM-VAE-Prod models the generative process in products-of-experts fashion for better performance and iTM-VAE-G places a prior over the concentration parameter such that the model can adapt a suitable concentration parameter to data automatically.', 'Experimental results on 20News and Reuters RCV1-V2 datasets show that the proposed models outperform the state-of-the-arts in terms of perplexity, topic coherence and document retrieval tasks.', 'Moreover, the ability of adjusting the concentration parameter to data is also confirmed by experiments.']","[0, 0, 0, 0, 0, 1, 0]","[0.2631579041481018, 0.19512194395065308, 0.13333332538604736, 0.2545454502105713, 0.12903225421905518, 0.5, 0.10526315122842789]",SkxqZngC-,"['A Bayesian Nonparametric Topic Model with Variational Auto-Encoders which achieves the state-of-the-arts on public benchmarks in terms of perplexity, topic coherence and retrieval tasks.', ""This paper constructs an infinite Topic Model with Variational Auto-Encoders by combining Nalisnick & Smith's stick-breaking variational auto-encoder with latent Dirichlet allocation and several inference techniques used in Miao.""]","['topic modeling text document one important task representation learning ', 'work  propose itmvae  bayesian nonparametric  bnp  topic model variational autoencoders ', 'one hand  bnp topic model  itmvae potentially infinite topic adapt topic number data automatically ', 'hand  different bnp topic model  inference itmvae modeled neural network  rich representation capacity computed simple feedforward manner ', 'two variant itmvae also proposed paper  itmvaeprod model generative process productsofexperts fashion better performance itmvaeg place prior concentration parameter model adapt suitable concentration parameter data automatically ', 'experimental result 20news reuters rcv1v2 datasets show proposed model outperform stateofthearts term perplexity  topic coherence document retrieval task ', 'moreover  ability adjusting concentration parameter data also confirmed experiment ']","Topic modeling of text documents is one of the most important tasks in representation learning., In this work, we propose iTM-VAE, which is a Bayesian nonparametric (BNP) topic model with variational auto-encoders., On one hand, as a BNP topic model, iTM-VAE potentially has infinite topics and can adapt the topic number to data automatically., On the other hand, different with the other BNP topic models, the inference of iTM-VAE is modeled by neural networks, which has rich representation capacity and can be computed in a simple feed-forward manner., Two variants of iTM-VAE are also proposed in this paper, where iTM-VAE-Prod models the generative process in products-of-experts fashion for better performance and iTM-VAE-G places a prior over the concentration parameter such that the model can adapt a suitable concentration parameter to data automatically., Experimental results on 20News and Reuters RCV1-V2 datasets show that the proposed models outperform the state-of-the-arts in terms of perplexity, topic coherence and document retrieval tasks., Moreover, the ability of adjusting the concentration parameter to data is also confirmed by experiments.",17,5.6531791907514455,10.176470588235293
294,"['Knowledge Distillation (KD) is a widely used technique in recent deep learning research to obtain small and simple models whose performance is on a par with their large and complex counterparts.', 'Standard Knowledge Distillation tends to be time-consuming because of the training time spent to obtain a teacher model that would then provide guidance for the student model.', 'It might be possible to cut short the time by training a teacher model on the fly, but it is not trivial to have such a high-capacity teacher that gives quality guidance to student models this way.', 'To improve this, we present a novel framework of Knowledge Distillation exploiting dark knowledge from the whole training set.', 'In this framework, we propose a simple and effective implementation named Distillation by Utilizing Peer Samples (DUPS) in one generation.', 'We verify our algorithm on numerous experiments.', 'Compared with standard training on modern architectures, DUPS achieves an average improvement of 1%-2% on various tasks with nearly zero extra cost.', 'Considering some typical Knowledge Distillation methods which are much more time-consuming, we also get comparable or even better performance using DUPS.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.1428571343421936, 0.31578946113586426, 0.1304347813129425, 0.4848484694957733, 0.11764705181121826, 0.0952380895614624, 0.05882352590560913, 0.11428570747375488]",HyxfGCVYDr,"['We present a novel framework of Knowledge Distillation utilizing peer samples as the teacher', 'Proposes a method for improving the effectiveness of knowledge distillation by softening the labels used and employing a dataset instead of a single sample.', 'This paper proposes to address the extra computational cost of training with knowledge distillation, building on the recently proposed Snapshot Distillation technique.']","['knowledge distillation  kd  widely used technique recent deep learning research obtain small simple model whose performance par large complex counterpart ', 'standard knowledge distillation tends timeconsuming training time spent obtain teacher model would provide guidance student model ', 'might possible cut short time training teacher model fly  trivial highcapacity teacher give quality guidance student model way ', 'improve  present novel framework knowledge distillation exploiting dark knowledge whole training set ', 'framework  propose simple effective implementation named distillation utilizing peer sample  dups  one generation ', 'verify algorithm numerous experiment ', 'compared standard training modern architecture  dups achieves average improvement 1  2  various task nearly zero extra cost ', 'considering typical knowledge distillation method much timeconsuming  also get comparable even better performance using dups ']","Knowledge Distillation (KD) is a widely used technique in recent deep learning research to obtain small and simple models whose performance is on a par with their large and complex counterparts., Standard Knowledge Distillation tends to be time-consuming because of the training time spent to obtain a teacher model that would then provide guidance for the student model., It might be possible to cut short the time by training a teacher model on the fly, but it is not trivial to have such a high-capacity teacher that gives quality guidance to student models this way., To improve this, we present a novel framework of Knowledge Distillation exploiting dark knowledge from the whole training set., In this framework, we propose a simple and effective implementation named Distillation by Utilizing Peer Samples (DUPS) in one generation., We verify our algorithm on numerous experiments., Compared with standard training on modern architectures, DUPS achieves an average improvement of 1%-2% on various tasks with nearly zero extra cost., Considering some typical Knowledge Distillation methods which are much more time-consuming, we also get comparable or even better performance using DUPS.",13,5.423913043478261,14.153846153846153
295,"['We develop a metalearning approach for learning hierarchically structured poli- cies, improving sample efficiency on unseen tasks through the use of shared primitivespolicies that are executed for large numbers of timesteps.', 'Specifi- cally, a set of primitives are shared within a distribution of tasks, and are switched between by task-specific policies.', 'We provide a concrete metric for measuring the strength of such hierarchies, leading to an optimization problem for quickly reaching high reward on unseen tasks.', 'We then present an algorithm to solve this problem end-to-end through the use of any off-the-shelf reinforcement learning method, by repeatedly sampling new tasks and resetting task-specific policies.', 'We successfully discover meaningful motor primitives for the directional movement of four-legged robots, solely by interacting with distributions of mazes.', 'We also demonstrate the transferability of primitives to solve long-timescale sparse-reward obstacle courses, and we enable 3D humanoid robots to robustly walk and crawl with the same policy.']","[0, 1, 0, 0, 0, 0]","[0.20000000298023224, 0.2142857164144516, 0.17142856121063232, 0.20512820780277252, 0.06666666269302368, 0.0555555522441864]",SyX0IeWAW,"['learn hierarchal sub-policies through end-to-end training over a distribution of tasks', 'The authors consider the problem of learning a useful set of sub policies that can be shared between tasks so as to jump start learning on new tasks drawn from the task distribution. ', 'This paper proposes a novel method for inducing temporal hierarchical structure in a specialized multi-task setting.']","['develop metalearning approach learning hierarchically structured poli cies  improving sample efficiency unseen task use shared primitivespolicies executed large number timesteps ', 'specifi cally  set primitive shared within distribution task  switched taskspecific policy ', 'provide concrete metric measuring strength hierarchy  leading optimization problem quickly reaching high reward unseen task ', 'present algorithm solve problem endtoend use offtheshelf reinforcement learning method  repeatedly sampling new task resetting taskspecific policy ', 'successfully discover meaningful motor primitive directional movement fourlegged robot  solely interacting distribution maze ', 'also demonstrate transferability primitive solve longtimescale sparsereward obstacle course  enable 3d humanoid robot robustly walk crawl policy ']","We develop a metalearning approach for learning hierarchically structured poli- cies, improving sample efficiency on unseen tasks through the use of shared primitivespolicies that are executed for large numbers of timesteps., Specifi- cally, a set of primitives are shared within a distribution of tasks, and are switched between by task-specific policies., We provide a concrete metric for measuring the strength of such hierarchies, leading to an optimization problem for quickly reaching high reward on unseen tasks., We then present an algorithm to solve this problem end-to-end through the use of any off-the-shelf reinforcement learning method, by repeatedly sampling new tasks and resetting task-specific policies., We successfully discover meaningful motor primitives for the directional movement of four-legged robots, solely by interacting with distributions of mazes., We also demonstrate the transferability of primitives to solve long-timescale sparse-reward obstacle courses, and we enable 3D humanoid robots to robustly walk and crawl with the same policy.",13,5.980263157894737,11.692307692307692
296,"['This paper proposes a new model for document embedding.', 'Existing approaches either require complex inference or use recurrent neural networks that are difficult to parallelize.', 'We take a different route and use recent advances in language modeling to develop a convolutional neural network embedding model.', 'This allows us to train deeper architectures that are fully parallelizable.', 'Stacking layers together increases the receptive filed allowing each successive layer to model increasingly longer range semantic dependences within the document.', 'Empirically we demonstrate superior results on two publicly available benchmarks.', 'Full code will be released with the final version of this paper.']","[1, 0, 0, 0, 0, 0, 0]","[0.47058823704719543, 0.0833333283662796, 0.29629629850387573, 0.0, 0.1428571343421936, 0.0, 0.0]",ryHM_fbA-,"['Convolutional neural network model for unsupervised document embedding.', 'Introduces a new model for the general task of inducing document representations (embeddings) which uses a CNN architecture to improve computational efficiency.', 'This paper proposes using CNNs with a skip-gram like objective as a fast way to output document embeddings']","['paper proposes new model document embedding ', 'existing approach either require complex inference use recurrent neural network difficult parallelize ', 'take different route use recent advance language modeling develop convolutional neural network embedding model ', 'allows u train deeper architecture fully parallelizable ', 'stacking layer together increase receptive filed allowing successive layer model increasingly longer range semantic dependence within document ', 'empirically demonstrate superior result two publicly available benchmark ', 'full code released final version paper ']","This paper proposes a new model for document embedding., Existing approaches either require complex inference or use recurrent neural networks that are difficult to parallelize., We take a different route and use recent advances in language modeling to develop a convolutional neural network embedding model., This allows us to train deeper architectures that are fully parallelizable., Stacking layers together increases the receptive filed allowing each successive layer to model increasingly longer range semantic dependences within the document., Empirically we demonstrate superior results on two publicly available benchmarks., Full code will be released with the final version of this paper.",7,6.0,14.142857142857142
297,"['We prove bounds on the generalization error of convolutional networks.\n', 'The bounds are in terms of the training loss, the number of\n', 'parameters, the Lipschitz constant of the loss and the distance from\n', 'the weights to the initial weights.', ' They are independent of the\n', 'number of pixels in the input, and the height and width of hidden\n', 'feature maps.', ' We present experiments with CIFAR-10, along with varying\n', 'hyperparameters of a deep convolutional network, comparing our bounds\n', 'with practical generalization gaps.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.5833333134651184, 0.17391303181648254, 0.09090908616781235, 0.0, 0.1111111044883728, 0.08695651590824127, 0.09999999403953552, 0.27272728085517883, 0.11764705181121826]",r1e_FpNFDr,"['We prove generalization bounds for convolutional neural networks that take account of weight-tying', ""Studies the generalization power of CNNs and improves the upper bounds of generalization errors, showing correlation between the generalization error of learned CNNs and the upper bound's dominant term."", 'This paper presents a generalization bound for convolutional neural networks based on the number of parameters, the Lipschitz constant, and the distance of the final weights from initialization.']","['prove bound generalization error convolutional network ', 'bound term training loss  number', 'parameter  lipschitz constant loss distance', 'weight initial weight ', 'independent', 'number pixel input  height width hidden', 'feature map ', 'present experiment cifar10  along varying', 'hyperparameters deep convolutional network  comparing bound', 'practical generalization gap ']","We prove bounds on the generalization error of convolutional networks.
, The bounds are in terms of the training loss, the number of
, parameters, the Lipschitz constant of the loss and the distance from
, the weights to the initial weights.,  They are independent of the
, number of pixels in the input, and the height and width of hidden
, feature maps.,  We present experiments with CIFAR-10, along with varying
, hyperparameters of a deep convolutional network, comparing our bounds
, with practical generalization gaps.",15,5.275,5.333333333333333
298,"['MobileNets family of computer vision neural networks have fueled tremendous progress in the design and organization of resource-efficient architectures in recent years.', 'New applications with stringent real-time requirements in highly constrained devices require further compression of MobileNets-like already computeefficient networks.', 'Model quantization is a widely used technique to compress and accelerate neural network inference and prior works have quantized MobileNets to 4  6 bits albeit with a modest to significant drop in accuracy.', 'While quantization to sub-byte values (i.e. precision  8 bits) has been valuable, even further quantization of MobileNets to binary or ternary values is necessary to realize significant energy savings and possibly runtime speedups on specialized hardware, such as ASICs and FPGAs.', 'Under the key observation that convolutional filters at each layer of a deep neural network may respond differently to ternary quantization, we propose a novel quantization method that generates per-layer hybrid filter banks consisting of full-precision and ternary weight filters for MobileNets.', 'The layer-wise hybrid filter banks essentially combine the strengths of full-precision and ternary weight filters to derive a compact, energy-efficient architecture for MobileNets.', 'Using this proposed quantization method, we quantized a substantial portion of weight filters of MobileNets to ternary values resulting in 27.98% savings in energy, and a 51.07% reduction in the model size, while achieving comparable accuracy and no degradation in throughput on specialized hardware in comparison to the baseline full-precision MobileNets.']","[0, 0, 0, 0, 0, 0, 1]","[0.17391303181648254, 0.09090908616781235, 0.1428571343421936, 0.21875, 0.2857142686843872, 0.3265306055545807, 0.4057970941066742]",S1lVhxSYPH,"['2x savings in model size, 28% energy reduction for MobileNets on ImageNet at no loss in accuracy using hybrid layers composed of conventional full-precision filters and ternary filters', 'Focuses on quantizing the MobileNets architecture to ternary values, lowering the required space and computation in order to make neural networks more energy efficient.', 'The paper proposes layer-wise hybrid filter bank which only quantizes a fraction of convolutional filters to ternary values towards the MobileNets architecture.']","['mobilenets family computer vision neural network fueled tremendous progress design organization resourceefficient architecture recent year ', 'new application stringent realtime requirement highly constrained device require compression mobilenetslike already computeefficient network ', 'model quantization widely used technique compress accelerate neural network inference prior work quantized mobilenets 4  6 bit albeit modest significant drop accuracy ', 'quantization subbyte value  ie  precision  8 bit  valuable  even quantization mobilenets binary ternary value necessary realize significant energy saving possibly runtime speedup specialized hardware  asics fpgas ', 'key observation convolutional filter layer deep neural network may respond differently ternary quantization  propose novel quantization method generates perlayer hybrid filter bank consisting fullprecision ternary weight filter mobilenets ', 'layerwise hybrid filter bank essentially combine strength fullprecision ternary weight filter derive compact  energyefficient architecture mobilenets ', 'using proposed quantization method  quantized substantial portion weight filter mobilenets ternary value resulting 2798  saving energy  5107  reduction model size  achieving comparable accuracy degradation throughput specialized hardware comparison baseline fullprecision mobilenets ']","MobileNets family of computer vision neural networks have fueled tremendous progress in the design and organization of resource-efficient architectures in recent years., New applications with stringent real-time requirements in highly constrained devices require further compression of MobileNets-like already computeefficient networks., Model quantization is a widely used technique to compress and accelerate neural network inference and prior works have quantized MobileNets to 4  6 bits albeit with a modest to significant drop in accuracy., While quantization to sub-byte values (i.e. precision  8 bits) has been valuable, even further quantization of MobileNets to binary or ternary values is necessary to realize significant energy savings and possibly runtime speedups on specialized hardware, such as ASICs and FPGAs., Under the key observation that convolutional filters at each layer of a deep neural network may respond differently to ternary quantization, we propose a novel quantization method that generates per-layer hybrid filter banks consisting of full-precision and ternary weight filters for MobileNets., The layer-wise hybrid filter banks essentially combine the strengths of full-precision and ternary weight filters to derive a compact, energy-efficient architecture for MobileNets., Using this proposed quantization method, we quantized a substantial portion of weight filters of MobileNets to ternary values resulting in 27.98% savings in energy, and a 51.07% reduction in the model size, while achieving comparable accuracy and no degradation in throughput on specialized hardware in comparison to the baseline full-precision MobileNets.",14,6.129310344827586,15.466666666666667
299,"['Performing controlled experiments on noisy data is essential in thoroughly understanding deep learning across a spectrum of noise levels.', 'Due to the lack of suitable datasets, previous research have only examined deep learning on controlled synthetic noise, and real-world noise has never been systematically studied in a controlled setting.', 'To this end, this paper establishes a benchmark of real-world noisy labels at 10 controlled noise levels.', 'As real-world noise possesses unique properties, to understand the difference, we conduct a large-scale study across a variety of noise levels and types, architectures, methods, and training settings.', 'Our study shows that: (1) Deep Neural Networks (DNNs) generalize much better on real-world noise.', '(2) DNNs may not learn patterns first on real-world noisy data.', '(3) When networks are fine-tuned, ImageNet architectures generalize well on noisy data.', '(4) Real-world noise appears to be less harmful, yet it is more difficult for robust DNN methods to improve.', '(5) Robust learning methods that work well on synthetic noise may not work as well on real-world noise, and vice versa.', 'We hope our benchmark, as well as our findings, will facilitate deep learning research on noisy data.\n']","[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.3333333134651184, 0.260869562625885, 0.42424240708351135, 0.2380952388048172, 0.1249999925494194, 0.2142857164144516, 0.13793103396892548, 0.05714285373687744, 0.17142856121063232, 0.1818181723356247]",Syx-bCEFPS,"['We establish a benchmark of controlled real noise and reveal several interesting findings about real-world noisy data.', 'This paper compares 6 existing noisy label learning methods in two training settings: from scratch, and finetuning.', 'The authors establish a large dataset and benchmark of controlled real-world noise for performing controlled experiments on noisy data in deep learning.']","['performing controlled experiment noisy data essential thoroughly understanding deep learning across spectrum noise level ', 'due lack suitable datasets  previous research examined deep learning controlled synthetic noise  realworld noise never systematically studied controlled setting ', 'end  paper establishes benchmark realworld noisy label 10 controlled noise level ', 'realworld noise posse unique property  understand difference  conduct largescale study across variety noise level type  architecture  method  training setting ', 'study show   1  deep neural network  dnns  generalize much better realworld noise ', ' 2  dnns may learn pattern first realworld noisy data ', ' 3  network finetuned  imagenet architecture generalize well noisy data ', ' 4  realworld noise appears le harmful  yet difficult robust dnn method improve ', ' 5  robust learning method work well synthetic noise may work well realworld noise  vice versa ', 'hope benchmark  well finding  facilitate deep learning research noisy data ']","Performing controlled experiments on noisy data is essential in thoroughly understanding deep learning across a spectrum of noise levels., Due to the lack of suitable datasets, previous research have only examined deep learning on controlled synthetic noise, and real-world noise has never been systematically studied in a controlled setting., To this end, this paper establishes a benchmark of real-world noisy labels at 10 controlled noise levels., As real-world noise possesses unique properties, to understand the difference, we conduct a large-scale study across a variety of noise levels and types, architectures, methods, and training settings., Our study shows that: (1) Deep Neural Networks (DNNs) generalize much better on real-world noise., (2) DNNs may not learn patterns first on real-world noisy data., (3) When networks are fine-tuned, ImageNet architectures generalize well on noisy data., (4) Real-world noise appears to be less harmful, yet it is more difficult for robust DNN methods to improve., (5) Robust learning methods that work well on synthetic noise may not work as well on real-world noise, and vice versa., We hope our benchmark, as well as our findings, will facilitate deep learning research on noisy data.
",23,5.439153439153439,8.217391304347826
300,"['Designing RNA molecules has garnered recent interest in medicine, synthetic biology, biotechnology and bioinformatics since many functional RNA molecules were shown to be involved in regulatory processes for transcription, epigenetics and translation.', ""Since an RNA's function depends on its structural properties, the RNA Design problem is to find an RNA sequence which satisfies given structural constraints."", 'Here, we propose a new algorithm for the RNA Design problem, dubbed LEARNA.', 'LEARNA uses deep reinforcement learning to train a policy network to sequentially design an entire RNA sequence given a specified target structure.', 'By meta-learning across 65000 different RNA Design tasks for one hour on 20 CPU cores, our extension Meta-LEARNA constructs an RNA Design policy that can be applied out of the box to solve novel RNA Design tasks.', 'Methodologically, for what we believe to be the first time, we jointly optimize over a rich space of architectures for the policy network, the hyperparameters of the training procedure and the formulation of the decision process.', 'Comprehensive empirical results on two widely-used RNA Design benchmarks, as well as a third one that we introduce, show that our approach achieves new state-of-the-art performance on the former while also being orders of magnitudes faster in reaching the previous state-of-the-art performance.', ""In an ablation study, we analyze the importance of our method's different components.\n""]","[0, 1, 0, 0, 0, 0, 0, 0]","[0.13636362552642822, 0.2702702581882477, 0.20689654350280762, 0.2222222238779068, 0.2083333283662796, 0.1395348757505417, 0.11538460850715637, 0.06666666269302368]",ByfyHh05tQ,"['We learn to solve the RNA Design problem with reinforcement learning using meta learning and autoML approaches.', 'Used policy gradient optimization for generating RNA sequences which fold into a target secondary structure, resulting in clear accuracy and runtime improvements. ']","['designing rna molecule garnered recent interest medicine  synthetic biology  biotechnology bioinformatics since many functional rna molecule shown involved regulatory process transcription  epigenetics translation ', 'since rna function depends structural property  rna design problem find rna sequence satisfies given structural constraint ', ' propose new algorithm rna design problem  dubbed learna ', 'learna us deep reinforcement learning train policy network sequentially design entire rna sequence given specified target structure ', 'metalearning across 65000 different rna design task one hour 20 cpu core  extension metalearna construct rna design policy applied box solve novel rna design task ', 'methodologically  believe first time  jointly optimize rich space architecture policy network  hyperparameters training procedure formulation decision process ', 'comprehensive empirical result two widelyused rna design benchmark  well third one introduce  show approach achieves new stateoftheart performance former also order magnitude faster reaching previous stateoftheart performance ', 'ablation study  analyze importance method different component ']","Designing RNA molecules has garnered recent interest in medicine, synthetic biology, biotechnology and bioinformatics since many functional RNA molecules were shown to be involved in regulatory processes for transcription, epigenetics and translation., Since an RNA's function depends on its structural properties, the RNA Design problem is to find an RNA sequence which satisfies given structural constraints., Here, we propose a new algorithm for the RNA Design problem, dubbed LEARNA., LEARNA uses deep reinforcement learning to train a policy network to sequentially design an entire RNA sequence given a specified target structure., By meta-learning across 65000 different RNA Design tasks for one hour on 20 CPU cores, our extension Meta-LEARNA constructs an RNA Design policy that can be applied out of the box to solve novel RNA Design tasks., Methodologically, for what we believe to be the first time, we jointly optimize over a rich space of architectures for the policy network, the hyperparameters of the training procedure and the formulation of the decision process., Comprehensive empirical results on two widely-used RNA Design benchmarks, as well as a third one that we introduce, show that our approach achieves new state-of-the-art performance on the former while also being orders of magnitudes faster in reaching the previous state-of-the-art performance., In an ablation study, we analyze the importance of our method's different components.
",21,5.598173515981735,10.428571428571429
301,"['Pruning is a popular technique for compressing a neural network: a large pre-trained network is fine-tuned while connections are successively removed.', 'However, the value of pruning has largely evaded scrutiny.', 'In this extended abstract, we examine residual networks obtained through Fisher-pruning and make two interesting observations.', 'First, when time-constrained, it is better to train a simple, smaller network from scratch than prune a large network.', 'Second, it is the architectures obtained through the pruning process  --- not the learnt weights --- that prove valuable.', 'Such architectures are powerful when trained from scratch.', 'Furthermore, these architectures are easy to approximate without any further pruning: we can prune once and obtain a family of new, scalable network architectures for different memory requirements.']","[0, 0, 0, 0, 0, 0, 1]","[0.060606054961681366, 0.0833333283662796, 0.06451612710952759, 0.1249999925494194, 0.12903225421905518, 0.08695651590824127, 0.1428571343421936]",r1lbgwFj5m,"['Training small networks beats pruning, but pruning finds good small networks to train that are easy to copy.']","['pruning popular technique compressing neural network  large pretrained network finetuned connection successively removed ', 'however  value pruning largely evaded scrutiny ', 'extended abstract  examine residual network obtained fisherpruning make two interesting observation ', 'first  timeconstrained  better train simple  smaller network scratch prune large network ', 'second  architecture obtained pruning process   learnt weight   prove valuable ', 'architecture powerful trained scratch ', 'furthermore  architecture easy approximate without pruning  prune obtain family new  scalable network architecture different memory requirement ']","Pruning is a popular technique for compressing a neural network: a large pre-trained network is fine-tuned while connections are successively removed., However, the value of pruning has largely evaded scrutiny., In this extended abstract, we examine residual networks obtained through Fisher-pruning and make two interesting observations., First, when time-constrained, it is better to train a simple, smaller network from scratch than prune a large network., Second, it is the architectures obtained through the pruning process  --- not the learnt weights --- that prove valuable., Such architectures are powerful when trained from scratch., Furthermore, these architectures are easy to approximate without any further pruning: we can prune once and obtain a family of new, scalable network architectures for different memory requirements.",15,5.883333333333334,8.0
302,"['Supervised learning problems---particularly those involving social data---are often subjective.', 'That is, human readers, looking at the same data, might come to legitimate but completely different conclusions based on their personal experiences.', ""Yet in machine learning settings feedback from multiple human annotators is often reduced to a single ``ground truth'' label, thus hiding the true, potentially rich and diverse interpretations of the data found across the social spectrum."", 'We explore the rewards and challenges of discovering and learning representative distributions of the labeling opinions of a large human population.', 'A major, critical cost to this approach is the number of humans needed to provide enough labels not only to obtain representative samples but also to train a machine to predict representative distributions on unlabeled data.', 'We propose aggregating label distributions over, not just individuals, but also data items, in order to maximize the costs of humans in the loop.', 'We test different aggregation approaches on state-of-the-art deep learning models.', 'Our results suggest that careful label aggregation methods can greatly reduce the number of samples needed to obtain representative distributions.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.0833333283662796, 0.10810810327529907, 0.20408162474632263, 0.25, 0.17391303181648254, 0.2702702581882477, 0.1599999964237213, 0.17142856121063232]",HJlsixKqyQ,['We study the problem of learning to predict the underlying diversity of beliefs present in supervised learning domains.'],"['supervised learning problem  particularly involving social data  often subjective ', ' human reader  looking data  might come legitimate completely different conclusion based personal experience ', 'yet machine learning setting feedback multiple human annotator often reduced single  ground truth  label  thus hiding true  potentially rich diverse interpretation data found across social spectrum ', 'explore reward challenge discovering learning representative distribution labeling opinion large human population ', 'major  critical cost approach number human needed provide enough label obtain representative sample also train machine predict representative distribution unlabeled data ', 'propose aggregating label distribution  individual  also data item  order maximize cost human loop ', 'test different aggregation approach stateoftheart deep learning model ', 'result suggest careful label aggregation method greatly reduce number sample needed obtain representative distribution ']","Supervised learning problems---particularly those involving social data---are often subjective., That is, human readers, looking at the same data, might come to legitimate but completely different conclusions based on their personal experiences., Yet in machine learning settings feedback from multiple human annotators is often reduced to a single ``ground truth'' label, thus hiding the true, potentially rich and diverse interpretations of the data found across the social spectrum., We explore the rewards and challenges of discovering and learning representative distributions of the labeling opinions of a large human population., A major, critical cost to this approach is the number of humans needed to provide enough labels not only to obtain representative samples but also to train a machine to predict representative distributions on unlabeled data., We propose aggregating label distributions over, not just individuals, but also data items, in order to maximize the costs of humans in the loop., We test different aggregation approaches on state-of-the-art deep learning models., Our results suggest that careful label aggregation methods can greatly reduce the number of samples needed to obtain representative distributions.",17,5.882022471910112,10.470588235294118
303,"['Recent advancements in deep learning techniques such as Convolutional Neural Networks(CNN) and Generative Adversarial Networks(GAN) have achieved breakthroughs in the problem of semantic image inpainting, the task of reconstructing missing pixels in given images.', 'While much more effective than conventional approaches, deep learning models require large datasets and great computational resources for training, and inpainting quality varies considerably when training data vary in size and diversity.', 'To address these problems, we present in this paper a inpainting strategy of \\textit{Comparative Sample Augmentation}, which enhances the quality of training set by filtering out irrelevant images and constructing additional images using information about the surrounding regions of the images to be inpainted.', 'Experiments on multiple datasets demonstrate that our method extends the applicability of deep inpainting models to training sets with varying sizes, while maintaining inpainting quality as measured by qualitative and quantitative metrics for a large class of deep models, with little need for model-specific consideration.']","[0, 0, 0, 1]","[0.04651162400841713, 0.1395348757505417, 0.19607843458652496, 0.22641509771347046]",Sklsts5H_E,"['We introduced a strategy which enables inpainting models on datasets of various sizes', 'Help image inpainting using GANs by using a comparative augmenting filter and adding random noise to each pixel.']","['recent advancement deep learning technique convolutional neural network  cnn  generative adversarial network  gan  achieved breakthrough problem semantic image inpainting  task reconstructing missing pixel given image ', 'much effective conventional approach  deep learning model require large datasets great computational resource training  inpainting quality varies considerably training data vary size diversity ', 'address problem  present paper inpainting strategy textit  comparative sample augmentation   enhances quality training set filtering irrelevant image constructing additional image using information surrounding region image inpainted ', 'experiment multiple datasets demonstrate method extends applicability deep inpainting model training set varying size  maintaining inpainting quality measured qualitative quantitative metric large class deep model  little need modelspecific consideration ']","Recent advancements in deep learning techniques such as Convolutional Neural Networks(CNN) and Generative Adversarial Networks(GAN) have achieved breakthroughs in the problem of semantic image inpainting, the task of reconstructing missing pixels in given images., While much more effective than conventional approaches, deep learning models require large datasets and great computational resources for training, and inpainting quality varies considerably when training data vary in size and diversity., To address these problems, we present in this paper a inpainting strategy of \textit{Comparative Sample Augmentation}, which enhances the quality of training set by filtering out irrelevant images and constructing additional images using information about the surrounding regions of the images to be inpainted., Experiments on multiple datasets demonstrate that our method extends the applicability of deep inpainting models to training sets with varying sizes, while maintaining inpainting quality as measured by qualitative and quantitative metrics for a large class of deep models, with little need for model-specific consideration.",11,6.290322580645161,14.090909090909092
304,"['Generative adversarial networks (GANs) are a family of generative models that do not minimize a single training criterion.', 'Unlike other generative models, the data distribution is learned via a game between a generator (the generative model) and a discriminator (a teacher providing training signal) that each minimize their own cost.', 'GANs are designed to reach a Nash equilibrium at which each player cannot reduce their cost without changing the other players parameters.', 'One useful approach for the theory of GANs is to show that a divergence between the training distribution and the model distribution obtains its minimum value at equilibrium.', 'Several recent research directions have been motivated by the idea that this divergence is the primary guide for the learning process and that every step of learning should decrease the divergence.', 'We show that this view is overly restrictive.', 'During GAN training, the discriminator provides learning signal in situations where the gradients of the divergences between distributions would not be useful.', 'We provide empirical counterexamples to the view of GAN training as divergence minimization.', 'Specifically, we demonstrate that GANs are able to learn distributions in situations where the divergence minimization point of view predicts they would fail.', 'We also show that gradient penalties motivated from the divergence minimization perspective are equally helpful when applied in other contexts in which the divergence minimization perspective does not predict they would be helpful.', 'This contributes to a growing body of evidence that GAN training may be more usefully viewed as approaching Nash equilibria via trajectories that do not necessarily minimize a specific divergence at each step.']","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.25, 0.09090908616781235, 0.0, 0.19999998807907104, 0.14999999105930328, 0.17391303181648254, 0.22857142984867096, 0.4285714328289032, 0.21052631735801697, 0.2857142686843872, 0.3913043439388275]",ByQpn1ZA-,"['We find evidence that divergence minimization may not be an accurate characterization of GAN training.', 'The submission aims to present empirical evidence that the theory of divergence minimization is more a tool to understand the outcome of training GANs than a necessary condition to be enforce during training itself', 'This paper studies non-saturating GANs and the effect of two penalized gradient approaches, considering several thought experiments to demonstrate observations and validate them on real data experiments.']","['generative adversarial network  gans  family generative model minimize single training criterion ', 'unlike generative model  data distribution learned via game generator  generative model  discriminator  teacher providing training signal  minimize cost ', 'gans designed reach nash equilibrium player reduce cost without changing player  parameter ', 'one useful approach theory gans show divergence training distribution model distribution obtains minimum value equilibrium ', 'several recent research direction motivated idea divergence primary guide learning process every step learning decrease divergence ', 'show view overly restrictive ', 'gan training  discriminator provides learning signal situation gradient divergence distribution would useful ', 'provide empirical counterexample view gan training divergence minimization ', 'specifically  demonstrate gans able learn distribution situation divergence minimization point view predicts would fail ', 'also show gradient penalty motivated divergence minimization perspective equally helpful applied context divergence minimization perspective predict would helpful ', 'contributes growing body evidence gan training may usefully viewed approaching nash equilibrium via trajectory necessarily minimize specific divergence step ']","Generative adversarial networks (GANs) are a family of generative models that do not minimize a single training criterion., Unlike other generative models, the data distribution is learned via a game between a generator (the generative model) and a discriminator (a teacher providing training signal) that each minimize their own cost., GANs are designed to reach a Nash equilibrium at which each player cannot reduce their cost without changing the other players parameters., One useful approach for the theory of GANs is to show that a divergence between the training distribution and the model distribution obtains its minimum value at equilibrium., Several recent research directions have been motivated by the idea that this divergence is the primary guide for the learning process and that every step of learning should decrease the divergence., We show that this view is overly restrictive., During GAN training, the discriminator provides learning signal in situations where the gradients of the divergences between distributions would not be useful., We provide empirical counterexamples to the view of GAN training as divergence minimization., Specifically, we demonstrate that GANs are able to learn distributions in situations where the divergence minimization point of view predicts they would fail., We also show that gradient penalties motivated from the divergence minimization perspective are equally helpful when applied in other contexts in which the divergence minimization perspective does not predict they would be helpful., This contributes to a growing body of evidence that GAN training may be more usefully viewed as approaching Nash equilibria via trajectories that do not necessarily minimize a specific divergence at each step.",14,5.634980988593156,18.785714285714285
305,"['Measuring Mutual Information (MI) between high-dimensional, continuous, random variables from observed samples has wide theoretical and practical applications.', 'Recent works have developed accurate MI estimators through provably low-bias approximations and tight variational lower bounds assuming abundant supply of samples, but require an unrealistic number of samples to guarantee statistical significance of the estimation.', 'In this work, we focus on improving data efficiency and propose a Data-Efficient MINE Estimator (DEMINE) that can provide a tight lower confident interval of MI under limited data, through adding cross-validation to the MINE lower bound (Belghazi et al., 2018).', 'Hyperparameter search is employed and a novel meta-learning approach with task augmentation is developed to increase robustness to hyperparamters, reduce overfitting and improve accuracy.', 'With improved data-efficiency, our DEMINE estimator enables statistical testing of dependency at practical dataset sizes.', 'We demonstrate the effectiveness of DEMINE on synthetic benchmarks and a real world fMRI dataset, with application of inter-subject correlation analysis.']","[0, 0, 0, 0, 0, 1]","[0.10810810327529907, 0.11538460850715637, 0.13793103396892548, 0.09999999403953552, 0.23529411852359772, 0.3589743673801422]",SklOypVKvS,"['A new & practical statistical test of dependency using neural networks, benchmarked on synthetic and a real fMRI datasets.', 'Proposes a neural-network-based estimation of mutal information which can reliably work with small datasets, reducing the sample complexity by decoupling the network learning problem and the estimation problem.']","['measuring mutual information  mi  highdimensional  continuous  random variable observed sample wide theoretical practical application ', 'recent work developed accurate mi estimator provably lowbias approximation tight variational lower bound assuming abundant supply sample  require unrealistic number sample guarantee statistical significance estimation ', 'work  focus improving data efficiency propose dataefficient mine estimator  demine  provide tight lower confident interval mi limited data  adding crossvalidation mine lower bound  belghazi et al  2018  ', 'hyperparameter search employed novel metalearning approach task augmentation developed increase robustness hyperparamters  reduce overfitting improve accuracy ', 'improved dataefficiency  demine estimator enables statistical testing dependency practical dataset size ', 'demonstrate effectiveness demine synthetic benchmark real world fmri dataset  application intersubject correlation analysis ']","Measuring Mutual Information (MI) between high-dimensional, continuous, random variables from observed samples has wide theoretical and practical applications., Recent works have developed accurate MI estimators through provably low-bias approximations and tight variational lower bounds assuming abundant supply of samples, but require an unrealistic number of samples to guarantee statistical significance of the estimation., In this work, we focus on improving data efficiency and propose a Data-Efficient MINE Estimator (DEMINE) that can provide a tight lower confident interval of MI under limited data, through adding cross-validation to the MINE lower bound (Belghazi et al., 2018)., Hyperparameter search is employed and a novel meta-learning approach with task augmentation is developed to increase robustness to hyperparamters, reduce overfitting and improve accuracy., With improved data-efficiency, our DEMINE estimator enables statistical testing of dependency at practical dataset sizes., We demonstrate the effectiveness of DEMINE on synthetic benchmarks and a real world fMRI dataset, with application of inter-subject correlation analysis.",15,6.422077922077922,10.266666666666667
306,"['Language and vision are processed as two different modal in current work for image captioning.', 'However, recent work on Super Characters method shows the effectiveness of two-dimensional word embedding, which converts text classification problem into image classification problem.', 'In this paper, we propose the SuperCaptioning method, which borrows the idea of two-dimensional word embedding from Super Characters method, and processes the information of language and vision together in one single CNN model.', 'The experimental results on Flickr30k data shows the proposed method gives high quality image captions.', 'An interactive demo is ready to show at the workshop.']","[0, 0, 1, 0, 0]","[0.0952380895614624, 0.14814814925193787, 0.17142856121063232, 0.0, 0.0]",BklRs139T4,['Image captioning using two-dimensional word embedding.'],"['language vision processed two different modal current work image captioning ', 'however  recent work super character method show effectiveness twodimensional word embedding  convert text classification problem image classification problem ', 'paper  propose supercaptioning method  borrows idea twodimensional word embedding super character method  process information language vision together one single cnn model ', 'experimental result flickr30k data show proposed method give high quality image caption ', 'interactive demo ready show workshop ']","Language and vision are processed as two different modal in current work for image captioning., However, recent work on Super Characters method shows the effectiveness of two-dimensional word embedding, which converts text classification problem into image classification problem., In this paper, we propose the SuperCaptioning method, which borrows the idea of two-dimensional word embedding from Super Characters method, and processes the information of language and vision together in one single CNN model., The experimental results on Flickr30k data shows the proposed method gives high quality image captions., An interactive demo is ready to show at the workshop.",10,5.814432989690721,9.7
307,"['Determining the optimal order in which data examples are presented to Deep Neural Networks during training is a non-trivial problem.', 'However, choosing a non-trivial scheduling method may drastically improve convergence.', 'In this paper, we propose a Self-Paced Learning (SPL)-fused Deep Metric Learning (DML) framework, which we call Learning Embeddings for Adaptive Pace (LEAP).', 'Our method parameterizes mini-batches dynamically based on the \\textit{easiness} and \\textit{true diverseness} of the sample within a salient feature representation space.', 'In LEAP, we train an \\textit{embedding} Convolutional Neural Network (CNN) to learn an expressive representation space by adaptive density discrimination using the Magnet Loss.', 'The \\textit{student} CNN classifier dynamically selects samples to form a mini-batch based on the \\textit{easiness} from cross-entropy losses and \\textit{true diverseness} of examples from the representation space sculpted by the \\textit{embedding} CNN.', 'We evaluate LEAP using deep CNN architectures for the task of supervised image classification on MNIST, FashionMNIST, CIFAR-10, CIFAR-100, and SVHN.', 'We show that the LEAP framework converges faster with respect to the number of mini-batch updates required to achieve a comparable or better test performance on each of the datasets.']","[0, 0, 0, 0, 0, 0, 0, 1]","[0.21276594698429108, 0.054054051637649536, 0.04255318641662598, 0.21276594698429108, 0.19999998807907104, 0.2545454502105713, 0.1666666567325592, 0.30188679695129395]",rk9kKMZ0-,"['LEAP combines the strength of adaptive sampling with that of mini-batch online learning and adaptive representation learning to formulate a representative self-paced strategy in an end-to-end DNN training protocol. ', ""Introduces a method for creating mini batches for a student network by using a second learned representation space to dynamically select examples by their 'easiness and true diverseness'."", 'Experiments the classification accuracy on MNIST, FashionMNIST, and CIFAR-10 datasets to learn a representation with curriculum learning style minibatch selection in an end-to-end framework.']","['determining optimal order data example presented deep neural network training nontrivial problem ', 'however  choosing nontrivial scheduling method may drastically improve convergence ', 'paper  propose selfpaced learning  spl  fused deep metric learning  dml  framework  call learning embeddings adaptive pace  leap  ', 'method parameterizes minibatches dynamically based textit  easiness  textit  true diverseness  sample within salient feature representation space ', 'leap  train textit  embedding  convolutional neural network  cnn  learn expressive representation space adaptive density discrimination using magnet loss ', 'textit  student  cnn classifier dynamically selects sample form minibatch based textit  easiness  crossentropy loss textit  true diverseness  example representation space sculpted textit  embedding  cnn ', 'evaluate leap using deep cnn architecture task supervised image classification mnist  fashionmnist  cifar10  cifar100  svhn ', 'show leap framework converges faster respect number minibatch update required achieve comparable better test performance datasets ']","Determining the optimal order in which data examples are presented to Deep Neural Networks during training is a non-trivial problem., However, choosing a non-trivial scheduling method may drastically improve convergence., In this paper, we propose a Self-Paced Learning (SPL)-fused Deep Metric Learning (DML) framework, which we call Learning Embeddings for Adaptive Pace (LEAP)., Our method parameterizes mini-batches dynamically based on the \textit{easiness} and \textit{true diverseness} of the sample within a salient feature representation space., In LEAP, we train an \textit{embedding} Convolutional Neural Network (CNN) to learn an expressive representation space by adaptive density discrimination using the Magnet Loss., The \textit{student} CNN classifier dynamically selects samples to form a mini-batch based on the \textit{easiness} from cross-entropy losses and \textit{true diverseness} of examples from the representation space sculpted by the \textit{embedding} CNN., We evaluate LEAP using deep CNN architectures for the task of supervised image classification on MNIST, FashionMNIST, CIFAR-10, CIFAR-100, and SVHN., We show that the LEAP framework converges faster with respect to the number of mini-batch updates required to achieve a comparable or better test performance on each of the datasets.",16,6.209944751381215,11.3125
308,"['Conventional deep reinforcement learning typically determines an appropriate primitive action at each timestep, which requires enormous amount of time and effort for learning an effective policy, especially in large and complex environments.', 'To deal with the issue fundamentally, we incorporate macro actions, defined as sequences of primitive actions, into the primitive action space to form an augmented action space.', 'The problem lies in how to find an appropriate macro action to augment the primitive action space.  ', 'The agent using a proper augmented action space is able to jump to a farther state and thus speed up the exploration process as well as facilitate the learning procedure.', 'In previous researches, macro actions are developed by mining the most frequently used action sequences or repeating previous actions.', 'However, the most frequently used action sequences are extracted from a past policy, which may only reinforce the original behavior of that policy.', 'On the other hand, repeating actions may limit the diversity of behaviors of the agent.', 'Instead, we propose to construct macro actions by a genetic algorithm, which eliminates the dependency of the macro action derivation procedure from the past policies of the agent.  ', 'Our approach appends a macro action to the primitive action space once at a time and evaluates whether the augmented action space leads to promising performance or not.   ', 'We perform extensive experiments and show that the constructed macro actions are able to speed up the learning process for a variety of deep reinforcement learning methods.', 'Our experimental results also demonstrate that the macro actions suggested by our approach are transferable among deep reinforcement learning methods and similar environments.', 'We further provide a comprehensive set of ablation analysis to validate our methodology.']","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.11764705181121826, 0.22727271914482117, 0.21052631735801697, 0.25, 0.25641024112701416, 0.3181818127632141, 0.23529411852359772, 0.9130434989929199, 0.2222222238779068, 0.2978723347187042, 0.17777776718139648, 0.22857142984867096]",SJgubJrKPr,"['We propose to construct macro actions by a genetic algorithm, which eliminates the dependency of the macro action derivation procedure from the past policies of the agent.', 'This paper proposes a generic algorithm for constructing macro actions for deep reinforcement learning by appending a macro action to the primitive action space.']","['conventional deep reinforcement learning typically determines appropriate primitive action timestep  requires enormous amount time effort learning effective policy  especially large complex environment ', 'deal issue fundamentally  incorporate macro action  defined sequence primitive action  primitive action space form augmented action space ', 'problem lie find appropriate macro action augment primitive action space ', 'agent using proper augmented action space able jump farther state thus speed exploration process well facilitate learning procedure ', 'previous research  macro action developed mining frequently used action sequence repeating previous action ', 'however  frequently used action sequence extracted past policy  may reinforce original behavior policy ', 'hand  repeating action may limit diversity behavior agent ', 'instead  propose construct macro action genetic algorithm  eliminates dependency macro action derivation procedure past policy agent ', 'approach appends macro action primitive action space time evaluates whether augmented action space lead promising performance ', 'perform extensive experiment show constructed macro action able speed learning process variety deep reinforcement learning method ', 'experimental result also demonstrate macro action suggested approach transferable among deep reinforcement learning method similar environment ', 'provide comprehensive set ablation analysis validate methodology ']","Conventional deep reinforcement learning typically determines an appropriate primitive action at each timestep, which requires enormous amount of time and effort for learning an effective policy, especially in large and complex environments., To deal with the issue fundamentally, we incorporate macro actions, defined as sequences of primitive actions, into the primitive action space to form an augmented action space., The problem lies in how to find an appropriate macro action to augment the primitive action space.  , The agent using a proper augmented action space is able to jump to a farther state and thus speed up the exploration process as well as facilitate the learning procedure., In previous researches, macro actions are developed by mining the most frequently used action sequences or repeating previous actions., However, the most frequently used action sequences are extracted from a past policy, which may only reinforce the original behavior of that policy., On the other hand, repeating actions may limit the diversity of behaviors of the agent., Instead, we propose to construct macro actions by a genetic algorithm, which eliminates the dependency of the macro action derivation procedure from the past policies of the agent.  , Our approach appends a macro action to the primitive action space once at a time and evaluates whether the augmented action space leads to promising performance or not.   , We perform extensive experiments and show that the constructed macro actions are able to speed up the learning process for a variety of deep reinforcement learning methods., Our experimental results also demonstrate that the macro actions suggested by our approach are transferable among deep reinforcement learning methods and similar environments., We further provide a comprehensive set of ablation analysis to validate our methodology.",23,5.5177304964539005,12.26086956521739
309,"['A key problem in neuroscience and life sciences more generally is that the data generation process is often best thought of as a hierarchy of dynamic systems.', 'One example of this is in-vivo calcium imaging data, where observed calcium transients are driven by a combination of electro-chemical kinetics where hypothesized trajectories around manifolds determining the frequency of these transients.', 'A recent approach using sequential variational auto-encoders demonstrated it was possible to learn the latent dynamic structure of reaching behaviour from spiking data modelled as a Poisson process.', 'Here we extend this approach using a ladder method to infer the spiking events driving calcium transients along with the deeper latent dynamic system.', 'We show strong performance of this approach on a benchmark synthetic dataset against a number of alternatives.']","[0, 0, 0, 1, 0]","[0.04651162400841713, 0.08888888359069824, 0.1304347813129425, 0.1463414579629898, 0.12121211737394333]",B1eWVQYULB,['We propose an extension to LFADS capable of inferring spike trains to reconstruct calcium fluorescence traces using hierarchical VAEs.'],"['key problem neuroscience life science generally data generation process often best thought hierarchy dynamic system ', 'one example invivo calcium imaging data  observed calcium transient driven combination electrochemical kinetics hypothesized trajectory around manifold determining frequency transient ', 'recent approach using sequential variational autoencoders demonstrated possible learn latent dynamic structure reaching behaviour spiking data modelled poisson process ', 'extend approach using ladder method infer spiking event driving calcium transient along deeper latent dynamic system ', 'show strong performance approach benchmark synthetic dataset number alternative ']","A key problem in neuroscience and life sciences more generally is that the data generation process is often best thought of as a hierarchy of dynamic systems., One example of this is in-vivo calcium imaging data, where observed calcium transients are driven by a combination of electro-chemical kinetics where hypothesized trajectories around manifolds determining the frequency of these transients., A recent approach using sequential variational auto-encoders demonstrated it was possible to learn the latent dynamic structure of reaching behaviour from spiking data modelled as a Poisson process., Here we extend this approach using a ladder method to infer the spiking events driving calcium transients along with the deeper latent dynamic system., We show strong performance of this approach on a benchmark synthetic dataset against a number of alternatives.",6,5.7109375,21.333333333333332
310,"['In spite of the recent success of neural machine translation (NMT) in standard benchmarks, the lack of large parallel corpora poses a major practical problem for many language pairs.', 'There have been several proposals to alleviate this issue with, for instance, triangulation and semi-supervised learning techniques, but they still require a strong cross-lingual signal.', 'In this work, we completely remove the need of parallel data and propose a novel method to train an NMT system in a completely unsupervised manner, relying on nothing but monolingual corpora.', 'Our model builds upon the recent work on unsupervised embedding mappings, and consists of a slightly modified attentional encoder-decoder model that can be trained on monolingual corpora alone using a combination of denoising and backtranslation.', 'Despite the simplicity of the approach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014 French-to-English and German-to-English translation.', 'The model can also profit from small parallel corpora, and attains 21.81 and 15.24 points when combined with 100,000 parallel sentences, respectively.', 'Our implementation is released as an open source project.']","[0, 0, 1, 0, 0, 0, 0]","[0.260869562625885, 0.08888888359069824, 0.47999998927116394, 0.19999998807907104, 0.1463414579629898, 0.0, 0.06896550953388214]",Sy2ogebAW,"['We introduce the first successful method to train neural machine translation in an unsupervised manner, using nothing but monolingual corpora', 'The authors present a model for unsupervised NMT which requires no parallel corpora between the two languages of interest. ', 'This is a paper on unsupervised MT which trains a standard architecture using word embeddings in a shared embedding space only with bilingual word papers and an encoder-decoder trained using monolingual data.']","['spite recent success neural machine translation  nmt  standard benchmark  lack large parallel corpus pose major practical problem many language pair ', 'several proposal alleviate issue  instance  triangulation semisupervised learning technique  still require strong crosslingual signal ', 'work  completely remove need parallel data propose novel method train nmt system completely unsupervised manner  relying nothing monolingual corpus ', 'model build upon recent work unsupervised embedding mapping  consists slightly modified attentional encoderdecoder model trained monolingual corpus alone using combination denoising backtranslation ', 'despite simplicity approach  system obtains 1556 1021 bleu point wmt 2014 frenchtoenglish germantoenglish translation ', 'model also profit small parallel corpus  attains 2181 1524 point combined 100000 parallel sentence  respectively ', 'implementation released open source project ']","In spite of the recent success of neural machine translation (NMT) in standard benchmarks, the lack of large parallel corpora poses a major practical problem for many language pairs., There have been several proposals to alleviate this issue with, for instance, triangulation and semi-supervised learning techniques, but they still require a strong cross-lingual signal., In this work, we completely remove the need of parallel data and propose a novel method to train an NMT system in a completely unsupervised manner, relying on nothing but monolingual corpora., Our model builds upon the recent work on unsupervised embedding mappings, and consists of a slightly modified attentional encoder-decoder model that can be trained on monolingual corpora alone using a combination of denoising and backtranslation., Despite the simplicity of the approach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014 French-to-English and German-to-English translation., The model can also profit from small parallel corpora, and attains 21.81 and 15.24 points when combined with 100,000 parallel sentences, respectively., Our implementation is released as an open source project.",17,5.705202312138728,10.176470588235293
311,"['We describe a new training methodology for generative adversarial networks.', 'The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses.', 'This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2.', 'We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10.', 'Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator.', 'Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation.', 'As an additional contribution, we construct a higher-quality version of the CelebA dataset.']","[1, 0, 0, 0, 0, 0, 0]","[0.3571428656578064, 0.08510638028383255, 0.1428571343421936, 0.19512194395065308, 0.0, 0.1666666567325592, 0.06451612710952759]",Hk99zCeAb,"['We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.', 'Introduces progressive growing and a simple parameter-free minibatch summary statistic feature for use in GAN training to enable synthesis of high-resolution images.']","['describe new training methodology generative adversarial network ', 'key idea grow generator discriminator progressively  starting low resolution  add new layer model increasingly fine detail training progress ', 'speed training greatly stabilizes  allowing u produce image unprecedented quality  eg  celeba image 10242 ', 'also propose simple way increase variation generated image  achieve record inception score 880 unsupervised cifar10 ', 'additionally  describe several implementation detail important discouraging unhealthy competition generator discriminator ', 'finally  suggest new metric evaluating gan result  term image quality variation ', 'additional contribution  construct higherquality version celeba dataset ']","We describe a new training methodology for generative adversarial networks., The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses., This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2., We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10., Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator., Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation., As an additional contribution, we construct a higher-quality version of the CelebA dataset.",16,5.681481481481481,8.4375
312,"['Designing a convolution for a spherical neural network requires a delicate tradeoff between efficiency and rotation equivariance.', 'DeepSphere, a method based on a graph representation of the discretized sphere, strikes a controllable balance between these two desiderata.', 'This contribution is twofold.', 'First, we study both theoretically and empirically how equivariance is affected by the underlying graph with respect to the number of pixels and neighbors.', 'Second, we evaluate DeepSphere on relevant problems.', 'Experiments show state-of-the-art performance and demonstrates the efficiency and flexibility of this formulation.', 'Perhaps surprisingly, comparison with previous work suggests that anisotropic filters might be an unnecessary price to pay.']","[0, 1, 0, 0, 0, 0, 0]","[0.19354838132858276, 0.23529411852359772, 0.0, 0.052631575614213943, 0.0, 0.0714285671710968, 0.12121211737394333]",B1e3OlStPB,"['A graph-based spherical CNN that strikes an interesting balance of trade-offs for a wide variety of applications.', 'Combines existing CNN frameworks based on the discretization of a sphere as a graph to show a convergence result which is related to the rotation equivalence on a sphere.', 'The authors use the existing graph CNN formulation and a pooling strategy that exploits hierarchical pixelations of the sphere to learn from the discretized sphere.']","['designing convolution spherical neural network requires delicate tradeoff efficiency rotation equivariance ', 'deepsphere  method based graph representation discretized sphere  strike controllable balance two desideratum ', 'contribution twofold ', 'first  study theoretically empirically equivariance affected underlying graph respect number pixel neighbor ', 'second  evaluate deepsphere relevant problem ', 'experiment show stateoftheart performance demonstrates efficiency flexibility formulation ', 'perhaps surprisingly  comparison previous work suggests anisotropic filter might unnecessary price pay ']","Designing a convolution for a spherical neural network requires a delicate tradeoff between efficiency and rotation equivariance., DeepSphere, a method based on a graph representation of the discretized sphere, strikes a controllable balance between these two desiderata., This contribution is twofold., First, we study both theoretically and empirically how equivariance is affected by the underlying graph with respect to the number of pixels and neighbors., Second, we evaluate DeepSphere on relevant problems., Experiments show state-of-the-art performance and demonstrates the efficiency and flexibility of this formulation., Perhaps surprisingly, comparison with previous work suggests that anisotropic filters might be an unnecessary price to pay.",12,6.294117647058823,8.5
313,"['The notion of the stationary equilibrium ensemble has played a central role in statistical mechanics.', 'In machine learning as well, training serves as generalized equilibration that drives the probability distribution of model parameters toward stationarity.', 'Here, we derive stationary fluctuation-dissipation relations that link measurable quantities and hyperparameters in the stochastic gradient descent algorithm.', 'These relations hold exactly for any stationary state and can in particular be used to adaptively set training schedule.', 'We can further use the relations to efficiently extract information pertaining to a loss-function landscape such as the magnitudes of its Hessian and anharmonicity.', 'Our claims are empirically verified.']","[0, 0, 0, 1, 0, 0]","[0.0, 0.04999999329447746, 0.1538461446762085, 0.44999998807907104, 0.23255813121795654, 0.0]",SkNksoRctQ,"['We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.', ""Paper's concepts work in the discrete-time formalism, use the master equation, and  remove reliance on a locally quadratic approximation of the loss function or on any Gaussian asumptions of the SGD noise. "", 'The authors derive the stationary fluctuation-dissipation relations that link measurable quantities and hyperparameters in SGD and use the relations to set training schedule adaptively and analyze the loss-function landscape.']","['notion stationary equilibrium ensemble played central role statistical mechanic ', 'machine learning well  training serf generalized equilibration drive probability distribution model parameter toward stationarity ', ' derive stationary fluctuationdissipation relation link measurable quantity hyperparameters stochastic gradient descent algorithm ', 'relation hold exactly stationary state particular used adaptively set training schedule ', 'use relation efficiently extract information pertaining lossfunction landscape magnitude hessian anharmonicity ', 'claim empirically verified ']","The notion of the stationary equilibrium ensemble has played a central role in statistical mechanics., In machine learning as well, training serves as generalized equilibration that drives the probability distribution of model parameters toward stationarity., Here, we derive stationary fluctuation-dissipation relations that link measurable quantities and hyperparameters in the stochastic gradient descent algorithm., These relations hold exactly for any stationary state and can in particular be used to adaptively set training schedule., We can further use the relations to efficiently extract information pertaining to a loss-function landscape such as the magnitudes of its Hessian and anharmonicity., Our claims are empirically verified.",8,6.306930693069307,12.625
314,"['Recurrent neural networks (RNNs) are difficult to train on sequence processing tasks, not only because input noise may be amplified through feedback, but also because any inaccuracy in the weights has similar consequences as input noise.', 'We describe a method for denoising the hidden state during training to achieve more robust representations thereby improving generalization performance.', ""Attractor dynamics are incorporated into the hidden state to `clean up' representations at each step of a sequence."", 'The attractor dynamics are trained through an auxillary denoising loss to recover previously experienced hidden states from noisy versions of those states.', 'This state-denoised recurrent neural network (SDRNN) performs multiple steps of internal processing for each external sequence step.', 'On a range of tasks, we show that the SDRNN outperforms a generic RNN as well as a variant of the SDRNN with attractor dynamics on the hidden state but without the auxillary loss.', 'We argue that attractor dynamics---and corresponding connectivity constraints---are an essential component of the deep learning arsenal and should be invoked not only for recurrent networks but also for improving deep feedforward nets and intertask transfer.']","[0, 1, 0, 0, 0, 0, 0]","[0.08163265138864517, 0.5, 0.29411762952804565, 0.21621620655059814, 0.1818181723356247, 0.2380952388048172, 0.2083333283662796]",HJgyAoRqFQ,['We propose a mechanism for denoising the internal state of an RNN to improve generalization performance.'],"['recurrent neural network  rnns  difficult train sequence processing task  input noise may amplified feedback  also inaccuracy weight similar consequence input noise ', 'describe method denoising hidden state training achieve robust representation thereby improving generalization performance ', 'attractor dynamic incorporated hidden state  clean  representation step sequence ', 'attractor dynamic trained auxillary denoising loss recover previously experienced hidden state noisy version state ', 'statedenoised recurrent neural network  sdrnn  performs multiple step internal processing external sequence step ', 'range task  show sdrnn outperforms generic rnn well variant sdrnn attractor dynamic hidden state without auxillary loss ', 'argue attractor dynamic  corresponding connectivity constraint  essential component deep learning arsenal invoked recurrent network also improving deep feedforward net intertask transfer ']","Recurrent neural networks (RNNs) are difficult to train on sequence processing tasks, not only because input noise may be amplified through feedback, but also because any inaccuracy in the weights has similar consequences as input noise., We describe a method for denoising the hidden state during training to achieve more robust representations thereby improving generalization performance., Attractor dynamics are incorporated into the hidden state to `clean up' representations at each step of a sequence., The attractor dynamics are trained through an auxillary denoising loss to recover previously experienced hidden states from noisy versions of those states., This state-denoised recurrent neural network (SDRNN) performs multiple steps of internal processing for each external sequence step., On a range of tasks, we show that the SDRNN outperforms a generic RNN as well as a variant of the SDRNN with attractor dynamics on the hidden state but without the auxillary loss., We argue that attractor dynamics---and corresponding connectivity constraints---are an essential component of the deep learning arsenal and should be invoked not only for recurrent networks but also for improving deep feedforward nets and intertask transfer.",10,5.769230769230769,18.2
315,"['We consider reinforcement learning in input-driven environments, where an exogenous, stochastic input process affects the dynamics of the system.', 'Input processes arise in many applications, including queuing systems, robotics control with disturbances, and object tracking.', 'Since the state dynamics and rewards depend on the input process, the state alone provides limited information for the expected future returns.', 'Therefore, policy gradient methods with standard state-dependent baselines suffer high variance during training.', 'We derive a bias-free, input-dependent baseline to reduce this variance, and analytically show its benefits over state-dependent baselines.', 'We then propose a meta-learning approach to overcome the complexity of learning a baseline that depends on a long sequence of inputs.', 'Our experimental results show that across environments from queuing systems, computer networks, and MuJoCo robotic locomotion, input-dependent baselines consistently improve training stability and result in better eventual policies.']","[1, 0, 0, 0, 0, 0, 0]","[0.19999998807907104, 0.0833333283662796, 0.1599999964237213, 0.17777776718139648, 0.19999998807907104, 0.19607841968536377, 0.16949151456356049]",Hyg1G2AqtQ,"['For environments dictated partially by external input processes, we derive an input-dependent baseline that provably reduces the variance for policy gradient methods and improves the policy performance in a wide range of RL tasks.', 'The authors consider the problem of learning in input-driven environments, show how the PG theorem still applies for an input-aware critic, and show that input-dependent baselines are the best to use in conjecture with that critic.', 'This paper introduces the notion of input-dependent baselines in Policy Gradient Methods in RL, and proposes different methods to train the input dependent baseline function to help clear variance from external factor perturbation.']","['consider reinforcement learning inputdriven environment  exogenous  stochastic input process affect dynamic system ', 'input process arise many application  including queuing system  robotics control disturbance  object tracking ', 'since state dynamic reward depend input process  state alone provides limited information expected future return ', 'therefore  policy gradient method standard statedependent baseline suffer high variance training ', 'derive biasfree  inputdependent baseline reduce variance  analytically show benefit statedependent baseline ', 'propose metalearning approach overcome complexity learning baseline depends long sequence input ', 'experimental result show across environment queuing system  computer network  mujoco robotic locomotion  inputdependent baseline consistently improve training stability result better eventual policy ']","We consider reinforcement learning in input-driven environments, where an exogenous, stochastic input process affects the dynamics of the system., Input processes arise in many applications, including queuing systems, robotics control with disturbances, and object tracking., Since the state dynamics and rewards depend on the input process, the state alone provides limited information for the expected future returns., Therefore, policy gradient methods with standard state-dependent baselines suffer high variance during training., We derive a bias-free, input-dependent baseline to reduce this variance, and analytically show its benefits over state-dependent baselines., We then propose a meta-learning approach to overcome the complexity of learning a baseline that depends on a long sequence of inputs., Our experimental results show that across environments from queuing systems, computer networks, and MuJoCo robotic locomotion, input-dependent baselines consistently improve training stability and result in better eventual policies.",19,6.434782608695652,7.2631578947368425
316,"['Deep networks have shown great performance in classification tasks.', 'However, the parameters learned by the classifier networks usually discard stylistic information of the input, in favour of information strictly relevant to classification.', 'We introduce a network that has the capacity to do both classification and reconstruction by adding a ""style memory"" to the output layer of the network.', 'We also show how to train such a neural network as a deep multi-layer autoencoder, jointly minimizing both classification and reconstruction losses.', 'The generative capacity of our network demonstrates that the combination of style-memory neurons with the classifier neurons yield good reconstructions of the inputs when the classification is correct.', 'We further investigate the nature of the style memory, and how it relates to composing digits and letters.']","[0, 0, 1, 0, 0, 0]","[0.0, 0.22857142984867096, 0.3243243098258972, 0.1621621549129486, 0.31578946113586426, 0.3125]",Hyp-JJJRW,"['Augmenting the top layer of a classifier network with a style memory enables it to be generative.', 'This paper proposes to train a classifier neural network not just to classifiy, but also to reconstruct a representation of its input, in order to factorize the class information from the appearance .', 'The paper proposes training an autoencoder such that the middle layer representation consists of the class label of the input and a hidden vector representation']","['deep network shown great performance classification task ', 'however  parameter learned classifier network usually discard stylistic information input  favour information strictly relevant classification ', 'introduce network capacity classification reconstruction adding  style memory  output layer network ', 'also show train neural network deep multilayer autoencoder  jointly minimizing classification reconstruction loss ', 'generative capacity network demonstrates combination stylememory neuron classifier neuron yield good reconstruction input classification correct ', 'investigate nature style memory  relates composing digit letter ']","Deep networks have shown great performance in classification tasks., However, the parameters learned by the classifier networks usually discard stylistic information of the input, in favour of information strictly relevant to classification., We introduce a network that has the capacity to do both classification and reconstruction by adding a ""style memory"" to the output layer of the network., We also show how to train such a neural network as a deep multi-layer autoencoder, jointly minimizing both classification and reconstruction losses., The generative capacity of our network demonstrates that the combination of style-memory neurons with the classifier neurons yield good reconstructions of the inputs when the classification is correct., We further investigate the nature of the style memory, and how it relates to composing digits and letters.",10,5.73015873015873,12.6
317,"['Routing models, a form of conditional computation where examples are routed through a subset of components in a larger network, have shown promising results in recent works.', 'Surprisingly, routing models to date have lacked important properties, such as architectural diversity and large numbers of routing decisions.', 'Both architectural diversity and routing depth can increase the representational power of a routing network.', 'In this work, we address both of these deficiencies.', 'We discuss the significance of architectural diversity in routing models, and explain the tradeoffs between capacity and optimization when increasing routing depth.', 'In our experiments, we find that adding architectural diversity to routing models significantly improves performance, cutting the error rates of a strong baseline by 35% on an Omniglot setup.', 'However, when scaling up routing depth, we find that modern routing techniques struggle with optimization.', 'We conclude by discussing both the positive and negative results, and suggest directions for future research.']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.09999999403953552, 0.4000000059604645, 0.25806450843811035, 0.07692307233810425, 0.1666666567325592, 0.260869562625885, 0.12903225421905518, 0.0]",BkxWJnC9tX,"['Per-example routing models benefit from architectural diversity, but still struggle to scale to a large number of routing decisions.', 'Adds diversity to the type of architectural unit available for the router at each decision and scaling to deeper networks, achieving state of the art performance on Omniglot. ', 'This work extends routing networks to use diverse architectures across routed modules']","['routing model  form conditional computation example routed subset component larger network  shown promising result recent work ', 'surprisingly  routing model date lacked important property  architectural diversity large number routing decision ', 'architectural diversity routing depth increase representational power routing network ', 'work  address deficiency ', 'discus significance architectural diversity routing model  explain tradeoff capacity optimization increasing routing depth ', 'experiment  find adding architectural diversity routing model significantly improves performance  cutting error rate strong baseline 35  omniglot setup ', 'however  scaling routing depth  find modern routing technique struggle optimization ', 'conclude discussing positive negative result  suggest direction future research ']","Routing models, a form of conditional computation where examples are routed through a subset of components in a larger network, have shown promising results in recent works., Surprisingly, routing models to date have lacked important properties, such as architectural diversity and large numbers of routing decisions., Both architectural diversity and routing depth can increase the representational power of a routing network., In this work, we address both of these deficiencies., We discuss the significance of architectural diversity in routing models, and explain the tradeoffs between capacity and optimization when increasing routing depth., In our experiments, we find that adding architectural diversity to routing models significantly improves performance, cutting the error rates of a strong baseline by 35% on an Omniglot setup., However, when scaling up routing depth, we find that modern routing techniques struggle with optimization., We conclude by discussing both the positive and negative results, and suggest directions for future research.",19,5.855263157894737,8.0
318,"['Across numerous applications, forecasting relies on numerical solvers for partial differential equations (PDEs).', 'Although the use of deep-learning techniques has been proposed, the uses have been restricted by the fact the training data are obtained using PDE solvers.', 'Thereby, the uses were limited to domains, where the PDE solver was applicable, but no further. \n\n', 'We present methods for training on small domains, while applying the trained models on larger domains, with consistency constraints ensuring the solutions are physically meaningful even at the boundary of the small domains.', 'We demonstrate the results on an air-pollution forecasting model for Dublin, Ireland.']","[0, 0, 0, 1, 0]","[0.04651162400841713, 0.19607841968536377, 0.1304347813129425, 0.5263158082962036, 0.1904761791229248]",HJeEWnR9F7,"['We present RNNs for training surrogate models of PDEs, wherein consistency constraints ensure the solutions are physically meaningful, even when the training uses much smaller domains than the trained model is applied to.']","['across numerous application  forecasting relies numerical solver partial differential equation  pdes  ', 'although use deeplearning technique proposed  us restricted fact training data obtained using pde solver ', 'thereby  us limited domain  pde solver applicable  ', 'present method training small domain  applying trained model larger domain  consistency constraint ensuring solution physically meaningful even boundary small domain ', 'demonstrate result airpollution forecasting model dublin  ireland ']","Across numerous applications, forecasting relies on numerical solvers for partial differential equations (PDEs)., Although the use of deep-learning techniques has been proposed, the uses have been restricted by the fact the training data are obtained using PDE solvers., Thereby, the uses were limited to domains, where the PDE solver was applicable, but no further. 

, We present methods for training on small domains, while applying the trained models on larger domains, with consistency constraints ensuring the solutions are physically meaningful even at the boundary of the small domains., We demonstrate the results on an air-pollution forecasting model for Dublin, Ireland.",13,5.737373737373737,7.615384615384615
319,"['We address the issue of limit cycling behavior in training Generative Adversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for training Wasserstein GANs.', 'Recent theoretical results have shown that optimistic mirror decent (OMD) can enjoy faster regret rates in the context of zero-sum games.', 'WGANs is exactly a context of solving a zero-sum game with simultaneous no-regret dynamics.  ', 'Moreover, we show that optimistic mirror decent addresses the limit cycling problem in training WGANs.', 'We formally show that in the case of bi-linear zero-sum games the last iterate of OMD dynamics converges to an equilibrium, in contrast to GD dynamics which are bound to cycle.', 'We also portray the huge qualitative difference between GD and OMD dynamics with toy examples, even when GD is modified with many adaptations proposed in the recent literature, such as gradient penalty or momentum.', 'We apply OMD WGAN training to a bioinformatics problem of generating DNA sequences.', 'We observe that models trained with OMD achieve consistently smaller KL divergence with respect to the true underlying distribution, than models trained with GD variants.', 'Finally, we introduce a new algorithm, Optimistic Adam, which is an optimistic variant of Adam.', 'We apply it to WGAN training on CIFAR10 and observe improved performance in terms of inception score as compared to Adam.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.5116279125213623, 0.2926829159259796, 0.05882352590560913, 0.4000000059604645, 0.2222222238779068, 0.15686273574829102, 0.24242423474788666, 0.1463414579629898, 0.2857142686843872, 0.29999998211860657]",SJJySbbAZ,"['We propose the use of optimistic mirror decent to address cycling problems in the training of GANs. We also introduce the Optimistic Adam algorithm', 'This paper proposes the use of optimistic mirror descent to train WGANs', 'The paper proposes to use optimistic gradient descent for GAN training that avoids the cycling behavior observed with SGD and its variants and provides promising results in GAN training.', 'This paper proposes a simple modification of standard gradient descent, claiming to improve the convergence of GANs and other minimax optimization problems.']","['address issue limit cycling behavior training generative adversarial network propose use optimistic mirror decent  omd  training wasserstein gans ', 'recent theoretical result shown optimistic mirror decent  omd  enjoy faster regret rate context zerosum game ', 'wgans exactly context solving zerosum game simultaneous noregret dynamic ', 'moreover  show optimistic mirror decent address limit cycling problem training wgans ', 'formally show case bilinear zerosum game last iterate omd dynamic converges equilibrium  contrast gd dynamic bound cycle ', 'also portray huge qualitative difference gd omd dynamic toy example  even gd modified many adaptation proposed recent literature  gradient penalty momentum ', 'apply omd wgan training bioinformatics problem generating dna sequence ', 'observe model trained omd achieve consistently smaller kl divergence respect true underlying distribution  model trained gd variant ', 'finally  introduce new algorithm  optimistic adam  optimistic variant adam ', 'apply wgan training cifar10 observe improved performance term inception score compared adam ']","We address the issue of limit cycling behavior in training Generative Adversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for training Wasserstein GANs., Recent theoretical results have shown that optimistic mirror decent (OMD) can enjoy faster regret rates in the context of zero-sum games., WGANs is exactly a context of solving a zero-sum game with simultaneous no-regret dynamics.  , Moreover, we show that optimistic mirror decent addresses the limit cycling problem in training WGANs., We formally show that in the case of bi-linear zero-sum games the last iterate of OMD dynamics converges to an equilibrium, in contrast to GD dynamics which are bound to cycle., We also portray the huge qualitative difference between GD and OMD dynamics with toy examples, even when GD is modified with many adaptations proposed in the recent literature, such as gradient penalty or momentum., We apply OMD WGAN training to a bioinformatics problem of generating DNA sequences., We observe that models trained with OMD achieve consistently smaller KL divergence with respect to the true underlying distribution, than models trained with GD variants., Finally, we introduce a new algorithm, Optimistic Adam, which is an optimistic variant of Adam., We apply it to WGAN training on CIFAR10 and observe improved performance in terms of inception score as compared to Adam.",18,5.3534883720930235,11.944444444444445
320,"['Learning good representations of users and items is crucially important to recommendation with implicit feedback.', 'Matrix factorization is the basic idea to derive the representations of users and items by decomposing the given interaction matrix.', 'However, existing matrix factorization based approaches share the limitation in that the interaction between user embedding and item embedding is only weakly enforced by fitting the given individual rating value, which may lose potentially useful information.', 'In this paper, we propose a novel Augmented Generalized Matrix Factorization (AGMF) approach that is able to incorporate the historical interaction information of users and items for learning effective representations of users and items.', 'Despite the simplicity of our proposed approach, extensive experiments on four public implicit feedback datasets demonstrate that our approach outperforms state-of-the-art counterparts.', 'Furthermore, the ablation study demonstrates that by using multi-hot encoding to enrich user embedding and item embedding for Generalized Matrix Factorization, better performance, faster convergence, and lower training loss can be achieved.']","[0, 1, 0, 0, 0, 0]","[0.1428571343421936, 0.19354838132858276, 0.1304347813129425, 0.09302324801683426, 0.11764705181121826, 0.09302324801683426]",BJl750VYwH,"['A simple extension of generalized matrix factorization can outperform state-of-the-art approaches for recommendation.', 'The work presents a matrix factorization framework for enforcing the effect of historical data when learning user preferences in collaborative filtering settings.']","['learning good representation user item crucially important recommendation implicit feedback ', 'matrix factorization basic idea derive representation user item decomposing given interaction matrix ', 'however  existing matrix factorization based approach share limitation interaction user embedding item embedding weakly enforced fitting given individual rating value  may lose potentially useful information ', 'paper  propose novel augmented generalized matrix factorization  agmf  approach able incorporate historical interaction information user item learning effective representation user item ', 'despite simplicity proposed approach  extensive experiment four public implicit feedback datasets demonstrate approach outperforms stateoftheart counterpart ', 'furthermore  ablation study demonstrates using multihot encoding enrich user embedding item embedding generalized matrix factorization  better performance  faster convergence  lower training loss achieved ']","Learning good representations of users and items is crucially important to recommendation with implicit feedback., Matrix factorization is the basic idea to derive the representations of users and items by decomposing the given interaction matrix., However, existing matrix factorization based approaches share the limitation in that the interaction between user embedding and item embedding is only weakly enforced by fitting the given individual rating value, which may lose potentially useful information., In this paper, we propose a novel Augmented Generalized Matrix Factorization (AGMF) approach that is able to incorporate the historical interaction information of users and items for learning effective representations of users and items., Despite the simplicity of our proposed approach, extensive experiments on four public implicit feedback datasets demonstrate that our approach outperforms state-of-the-art counterparts., Furthermore, the ablation study demonstrates that by using multi-hot encoding to enrich user embedding and item embedding for Generalized Matrix Factorization, better performance, faster convergence, and lower training loss can be achieved.",14,6.320754716981132,11.357142857142858
321,"['We propose an unsupervised method for building dynamic representations of sequential data, particularly of observed interactions.', 'The method simultaneously acquires representations of input data and its dynamics.', 'It is based on a hierarchical generative model composed of two levels.', 'In the first level, a model learns representations to generate observed data.', 'In the second level, representational states encode the dynamics of the lower one.', 'The model is designed as a Bayesian network with switching variables represented in the higher level, and which generates transition models.', 'The method actively explores the latent space guided by its knowledge and the uncertainty about it.', 'That is achieved by updating the latent variables from prediction error signals backpropagated to the latent space.', 'So, no encoder or inference models are used since the generators also serve as their inverse transformations.\n', 'The method is evaluated in two scenarios, with static images and with videos.', 'The results show that the adaptation over time leads to better performance than with similar architectures without temporal dependencies, e.g., variational autoencoders.', 'With videos, it is shown that the system extracts the dynamics of the data in states that highly correlate with the ground truth of the actions observed.']","[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.3030303120613098, 0.48275861144065857, 0.13333332538604736, 0.13333332538604736, 0.13793103396892548, 0.1538461446762085, 0.1818181723356247, 0.0, 0.0555555522441864, 0.19999998807907104, 0.0952380895614624, 0.25641024112701416]",Sk7cHb-C-,"['A method that build representations of sequential data and its dynamics through generative models with an active process', 'Combines neural networks and Gaussian distributions to create an architecture and generative model for images and video which minimizes the error between generated and supplied images.', 'The paper proposes a Bayesian network model, realized as a neural network, that learns different data in the form of a linear dynamical system']","['propose unsupervised method building dynamic representation sequential data  particularly observed interaction ', 'method simultaneously acquires representation input data dynamic ', 'based hierarchical generative model composed two level ', 'first level  model learns representation generate observed data ', 'second level  representational state encode dynamic lower one ', 'model designed bayesian network switching variable represented higher level  generates transition model ', 'method actively explores latent space guided knowledge uncertainty ', 'achieved updating latent variable prediction error signal backpropagated latent space ', ' encoder inference model used since generator also serve inverse transformation ', 'method evaluated two scenario  static image video ', 'result show adaptation time lead better performance similar architecture without temporal dependency  eg  variational autoencoders ', 'video  shown system extract dynamic data state highly correlate ground truth action observed ']","We propose an unsupervised method for building dynamic representations of sequential data, particularly of observed interactions., The method simultaneously acquires representations of input data and its dynamics., It is based on a hierarchical generative model composed of two levels., In the first level, a model learns representations to generate observed data., In the second level, representational states encode the dynamics of the lower one., The model is designed as a Bayesian network with switching variables represented in the higher level, and which generates transition models., The method actively explores the latent space guided by its knowledge and the uncertainty about it., That is achieved by updating the latent variables from prediction error signals backpropagated to the latent space., So, no encoder or inference models are used since the generators also serve as their inverse transformations.
, The method is evaluated in two scenarios, with static images and with videos., The results show that the adaptation over time leads to better performance than with similar architectures without temporal dependencies, e.g., variational autoencoders., With videos, it is shown that the system extracts the dynamics of the data in states that highly correlate with the ground truth of the actions observed.",21,5.624365482233503,9.380952380952381
322,"['Activation is a nonlinearity function that plays a predominant role in the convergence and performance of deep neural networks.', 'While Rectified Linear Unit (ReLU) is the most successful activation function, its derivatives have shown superior performance on benchmark datasets.', 'In this work, we explore the polynomials as activation functions (order  2) that can approximate continuous real valued function within a given interval.', 'Leveraging this property, the main idea is to learn the nonlinearity, accepting that the ensuing function may not be monotonic.', 'While having the ability to learn more suitable nonlinearity, we cannot ignore the fact that it is a challenge to achieve stable performance due to exploding gradients - which is prominent with the increase in order.', 'To handle this issue, we introduce dynamic input scaling, output scaling, and lower learning rate for the polynomial weights.', 'Moreover, lower learning rate will control the abrupt fluctuations of the polynomials between weight updates.', 'In experiments on three public datasets, our proposed method matches the performance of prior activation functions, thus providing insight into a networks nonlinearity preference.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.0, 0.07692307233810425, 0.20000000298023224, 0.0, 0.0, 0.0833333283662796, 0.0, 0.06666666269302368]",rkxsgkHKvH,"['We propose polynomial as activation functions.', 'The authors introduce learnable activation functions that are parameterized by polynomial functions and show results slightly better than ReLU.']","['activation nonlinearity function play predominant role convergence performance deep neural network ', 'rectified linear unit  relu  successful activation function  derivative shown superior performance benchmark datasets ', 'work  explore polynomial activation function  order  2  approximate continuous real valued function within given interval ', 'leveraging property  main idea learn nonlinearity  accepting ensuing function may monotonic ', 'ability learn suitable nonlinearity  ignore fact challenge achieve stable performance due exploding gradient  prominent increase order ', 'handle issue  introduce dynamic input scaling  output scaling  lower learning rate polynomial weight ', 'moreover  lower learning rate control abrupt fluctuation polynomial weight update ', 'experiment three public datasets  proposed method match performance prior activation function  thus providing insight network  nonlinearity preference ']","Activation is a nonlinearity function that plays a predominant role in the convergence and performance of deep neural networks., While Rectified Linear Unit (ReLU) is the most successful activation function, its derivatives have shown superior performance on benchmark datasets., In this work, we explore the polynomials as activation functions (order  2) that can approximate continuous real valued function within a given interval., Leveraging this property, the main idea is to learn the nonlinearity, accepting that the ensuing function may not be monotonic., While having the ability to learn more suitable nonlinearity, we cannot ignore the fact that it is a challenge to achieve stable performance due to exploding gradients - which is prominent with the increase in order., To handle this issue, we introduce dynamic input scaling, output scaling, and lower learning rate for the polynomial weights., Moreover, lower learning rate will control the abrupt fluctuations of the polynomials between weight updates., In experiments on three public datasets, our proposed method matches the performance of prior activation functions, thus providing insight into a networks nonlinearity preference.",19,5.6892655367231635,9.31578947368421
323,"['We introduce CBF, an exploration method that works in the absence of rewards or end of episode signal.', 'CBF is based on intrinsic reward derived from the error of a dynamics model operating in feature space.', 'It was inspired by (Pathak et al., 2017), is easy to implement, and can achieve results such as passing four levels of Super Mario Bros, navigating VizDoom mazes and passing two levels of SpaceInvaders.', 'We investigated the effect of combining the method with several auxiliary tasks, but find inconsistent improvements over the CBF baseline.\n']","[0, 1, 0, 0]","[0.24242423474788666, 0.5294117331504822, 0.04255318641662598, 0.17142856121063232]",H1RPJf5Tz,['A simple intrinsic motivation method using forward dynamics model error in feature space of the policy.'],"['introduce cbf  exploration method work absence reward end episode signal ', 'cbf based intrinsic reward derived error dynamic model operating feature space ', 'inspired  pathak et al  2017   easy implement  achieve result passing four level super mario bros  navigating vizdoom maze passing two level spaceinvaders ', 'investigated effect combining method several auxiliary task  find inconsistent improvement cbf baseline ']","We introduce CBF, an exploration method that works in the absence of rewards or end of episode signal., CBF is based on intrinsic reward derived from the error of a dynamics model operating in feature space., It was inspired by (Pathak et al., 2017), is easy to implement, and can achieve results such as passing four levels of Super Mario Bros, navigating VizDoom mazes and passing two levels of SpaceInvaders., We investigated the effect of combining the method with several auxiliary tasks, but find inconsistent improvements over the CBF baseline.
",10,5.033333333333333,9.0
324,"['This paper is concerned with the robustness of VAEs to adversarial attacks.', 'We highlight that conventional VAEs are brittle under attack but that methods recently introduced for disentanglement such as -TCVAE (Chen et al., 2018) improve robustness, as demonstrated through a variety of previously proposed adversarial attacks (Tabacof et al. (2016); Gondim-Ribeiro et al. (2018); Kos et al.(2018)).', 'This motivated us to develop Seatbelt-VAE, a new hierarchical disentangled VAE that is designed to be significantly more robust to adversarial attacks than existing approaches, while retaining high quality reconstructions.']","[0, 0, 1]","[0.2380952388048172, 0.19999998807907104, 0.37931033968925476]",rkeZ9a4Fwr,"['We show that disentangled VAEs are more robust than vanilla VAEs to adversarial attacks that aim to trick them into decoding the adversarial input to a chosen target. We then develop an even more robust hierarchical disentangled VAE, Seatbelt-VAE.', 'The authors propose a new VAE model called seatbelt-VAE, showing to be more robust for latent attack than benchmarks.']","['paper concerned robustness vaes adversarial attack ', 'highlight conventional vaes brittle attack method recently introduced disentanglement tcvae  chen et al  2018  improve robustness  demonstrated variety previously proposed adversarial attack  tabacof et al   2016   gondimribeiro et al   2018   ko et al   2018   ', 'motivated u develop seatbeltvae  new hierarchical disentangled vae designed significantly robust adversarial attack existing approach  retaining high quality reconstruction ']","This paper is concerned with the robustness of VAEs to adversarial attacks., We highlight that conventional VAEs are brittle under attack but that methods recently introduced for disentanglement such as -TCVAE (Chen et al., 2018) improve robustness, as demonstrated through a variety of previously proposed adversarial attacks (Tabacof et al. (2016); Gondim-Ribeiro et al. (2018); Kos et al.(2018))., This motivated us to develop Seatbelt-VAE, a new hierarchical disentangled VAE that is designed to be significantly more robust to adversarial attacks than existing approaches, while retaining high quality reconstructions.",7,6.034090909090909,8.9
325,"['The backpropagation algorithm is the de-facto standard for credit assignment in artificial neural networks due to its empirical results.', 'Since its conception, variants of the backpropagation algorithm have emerged.', 'More specifically, variants that leverage function changes in the backpropagation equations to satisfy their specific requirements.', 'Feedback Alignment is one such example, which replaces the weight transpose matrix in the backpropagation equations with a random matrix in search of a more biologically plausible credit assignment algorithm.', 'In this work, we show that function changes in the  backpropagation procedure is equivalent to adding an implicit learning rate to an artificial neural network.', 'Furthermore, we learn activation function derivatives in the backpropagation equations to demonstrate early convergence in these artificial neural networks.', 'Our work reports competitive performances with early convergence on MNIST and CIFAR10 on sufficiently large deep neural network architectures.']","[0, 0, 0, 0, 1, 0, 0]","[0.29411762952804565, 0.1599999964237213, 0.4516128897666931, 0.19512194395065308, 0.6842105388641357, 0.3636363446712494, 0.0]",r1lgvNr324,['We demonstrate that function changes in the backpropagation is equivalent to an implicit learning rate'],"['backpropagation algorithm defacto standard credit assignment artificial neural network due empirical result ', 'since conception  variant backpropagation algorithm emerged ', 'specifically  variant leverage function change backpropagation equation satisfy specific requirement ', 'feedback alignment one example  replaces weight transpose matrix backpropagation equation random matrix search biologically plausible credit assignment algorithm ', 'work  show function change backpropagation procedure equivalent adding implicit learning rate artificial neural network ', 'furthermore  learn activation function derivative backpropagation equation demonstrate early convergence artificial neural network ', 'work report competitive performance early convergence mnist cifar10 sufficiently large deep neural network architecture ']","The backpropagation algorithm is the de-facto standard for credit assignment in artificial neural networks due to its empirical results., Since its conception, variants of the backpropagation algorithm have emerged., More specifically, variants that leverage function changes in the backpropagation equations to satisfy their specific requirements., Feedback Alignment is one such example, which replaces the weight transpose matrix in the backpropagation equations with a random matrix in search of a more biologically plausible credit assignment algorithm., In this work, we show that function changes in the  backpropagation procedure is equivalent to adding an implicit learning rate to an artificial neural network., Furthermore, we learn activation function derivatives in the backpropagation equations to demonstrate early convergence in these artificial neural networks., Our work reports competitive performances with early convergence on MNIST and CIFAR10 on sufficiently large deep neural network architectures.",12,6.326086956521739,11.5
326,"['Unsupervised text style transfer is the task of re-writing text of a given style into a target style without using a parallel corpus of source style and target style sentences for training.', 'Style transfer systems are evaluated on their ability to generate sentences that', '1) possess the target style,', '2) are fluent and natural sounding, and', '3) preserve the non-stylistic parts (content) of the source sentence.', 'We train a reinforcement learning (RL) based unsupervised style transfer system that incorporates rewards for the above measures, and describe novel rewards shaping methods for the same.', 'Our approach does not attempt to disentangle style and content, and leverages the power of massively pre-trained language models as well as the Transformer.', 'Our system significantly outperforms existing state-of-art systems based on human as well as automatic evaluations on target style, fluency and content preservation as well as on overall success of style transfer, on a variety of datasets.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.20000000298023224, 0.19999998807907104, 0.0, 0.0, 0.0, 0.25, 0.20689654350280762, 0.0555555522441864]",SJxivAEYvr,"['A reinforcement learning approach to text style transfer', 'Introduces an RL-based method which leverages a pre-trained language model to transfer text style, without a disentanglement objective, while using style-transfer generations from another model.', 'The authors propose a combination reward composed of fluency, content, and style for text style transfer.']","['unsupervised text style transfer task rewriting text given style target style without using parallel corpus source style target style sentence training ', 'style transfer system evaluated ability generate sentence', '1  posse target style ', '2  fluent natural sounding ', '3  preserve nonstylistic part  content  source sentence ', 'train reinforcement learning  rl  based unsupervised style transfer system incorporates reward measure  describe novel reward shaping method ', 'approach attempt disentangle style content  leverage power massively pretrained language model well transformer ', 'system significantly outperforms existing stateofart system based human well automatic evaluation target style  fluency content preservation well overall success style transfer  variety datasets ']","Unsupervised text style transfer is the task of re-writing text of a given style into a target style without using a parallel corpus of source style and target style sentences for training., Style transfer systems are evaluated on their ability to generate sentences that, 1) possess the target style,, 2) are fluent and natural sounding, and, 3) preserve the non-stylistic parts (content) of the source sentence., We train a reinforcement learning (RL) based unsupervised style transfer system that incorporates rewards for the above measures, and describe novel rewards shaping methods for the same., Our approach does not attempt to disentangle style and content, and leverages the power of massively pre-trained language models as well as the Transformer., Our system significantly outperforms existing state-of-art systems based on human as well as automatic evaluations on target style, fluency and content preservation as well as on overall success of style transfer, on a variety of datasets.",13,5.4640522875816995,11.76923076923077
327,"['Despite the success of Generative Adversarial Networks (GANs) in image synthesis, there lacks enough understanding on what networks have learned inside the deep generative representations and how photo-realistic images are able to be composed from random noises.', 'In this work, we show that highly-structured semantic hierarchy emerges from the generative representations as the variation factors for synthesizing scenes.', 'By probing the layer-wise representations with a broad set of visual concepts at different abstraction levels, we are able to quantify the causality between the activations and the semantics occurring in the output image.', 'Such a quantification identifies the human-understandable variation factors learned by GANs to compose scenes.', 'The qualitative and quantitative results suggest that the generative representations learned by GAN are specialized to synthesize different hierarchical semantics: the early layers tend to determine the spatial layout and configuration, the middle layers control the categorical objects, and the later layers finally render the scene attributes as well as color scheme.', 'Identifying such a set of manipulatable latent semantics facilitates semantic scene manipulation.']","[0, 1, 0, 0, 0, 0]","[0.18518517911434174, 0.6842105388641357, 0.1666666567325592, 0.1875, 0.17241379618644714, 0.13333332538604736]",Syxp-1HtvB,"['We show that highly-structured semantic hierarchy emerges in the deep generative representations as a result for synthesizing scenes.', 'Paper investigates the aspects encoded by the latent variables input into different layers in StyleGAN.', 'The paper presents a visually-guided interpretation of activations of the convolution layers in the generator of StyleGAN on layout, scene category, scene attributes, and color.']","['despite success generative adversarial network  gans  image synthesis  lack enough understanding network learned inside deep generative representation photorealistic image able composed random noise ', 'work  show highlystructured semantic hierarchy emerges generative representation variation factor synthesizing scene ', 'probing layerwise representation broad set visual concept different abstraction level  able quantify causality activation semantics occurring output image ', 'quantification identifies humanunderstandable variation factor learned gans compose scene ', 'qualitative quantitative result suggest generative representation learned gan specialized synthesize different hierarchical semantics  early layer tend determine spatial layout configuration  middle layer control categorical object  later layer finally render scene attribute well color scheme ', 'identifying set manipulatable latent semantics facilitates semantic scene manipulation ']","Despite the success of Generative Adversarial Networks (GANs) in image synthesis, there lacks enough understanding on what networks have learned inside the deep generative representations and how photo-realistic images are able to be composed from random noises., In this work, we show that highly-structured semantic hierarchy emerges from the generative representations as the variation factors for synthesizing scenes., By probing the layer-wise representations with a broad set of visual concepts at different abstraction levels, we are able to quantify the causality between the activations and the semantics occurring in the output image., Such a quantification identifies the human-understandable variation factors learned by GANs to compose scenes., The qualitative and quantitative results suggest that the generative representations learned by GAN are specialized to synthesize different hierarchical semantics: the early layers tend to determine the spatial layout and configuration, the middle layers control the categorical objects, and the later layers finally render the scene attributes as well as color scheme., Identifying such a set of manipulatable latent semantics facilitates semantic scene manipulation.",11,6.158823529411765,15.454545454545455
328,"['Variational autoencoders (VAEs) defined over SMILES string and graph-based representations of molecules promise to improve the optimization of molecular properties, thereby revolutionizing the pharmaceuticals and materials industries.', 'However, these VAEs are hindered by the non-unique nature of SMILES strings and the computational cost of graph convolutions.', 'To efficiently pass messages along all paths through the molecular graph, we encode multiple SMILES strings of a single molecule using a set of stacked recurrent neural networks, harmonizing hidden representations of each atom between SMILES representations, and use attentional pooling to build a final fixed-length latent representation.', 'By then decoding to a disjoint set of SMILES strings of the molecule, our All SMILES VAE learns an almost bijective mapping between molecules and latent representations near the high-probability-mass subspace of the prior.', 'Our SMILES-derived but molecule-based latent representations significantly surpass the state-of-the-art in a variety of fully- and semi-supervised property regression and molecular property optimization tasks.']","[0, 0, 1, 0, 0]","[0.2181818187236786, 0.1666666567325592, 0.4864864945411682, 0.2666666507720947, 0.4528301954269409]",rkxUfANKwB,"['We pool messages amongst multiple SMILES strings of the same molecule to pass information along all paths through the molecular graph, producing latent representations that significantly surpass the state-of-the-art in a variety of tasks.', 'Method uses multiple inputs of SMILES strings, character-wise feature fusion across those strings, and network training through multiple output targets of SMILES strings, creating a robust fixed-length latent representation independent of SMILES variation.  ', 'The authors describe a novel variational autoencoder like method for molecules which encode molecules as strings to reduce the operations needed to share information across atoms in the molecule.']","['variational autoencoders  vaes  defined smile string graphbased representation molecule promise improve optimization molecular property  thereby revolutionizing pharmaceutical material industry ', 'however  vaes hindered nonunique nature smile string computational cost graph convolution ', 'efficiently pas message along path molecular graph  encode multiple smile string single molecule using set stacked recurrent neural network  harmonizing hidden representation atom smile representation  use attentional pooling build final fixedlength latent representation ', 'decoding disjoint set smile string molecule  smile vae learns almost bijective mapping molecule latent representation near highprobabilitymass subspace prior ', 'smilesderived moleculebased latent representation significantly surpass stateoftheart variety fully semisupervised property regression molecular property optimization task ']","Variational autoencoders (VAEs) defined over SMILES string and graph-based representations of molecules promise to improve the optimization of molecular properties, thereby revolutionizing the pharmaceuticals and materials industries., However, these VAEs are hindered by the non-unique nature of SMILES strings and the computational cost of graph convolutions., To efficiently pass messages along all paths through the molecular graph, we encode multiple SMILES strings of a single molecule using a set of stacked recurrent neural networks, harmonizing hidden representations of each atom between SMILES representations, and use attentional pooling to build a final fixed-length latent representation., By then decoding to a disjoint set of SMILES strings of the molecule, our All SMILES VAE learns an almost bijective mapping between molecules and latent representations near the high-probability-mass subspace of the prior., Our SMILES-derived but molecule-based latent representations significantly surpass the state-of-the-art in a variety of fully- and semi-supervised property regression and molecular property optimization tasks.",11,6.421052631578948,13.818181818181818
329,"['We propose a simple yet highly effective method that addresses the mode-collapse problem in the Conditional Generative  Adversarial  Network (cGAN).', 'Although conditional distributions are multi-modal (i.e., having many modes) in practice, most cGAN approaches tend to learn an overly simplified distribution where an input is always mapped to a single output regardless of variations in latent code.', 'To address such issue, we propose to explicitly regularize the generator to produce diverse outputs depending on latent codes.', 'The proposed regularization is simple, general, and can be easily integrated into most conditional GAN objectives.', 'Additionally, explicit regularization on generator allows our method to control a balance between visual quality and diversity.', 'We demonstrate the effectiveness of our method on three conditional generation tasks: image-to-image translation, image inpainting, and future video prediction.', 'We show that simple addition of our regularization to existing models leads to surprisingly diverse generations, substantially outperforming the previous approaches for multi-modal conditional generation specifically designed in each individual task.']","[1, 0, 0, 0, 0, 0, 0]","[0.4000000059604645, 0.11538460850715637, 0.05882352590560913, 0.1249999925494194, 0.12121211737394333, 0.1666666567325592, 0.21739129722118378]",rJliMh09F7,"['We propose a simple and general approach that avoids a mode collapse problem in various conditional GANs.', 'The paper proposes a regularization term for the conditional GAN objective in order to promote diverse multimodal generation and prevent mode collapse.', 'The paper proposes a method for generating diverse outputs for various conditional GAN frameworks including image-to-image translation, image-inpainting, and video prediction, which can be applied to various conditional synthesis frameworks for various tasks. ']","['propose simple yet highly effective method address modecollapse problem conditional generative adversarial network  cgan  ', 'although conditional distribution multimodal  ie  many mode  practice  cgan approach tend learn overly simplified distribution input always mapped single output regardless variation latent code ', 'address issue  propose explicitly regularize generator produce diverse output depending latent code ', 'proposed regularization simple  general  easily integrated conditional gan objective ', 'additionally  explicit regularization generator allows method control balance visual quality diversity ', 'demonstrate effectiveness method three conditional generation task  imagetoimage translation  image inpainting  future video prediction ', 'show simple addition regularization existing model lead surprisingly diverse generation  substantially outperforming previous approach multimodal conditional generation specifically designed individual task ']","We propose a simple yet highly effective method that addresses the mode-collapse problem in the Conditional Generative  Adversarial  Network (cGAN)., Although conditional distributions are multi-modal (i.e., having many modes) in practice, most cGAN approaches tend to learn an overly simplified distribution where an input is always mapped to a single output regardless of variations in latent code., To address such issue, we propose to explicitly regularize the generator to produce diverse outputs depending on latent codes., The proposed regularization is simple, general, and can be easily integrated into most conditional GAN objectives., Additionally, explicit regularization on generator allows our method to control a balance between visual quality and diversity., We demonstrate the effectiveness of our method on three conditional generation tasks: image-to-image translation, image inpainting, and future video prediction., We show that simple addition of our regularization to existing models leads to surprisingly diverse generations, substantially outperforming the previous approaches for multi-modal conditional generation specifically designed in each individual task.",16,6.31875,10.0
330,"['The transformer is a state-of-the-art neural translation model that uses attention to iteratively refine lexical representations with information drawn from the surrounding context.', 'Lexical features are fed into the first layer and propagated through a deep network of hidden layers.', 'We argue that the need to represent and propagate lexical features in each layer limits the models capacity for learning and representing other information relevant to the task.', 'To alleviate this bottleneck, we introduce gated shortcut connections between the embedding layer and each subsequent layer within the encoder and decoder.', 'This enables the model to access relevant lexical content dynamically, without expending limited resources on storing it within intermediate states.', 'We show that the proposed modification yields consistent improvements on standard WMT translation tasks and reduces the amount of lexical information passed along the hidden layers.', 'We furthermore evaluate different ways to integrate lexical connections into the transformer architecture and present ablation experiments exploring the effect of proposed shortcuts on model behavior.']","[0, 0, 1, 0, 0, 0, 0]","[0.307692289352417, 0.12121211737394333, 0.3499999940395355, 0.17142856121063232, 0.1666666567325592, 0.09999999403953552, 0.24390242993831635]",SJgfQH6PQ4,['Equipping the transformer model with shortcuts to the embedding layer frees up model capacity for learning novel information.'],"['transformer stateoftheart neural translation model us attention iteratively refine lexical representation information drawn surrounding context ', 'lexical feature fed first layer propagated deep network hidden layer ', 'argue need represent propagate lexical feature layer limit model  capacity learning representing information relevant task ', 'alleviate bottleneck  introduce gated shortcut connection embedding layer subsequent layer within encoder decoder ', 'enables model access relevant lexical content dynamically  without expending limited resource storing within intermediate state ', 'show proposed modification yield consistent improvement standard wmt translation task reduces amount lexical information passed along hidden layer ', 'furthermore evaluate different way integrate lexical connection transformer architecture present ablation experiment exploring effect proposed shortcut model behavior ']","The transformer is a state-of-the-art neural translation model that uses attention to iteratively refine lexical representations with information drawn from the surrounding context., Lexical features are fed into the first layer and propagated through a deep network of hidden layers., We argue that the need to represent and propagate lexical features in each layer limits the models capacity for learning and representing other information relevant to the task., To alleviate this bottleneck, we introduce gated shortcut connections between the embedding layer and each subsequent layer within the encoder and decoder., This enables the model to access relevant lexical content dynamically, without expending limited resources on storing it within intermediate states., We show that the proposed modification yields consistent improvements on standard WMT translation tasks and reduces the amount of lexical information passed along the hidden layers., We furthermore evaluate different ways to integrate lexical connections into the transformer architecture and present ablation experiments exploring the effect of proposed shortcuts on model behavior.",9,6.092592592592593,18.0
331,"['Probability density estimation is a classical and well studied problem, but standard density estimation methods have historically lacked the power to model complex and high-dimensional image distributions.  ', 'More recent generative models leverage the power of neural networks to implicitly learn and represent probability models over complex images.  ', 'We describe methods to extract explicit probability density estimates from GANs, and explore the properties of these image density functions.  ', 'We perform sanity check experiments to provide evidence that these probabilities are reasonable.  ', 'However, we also show that density functions of natural images are difficult to interpret and thus limited in use.  ', 'We study reasons for this lack of interpretability, and suggest that we can get better interpretability by doing density estimation on latent representations of images.  ']","[0, 0, 1, 0, 0, 0]","[0.20512820780277252, 0.1764705777168274, 0.3529411852359772, 0.0714285671710968, 0.1764705777168274, 0.1538461446762085]",HJxw9lStPH,"['We examine the relationship between probability density values and image content in non-invertible GANs.', 'The authors try to estimate the probability distribution of the image with the help of GAN and develop a proper approximation to the PDFs in the latent space.']","['probability density estimation classical well studied problem  standard density estimation method historically lacked power model complex highdimensional image distribution ', 'recent generative model leverage power neural network implicitly learn represent probability model complex image ', 'describe method extract explicit probability density estimate gans  explore property image density function ', 'perform sanity check experiment provide evidence probability reasonable ', 'however  also show density function natural image difficult interpret thus limited use ', 'study reason lack interpretability  suggest get better interpretability density estimation latent representation image ']","Probability density estimation is a classical and well studied problem, but standard density estimation methods have historically lacked the power to model complex and high-dimensional image distributions.  , More recent generative models leverage the power of neural networks to implicitly learn and represent probability models over complex images.  , We describe methods to extract explicit probability density estimates from GANs, and explore the properties of these image density functions.  , We perform sanity check experiments to provide evidence that these probabilities are reasonable.  , However, we also show that density functions of natural images are difficult to interpret and thus limited in use.  , We study reasons for this lack of interpretability, and suggest that we can get better interpretability by doing density estimation on latent representations of images.  ",10,5.991935483870968,12.4
332,"['Convolutional Neural Networks (CNNs) are composed of multiple convolution layers and show elegant performance in vision tasks.\n', 'The design of the regular convolution is based on the Receptive Field (RF) where the information within a specific region is processed.\n', ""In the view of the regular convolution's RF, the outputs of neurons in lower layers with smaller RF are bundled to create neurons in higher layers with larger RF. \n"", 'As a result, the neurons in high layers are able to capture the global context even though the neurons in low layers only see the local information.\n', 'However, in lower layers of the biological brain, the information outside of the RF changes the properties of neurons.\n', 'In this work, we extend the regular convolution and propose spatially shuffled convolution (ss convolution).\n', 'In ss convolution, the regular convolution is able to use the information outside of its RF by spatial shuffling which is a simple and lightweight operation.\n', 'We perform experiments on CIFAR-10 and ImageNet-1k dataset, and show that ss convolution improves the classification performance across various CNNs.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.11764705181121826, 0.277777761220932, 0.15789473056793213, 0.10526315122842789, 0.25806450843811035, 0.3870967626571655, 0.3414634168148041, 0.22857142984867096]",SkgODpVFDr,"['We propose spatially shuffled convolution that the regular convolution incorporates the information from outside of its receptive field.', 'Proposes SS convulation which uses information outside of its RF, showing improved results when tested on multiple CNN models.', 'The authors proposed a shuffle strategy for convolution layers in convolution layers in convolutional neural networks.']","['convolutional neural network  cnns  composed multiple convolution layer show elegant performance vision task ', 'design regular convolution based receptive field  rf  information within specific region processed ', 'view regular convolution rf  output neuron lower layer smaller rf bundled create neuron higher layer larger rf ', 'result  neuron high layer able capture global context even though neuron low layer see local information ', 'however  lower layer biological brain  information outside rf change property neuron ', 'work  extend regular convolution propose spatially shuffled convolution  s convolution  ', 's convolution  regular convolution able use information outside rf spatial shuffling simple lightweight operation ', 'perform experiment cifar10 imagenet1k dataset  show s convolution improves classification performance across various cnns ']","Convolutional Neural Networks (CNNs) are composed of multiple convolution layers and show elegant performance in vision tasks.
, The design of the regular convolution is based on the Receptive Field (RF) where the information within a specific region is processed.
, In the view of the regular convolution's RF, the outputs of neurons in lower layers with smaller RF are bundled to create neurons in higher layers with larger RF. 
, As a result, the neurons in high layers are able to capture the global context even though the neurons in low layers only see the local information.
, However, in lower layers of the biological brain, the information outside of the RF changes the properties of neurons.
, In this work, we extend the regular convolution and propose spatially shuffled convolution (ss convolution).
, In ss convolution, the regular convolution is able to use the information outside of its RF by spatial shuffling which is a simple and lightweight operation.
, We perform experiments on CIFAR-10 and ImageNet-1k dataset, and show that ss convolution improves the classification performance across various CNNs.",15,5.308571428571429,11.666666666666666
333,"['We propose a framework to model the distribution of sequential data coming from\n', 'a set of entities connected in a graph with a known topology.', 'The method is\n', 'based on a mixture of shared hidden Markov models (HMMs), which are trained\n', 'in order to exploit the knowledge of the graph structure and in such a way that the\n', 'obtained mixtures tend to be sparse.', 'Experiments in different application domains\n', 'demonstrate the effectiveness and versatility of the method.']","[1, 0, 0, 0, 0, 0, 0, 0]","[0.5185185074806213, 0.3333333432674408, 0.11764705926179886, 0.07407406717538834, 0.2857142686843872, 0.09999999403953552, 0.0, 0.2857142686843872]",HJM4SjR5KQ,"['A method to model the generative distribution of sequences coming from graph connected entities.', ""The authors propose a method to model sequential data from multiple interconnected sources using a mixture of common pool of HMM's.""]","['propose framework model distribution sequential data coming', 'set entity connected graph known topology ', 'method', 'based mixture shared hidden markov model  hmms   trained', 'order exploit knowledge graph structure way', 'obtained mixture tend sparse ', 'experiment different application domain', 'demonstrate effectiveness versatility method ']","We propose a framework to model the distribution of sequential data coming from
, a set of entities connected in a graph with a known topology., The method is
, based on a mixture of shared hidden Markov models (HMMs), which are trained
, in order to exploit the knowledge of the graph structure and in such a way that the
, obtained mixtures tend to be sparse., Experiments in different application domains
, demonstrate the effectiveness and versatility of the method.",9,4.9480519480519485,8.555555555555555
334,"['To gain high rewards in muti-agent scenes, it is sometimes necessary to understand other agents and make corresponding optimal decisions.', 'We can solve these tasks by first building models for other agents and then finding the optimal policy with these models.', 'To get an accurate model, many observations are needed and this can be sample-inefficient.', ""What's more, the learned model and policy can overfit to current agents and cannot generalize if the other agents are replaced by new agents."", 'In many practical situations, each agent we face can be considered as a sample from a population with a fixed but unknown distribution.', 'Thus we can treat the task against some specific agents as a task sampled from a task distribution.', 'We apply meta-learning method to build models and learn policies.', 'Therefore when new agents come, we can adapt to them efficiently.', 'Experiments on grid games show that our method can quickly get high rewards.']","[0, 0, 0, 0, 0, 0, 0, 1, 0]","[0.0555555522441864, 0.0, 0.0, 0.1111111044883728, 0.05405404791235924, 0.0, 0.1538461446762085, 0.2222222238779068, 0.06896550953388214]",r1fiFs09YX,"['Our work applies meta-learning to multi-agent Reinforcement Learning to help our agent efficiently adapted to new coming opponents.', 'This paper focuses on fast adaptation to new behaviour of the other agents of the environment using a method based on MAML', 'The paper presents an approach to multi-agent learning based on the framework of model-agnostic meta learning for the task of opponent modeling for multi-agent RL.']","['gain high reward mutiagent scene  sometimes necessary understand agent make corresponding optimal decision ', 'solve task first building model agent finding optimal policy model ', 'get accurate model  many observation needed sampleinefficient ', ' learned model policy overfit current agent generalize agent replaced new agent ', 'many practical situation  agent face considered sample population fixed unknown distribution ', 'thus treat task specific agent task sampled task distribution ', 'apply metalearning method build model learn policy ', 'therefore new agent come  adapt efficiently ', 'experiment grid game show method quickly get high reward ']","To gain high rewards in muti-agent scenes, it is sometimes necessary to understand other agents and make corresponding optimal decisions., We can solve these tasks by first building models for other agents and then finding the optimal policy with these models., To get an accurate model, many observations are needed and this can be sample-inefficient., What's more, the learned model and policy can overfit to current agents and cannot generalize if the other agents are replaced by new agents., In many practical situations, each agent we face can be considered as a sample from a population with a fixed but unknown distribution., Thus we can treat the task against some specific agents as a task sampled from a task distribution., We apply meta-learning method to build models and learn policies., Therefore when new agents come, we can adapt to them efficiently., Experiments on grid games show that our method can quickly get high rewards.",14,5.058441558441558,11.0
335,"['We characterize the singular values of the linear transformation associated with a standard 2D multi-channel convolutional layer, enabling their efficient computation.  ', 'This characterization also leads to an algorithm for projecting a convolutional layer onto an operator-norm ball.', 'We show that this is an effective regularizer;  for example, it improves the test error of a deep residual network using batch normalization on CIFAR-10 from 6.2% to 5.3%.']","[1, 0, 0]","[1.0, 0.1111111044883728, 0.1538461446762085]",rJevYoA9Fm,"['We characterize the singular values of the linear transformation associated with a standard 2D multi-channel convolutional layer, enabling their efficient computation. ', 'The paper is dedicated to computation of singular values of convolutional layers', 'Derives exact formulas for computing singular values of convolutional layers of deep neural networks and show that computing the singular values can be done much faster than computing the full SVD of the convolution matrix by appealing to fast FFT transformations.']","['characterize singular value linear transformation associated standard 2d multichannel convolutional layer  enabling efficient computation ', 'characterization also lead algorithm projecting convolutional layer onto operatornorm ball ', 'show effective regularizer  example  improves test error deep residual network using batch normalization cifar10 62  53  ']","We characterize the singular values of the linear transformation associated with a standard 2D multi-channel convolutional layer, enabling their efficient computation.  , This characterization also leads to an algorithm for projecting a convolutional layer onto an operator-norm ball., We show that this is an effective regularizer;  for example, it improves the test error of a deep residual network using batch normalization on CIFAR-10 from 6.2% to 5.3%.",5,5.833333333333333,13.2
336,"['Trading off exploration and exploitation in an unknown environment is key to maximising expected return during learning.', ""A Bayes-optimal policy, which does so optimally, conditions its actions not only on the environment state but on the agent's uncertainty about the environment."", 'Computing a Bayes-optimal policy is however intractable for all but the smallest tasks.', 'In this paper, we introduce variational Bayes-Adaptive Deep RL (variBAD), a way to meta-learn to perform approximate inference in an unknown environment, and incorporate task uncertainty directly during action selection.', 'In a grid-world domain, we illustrate how variBAD performs structured online exploration as a function of task uncertainty.', 'We also evaluate variBAD on MuJoCo domains widely used in meta-RL and show that it achieves higher return during training than existing methods.']","[0, 0, 0, 1, 0, 0]","[0.15789473056793213, 0.04878048226237297, 0.1764705777168274, 0.2800000011920929, 0.10526315122842789, 0.045454539358615875]",Hkl9JlBYvr,"['VariBAD opens a path to tractable approximate Bayes-optimal exploration for deep RL using ideas from meta-learning, Bayesian RL, and approximate variational inference.', 'This paper presents a new deep reinforcement learning method that can efficiently trade-off exploration and exploitation that combines meta-learning, variational inference, and bayesian RL.']","['trading exploration exploitation unknown environment key maximising expected return learning ', 'bayesoptimal policy  optimally  condition action environment state agent uncertainty environment ', 'computing bayesoptimal policy however intractable smallest task ', 'paper  introduce variational bayesadaptive deep rl  varibad   way metalearn perform approximate inference unknown environment  incorporate task uncertainty directly action selection ', 'gridworld domain  illustrate varibad performs structured online exploration function task uncertainty ', 'also evaluate varibad mujoco domain widely used metarl show achieves higher return training existing method ']","Trading off exploration and exploitation in an unknown environment is key to maximising expected return during learning., A Bayes-optimal policy, which does so optimally, conditions its actions not only on the environment state but on the agent's uncertainty about the environment., Computing a Bayes-optimal policy is however intractable for all but the smallest tasks., In this paper, we introduce variational Bayes-Adaptive Deep RL (variBAD), a way to meta-learn to perform approximate inference in an unknown environment, and incorporate task uncertainty directly during action selection., In a grid-world domain, we illustrate how variBAD performs structured online exploration as a function of task uncertainty., We also evaluate variBAD on MuJoCo domains widely used in meta-RL and show that it achieves higher return during training than existing methods.",12,5.824,10.416666666666666
337,"['In a continual learning setting, new categories may be introduced over time, and an ideal learning system should perform well on both the original categories and the new categories.', 'While deep neural nets have achieved resounding success in the classical setting, they are known to forget about knowledge acquired in prior episodes of learning if the examples encountered in the current episode of learning are drastically different from those encountered in prior episodes.', 'This makes deep neural nets ill-suited to continual learning.', 'In this paper, we propose a new model that can both leverage the expressive power of deep neural nets and is resilient to forgetting when new categories are introduced.', 'We demonstrate an improvement in terms of accuracy on original classes compared to a vanilla deep neural net.']","[0, 0, 1, 0, 0]","[0.0624999962747097, 0.0476190447807312, 0.1111111044883728, 0.10810810327529907, 0.07407406717538834]",r1lEjlHKPH,"['We show metric learning can help reduce catastrophic forgetting', 'This paper applies metric learning to reduce catastrophic forgetting on neural networks by improving the expressiveness of the final layer, leading to better results in continual learning.']","['continual learning setting  new category may introduced time  ideal learning system perform well original category new category ', 'deep neural net achieved resounding success classical setting  known forget knowledge acquired prior episode learning example encountered current episode learning drastically different encountered prior episode ', 'make deep neural net illsuited continual learning ', 'paper  propose new model leverage expressive power deep neural net resilient forgetting new category introduced ', 'demonstrate improvement term accuracy original class compared vanilla deep neural net ']","In a continual learning setting, new categories may be introduced over time, and an ideal learning system should perform well on both the original categories and the new categories., While deep neural nets have achieved resounding success in the classical setting, they are known to forget about knowledge acquired in prior episodes of learning if the examples encountered in the current episode of learning are drastically different from those encountered in prior episodes., This makes deep neural nets ill-suited to continual learning., In this paper, we propose a new model that can both leverage the expressive power of deep neural nets and is resilient to forgetting when new categories are introduced., We demonstrate an improvement in terms of accuracy on original classes compared to a vanilla deep neural net.",9,5.294573643410852,14.333333333333334
338,"['Biomedical knowledge bases are crucial in modern data-driven biomedical sciences, but auto-mated biomedical knowledge base construction remains challenging.', 'In this paper, we consider the problem of disease entity normalization, an essential task in constructing a biomedical knowledge base.  ', 'We present NormCo, a deep coherence model which considers the semantics of an entity mention, as well as the topical coherence of the mentions within a single document.', 'NormCo mod-els entity mentions using a simple semantic model which composes phrase representations from word embeddings, and treats coherence as a disease concept co-mention sequence using an RNN rather than modeling the joint probability of all concepts in a document, which requires NP-hard inference.  ', 'To overcome the issue of data sparsity, we used distantly supervised data and synthetic data generated from priors derived from the BioASQ dataset.  ', 'Our experimental results show thatNormCo outperforms state-of-the-art baseline methods on two disease normalization corpora in terms of (1) prediction quality and (2) efficiency, and is at least as performant in terms of accuracy and F1 score on tagged documents.']","[0, 0, 1, 0, 0, 0]","[0.0, 0.25531914830207825, 0.9166666865348816, 0.3283582031726837, 0.08695651590824127, 0.1355932205915451]",BJerQWcp6Q,"['We present NormCo, a deep coherence model which considers the semantics of an entity mention, as well as the topical coherence of the mentions within a single document to perform disease entity normalization.', 'Uses a GRU autoencoder to represent the ""context"" (related enitities of a given disease within the span of a sentence), solving the BioNLP task with significant improvements over the best-known methods.']","['biomedical knowledge base crucial modern datadriven biomedical science  automated biomedical knowledge base construction remains challenging ', 'paper  consider problem disease entity normalization  essential task constructing biomedical knowledge base ', 'present normco  deep coherence model considers semantics entity mention  well topical coherence mention within single document ', 'normco model entity mention using simple semantic model composes phrase representation word embeddings  treat coherence disease concept comention sequence using rnn rather modeling joint probability concept document  requires nphard inference ', 'overcome issue data sparsity  used distantly supervised data synthetic data generated prior derived bioasq dataset ', 'experimental result show thatnormco outperforms stateoftheart baseline method two disease normalization corpus term  1  prediction quality  2  efficiency  least performant term accuracy f1 score tagged document ']","Biomedical knowledge bases are crucial in modern data-driven biomedical sciences, but auto-mated biomedical knowledge base construction remains challenging., In this paper, we consider the problem of disease entity normalization, an essential task in constructing a biomedical knowledge base.  , We present NormCo, a deep coherence model which considers the semantics of an entity mention, as well as the topical coherence of the mentions within a single document., NormCo mod-els entity mentions using a simple semantic model which composes phrase representations from word embeddings, and treats coherence as a disease concept co-mention sequence using an RNN rather than modeling the joint probability of all concepts in a document, which requires NP-hard inference.  , To overcome the issue of data sparsity, we used distantly supervised data and synthetic data generated from priors derived from the BioASQ dataset.  , Our experimental results show thatNormCo outperforms state-of-the-art baseline methods on two disease normalization corpora in terms of (1) prediction quality and (2) efficiency, and is at least as performant in terms of accuracy and F1 score on tagged documents.",15,5.790697674418604,11.466666666666667
339,"['We explore the role of multiplicative interaction as a unifying framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions amongst others.\n', 'Multiplicative interaction layers as primitive operations have a long-established presence in the literature, though this often not emphasized and thus under-appreciated.', 'We begin by showing that such layers strictly enrich the representable function classes of neural networks.', 'We conjecture that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams of information or when conditional computation is required.', 'We therefore argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft-used concatenation operation.', 'Finally, we back up our claims and demonstrate the potential of multiplicative interactions by applying them in large-scale complex RL and sequence modelling tasks, where their use allows us to deliver state-of-the-art results, and thereby provides new evidence in support of multiplicative interactions playing a more prominent role when designing new neural network architectures.']","[1, 0, 0, 0, 0, 0]","[0.9836065769195557, 0.19607841968536377, 0.21739129722118378, 0.1538461446762085, 0.17241378128528595, 0.23376622796058655]",rylnK6VtDH,"['We explore the role of multiplicative interaction as a unifying framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions amongst others.', 'Presents multiplicative interaction as a unified characterization for representing commonly used model architecture design components, showing empirical proof of superior performance on tasks like RL and sequence modeling.', 'The paper explores different types of multiplicative interactions and finds MI models able to achieve a state-of-the-art performance on language modeling and reinforcement learning problems.']","['explore role multiplicative interaction unifying framework describe range classical modern neural network architectural motif  gating  attention layer  hypernetworks  dynamic convolution amongst others ', 'multiplicative interaction layer primitive operation longestablished presence literature  though often emphasized thus underappreciated ', 'begin showing layer strictly enrich representable function class neural network ', 'conjecture multiplicative interaction offer particularly powerful inductive bias fusing multiple stream information conditional computation required ', 'therefore argue considered many situation multiple compute information path need combined  place simple oftused concatenation operation ', 'finally  back claim demonstrate potential multiplicative interaction applying largescale complex rl sequence modelling task  use allows u deliver stateoftheart result  thereby provides new evidence support multiplicative interaction playing prominent role designing new neural network architecture ']","We explore the role of multiplicative interaction as a unifying framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions amongst others.
, Multiplicative interaction layers as primitive operations have a long-established presence in the literature, though this often not emphasized and thus under-appreciated., We begin by showing that such layers strictly enrich the representable function classes of neural networks., We conjecture that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams of information or when conditional computation is required., We therefore argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft-used concatenation operation., Finally, we back up our claims and demonstrate the potential of multiplicative interactions by applying them in large-scale complex RL and sequence modelling tasks, where their use allows us to deliver state-of-the-art results, and thereby provides new evidence in support of multiplicative interactions playing a more prominent role when designing new neural network architectures.",15,6.151685393258427,11.866666666666667
340,"['Developing conditional generative models for text-to-video synthesis is an extremely challenging yet an important topic of research in machine learning.', 'In this work, we address this problem by introducing Text-Filter conditioning Generative Adversarial Network (TFGAN), a GAN model with novel conditioning scheme that aids improving the text-video associations.', 'With a combination of this conditioning scheme and a deep GAN architecture, TFGAN generates photo-realistic videos from text on very challenging real-world video datasets.', 'In addition, we construct a benchmark synthetic dataset of moving shapes to systematically evaluate our conditioning scheme.', 'Extensive experiments demonstrate that TFGAN significantly outperforms the existing approaches, and can also generate videos of novel categories not seen during training.\n']","[0, 0, 1, 0, 0]","[0.06896550953388214, 0.0555555522441864, 0.24242423474788666, 0.0, 0.060606054961681366]",SJl11nCctX,"['An effective text-conditioning GAN framework for generating videos from text', 'This paper presents a GAN-based method for video generation conditioned on text description, with a new conditioning method that generates convolution filters from the encoded text, and uses them for a convolution in the discriminator.', 'This paper proposes conditional GAN models for text-to-video synthesis: developing text-feature-conditioned CNN filters and constructing moving-shape dataset with improved performance on video/image generation.']","['developing conditional generative model texttovideo synthesis extremely challenging yet important topic research machine learning ', 'work  address problem introducing textfilter conditioning generative adversarial network  tfgan   gan model novel conditioning scheme aid improving textvideo association ', 'combination conditioning scheme deep gan architecture  tfgan generates photorealistic video text challenging realworld video datasets ', 'addition  construct benchmark synthetic dataset moving shape systematically evaluate conditioning scheme ', 'extensive experiment demonstrate tfgan significantly outperforms existing approach  also generate video novel category seen training ']","Developing conditional generative models for text-to-video synthesis is an extremely challenging yet an important topic of research in machine learning., In this work, we address this problem by introducing Text-Filter conditioning Generative Adversarial Network (TFGAN), a GAN model with novel conditioning scheme that aids improving the text-video associations., With a combination of this conditioning scheme and a deep GAN architecture, TFGAN generates photo-realistic videos from text on very challenging real-world video datasets., In addition, we construct a benchmark synthetic dataset of moving shapes to systematically evaluate our conditioning scheme., Extensive experiments demonstrate that TFGAN significantly outperforms the existing approaches, and can also generate videos of novel categories not seen during training.
",10,6.441441441441442,11.1
341,"['Over-parameterization is ubiquitous nowadays in training neural networks to benefit both optimization in seeking global optima and generalization in reducing prediction error.', 'However, compressive networks are desired in many real world applications and direct training of small networks may be trapped in local optima.', 'In this paper, instead of pruning or distilling over-parameterized models to compressive ones, we propose a new approach based on \\emph{differential inclusions of inverse scale spaces}, that generates a family of models from simple to complex ones by coupling gradient descent and mirror descent to explore model structural sparsity.', 'It has a simple discretization, called the Split Linearized Bregman Iteration (SplitLBI), whose global convergence analysis in deep learning is established that from any initializations, algorithmic iterations converge to a critical point of empirical risks.', 'Experimental evidence shows that\\ SplitLBI may achieve state-of-the-art performance in large scale training on ImageNet-2012 dataset etc., while with \\emph{early stopping} it unveils effective subnet architecture with comparable test accuracies to dense models after retraining instead of pruning well-trained ones.']","[0, 0, 0, 0, 1]","[0.19999998807907104, 0.09999999403953552, 0.16129031777381897, 0.18518517911434174, 0.29999998211860657]",SkxUrTVKDH,"['SplitLBI is applied to deep learning to explore model structural sparsity, achieving state-of-the-art performance in ImageNet-2012 and unveiling effective subnet architecture.', 'Proposes an optimization based algorithm for finding important sparse structures of large-scale neural networks by coupling the learning of weight matrix and sparsity constraints, offering guaranteed convergence on nonconvex optimization problems.']","['overparameterization ubiquitous nowadays training neural network benefit optimization seeking global optimum generalization reducing prediction error ', 'however  compressive network desired many real world application direct training small network may trapped local optimum ', 'paper  instead pruning distilling overparameterized model compressive one  propose new approach based emph  differential inclusion inverse scale space   generates family model simple complex one coupling gradient descent mirror descent explore model structural sparsity ', 'simple discretization  called split linearized bregman iteration  splitlbi   whose global convergence analysis deep learning established initialization  algorithmic iteration converge critical point empirical risk ', 'experimental evidence show splitlbi may achieve stateoftheart performance large scale training imagenet2012 dataset etc  emph  early stopping  unveils effective subnet architecture comparable test accuracy dense model retraining instead pruning welltrained one ']","Over-parameterization is ubiquitous nowadays in training neural networks to benefit both optimization in seeking global optima and generalization in reducing prediction error., However, compressive networks are desired in many real world applications and direct training of small networks may be trapped in local optima., In this paper, instead of pruning or distilling over-parameterized models to compressive ones, we propose a new approach based on \emph{differential inclusions of inverse scale spaces}, that generates a family of models from simple to complex ones by coupling gradient descent and mirror descent to explore model structural sparsity., It has a simple discretization, called the Split Linearized Bregman Iteration (SplitLBI), whose global convergence analysis in deep learning is established that from any initializations, algorithmic iterations converge to a critical point of empirical risks., Experimental evidence shows that\ SplitLBI may achieve state-of-the-art performance in large scale training on ImageNet-2012 dataset etc., while with \emph{early stopping} it unveils effective subnet architecture with comparable test accuracies to dense models after retraining instead of pruning well-trained ones.",13,6.267857142857143,12.923076923076923
342,"['In this paper, we study the learned iterative shrinkage thresholding algorithm (LISTA) for solving sparse coding problems.  ', 'Following assumptions made by prior works, we first discover that the code components in its estimations may be lower than expected, i.e., require gains, and to address this problem, a gated mechanism amenable to theoretical analysis is then introduced.', 'Specific design of the gates is inspired by convergence analyses of the mechanism and hence its effectiveness can be formally guaranteed.', 'In addition to the gain gates, we further introduce overshoot gates for compensating insufficient step size in LISTA.', 'Extensive empirical results confirm our theoretical findings and verify the effectiveness of our method.']","[1, 0, 0, 0, 0]","[0.2631579041481018, 0.13333332538604736, 0.10256409645080566, 0.15789473056793213, 0.24242423474788666]",BygPO2VKPH,"['We propose gated mechanisms to enhance learned ISTA for sparse coding, with theoretical guarantees on the superiority of the method. ', 'Proposes extensions to LISTA which address underestimation by introducing ""gain gates"" and including momentum with ""overshoot gates"", showing improved convergence rates.', 'This paper is focused on solving sparse coding problems using LISTA-type networks by proposing a ""gain gating function"" to mitigate the weakness of the ""no false positive"" assumption.']","['paper  study learned iterative shrinkage thresholding algorithm  lista  solving sparse coding problem ', 'following assumption made prior work  first discover code component estimation may lower expected  ie  require gain  address problem  gated mechanism amenable theoretical analysis introduced ', 'specific design gate inspired convergence analysis mechanism hence effectiveness formally guaranteed ', 'addition gain gate  introduce overshoot gate compensating insufficient step size lista ', 'extensive empirical result confirm theoretical finding verify effectiveness method ']","In this paper, we study the learned iterative shrinkage thresholding algorithm (LISTA) for solving sparse coding problems.  , Following assumptions made by prior works, we first discover that the code components in its estimations may be lower than expected, i.e., require gains, and to address this problem, a gated mechanism amenable to theoretical analysis is then introduced., Specific design of the gates is inspired by convergence analyses of the mechanism and hence its effectiveness can be formally guaranteed., In addition to the gain gates, we further introduce overshoot gates for compensating insufficient step size in LISTA., Extensive empirical results confirm our theoretical findings and verify the effectiveness of our method.",12,5.706422018348624,9.083333333333334
343,"['The learning of hierarchical representations for image classification has experienced an impressive series of successes due in part to the availability of large-scale labeled data for training.', 'On the other hand, the trained classifiers have traditionally been evaluated on a handful of test images, which are deemed to be extremely sparsely distributed in the space of all natural images.', 'It is thus questionable whether recent performance improvements on the excessively re-used test sets generalize to real-world natural images with much richer content variations.', 'In addition, studies on adversarial learning show that it is effortless to construct adversarial examples that fool nearly all image classifiers, adding more complications to relative performance comparison of existing models.', 'This work presents an efficient framework for comparing image classifiers, which we name the MAximum Discrepancy (MAD) competition.', 'Rather than comparing image classifiers on fixed test sets, we adaptively sample a test set from an arbitrarily large corpus of unlabeled images so as to maximize the discrepancies between the classifiers, measured by the distance over WordNet hierarchy.', 'Human labeling on the resulting small and model-dependent image sets reveals the relative performance of the competing classifiers and provides useful insights on potential ways to improve them.', 'We report the MAD competition results of eleven ImageNet classifiers while noting that the framework is readily extensible and cost-effective to add future classifiers into the competition.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.2916666567325592, 0.2641509473323822, 0.2083333283662796, 0.19230768084526062, 0.380952388048172, 0.46666666865348816, 0.3333333134651184, 0.2978723347187042]",rJehNT4YPr,"['We present an efficient and adaptive framework for comparing image classifiers to maximize the discrepancies between the classifiers, in place of comparing on fixed test sets.', 'Error spotting mechanism which compares image classifiers by sampling their ""most disagreed"" test set, measuring disagreement through a semantics-aware distance derived form WordNet ontology.']","['learning hierarchical representation image classification experienced impressive series success due part availability largescale labeled data training ', 'hand  trained classifier traditionally evaluated handful test image  deemed extremely sparsely distributed space natural image ', 'thus questionable whether recent performance improvement excessively reused test set generalize realworld natural image much richer content variation ', 'addition  study adversarial learning show effortless construct adversarial example fool nearly image classifier  adding complication relative performance comparison existing model ', 'work present efficient framework comparing image classifier  name maximum discrepancy  mad  competition ', 'rather comparing image classifier fixed test set  adaptively sample test set arbitrarily large corpus unlabeled image maximize discrepancy classifier  measured distance wordnet hierarchy ', 'human labeling resulting small modeldependent image set reveals relative performance competing classifier provides useful insight potential way improve ', 'report mad competition result eleven imagenet classifier noting framework readily extensible costeffective add future classifier competition ']","The learning of hierarchical representations for image classification has experienced an impressive series of successes due in part to the availability of large-scale labeled data for training., On the other hand, the trained classifiers have traditionally been evaluated on a handful of test images, which are deemed to be extremely sparsely distributed in the space of all natural images., It is thus questionable whether recent performance improvements on the excessively re-used test sets generalize to real-world natural images with much richer content variations., In addition, studies on adversarial learning show that it is effortless to construct adversarial examples that fool nearly all image classifiers, adding more complications to relative performance comparison of existing models., This work presents an efficient framework for comparing image classifiers, which we name the MAximum Discrepancy (MAD) competition., Rather than comparing image classifiers on fixed test sets, we adaptively sample a test set from an arbitrarily large corpus of unlabeled images so as to maximize the discrepancies between the classifiers, measured by the distance over WordNet hierarchy., Human labeling on the resulting small and model-dependent image sets reveals the relative performance of the competing classifiers and provides useful insights on potential ways to improve them., We report the MAD competition results of eleven ImageNet classifiers while noting that the framework is readily extensible and cost-effective to add future classifiers into the competition.",15,5.902654867256637,15.066666666666666
344,"['Robustness of neural networks has recently been highlighted by the adversarial examples, i.e., inputs added with well-designed  perturbations which are imperceptible to humans but can cause the network to give incorrect outputs.', 'In this paper, we design a new CNN architecture that by itself has good robustness.', 'We introduce a simple but powerful technique, Random Mask, to modify existing CNN structures.', 'We show that CNN with Random Mask achieves state-of-the-art performance against black-box adversarial attacks without applying any adversarial training.', 'We next investigate the adversarial examples which fool a CNN with Random Mask.', 'Surprisingly, we find that these adversarial examples often fool humans as well.', 'This raises fundamental questions on how to define adversarial examples and robustness properly.']","[0, 0, 0, 0, 0, 0, 1]","[0.1538461446762085, 0.2083333283662796, 0.21276594698429108, 0.15686273574829102, 0.21739129722118378, 0.17777776718139648, 0.260869562625885]",SkgkJn05YX,"['We propose a technique that modifies CNN structures to enhance robustness while keeping high test accuracy, and raise doubt on whether current definition of adversarial examples is appropriate by generating adversarial examples able to fool humans.', 'This paper proposes a simple technique for improving the robustness of neural networks against black-box attacks.', 'The authors propose a simple method for increasing the robustness of convolutional neural networks against adversarial examples, with surprisingly good results.']","['robustness neural network recently highlighted adversarial example  ie  input added welldesigned perturbation imperceptible human cause network give incorrect output ', 'paper  design new cnn architecture good robustness ', 'introduce simple powerful technique  random mask  modify existing cnn structure ', 'show cnn random mask achieves stateoftheart performance blackbox adversarial attack without applying adversarial training ', 'next investigate adversarial example  fool  cnn random mask ', 'surprisingly  find adversarial example often  fool  human well ', 'raise fundamental question define adversarial example robustness properly ']","Robustness of neural networks has recently been highlighted by the adversarial examples, i.e., inputs added with well-designed  perturbations which are imperceptible to humans but can cause the network to give incorrect outputs., In this paper, we design a new CNN architecture that by itself has good robustness., We introduce a simple but powerful technique, Random Mask, to modify existing CNN structures., We show that CNN with Random Mask achieves state-of-the-art performance against black-box adversarial attacks without applying any adversarial training., We next investigate the adversarial examples which fool a CNN with Random Mask., Surprisingly, we find that these adversarial examples often fool humans as well., This raises fundamental questions on how to define adversarial examples and robustness properly.",13,5.906779661016949,9.076923076923077
345,"['Supervised deep learning methods require cleanly labeled large-scale datasets, but collecting such data is difficult and sometimes impossible.', 'There exist two popular frameworks to alleviate this problem: semi-supervised learning and robust learning to label noise.', 'Although these frameworks relax the restriction of supervised learning, they are studied independently.', 'Hence, the training scheme that is suitable when only small cleanly-labeled data are available remains unknown.', 'In this study, we consider learning from bi-quality data as a generalization of these studies, in which a small portion of data is cleanly labeled, and the rest is corrupt.', 'Under this framework, we compare recent algorithms for semi-supervised and robust learning.', 'The results suggest that semi-supervised learning outperforms robust learning with noisy labels.', 'We also propose a training strategy for mixing mixup techniques to learn from such bi-quality data effectively.']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.1249999925494194, 0.41379308700561523, 0.0, 0.0, 0.14999999105930328, 0.38461539149284363, 0.3199999928474426, 0.25806450843811035]",r1gp1jRN_4,"['We propose to compare semi-supervised and robust learning to noisy label under a shared setting', 'The authors propose a strategy based on mixup for training a model in a formal setting that includes the semi-supervised and the robust learning tasks as special cases.']","['supervised deep learning method require cleanly labeled largescale datasets  collecting data difficult sometimes impossible ', 'exist two popular framework alleviate problem  semisupervised learning robust learning label noise ', 'although framework relax restriction supervised learning  studied independently ', 'hence  training scheme suitable small cleanlylabeled data available remains unknown ', 'study  consider learning biquality data generalization study  small portion data cleanly labeled  rest corrupt ', 'framework  compare recent algorithm semisupervised robust learning ', 'result suggest semisupervised learning outperforms robust learning noisy label ', 'also propose training strategy mixing mixup technique learn biquality data effectively ']","Supervised deep learning methods require cleanly labeled large-scale datasets, but collecting such data is difficult and sometimes impossible., There exist two popular frameworks to alleviate this problem: semi-supervised learning and robust learning to label noise., Although these frameworks relax the restriction of supervised learning, they are studied independently., Hence, the training scheme that is suitable when only small cleanly-labeled data are available remains unknown., In this study, we consider learning from bi-quality data as a generalization of these studies, in which a small portion of data is cleanly labeled, and the rest is corrupt., Under this framework, we compare recent algorithms for semi-supervised and robust learning., The results suggest that semi-supervised learning outperforms robust learning with noisy labels., We also propose a training strategy for mixing mixup techniques to learn from such bi-quality data effectively.",15,6.029629629629629,9.0
346,"['Hierarchical Sparse Coding (HSC) is a powerful model to efficiently represent multi-dimensional, structured data such as images.', 'The simplest solution to solve this computationally hard problem is to decompose it into independent layerwise subproblems.', 'However, neuroscientific evidence would suggest inter-connecting these subproblems as in the Predictive Coding (PC) theory, which adds top-down connections between consecutive layers.', 'In this study, a new model called Sparse Deep Predictive Coding (SDPC) is introduced to assess the impact of this inter-layer feedback connection.', 'In particular, the SDPC is compared with a Hierarchical Lasso (Hi-La) network made out of a sequence of Lasso layers.', 'A 2-layered SDPC and a Hi-La networks are trained on 3 different databases and with different sparsity parameters on each layer.', 'First, we show that the overall prediction error generated by SDPC is lower thanks to the feedback mechanism as it transfers prediction error between layers.', 'Second, we demonstrate that the inference stage of the SDPC is faster to converge than for the Hi-La model.', 'Third, we show that the SDPC also accelerates the learning process.', 'Finally, the qualitative analysis of both models dictionaries, supported by their activation probability, show that the SDPC features are more generic and informative.']","[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.1875, 0.0, 0.2702702581882477, 0.21621620655059814, 0.1875, 0.0, 0.05405404791235924, 0.1249999925494194, 0.07999999821186066, 0.10810810327529907]",rJlcLaVFvB,"['This paper experimentally demonstrates the beneficial effect of top-down connections in Hierarchical Sparse Coding algorithm.', 'This paper presents a study that compares techniques for Hierarchical Sparse Coding, showing that the top-down term is beneficial in reducing predictive error and can learn faster.']","['hierarchical sparse coding  hsc  powerful model efficiently represent multidimensional  structured data image ', 'simplest solution solve computationally hard problem decompose independent layerwise subproblems ', 'however  neuroscientific evidence would suggest interconnecting subproblems predictive coding  pc  theory  add topdown connection consecutive layer ', 'study  new model called sparse deep predictive coding  sdpc  introduced ass impact interlayer feedback connection ', 'particular  sdpc compared hierarchical lasso  hilum  network made sequence lasso layer ', '2layered sdpc hilum network trained 3 different database different sparsity parameter layer ', 'first  show overall prediction error generated sdpc lower thanks feedback mechanism transfer prediction error layer ', 'second  demonstrate inference stage sdpc faster converge hilum model ', 'third  show sdpc also accelerates learning process ', 'finally  qualitative analysis model dictionary  supported activation probability  show sdpc feature generic informative ']","Hierarchical Sparse Coding (HSC) is a powerful model to efficiently represent multi-dimensional, structured data such as images., The simplest solution to solve this computationally hard problem is to decompose it into independent layerwise subproblems., However, neuroscientific evidence would suggest inter-connecting these subproblems as in the Predictive Coding (PC) theory, which adds top-down connections between consecutive layers., In this study, a new model called Sparse Deep Predictive Coding (SDPC) is introduced to assess the impact of this inter-layer feedback connection., In particular, the SDPC is compared with a Hierarchical Lasso (Hi-La) network made out of a sequence of Lasso layers., A 2-layered SDPC and a Hi-La networks are trained on 3 different databases and with different sparsity parameters on each layer., First, we show that the overall prediction error generated by SDPC is lower thanks to the feedback mechanism as it transfers prediction error between layers., Second, we demonstrate that the inference stage of the SDPC is faster to converge than for the Hi-La model., Third, we show that the SDPC also accelerates the learning process., Finally, the qualitative analysis of both models dictionaries, supported by their activation probability, show that the SDPC features are more generic and informative.",21,5.6767676767676765,9.428571428571429
347,"['Explaining a deep learning model can help users understand its behavior and allow researchers to discern its shortcomings.', 'Recent work has primarily focused on explaining models for tasks like image classification or visual question answering.  ', ""In this paper, we introduce an explanation approach for image similarity models, where a model's output is a score measuring the similarity of two inputs rather than a classification.  "", 'In this task, an explanation depends on both of the input images, so standard methods do not apply.', 'We propose an explanation method that pairs a saliency map identifying important image regions with an attribute that best explains the match.  ', 'We find that our explanations provide additional information not typically captured by saliency maps alone, and can also improve performance on the classic task of attribute recognition.', ""Our approach's ability to generalize is demonstrated on two datasets from diverse domains, Polyvore Outfits and Animals with Attributes 2.""]","[0, 0, 1, 0, 0, 0, 0]","[0.06666666269302368, 0.19354838132858276, 0.3499999940395355, 0.19354838132858276, 0.1764705777168274, 0.09999999403953552, 0.0]",S1l_ZlrFvS,"['A black box approach for explaining the predictions of an image similarity model.', 'Introduces method for image similarity model explanation which identifies attributes that contribute positively to the similarity score and pairs them with a generated saliency map.', 'The paper proposes an explanation mechanism that pairs the typical saliency map regions together with attributes for similarity matching deep neural networks.']","['explaining deep learning model help user understand behavior allow researcher discern shortcoming ', 'recent work primarily focused explaining model task like image classification visual question answering ', 'paper  introduce explanation approach image similarity model  model output score measuring similarity two input rather classification ', 'task  explanation depends input image  standard method apply ', 'propose explanation method pair saliency map identifying important image region attribute best explains match ', 'find explanation provide additional information typically captured saliency map alone  also improve performance classic task attribute recognition ', 'approach ability generalize demonstrated two datasets diverse domain  polyvore outfit animal attribute 2 ']","Explaining a deep learning model can help users understand its behavior and allow researchers to discern its shortcomings., Recent work has primarily focused on explaining models for tasks like image classification or visual question answering.  , In this paper, we introduce an explanation approach for image similarity models, where a model's output is a score measuring the similarity of two inputs rather than a classification.  , In this task, an explanation depends on both of the input images, so standard methods do not apply., We propose an explanation method that pairs a saliency map identifying important image regions with an attribute that best explains the match.  , We find that our explanations provide additional information not typically captured by saliency maps alone, and can also improve performance on the classic task of attribute recognition., Our approach's ability to generalize is demonstrated on two datasets from diverse domains, Polyvore Outfits and Animals with Attributes 2.",13,5.562913907284768,11.615384615384615
348,"['Adversarial examples have been shown to be an effective way of assessing the robustness of neural sequence-to-sequence (seq2seq) models, by applying perturbations to the input of a model leading to large degradation in performance.', 'However, these perturbations are only indicative of a weakness in the model if they do not change the semantics of the input in a way that would change the expected output.', 'Using the example of machine translation (MT), we propose a new evaluation framework for adversarial attacks on seq2seq models taking meaning preservation into account and demonstrate that existing methods may not preserve meaning in general.', 'Based on these findings, we propose new constraints for attacks on word-based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs.', 'Furthermore, we show that performing adversarial training with meaning-preserving attacks is beneficial to the model in terms of adversarial robustness without hurting test performance.']","[0, 0, 1, 0, 0]","[0.0, 0.0, 0.190476194024086, 0.17142856121063232, 0.12903225421905518]",BylkG20qYm,"['How you should evaluate adversarial attacks on seq2seq', 'The authors investigate ways of generating adversarial examples, showing that adversarial training with the attack most consistent with the introduced meaning-preservation criteria results in improved robustness to this type of attack without degradation in the non-adversarial setting.', 'The paper is about meaning-preserving adversarial perturbations in the context of Seq2Seq models']","['adversarial example shown effective way assessing robustness neural sequencetosequence  seq2seq  model  applying perturbation input model leading large degradation performance ', 'however  perturbation indicative weakness model change semantics input way would change expected output ', 'using example machine translation  mt   propose new evaluation framework adversarial attack seq2seq model taking meaning preservation account demonstrate existing method may preserve meaning general ', 'based finding  propose new constraint attack wordbased mt system show  via human automatic evaluation  produce semantically similar adversarial input ', 'furthermore  show performing adversarial training meaningpreserving attack beneficial model term adversarial robustness without hurting test performance ']","Adversarial examples have been shown to be an effective way of assessing the robustness of neural sequence-to-sequence (seq2seq) models, by applying perturbations to the input of a model leading to large degradation in performance., However, these perturbations are only indicative of a weakness in the model if they do not change the semantics of the input in a way that would change the expected output., Using the example of machine translation (MT), we propose a new evaluation framework for adversarial attacks on seq2seq models taking meaning preservation into account and demonstrate that existing methods may not preserve meaning in general., Based on these findings, we propose new constraints for attacks on word-based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs., Furthermore, we show that performing adversarial training with meaning-preserving attacks is beneficial to the model in terms of adversarial robustness without hurting test performance.",12,5.705882352941177,12.75
349,"['We introduce a new normalization technique that exhibits the fast convergence properties of batch normalization using a transformation of layer weights instead of layer outputs.', 'The proposed technique keeps the contribution of positive and negative weights to the layer output in equilibrium.', 'We validate our method on a set of standard benchmarks including CIFAR-10/100, SVHN and ILSVRC 2012 ImageNet.']","[1, 0, 0]","[0.23076923191547394, 0.1818181723356247, 0.0]",ryGDEjCcK7,"['An alternative normalization technique to batch normalization', 'Introduces a normalization technique, which normalizes the weights of convolutional layers. ', 'This manuscript introduces a new layer-wise transform, EquiNorm, to improve upon batch normalization that does not modify the inputs to the layers but rather the layer weights.']","['introduce new normalization technique exhibit fast convergence property batch normalization using transformation layer weight instead layer output ', 'proposed technique keep contribution positive negative weight layer output equilibrium ', 'validate method set standard benchmark including cifar10100  svhn ilsvrc 2012 imagenet ']","We introduce a new normalization technique that exhibits the fast convergence properties of batch normalization using a transformation of layer weights instead of layer outputs., The proposed technique keeps the contribution of positive and negative weights to the layer output in equilibrium., We validate our method on a set of standard benchmarks including CIFAR-10/100, SVHN and ILSVRC 2012 ImageNet.",4,5.813559322033898,14.75
350,"['We present a framework for building unsupervised representations of entities and their compositions, where each entity is viewed as a probability distribution rather than a fixed length vector.', 'In particular, this distribution is supported over the contexts which co-occur with the entity and are embedded in a suitable low-dimensional space.', 'This enables us to consider the problem of representation learning with a perspective from Optimal Transport and take advantage of its numerous tools such as Wasserstein distance and Wasserstein barycenters.', 'We elaborate how the method can be applied for obtaining unsupervised representations of text and illustrate the performance quantitatively as well as qualitatively on tasks such as measuring sentence similarity and word entailment, where we empirically observe significant gains (e.g., 4.1% relative improvement over Sent2vec and GenSen).\n\n', 'The key benefits of the proposed approach include:', '(a) capturing uncertainty and polysemy via modeling the entities as distributions,', '(b) utilizing the underlying geometry of the particular task (with the ground cost),', '(c) simultaneously providing interpretability with the notion of optimal transport between contexts and', '(d) easy applicability on top of existing point embedding methods.', 'In essence, the framework can be useful for any unsupervised or supervised problem (on text or other modalities); and only requires a co-occurrence structure inherent to many problems.', 'The code, as well as pre-built histograms, are available under https://github.com/context-mover.']","[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.307692289352417, 0.47058823704719543, 0.09999999403953552, 0.06779661029577255, 0.0, 0.0833333283662796, 0.0833333283662796, 0.07692307233810425, 0.0, 0.04999999701976776, 0.0833333283662796]",rygiEL8FOV,"['Represent each entity as a probability distribution over contexts embedded in a ground space.', 'Proposes to construct word embeddings from a histogram over context words, instead of as point vectors, which allows for measuring distances between two words in terms of optimal transport between the histograms through a method that augments representation of an entity from standard ""point in a vector space"" to a histogram with bins located at some points in that vector space. ']","['present framework building unsupervised representation entity composition  entity viewed probability distribution rather fixed length vector ', 'particular  distribution supported context cooccur entity embedded suitable lowdimensional space ', 'enables u consider problem representation learning perspective optimal transport take advantage numerous tool wasserstein distance wasserstein barycenter ', 'elaborate method applied obtaining unsupervised representation text illustrate performance quantitatively well qualitatively task measuring sentence similarity word entailment  empirically observe significant gain  eg  41  relative improvement sent2vec gensen  ', 'key benefit proposed approach include ', '  capturing uncertainty polysemy via modeling entity distribution ', ' b  utilizing underlying geometry particular task  ground cost  ', ' c  simultaneously providing interpretability notion optimal transport context', '  easy applicability top existing point embedding method ', 'essence  framework useful unsupervised supervised problem  text modality   requires cooccurrence structure inherent many problem ', 'code  well prebuilt histogram  available http  githubcomcontextmover ']","We present a framework for building unsupervised representations of entities and their compositions, where each entity is viewed as a probability distribution rather than a fixed length vector., In particular, this distribution is supported over the contexts which co-occur with the entity and are embedded in a suitable low-dimensional space., This enables us to consider the problem of representation learning with a perspective from Optimal Transport and take advantage of its numerous tools such as Wasserstein distance and Wasserstein barycenters., We elaborate how the method can be applied for obtaining unsupervised representations of text and illustrate the performance quantitatively as well as qualitatively on tasks such as measuring sentence similarity and word entailment, where we empirically observe significant gains (e.g., 4.1% relative improvement over Sent2vec and GenSen).

, The key benefits of the proposed approach include:, (a) capturing uncertainty and polysemy via modeling the entities as distributions,, (b) utilizing the underlying geometry of the particular task (with the ground cost),, (c) simultaneously providing interpretability with the notion of optimal transport between contexts and, (d) easy applicability on top of existing point embedding methods., In essence, the framework can be useful for any unsupervised or supervised problem (on text or other modalities); and only requires a co-occurrence structure inherent to many problems., The code, as well as pre-built histograms, are available under https://github.com/context-mover.",18,6.040723981900452,12.277777777777779
351,"['    Over the last few years, the phenomenon of adversarial examples --- maliciously constructed inputs that fool trained machine learning models --- has captured the attention of the research community, especially when the adversary is restricted to making small modifications of a correctly handled input.', 'At the same time, less surprisingly, image classifiers lack human-level performance on randomly corrupted images, such as images with additive Gaussian noise.', 'In this work, we show that these are two manifestations of the same underlying phenomenon.', 'We establish this connection in several ways.', 'First, we find that adversarial examples exist at the same distance scales we would expect from a linear model with the same performance on corrupted images.', 'Next, we show that Gaussian data augmentation during training improves robustness to small adversarial perturbations and that adversarial training improves robustness to several types of image corruptions.', 'Finally, we present a model-independent upper bound on the distance from a corrupted image to its nearest error given test performance and show that in practice we already come close to achieving the bound, so that improving robustness further for the corrupted image distribution requires significantly reducing test error.', 'All of this suggests that improving adversarial robustness should go hand in hand with improving performance in the presence of more general and realistic image corruptions.', 'This yields a computationally tractable evaluation metric for defenses to consider: test error in noisy image distributions.']","[0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.14814814925193787, 0.05128204822540283, 0.1249999925494194, 0.0, 0.09999999403953552, 0.21052631735801697, 0.1428571343421936, 0.20512819290161133, 0.05882352590560913]",S1xoy3CcYX,"['Small adversarial perturbations should be expected given observed error rates of models outside the natural data distribution.', 'This paper proposes an alternative view for adversarial examples in high dimension spaces by considering the ""error rate"" in a Gaussian distribution centered at each test point.']","['last year  phenomenon adversarial example   maliciously constructed input fool trained machine learning model   captured attention research community  especially adversary restricted making small modification correctly handled input ', 'time  le surprisingly  image classifier lack humanlevel performance randomly corrupted image  image additive gaussian noise ', 'work  show two manifestation underlying phenomenon ', 'establish connection several way ', 'first  find adversarial example exist distance scale would expect linear model performance corrupted image ', 'next  show gaussian data augmentation training improves robustness small adversarial perturbation adversarial training improves robustness several type image corruption ', 'finally  present modelindependent upper bound distance corrupted image nearest error given test performance show practice already come close achieving bound  improving robustness corrupted image distribution requires significantly reducing test error ', 'suggests improving adversarial robustness go hand hand improving performance presence general realistic image corruption ', 'yield computationally tractable evaluation metric defense consider  test error noisy image distribution ']","    Over the last few years, the phenomenon of adversarial examples --- maliciously constructed inputs that fool trained machine learning models --- has captured the attention of the research community, especially when the adversary is restricted to making small modifications of a correctly handled input., At the same time, less surprisingly, image classifiers lack human-level performance on randomly corrupted images, such as images with additive Gaussian noise., In this work, we show that these are two manifestations of the same underlying phenomenon., We establish this connection in several ways., First, we find that adversarial examples exist at the same distance scales we would expect from a linear model with the same performance on corrupted images., Next, we show that Gaussian data augmentation during training improves robustness to small adversarial perturbations and that adversarial training improves robustness to several types of image corruptions., Finally, we present a model-independent upper bound on the distance from a corrupted image to its nearest error given test performance and show that in practice we already come close to achieving the bound, so that improving robustness further for the corrupted image distribution requires significantly reducing test error., All of this suggests that improving adversarial robustness should go hand in hand with improving performance in the presence of more general and realistic image corruptions., This yields a computationally tractable evaluation metric for defenses to consider: test error in noisy image distributions.",19,5.76824034334764,12.263157894736842
352,"['Recent developments in natural language representations have been accompanied by large and expensive models that leverage vast amounts of general-domain text through self-supervised pre-training.', 'Due to the cost of applying such models to down-stream tasks, several model compression techniques on pre-trained language representations have been proposed (Sun et al., 2019; Sanh, 2019).', 'However, surprisingly,  the simple baseline of just pre-training and fine-tuning compact models has been overlooked.', 'In this paper, we first show that pre-training remains important in the context of smaller architectures, and fine-tuning pre-trained compact models can be competitive to more elaborate methods proposed in concurrent work.', 'Starting with pre-trained compact models, we then explore transferring task knowledge from large fine-tuned models through standard knowledge distillation.', 'The resulting simple, yet effective and general algorithm, Pre-trained Distillation, brings further improvements.', 'Through extensive experiments, we more generally explore the interaction between pre-training and distillation under two variables that have been under-studied: model size and properties of unlabeled task data.', 'One surprising observation is that they have a compound effect even when sequentially applied on the same data.', 'To accelerate future research, we will make our 24 pre-trained miniature BERT models publicly available.']","[0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.25641024112701416, 0.1395348757505417, 0.3333333134651184, 0.30434781312942505, 0.24242423474788666, 0.0714285671710968, 0.1904761791229248, 0.060606054961681366, 0.06666666269302368]",BJg7x1HFvB,"['Studies how self-supervised learning and knowledge distillation interact in the context of building compact models.', 'Investigates training compact pre-trained language models via distillation and shows that using a teacher for distilling a compact student model performs better than directly pre-training the model.', 'This submission shows that pre-training a student directly on masked language modeling is better than distillation, and the best is to combine both and distill from that pre-trained student model.']","['recent development natural language representation accompanied large expensive model leverage vast amount generaldomain text selfsupervised pretraining ', 'due cost applying model downstream task  several model compression technique pretrained language representation proposed  sun et al  2019  sanh  2019  ', 'however  surprisingly  simple baseline pretraining finetuning compact model overlooked ', 'paper  first show pretraining remains important context smaller architecture  finetuning pretrained compact model competitive elaborate method proposed concurrent work ', 'starting pretrained compact model  explore transferring task knowledge large finetuned model standard knowledge distillation ', 'resulting simple  yet effective general algorithm  pretrained distillation  brings improvement ', 'extensive experiment  generally explore interaction pretraining distillation two variable understudied  model size property unlabeled task data ', 'one surprising observation compound effect even sequentially applied data ', 'accelerate future research  make 24 pretrained miniature bert model publicly available ']","Recent developments in natural language representations have been accompanied by large and expensive models that leverage vast amounts of general-domain text through self-supervised pre-training., Due to the cost of applying such models to down-stream tasks, several model compression techniques on pre-trained language representations have been proposed (Sun et al., 2019; Sanh, 2019)., However, surprisingly,  the simple baseline of just pre-training and fine-tuning compact models has been overlooked., In this paper, we first show that pre-training remains important in the context of smaller architectures, and fine-tuning pre-trained compact models can be competitive to more elaborate methods proposed in concurrent work., Starting with pre-trained compact models, we then explore transferring task knowledge from large fine-tuned models through standard knowledge distillation., The resulting simple, yet effective and general algorithm, Pre-trained Distillation, brings further improvements., Through extensive experiments, we more generally explore the interaction between pre-training and distillation under two variables that have been under-studied: model size and properties of unlabeled task data., One surprising observation is that they have a compound effect even when sequentially applied on the same data., To accelerate future research, we will make our 24 pre-trained miniature BERT models publicly available.",22,6.34375,8.727272727272727
353,"['In this paper, we investigate lossy compression of deep neural networks (DNNs) by weight quantization and lossless source coding for memory-efficient deployment.', 'Whereas the previous work addressed non-universal scalar quantization and entropy coding of DNN weights, we for the first time introduce universal DNN compression by universal vector quantization and universal source coding.', 'In particular, we examine universal randomized lattice quantization of DNNs, which randomizes DNN weights by uniform random dithering before lattice quantization and can perform near-optimally on any source without relying on knowledge of its probability distribution.', 'Moreover, we present a method of fine-tuning vector quantized DNNs to recover the performance loss after quantization.', 'Our experimental results show that the proposed universal DNN compression scheme compresses the 32-layer ResNet (trained on CIFAR-10) and the AlexNet (trained on ImageNet) with compression ratios of $47.1$ and $42.5$, respectively.']","[0, 0, 1, 0, 0]","[0.2978723347187042, 0.2857142686843872, 0.31578946113586426, 0.0952380895614624, 0.18867923319339752]",S1xD5nsUs7,"['We introduce the universal deep neural network compression scheme, which is applicable universally for compression of any models and can perform near-optimally regardless of their weight distribution.', 'Introduces a pipeline for network compression that is similar to deep compression and uses randomized lattice quantization instead of the classical vector quantization, and uses universal source coding (bzip2) instead of Huffman coding.']","['paper  investigate lossy compression deep neural network  dnns  weight quantization lossless source coding memoryefficient deployment ', 'whereas previous work addressed nonuniversal scalar quantization entropy coding dnn weight  first time introduce universal dnn compression universal vector quantization universal source coding ', 'particular  examine universal randomized lattice quantization dnns  randomizes dnn weight uniform random dithering lattice quantization perform nearoptimally source without relying knowledge probability distribution ', 'moreover  present method finetuning vector quantized dnns recover performance loss quantization ', 'experimental result show proposed universal dnn compression scheme compress 32layer resnet  trained cifar10  alexnet  trained imagenet  compression ratio  471   425   respectively ']","In this paper, we investigate lossy compression of deep neural networks (DNNs) by weight quantization and lossless source coding for memory-efficient deployment., Whereas the previous work addressed non-universal scalar quantization and entropy coding of DNN weights, we for the first time introduce universal DNN compression by universal vector quantization and universal source coding., In particular, we examine universal randomized lattice quantization of DNNs, which randomizes DNN weights by uniform random dithering before lattice quantization and can perform near-optimally on any source without relying on knowledge of its probability distribution., Moreover, we present a method of fine-tuning vector quantized DNNs to recover the performance loss after quantization., Our experimental results show that the proposed universal DNN compression scheme compresses the 32-layer ResNet (trained on CIFAR-10) and the AlexNet (trained on ImageNet) with compression ratios of $47.1$ and $42.5$, respectively.",11,6.253623188405797,12.545454545454545
354,"['What would be learned by variational autoencoder(VAE) and what influence the disentanglement of VAE?', ""This paper tries to preliminarily address VAE's intrinsic dimension, real factor, disentanglement and indicator issues theoretically in the idealistic situation and implementation issue practically through noise modeling perspective in the realistic case.  "", 'On intrinsic dimension issue, due to information conservation, the idealistic VAE learns and only learns intrinsic factor dimension.', 'Besides, suggested by mutual information separation property, the constraint induced by Gaussian prior to the VAE objective encourages the information sparsity in dimension.', 'On disentanglement issue,   subsequently, inspired by information conservation theorem the clarification on disentanglement in this paper is made.', 'On real factor issue, due to factor equivalence, the idealistic VAE possibly learns any factor set in the equivalence class.  ', 'On indicator issue, the behavior of current disentanglement metric is discussed, and several performance indicators regarding the disentanglement and generating influence are subsequently raised to evaluate the performance of VAE model and to supervise the used factors.', 'On implementation issue, the experiments under noise modeling and constraints empirically testify the theoretical analysis and also show their own characteristic in pursuing disentanglement.']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.1764705777168274, 0.7599999904632568, 0.22857142984867096, 0.1538461446762085, 0.21621620655059814, 0.21052631735801697, 0.1666666567325592, 0.2380952388048172]",SkERSm-0-,"['This paper tries to preliminarily address the disentanglement theoretically in the idealistic situation and practically through noise modelling perspective in the realistic case.', 'Studies the importance of the noise modelling in Gaussian VAE and proposes to train the noise using Empirical-Bayes like fashion.', 'Modifying how noise factors are treated when developing VAE models']","['would learned variational autoencoder  vae  influence disentanglement vae ', 'paper try preliminarily address vae intrinsic dimension  real factor  disentanglement indicator issue theoretically idealistic situation implementation issue practically noise modeling perspective realistic case ', 'intrinsic dimension issue  due information conservation  idealistic vae learns learns intrinsic factor dimension ', 'besides  suggested mutual information separation property  constraint induced gaussian prior vae objective encourages information sparsity dimension ', 'disentanglement issue  subsequently  inspired information conservation theorem clarification disentanglement paper made ', 'real factor issue  due factor equivalence  idealistic vae possibly learns factor set equivalence class ', 'indicator issue  behavior current disentanglement metric discussed  several performance indicator regarding disentanglement generating influence subsequently raised evaluate performance vae model supervise used factor ', 'implementation issue  experiment noise modeling constraint empirically testify theoretical analysis also show characteristic pursuing disentanglement ']","What would be learned by variational autoencoder(VAE) and what influence the disentanglement of VAE?, This paper tries to preliminarily address VAE's intrinsic dimension, real factor, disentanglement and indicator issues theoretically in the idealistic situation and implementation issue practically through noise modeling perspective in the realistic case.  , On intrinsic dimension issue, due to information conservation, the idealistic VAE learns and only learns intrinsic factor dimension., Besides, suggested by mutual information separation property, the constraint induced by Gaussian prior to the VAE objective encourages the information sparsity in dimension., On disentanglement issue,   subsequently, inspired by information conservation theorem the clarification on disentanglement in this paper is made., On real factor issue, due to factor equivalence, the idealistic VAE possibly learns any factor set in the equivalence class.  , On indicator issue, the behavior of current disentanglement metric is discussed, and several performance indicators regarding the disentanglement and generating influence are subsequently raised to evaluate the performance of VAE model and to supervise the used factors., On implementation issue, the experiments under noise modeling and constraints empirically testify the theoretical analysis and also show their own characteristic in pursuing disentanglement.",21,6.435483870967742,8.857142857142858
355,"['Weight decay is one of the standard tricks in the neural network toolbox, but the reasons for its regularization effect are poorly understood, and recent results have cast doubt on the traditional interpretation in terms of $L_2$ regularization.\n', 'Literal weight decay has been shown to outperform $L_2$ regularization for optimizers for which they differ. \n', 'We empirically investigate weight decay for three optimization algorithms (SGD, Adam, and K-FAC) and a variety of network architectures.', 'We identify three distinct mechanisms by which weight decay exerts a regularization effect, depending on the particular optimization algorithm and architecture: (1) increasing the effective learning rate, (2) approximately regularizing the input-output Jacobian norm, and (3) reducing the effective damping coefficient for second-order optimization. \n', 'Our results provide insight into how to improve the regularization of neural networks.']","[0, 0, 0, 1, 0]","[0.1599999964237213, 0.3636363446712494, 0.4000000059604645, 0.4285714328289032, 0.06666666269302368]",B1lz-3Rct7,"['We investigate weight decay regularization for different optimizers and identify three distinct mechanisms by which weight decay improves generalization.', 'Discusses the effect of weight decay on the training of deep network models with and without batch normalization and when using first/second order optimization methods and hypothesizes that a larger learning rate has a regularization effect.']","['weight decay one standard trick neural network toolbox  reason regularization effect poorly understood  recent result cast doubt traditional interpretation term  l2  regularization ', 'literal weight decay shown outperform  l2  regularization optimizers differ ', 'empirically investigate weight decay three optimization algorithm  sgd  adam  kfac  variety network architecture ', 'identify three distinct mechanism weight decay exerts regularization effect  depending particular optimization algorithm architecture   1  increasing effective learning rate   2  approximately regularizing inputoutput jacobian norm   3  reducing effective damping coefficient secondorder optimization ', 'result provide insight improve regularization neural network ']","Weight decay is one of the standard tricks in the neural network toolbox, but the reasons for its regularization effect are poorly understood, and recent results have cast doubt on the traditional interpretation in terms of $L_2$ regularization.
, Literal weight decay has been shown to outperform $L_2$ regularization for optimizers for which they differ. 
, We empirically investigate weight decay for three optimization algorithms (SGD, Adam, and K-FAC) and a variety of network architectures., We identify three distinct mechanisms by which weight decay exerts a regularization effect, depending on the particular optimization algorithm and architecture: (1) increasing the effective learning rate, (2) approximately regularizing the input-output Jacobian norm, and (3) reducing the effective damping coefficient for second-order optimization. 
, Our results provide insight into how to improve the regularization of neural networks.",12,6.092307692307692,10.833333333333334
356,"['In this paper we present the first freely available dataset for the development and evaluation of domain adaptation methods, for the sound event detection task.', 'The dataset contains 40 log mel-band energies extracted from $100$ different synthetic sound event tracks, with additive noise from nine different acoustic scenes (from indoor, outdoor, and vehicle environments), mixed at six different sound-to-noise ratios, SNRs, (from -12 to -27 dB with a step of -3 dB), and totaling to 5400 (9 * 100 * 6) sound files and a total length of 30 564 minutes.', 'We provide the dataset as is, the code to re-create the dataset and remix the sound event tracks and the acoustic scenes with different SNRs, and a baseline method that tests the adaptation performance with the proposed dataset and establishes some first results.']","[1, 0, 0]","[0.5882353186607361, 0.12121211737394333, 0.23255813121795654]",rJeyeVHPjX,['The very first freely available domain adaptation dataset for sound event detection.'],"['paper present first freely available dataset development evaluation domain adaptation method  sound event detection task ', 'dataset contains 40 log melband energy extracted  100  different synthetic sound event track  additive noise nine different acoustic scene  indoor  outdoor  vehicle environment   mixed six different soundtonoise ratio  snrs   12 27 db step 3 db   totaling 5400  9  100  6  sound file total length 30 564 minute ', 'provide dataset  code recreate dataset remix sound event track acoustic scene different snrs  baseline method test adaptation performance proposed dataset establishes first result ']","In this paper we present the first freely available dataset for the development and evaluation of domain adaptation methods, for the sound event detection task., The dataset contains 40 log mel-band energies extracted from $100$ different synthetic sound event tracks, with additive noise from nine different acoustic scenes (from indoor, outdoor, and vehicle environments), mixed at six different sound-to-noise ratios, SNRs, (from -12 to -27 dB with a step of -3 dB), and totaling to 5400 (9 * 100 * 6) sound files and a total length of 30 564 minutes., We provide the dataset as is, the code to re-create the dataset and remix the sound event tracks and the acoustic scenes with different SNRs, and a baseline method that tests the adaptation performance with the proposed dataset and establishes some first results.",13,5.029850746268656,10.307692307692308
357,"['This paper aims to address the limitations of mutual information estimators based on variational optimization.', 'By redefining the cost using generalized functions from nonextensive statistical mechanics we raise the upper bound of previous estimators and enable the control of the bias variance trade off.', 'Variational based estimators outperform previous methods especially in high dependence high dimensional scenarios found in machine learning setups.', 'Despite their performance, these estimators either exhibit a high variance or are upper bounded by log(batch size).', 'Our approach inspired by nonextensive statistical mechanics uses different generalizations for the logarithm and the exponential in the partition function.', 'This enables the estimator to capture changes in mutual information over a wider range of dimensions and correlations of the input variables whereas previous estimators saturate them.']","[0, 0, 0, 0, 1, 0]","[0.1818181723356247, 0.1875, 0.08695651590824127, 0.0, 0.23999999463558197, 0.125]",HJgR5lSFwr,"['Mutual information estimator based nonextensive statistical mechanics', 'This paper tries to establish novel variational lower bounds for mutual information by introducing parameter q and defining q-algebra, showing that the lower bounds have smaller variance and achieves high values.']","['paper aim address limitation mutual information estimator based variational optimization ', 'redefining cost using generalized function nonextensive statistical mechanic raise upper bound previous estimator enable control bias variance trade ', 'variational based estimator outperform previous method especially high dependence high dimensional scenario found machine learning setup ', 'despite performance  estimator either exhibit high variance upper bounded log  batch size  ', 'approach inspired nonextensive statistical mechanic us different generalization logarithm exponential partition function ', 'enables estimator capture change mutual information wider range dimension correlation input variable whereas previous estimator saturate ']","This paper aims to address the limitations of mutual information estimators based on variational optimization., By redefining the cost using generalized functions from nonextensive statistical mechanics we raise the upper bound of previous estimators and enable the control of the bias variance trade off., Variational based estimators outperform previous methods especially in high dependence high dimensional scenarios found in machine learning setups., Despite their performance, these estimators either exhibit a high variance or are upper bounded by log(batch size)., Our approach inspired by nonextensive statistical mechanics uses different generalizations for the logarithm and the exponential in the partition function., This enables the estimator to capture changes in mutual information over a wider range of dimensions and correlations of the input variables whereas previous estimators saturate them.",7,6.2063492063492065,18.0
358,"['Generative adversarial networks (GANs) are a widely used framework for learning generative models.', 'Wasserstein GANs (WGANs), one of the most successful variants of GANs, require solving a minmax problem to global optimality, but in practice, are successfully trained with stochastic gradient descent-ascent.', 'In this paper, we show that, when the generator is a one-layer network, stochastic gradient descent-ascent converges to a global solution in polynomial time and sample complexity.']","[0, 0, 1]","[0.12903225421905518, 0.260869562625885, 0.40909090638160706]",rJePwgSYwB,"['We show that stochastic gradient descent ascent converges to a global optimum for WGAN with one-layer generator network.', 'Attempts to prove that the Stochastic Gradient Decent-Ascent could converge to a global solution for the min-max problem of WGAN.']","['generative adversarial network  gans  widely used framework learning generative model ', 'wasserstein gans  wgans   one successful variant gans  require solving minmax problem global optimality  practice  successfully trained stochastic gradient descentascent ', 'paper  show  generator onelayer network  stochastic gradient descentascent converges global solution polynomial time sample complexity ']","Generative adversarial networks (GANs) are a widely used framework for learning generative models., Wasserstein GANs (WGANs), one of the most successful variants of GANs, require solving a minmax problem to global optimality, but in practice, are successfully trained with stochastic gradient descent-ascent., In this paper, we show that, when the generator is a one-layer network, stochastic gradient descent-ascent converges to a global solution in polynomial time and sample complexity.",10,5.971014492753623,6.9
359,"['Classifiers such as deep neural networks have been shown to be vulnerable against adversarial perturbations on problems with high-dimensional input space.', 'While adversarial training improves the robustness of classifiers against such adversarial perturbations, it leaves classifiers sensitive to them on a non-negligible fraction of the inputs.', 'We argue that there are two different kinds of adversarial perturbations: shared perturbations which fool a classifier on many inputs and singular perturbations which only fool the classifier on a small fraction of the data.', 'We find that adversarial training increases the robustness of classifiers against shared perturbations.', 'Moreover, it is particularly effective in removing universal perturbations, which can be seen as an extreme form of shared perturbations.', 'Unfortunately, adversarial training does not consistently increase the robustness against singular perturbations on unseen inputs.', 'However, we find that adversarial training decreases robustness of the remaining perturbations against image transformations such as changes to contrast and brightness or  Gaussian blurring.', 'It thus makes successful attacks on the classifier in the physical world less likely.', 'Finally, we show that even singular perturbations can be easily detected and must thus exhibit generalizable patterns even though the perturbations are specific for certain inputs.']","[0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.08510638028383255, 0.2978723347187042, 0.18867923319339752, 0.20512820780277252, 0.21739129722118378, 0.09756097197532654, 0.23529411852359772, 0.10256409645080566, 0.1599999964237213]",SyjsLqxR-,"['We empirically show that adversarial training is effective for removing universal perturbations, makes adversarial examples less robust to image transformations, and leaves them detectable for a detection approach.', 'Analyses adversarial training and its effect on universal adversarial examples as well as standard (basic iteration) adversarial examples and how adversarial training affects detection. ', 'The authors show that adversarial training is effective in protecting against ""shared"" adversarial perturbation, in particular against universal perturbation, but less effective to protect against singular perturbations.']","['classifier deep neural network shown vulnerable adversarial perturbation problem highdimensional input space ', 'adversarial training improves robustness classifier adversarial perturbation  leaf classifier sensitive nonnegligible fraction input ', 'argue two different kind adversarial perturbation  shared perturbation fool classifier many input singular perturbation fool classifier small fraction data ', 'find adversarial training increase robustness classifier shared perturbation ', 'moreover  particularly effective removing universal perturbation  seen extreme form shared perturbation ', 'unfortunately  adversarial training consistently increase robustness singular perturbation unseen input ', 'however  find adversarial training decrease robustness remaining perturbation image transformation change contrast brightness gaussian blurring ', 'thus make successful attack classifier physical world le likely ', 'finally  show even singular perturbation easily detected must thus exhibit generalizable pattern even though perturbation specific certain input ']","Classifiers such as deep neural networks have been shown to be vulnerable against adversarial perturbations on problems with high-dimensional input space., While adversarial training improves the robustness of classifiers against such adversarial perturbations, it leaves classifiers sensitive to them on a non-negligible fraction of the inputs., We argue that there are two different kinds of adversarial perturbations: shared perturbations which fool a classifier on many inputs and singular perturbations which only fool the classifier on a small fraction of the data., We find that adversarial training increases the robustness of classifiers against shared perturbations., Moreover, it is particularly effective in removing universal perturbations, which can be seen as an extreme form of shared perturbations., Unfortunately, adversarial training does not consistently increase the robustness against singular perturbations on unseen inputs., However, we find that adversarial training decreases robustness of the remaining perturbations against image transformations such as changes to contrast and brightness or  Gaussian blurring., It thus makes successful attacks on the classifier in the physical world less likely., Finally, we show that even singular perturbations can be easily detected and must thus exhibit generalizable patterns even though the perturbations are specific for certain inputs.",15,6.185567010309279,12.933333333333334
360,"['We address the challenging problem of efficient deep learning model deployment, where the goal is to design neural network architectures that can fit different hardware platform constraints.', 'Most of the traditional approaches either manually design or use Neural Architecture Search (NAS) to find a specialized neural network and train it from scratch for each case, which is computationally expensive and unscalable.', 'Our key idea is to decouple model training from architecture search to save the cost.', 'To this end, we propose to train a once-for-all network (OFA) that supports diverse architectural settings (depth, width, kernel size, and resolution).', 'Given a deployment scenario, we can then quickly get a specialized sub-network by selecting from the OFA network without additional training.', 'To prevent interference between many sub-networks during training, we also propose a novel progressive shrinking algorithm, which can train a surprisingly large number of sub-networks ($> 10^{19}$) simultaneously.', 'Extensive experiments on various hardware platforms (CPU, GPU, mCPU, mGPU, FPGA accelerator) show that OFA consistently outperforms SOTA NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3) while reducing orders of magnitude GPU hours and $CO_2$ emission.', 'In particular, OFA achieves a new SOTA 80.0% ImageNet top1 accuracy under the mobile setting ($<$600M FLOPs).', 'Code and pre-trained models are released at https://github.com/mit-han-lab/once-for-all.']","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.25, 0.1702127605676651, 0.0714285671710968, 0.3333333432674408, 0.11764705181121826, 0.14999999105930328, 0.14814814925193787, 0.0624999962747097, 0.0]",HylxE1HKwS,"['We introduce techniques to train a single once-for-all network that fits many hardware platforms.', 'Method results in a network from which one can extract sub-networks for various resouce constraints (latency, memory) which perform well without a need for retraining.', 'This paper tries to tackle the problem of searching best architectures for specialized resource constraint deployment scenarios with a prediction based NAS method.']","['address challenging problem efficient deep learning model deployment  goal design neural network architecture fit different hardware platform constraint ', 'traditional approach either manually design use neural architecture search  na  find specialized neural network train scratch case  computationally expensive unscalable ', 'key idea decouple model training architecture search save cost ', 'end  propose train onceforall network  ofa  support diverse architectural setting  depth  width  kernel size  resolution  ', 'given deployment scenario  quickly get specialized subnetwork selecting ofa network without additional training ', 'prevent interference many subnetworks training  also propose novel progressive shrinking algorithm  train surprisingly large number subnetworks    10  19    simultaneously ', 'extensive experiment various hardware platform  cpu  gpu  mcpu  mgpu  fpga accelerator  show ofa consistently outperforms sota na method  40  imagenet top1 accuracy improvement mobilenetv3  reducing order magnitude gpu hour  co2  emission ', 'particular  ofa achieves new sota 800  imagenet top1 accuracy mobile setting     600m flop  ', 'code pretrained model released http  githubcommithanlabonceforall ']","We address the challenging problem of efficient deep learning model deployment, where the goal is to design neural network architectures that can fit different hardware platform constraints., Most of the traditional approaches either manually design or use Neural Architecture Search (NAS) to find a specialized neural network and train it from scratch for each case, which is computationally expensive and unscalable., Our key idea is to decouple model training from architecture search to save the cost., To this end, we propose to train a once-for-all network (OFA) that supports diverse architectural settings (depth, width, kernel size, and resolution)., Given a deployment scenario, we can then quickly get a specialized sub-network by selecting from the OFA network without additional training., To prevent interference between many sub-networks during training, we also propose a novel progressive shrinking algorithm, which can train a surprisingly large number of sub-networks ($> 10^{19}$) simultaneously., Extensive experiments on various hardware platforms (CPU, GPU, mCPU, mGPU, FPGA accelerator) show that OFA consistently outperforms SOTA NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3) while reducing orders of magnitude GPU hours and $CO_2$ emission., In particular, OFA achieves a new SOTA 80.0% ImageNet top1 accuracy under the mobile setting ($<$600M FLOPs)., Code and pre-trained models are released at https://github.com/mit-han-lab/once-for-all.",23,6.0,9.173913043478262
361,"['A deep generative model is a powerful method of learning a data distribution, which has achieved tremendous success in numerous scenarios.', 'However, it is nontrivial for a single generative model to faithfully capture the distributions of the complex data such as images with complicate structures.', 'In this paper, we propose a novel approach of cascaded boosting for boosting generative models, where meta-models (i.e., weak learners) are cascaded together to produce a stronger model.', 'Any hidden variable meta-model can be leveraged as long as it can support the likelihood evaluation.', 'We derive a decomposable variational lower bound of the boosted model, which allows each meta-model to be trained separately and greedily.', 'We can further improve the learning power of the generative models by combing our cascaded boosting framework with the multiplicative boosting framework.']","[0, 0, 0, 0, 0, 1]","[0.06451612710952759, 0.11764705181121826, 0.21052631735801697, 0.1599999964237213, 0.0, 0.27586206793785095]",Hke2Rh4Kvr,"['Propose an approach for boosting generative models by cascading hidden variable models', 'This paper proposed a novel approach of cascaded boosting for boosting generative models which allows each each meta-model to be trained separately and greedily.']","['deep generative model powerful method learning data distribution  achieved tremendous success numerous scenario ', 'however  nontrivial single generative model faithfully capture distribution complex data image complicate structure ', 'paper  propose novel approach cascaded boosting boosting generative model  metamodels  ie  weak learner  cascaded together produce stronger model ', 'hidden variable metamodel leveraged long support likelihood evaluation ', 'derive decomposable variational lower bound boosted model  allows metamodel trained separately greedily ', 'improve learning power generative model combing cascaded boosting framework multiplicative boosting framework ']","A deep generative model is a powerful method of learning a data distribution, which has achieved tremendous success in numerous scenarios., However, it is nontrivial for a single generative model to faithfully capture the distributions of the complex data such as images with complicate structures., In this paper, we propose a novel approach of cascaded boosting for boosting generative models, where meta-models (i.e., weak learners) are cascaded together to produce a stronger model., Any hidden variable meta-model can be leveraged as long as it can support the likelihood evaluation., We derive a decomposable variational lower bound of the boosted model, which allows each meta-model to be trained separately and greedily., We can further improve the learning power of the generative models by combing our cascaded boosting framework with the multiplicative boosting framework.",12,5.613636363636363,11.0
362,"['Contextualized representation models such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks.', 'Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline.', 'We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena.', 'We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.']","[0, 0, 0, 1]","[0.20689654350280762, 0.14035087823867798, 0.3636363446712494, 0.47457626461982727]",SJzSgnRcKX,"['We probe for sentence structure in ELMo and related contextual embedding models. We find existing models efficiently encode syntax and show evidence of long-range dependencies, but only offer small improvements on semantic tasks.', 'Proposes the ""edge probing"" method and focuses on the relationship between spans rather than individual words, enabling the authors to look at syntactic constituency, dependencies, entity labels, and semantic role labeling.', 'Provides new insights on what is captured contextualized word embeddings by compiling a set of edge probing tasks. ']","['contextualized representation model elmo  peter et al  2018a  bert  devlin et al  2018  recently achieved stateoftheart result diverse array downstream nlp task ', 'building recent tokenlevel probing work  introduce novel edge probing task design construct broad suite subsentence task derived traditional structured nlp pipeline ', 'probe wordlevel contextual representation four recent model investigate encode sentence structure across range syntactic  semantic  local  longrange phenomenon ', 'find existing model trained language modeling translation produce strong representation syntactic phenomenon  offer comparably small improvement semantic task noncontextual baseline ']","Contextualized representation models such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks., Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline., We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena., We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.",11,6.043859649122807,10.363636363636363
363,"['Deep reinforcement learning has succeeded in sophisticated games such as Atari, Go, etc.', 'Real-world decision making, however, often requires reasoning with partial information extracted from complex visual observations.', 'This paper presents  Discriminative Particle Filter Reinforcement Learning (DPFRL), a new reinforcement learning framework for partial and complex observations.', 'DPFRL encodes a differentiable particle filter with learned transition and observation models in a neural network, which allows for reasoning with partial observations over multiple time steps.', 'While a standard particle filter relies on a generative observation model, DPFRL learns a discriminatively parameterized model that is training directly for decision making.', 'We show that the discriminative parameterization results in significantly improved performance, especially for tasks with complex visual observations, because it circumvents the difficulty of modelling observations explicitly.', 'In most cases, DPFRL outperforms state-of-the-art POMDP RL models in Flickering Atari Games, an existing POMDP RL benchmark, and in Natural Flickering Atari Games, a new, more challenging POMDP RL benchmark that we introduce.', 'We further show that DPFRL performs well for visual navigation with real-world data.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.1249999925494194, 0.23529411852359772, 0.4736841917037964, 0.40909090638160706, 0.19512194395065308, 0.2666666507720947, 0.13333332538604736, 0.1875]",HJl8_eHYvS,"['We introduce DPFRL, a framework for reinforcement learning under partial and complex observations with a fully differentiable discriminative particle filter', 'Introduces ideas for training DLR agents with latent state variables, modeled as a belief distribution, so they can handle partially observed environments.', 'This paper introduces a principled method for POMDP RL: Discriminative Particle Filter Reinforcement Learning that allows for reasoning with partial observations over multiple time steps, achieving state-of-the-art on benchmarks.']","['deep reinforcement learning succeeded sophisticated game atari  go  etc ', 'realworld decision making  however  often requires reasoning partial information extracted complex visual observation ', 'paper present discriminative particle filter reinforcement learning  dpfrl   new reinforcement learning framework partial complex observation ', 'dpfrl encodes differentiable particle filter learned transition observation model neural network  allows reasoning partial observation multiple time step ', 'standard particle filter relies generative observation model  dpfrl learns discriminatively parameterized model training directly decision making ', 'show discriminative parameterization result significantly improved performance  especially task complex visual observation  circumvents difficulty modelling observation explicitly ', 'case  dpfrl outperforms stateoftheart pomdp rl model flickering atari game  existing pomdp rl benchmark  natural flickering atari game  new  challenging pomdp rl benchmark introduce ', 'show dpfrl performs well visual navigation realworld data ']","Deep reinforcement learning has succeeded in sophisticated games such as Atari, Go, etc., Real-world decision making, however, often requires reasoning with partial information extracted from complex visual observations., This paper presents  Discriminative Particle Filter Reinforcement Learning (DPFRL), a new reinforcement learning framework for partial and complex observations., DPFRL encodes a differentiable particle filter with learned transition and observation models in a neural network, which allows for reasoning with partial observations over multiple time steps., While a standard particle filter relies on a generative observation model, DPFRL learns a discriminatively parameterized model that is training directly for decision making., We show that the discriminative parameterization results in significantly improved performance, especially for tasks with complex visual observations, because it circumvents the difficulty of modelling observations explicitly., In most cases, DPFRL outperforms state-of-the-art POMDP RL models in Flickering Atari Games, an existing POMDP RL benchmark, and in Natural Flickering Atari Games, a new, more challenging POMDP RL benchmark that we introduce., We further show that DPFRL performs well for visual navigation with real-world data.",22,6.395348837209302,7.818181818181818
364,"['Extending models with auxiliary latent variables is a well-known technique to in-crease model expressivity.', 'Bachman & Precup (2015); Naesseth et al. (2018); Cremer et al. (2017); Domke & Sheldon (2018) show that Importance Weighted Autoencoders (IWAE) (Burda et al., 2015) can be viewed as extending the variational family with auxiliary latent variables.', 'Similarly, we show that this view encompasses many of the recent developments in variational bounds (Maddisonet al., 2017; Naesseth et al., 2018; Le et al., 2017; Yin & Zhou, 2018; Molchanovet al., 2018; Sobolev & Vetrov, 2018).', 'The success of enriching the variational family with auxiliary latent variables motivates applying the same techniques to the generative model.', 'We develop a generative model analogous to the IWAE bound and empirically show that it outperforms the recently proposed Learned Accept/Reject Sampling algorithm (Bauer & Mnih, 2018), while being substantially easier to implement.', 'Furthermore, we show that this generative process provides new insights on ranking Noise Contrastive Estimation (Jozefowicz et al.,2016; Ma & Collins, 2018) and Contrastive Predictive Coding (Oord et al., 2018).']","[0, 0, 0, 1, 0, 0]","[0.1666666567325592, 0.1071428507566452, 0.07692307233810425, 0.25, 0.15094339847564697, 0.11999999731779099]",SyxPVLUYdE,"['Monte Carlo Objectives are analyzed using auxiliary variable variational inference, yielding a new analysis of CPC and NCE as well as a new generative model.', 'Proposes a different view on improving variational bounds with auxiliary latent variable models and explores the use of those models in the generative model.']","['extending model auxiliary latent variable wellknown technique increase model expressivity ', 'bachman  precup  2015   naesseth et al   2018   cremer et al   2017   domke  sheldon  2018  show importance weighted autoencoders  iwae   burda et al  2015  viewed extending variational family auxiliary latent variable ', 'similarly  show view encompasses many recent development variational bound  maddisonet al  2017  naesseth et al  2018  le et al  2017  yin  zhou  2018  molchanovet al  2018  sobolev  vetrov  2018  ', 'success enriching variational family auxiliary latent variable motivates applying technique generative model ', 'develop generative model analogous iwae bound empirically show outperforms recently proposed learned acceptreject sampling algorithm  bauer  mnih  2018   substantially easier implement ', 'furthermore  show generative process provides new insight ranking noise contrastive estimation  jozefowicz et al2016   collins  2018  contrastive predictive coding  oord et al  2018  ']","Extending models with auxiliary latent variables is a well-known technique to in-crease model expressivity., Bachman & Precup (2015); Naesseth et al. (2018); Cremer et al. (2017); Domke & Sheldon (2018) show that Importance Weighted Autoencoders (IWAE) (Burda et al., 2015) can be viewed as extending the variational family with auxiliary latent variables., Similarly, we show that this view encompasses many of the recent developments in variational bounds (Maddisonet al., 2017; Naesseth et al., 2018; Le et al., 2017; Yin & Zhou, 2018; Molchanovet al., 2018; Sobolev & Vetrov, 2018)., The success of enriching the variational family with auxiliary latent variables motivates applying the same techniques to the generative model., We develop a generative model analogous to the IWAE bound and empirically show that it outperforms the recently proposed Learned Accept/Reject Sampling algorithm (Bauer & Mnih, 2018), while being substantially easier to implement., Furthermore, we show that this generative process provides new insights on ranking Noise Contrastive Estimation (Jozefowicz et al.,2016; Ma & Collins, 2018) and Contrastive Predictive Coding (Oord et al., 2018).",19,5.738372093023256,8.19047619047619
365,"['Stochastic Gradient Descent or SGD is the most popular optimization algorithm for large-scale problems.', 'SGD estimates the gradient by uniform sampling with sample size one.', 'There have been several other works that suggest faster epoch wise convergence by using weighted non-uniform sampling for better gradient estimates.', 'Unfortunately, the per-iteration cost of maintaining this adaptive distribution for gradient estimation is more than calculating the full gradient.', 'As a result, the false impression of faster convergence in iterations leads to slower convergence in time, which we call a chicken-and-egg loop.', 'In this paper, we break this barrier by providing the first demonstration of a sampling scheme, which leads to superior gradient estimation, while keeping the sampling cost per iteration similar to that of the uniform sampling.', 'Such an algorithm is possible due to the sampling view of Locality Sensitive Hashing (LSH), which came to light recently.', 'As a consequence of superior and fast estimation, we reduce the running time of all existing gradient descent algorithms.', 'We demonstrate the benefits of our proposal on both SGD and AdaGrad.']","[0, 0, 0, 0, 0, 0, 0, 1, 0]","[0.0833333283662796, 0.1904761791229248, 0.06451612710952759, 0.2222222238779068, 0.13333332538604736, 0.1538461446762085, 0.13793103396892548, 0.5714285373687744, 0.27272728085517883]",SyVOjfbRb,"['We improve the running of all existing gradient descent algorithms.', 'Authors propose sampling stochastic gradients from a monotonic function proportional to gradient magnitudes by using LSH. ', 'Considers SGD over an objective of the form of a sum over examples of a quadratic loss.']","['stochastic gradient descent sgd popular optimization algorithm largescale problem ', 'sgd estimate gradient uniform sampling sample size one ', 'several work suggest faster epoch wise convergence using weighted nonuniform sampling better gradient estimate ', 'unfortunately  periteration cost maintaining adaptive distribution gradient estimation calculating full gradient ', 'result  false impression faster convergence iteration lead slower convergence time  call chickenandegg loop ', 'paper  break barrier providing first demonstration sampling scheme  lead superior gradient estimation  keeping sampling cost per iteration similar uniform sampling ', 'algorithm possible due sampling view locality sensitive hashing  lsh   came light recently ', 'consequence superior fast estimation  reduce running time existing gradient descent algorithm ', 'demonstrate benefit proposal sgd adagrad ']","Stochastic Gradient Descent or SGD is the most popular optimization algorithm for large-scale problems., SGD estimates the gradient by uniform sampling with sample size one., There have been several other works that suggest faster epoch wise convergence by using weighted non-uniform sampling for better gradient estimates., Unfortunately, the per-iteration cost of maintaining this adaptive distribution for gradient estimation is more than calculating the full gradient., As a result, the false impression of faster convergence in iterations leads to slower convergence in time, which we call a chicken-and-egg loop., In this paper, we break this barrier by providing the first demonstration of a sampling scheme, which leads to superior gradient estimation, while keeping the sampling cost per iteration similar to that of the uniform sampling., Such an algorithm is possible due to the sampling view of Locality Sensitive Hashing (LSH), which came to light recently., As a consequence of superior and fast estimation, we reduce the running time of all existing gradient descent algorithms., We demonstrate the benefits of our proposal on both SGD and AdaGrad.",17,5.56,10.294117647058824
366,"['In recent years we have made significant progress identifying computational principles that underlie neural function.', 'While not yet complete, we have sufficient evidence that a synthesis of these ideas could result in an understanding of how neural computation emerges from a combination of innate dynamics and plasticity, and which could potentially be used to construct new AI technologies with unique capabilities.', 'I discuss the relevant principles, the advantages they have for computation, and how they can benefit AI.', 'Limitations of current AI are generally recognized, but fewer people are aware that we understand enough about the brain to immediately offer novel AI formulations.\n']","[0, 0, 0, 1]","[0.10526315122842789, 0.15625, 0.10526315122842789, 0.978723406791687]",ryGcXQK8LS,"['Limitations of current AI are generally recognized, but fewer people are aware that we understand enough about the brain to immediately offer novel AI formulations.']","['recent year made significant progress identifying computational principle underlie neural function ', 'yet complete  sufficient evidence synthesis idea could result understanding neural computation emerges combination innate dynamic plasticity  could potentially used construct new ai technology unique capability ', 'discus relevant principle  advantage computation  benefit ai ', 'limitation current ai generally recognized  fewer people aware understand enough brain immediately offer novel ai formulation ']","In recent years we have made significant progress identifying computational principles that underlie neural function., While not yet complete, we have sufficient evidence that a synthesis of these ideas could result in an understanding of how neural computation emerges from a combination of innate dynamics and plasticity, and which could potentially be used to construct new AI technologies with unique capabilities., I discuss the relevant principles, the advantages they have for computation, and how they can benefit AI., Limitations of current AI are generally recognized, but fewer people are aware that we understand enough about the brain to immediately offer novel AI formulations.
",9,5.640776699029126,11.444444444444445
367,"['Recent work has demonstrated how predictive modeling can endow agents with rich knowledge of their surroundings, improving their ability to act in complex environments.', 'We propose question-answering as a general paradigm to decode and understand the representations that such agents develop, applying our method to two recent approaches to predictive modeling  action-conditional CPC (Guo et al., 2018) and SimCore (Gregor et al., 2019).', 'After training agents with these predictive objectives in a visually-rich, 3D environment with an assortment of objects, colors, shapes, and spatial configurations, we probe their internal state representations with a host of synthetic (English) questions, without backpropagating gradients from the question-answering decoder into the agent.', 'The performance of different agents when probed in this way reveals that they learn to encode detailed, and seemingly compositional, information about objects, properties and spatial relations from their physical environment.', 'Our approach is intuitive, i.e. humans can easily interpret the responses of the model as opposed to inspecting continuous vectors, and model-agnostic, i.e. applicable to any modeling approach.', 'By revealing the implicit knowledge of objects, quantities, properties and relations acquired by agents as they learn, question-conditional agent probing can stimulate the design and development of stronger predictive learning objectives.']","[1, 0, 0, 0, 0, 0]","[0.25, 0.18867924809455872, 0.14035087823867798, 0.21276594698429108, 0.1428571343421936, 0.2222222238779068]",Bylh2krYPr,"['We use question-answering to evaluate how much knowledge about the environment can agents learn by self-supervised prediction.', 'Proposes QA as a tool to investigate what agents learn about in the world, arguing this as an intuitive method for humans which allows for arbitrary complexity.', 'The authors propose a framework to assess representations built by predictive models that contain sufficient information to answer questions about the environment they are trained on, showing those by SimCore contained sufficient information for the LSTM to answer questions accurately.']","['recent work demonstrated predictive modeling endow agent rich knowledge surroundings  improving ability act complex environment ', 'propose questionanswering general paradigm decode understand representation agent develop  applying method two recent approach predictive modeling  actionconditional cpc  guo et al  2018  simcore  gregor et al  2019  ', 'training agent predictive objective visuallyrich  3d environment assortment object  color  shape  spatial configuration  probe internal state representation host synthetic  english  question  without backpropagating gradient questionanswering decoder agent ', 'performance different agent probed way reveals learn encode detailed  seemingly compositional  information object  property spatial relation physical environment ', 'approach intuitive  ie  human easily interpret response model opposed inspecting continuous vector  modelagnostic  ie  applicable modeling approach ', 'revealing implicit knowledge object  quantity  property relation acquired agent learn  questionconditional agent probing stimulate design development stronger predictive learning objective ']","Recent work has demonstrated how predictive modeling can endow agents with rich knowledge of their surroundings, improving their ability to act in complex environments., We propose question-answering as a general paradigm to decode and understand the representations that such agents develop, applying our method to two recent approaches to predictive modeling  action-conditional CPC (Guo et al., 2018) and SimCore (Gregor et al., 2019)., After training agents with these predictive objectives in a visually-rich, 3D environment with an assortment of objects, colors, shapes, and spatial configurations, we probe their internal state representations with a host of synthetic (English) questions, without backpropagating gradients from the question-answering decoder into the agent., The performance of different agents when probed in this way reveals that they learn to encode detailed, and seemingly compositional, information about objects, properties and spatial relations from their physical environment., Our approach is intuitive, i.e. humans can easily interpret the responses of the model as opposed to inspecting continuous vectors, and model-agnostic, i.e. applicable to any modeling approach., By revealing the implicit knowledge of objects, quantities, properties and relations acquired by agents as they learn, question-conditional agent probing can stimulate the design and development of stronger predictive learning objectives.",25,6.1457286432160805,7.37037037037037
368,"['In most real-world scenarios, training datasets are highly class-imbalanced, where deep neural networks suffer from generalizing to a balanced testing criterion.', 'In this paper, we explore a novel yet simple way to alleviate this issue via synthesizing less-frequent classes with adversarial examples of other classes.', 'Surprisingly, we found this counter-intuitive method can effectively learn generalizable features of minority classes by transferring and leveraging the diversity of the majority information.', 'Our experimental results on various types of class-imbalanced datasets in image classification and natural language processing show that the proposed method not only improves the generalization of minority classes significantly compared to other re-sampling or re-weighting methods, but also surpasses other methods of state-of-art level for the class-imbalanced classification.']","[0, 1, 0, 0]","[0.0624999962747097, 0.1818181723356247, 0.060606054961681366, 0.11320754140615463]",HJxaC1rKDS,"['We develop a new method for imbalanced classification using adversarial examples', 'Proposes a new optimization objective that generates synthetic samples by over-sampling the majority classes instead of minority classes, solving the problem of overfitting minority classes.', 'The authors propose to tackle imbalance classification using re-sampling methods, showing that adversarial examples in the minority class would help to train a new model that generalizes better.']","['realworld scenario  training datasets highly classimbalanced  deep neural network suffer generalizing balanced testing criterion ', 'paper  explore novel yet simple way alleviate issue via synthesizing lessfrequent class adversarial example class ', 'surprisingly  found counterintuitive method effectively learn generalizable feature minority class transferring leveraging diversity majority information ', 'experimental result various type classimbalanced datasets image classification natural language processing show proposed method improves generalization minority class significantly compared resampling reweighting method  also surpasses method stateofart level classimbalanced classification ']","In most real-world scenarios, training datasets are highly class-imbalanced, where deep neural networks suffer from generalizing to a balanced testing criterion., In this paper, we explore a novel yet simple way to alleviate this issue via synthesizing less-frequent classes with adversarial examples of other classes., Surprisingly, we found this counter-intuitive method can effectively learn generalizable features of minority classes by transferring and leveraging the diversity of the majority information., Our experimental results on various types of class-imbalanced datasets in image classification and natural language processing show that the proposed method not only improves the generalization of minority classes significantly compared to other re-sampling or re-weighting methods, but also surpasses other methods of state-of-art level for the class-imbalanced classification.",9,6.491525423728813,13.11111111111111
369,"['Active matter consists of active agents which transform energy extracted from surroundings into momentum, producing a variety of collective phenomena.', 'A model, synthetic active system composed of microtubule polymers driven by protein motors spontaneously forms a liquid-crystalline nematic phase.', 'Extensile stress created by the protein motors precipitates continuous buckling and folding of the microtubules creating motile topological defects and turbulent fluid flows.', 'Defect motion is determined by the rheological properties of the material; however, these remain largely unquantified.', 'Measuring defects dynamics can yield fundamental insights into active nematics, a class of materials that include bacterial films and animal cells.', 'Current methods for defect detection lack robustness and precision, and require fine-tuning for datasets with different visual quality.  ', 'In this study, we applied Deep Learning to train a defect detector to automatically analyze microscopy videos of the microtubule active nematic.  ', 'Experimental results indicate that our method is robust and accurate.', 'It is expected to significantly increase the amount of video data that can be processed.']","[1, 0, 0, 0, 0, 0, 0, 0, 0]","[0.13333332538604736, 0.06666666269302368, 0.0624999962747097, 0.07692307233810425, 0.0624999962747097, 0.0, 0.060606054961681366, 0.0, 0.07692307233810425]",HklVTi09tm,"['An interesting application of CNN in soft condensed matter physics experiments.', 'The authors demonstrate that a deep learning approach offers improvement to both the identification accuracy and rate at which defects can be identified of nematic liquid crystals.', 'Apply a well known neural model (YOLO) to detect bounding boxes of objects in images.']","['active matter consists active agent transform energy extracted surroundings momentum  producing variety collective phenomenon ', 'model  synthetic active system composed microtubule polymer driven protein motor spontaneously form liquidcrystalline nematic phase ', 'extensile stress created protein motor precipitate continuous buckling folding microtubule creating motile topological defect turbulent fluid flow ', 'defect motion determined rheological property material  however  remain largely unquantified ', 'measuring defect dynamic yield fundamental insight active nematics  class material include bacterial film animal cell ', 'current method defect detection lack robustness precision  require finetuning datasets different visual quality ', 'study  applied deep learning train defect detector automatically analyze microscopy video microtubule active nematic ', 'experimental result indicate method robust accurate ', 'expected significantly increase amount video data processed ']","Active matter consists of active agents which transform energy extracted from surroundings into momentum, producing a variety of collective phenomena., A model, synthetic active system composed of microtubule polymers driven by protein motors spontaneously forms a liquid-crystalline nematic phase., Extensile stress created by the protein motors precipitates continuous buckling and folding of the microtubules creating motile topological defects and turbulent fluid flows., Defect motion is determined by the rheological properties of the material; however, these remain largely unquantified., Measuring defects dynamics can yield fundamental insights into active nematics, a class of materials that include bacterial films and animal cells., Current methods for defect detection lack robustness and precision, and require fine-tuning for datasets with different visual quality.  , In this study, we applied Deep Learning to train a defect detector to automatically analyze microscopy videos of the microtubule active nematic.  , Experimental results indicate that our method is robust and accurate., It is expected to significantly increase the amount of video data that can be processed.",15,6.158536585365853,10.933333333333334
370,"['In this work we study locality and compositionality in the context of learning representations for Zero Shot Learning (ZSL). \n', 'In order to well-isolate the importance of these properties in learned representations, we impose the additional constraint that, differently from most recent work in ZSL, no pre-training on different datasets (e.g. ImageNet) is performed.\n', 'The results of our experiment show how locality, in terms of small parts of the input, and compositionality, i.e. how well can the learned representations be expressed as a function of a smaller vocabulary, are both deeply related to generalization and motivate the focus on more local-aware models in future research directions for representation learning.']","[1, 0, 0]","[0.42424240708351135, 0.12765957415103912, 0.23333333432674408]",Hye_V0NKwr,"['An analysis of the effects of compositionality and locality on representation learning for zero-shot learning.', ""Proposes evaluation framework for ZSL where the model is not allowed to be pretrained and instead, model parameters are randomly initialized for better understanding of what's happening in ZSL.""]","['work study locality compositionality context learning representation zero shot learning  zsl  ', 'order wellisolate importance property learned representation  impose additional constraint  differently recent work zsl  pretraining different datasets  eg  imagenet  performed ', 'result experiment show locality  term small part input  compositionality  ie  well learned representation expressed function smaller vocabulary  deeply related generalization motivate focus localaware model future research direction representation learning ']","In this work we study locality and compositionality in the context of learning representations for Zero Shot Learning (ZSL). 
, In order to well-isolate the importance of these properties in learned representations, we impose the additional constraint that, differently from most recent work in ZSL, no pre-training on different datasets (e.g. ImageNet) is performed.
, The results of our experiment show how locality, in terms of small parts of the input, and compositionality, i.e. how well can the learned representations be expressed as a function of a smaller vocabulary, are both deeply related to generalization and motivate the focus on more local-aware models in future research directions for representation learning.",10,5.62962962962963,9.0
371,"['It is becoming increasingly clear that many machine learning classifiers are vulnerable to adversarial examples.', 'In attempting to explain the origin of adversarial examples, previous studies have typically focused on the fact that neural networks operate on high dimensional data, they overfit, or they are too linear.', 'Here we show that distributions of logit differences have a universal functional form.', 'This functional form is independent of architecture, dataset, and training protocol; nor does it change during training.', 'This leads to adversarial error having a universal scaling, as a power-law, with respect to the size of the adversarial perturbation.', 'We show that this universality holds for a broad range of datasets (MNIST, CIFAR10, ImageNet, and random data), models (including state-of-the-art deep networks, linear models, adversarially trained networks, and networks trained on randomly shuffled labels), and attacks (FGSM, step l.l., PGD).', 'Motivated by these results, we study the effects of reducing prediction entropy on adversarial robustness.', 'Finally, we study the effect of network architectures on adversarial sensitivity.', 'To do this, we use neural architecture search with reinforcement learning to find adversarially robust architectures on CIFAR10.', 'Our resulting architecture is more robust to white \\emph{and} black box attacks compared to previous attempts.\n']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.0, 0.0, 0.07407406717538834, 0.13333332538604736, 0.06451612710952759, 0.1538461446762085, 0.0, 0.0, 0.0624999962747097, 0.06666666269302368]",rk6H0ZbRb,"['Adversarial error has similar power-law form for all datasets and models studied, and architecture matters.']","['becoming increasingly clear many machine learning classifier vulnerable adversarial example ', 'attempting explain origin adversarial example  previous study typically focused fact neural network operate high dimensional data  overfit  linear ', 'show distribution logit difference universal functional form ', 'functional form independent architecture  dataset  training protocol  change training ', 'lead adversarial error universal scaling  powerlaw  respect size adversarial perturbation ', 'show universality hold broad range datasets  mnist  cifar10  imagenet  random data   model  including stateoftheart deep network  linear model  adversarially trained network  network trained randomly shuffled label   attack  fgsm  step  pgd  ', 'motivated result  study effect reducing prediction entropy adversarial robustness ', 'finally  study effect network architecture adversarial sensitivity ', ' use neural architecture search reinforcement learning find adversarially robust architecture cifar10 ', 'resulting architecture robust white emph   black box attack compared previous attempt ']","It is becoming increasingly clear that many machine learning classifiers are vulnerable to adversarial examples., In attempting to explain the origin of adversarial examples, previous studies have typically focused on the fact that neural networks operate on high dimensional data, they overfit, or they are too linear., Here we show that distributions of logit differences have a universal functional form., This functional form is independent of architecture, dataset, and training protocol; nor does it change during training., This leads to adversarial error having a universal scaling, as a power-law, with respect to the size of the adversarial perturbation., We show that this universality holds for a broad range of datasets (MNIST, CIFAR10, ImageNet, and random data), models (including state-of-the-art deep networks, linear models, adversarially trained networks, and networks trained on randomly shuffled labels), and attacks (FGSM, step l.l., PGD)., Motivated by these results, we study the effects of reducing prediction entropy on adversarial robustness., Finally, we study the effect of network architectures on adversarial sensitivity., To do this, we use neural architecture search with reinforcement learning to find adversarially robust architectures on CIFAR10., Our resulting architecture is more robust to white \emph{and} black box attacks compared to previous attempts.
",30,5.864321608040201,6.633333333333334
372,"['    Reinforcement learning (RL) has led to increasingly complex looking behavior in recent years.', 'However, such complexity can be misleading and hides over-fitting.', 'We find that visual representations may be a useful metric of complexity, and both correlates well objective optimization and causally effects reward optimization.', 'We then propose curious representation learning (CRL) which allows us to use better visual representation learning algorithms to correspondingly increase visual representation in policy through an intrinsic objective on both simulated environments and transfer to real images.', 'Finally, we show better visual representations induced by CRL allows us to obtain better performance on Atari without any reward than other curiosity objectives.']","[0, 0, 1, 0, 0]","[0.12121211737394333, 0.06896550953388214, 0.3414634168148041, 0.2745097875595093, 0.23255813121795654]",HkgYEyrFDr,"['We present a formulation of curiosity as a visual representation learning problem and show that it allows good visual representations in agents.', 'This paper formulates curiosity based RL training as learning a visual representation model, arguing that focusing on better LR and maximising model loss for novel scenes will get better overall performance.']","['reinforcement learning  rl  led increasingly complex looking behavior recent year ', 'however  complexity misleading hide overfitting ', 'find visual representation may useful metric complexity  correlate well objective optimization causally effect reward optimization ', 'propose curious representation learning  crl  allows u use better visual representation learning algorithm correspondingly increase visual representation policy intrinsic objective simulated environment transfer real image ', 'finally  show better visual representation induced crl allows u obtain better performance atari without reward curiosity objective ']","    Reinforcement learning (RL) has led to increasingly complex looking behavior in recent years., However, such complexity can be misleading and hides over-fitting., We find that visual representations may be a useful metric of complexity, and both correlates well objective optimization and causally effects reward optimization., We then propose curious representation learning (CRL) which allows us to use better visual representation learning algorithms to correspondingly increase visual representation in policy through an intrinsic objective on both simulated environments and transfer to real images., Finally, we show better visual representations induced by CRL allows us to obtain better performance on Atari without any reward than other curiosity objectives.",8,6.179245283018868,13.25
373,"['This paper introduces the task of semantic instance completion: from an incomplete RGB-D scan of a scene, we aim to detect the individual object instances comprising the scene and infer their complete object geometry.', 'This enables a semantically meaningful decomposition of a scanned scene into individual, complete 3D objects, including hidden and unobserved object parts.', 'This will open up new possibilities for interactions with object in a scene, for instance for virtual or robotic agents.', 'To address this task, we propose 3D-SIC, a new data-driven approach that jointly detects object instances and predicts their completed geometry.', 'The core idea of 3D-SIC is a novel end-to-end 3D neural network architecture that leverages joint color and geometry feature learning.', 'The fully-convolutional nature of our 3D network enables efficient inference of semantic instance completion for 3D scans at scale of large indoor environments in a single forward pass.', 'In a series evaluation, we evaluate on both real and synthetic scan benchmark data, where we outperform state-of-the-art approaches by over 15 in mAP@0.5 on ScanNet, and over 18 in mAP@0.5 on SUNCG.']","[1, 0, 0, 0, 0, 0, 0]","[0.8301886916160583, 0.2790697515010834, 0.1463414579629898, 0.3181818127632141, 0.1818181723356247, 0.0833333283662796, 0.1599999964237213]",SJxjanVKDH,"['From an incomplete RGB-D scan of a scene, we aim to detect the individual object instances comprising the scene and infer their complete object geometry.', 'Proposes an end-to-end 3D CNN structure which combines color features and 3D features to predict the missing 3D structure of a scene from RGB-D scans.', 'The authors propose a novel end-to-end 3D convolutional network which predicts 3D semantic instance completion as object bounding boxes, class labels and complete object geometry.']","['paper introduces task semantic instance completion  incomplete rgbd scan scene  aim detect individual object instance comprising scene infer complete object geometry ', 'enables semantically meaningful decomposition scanned scene individual  complete 3d object  including hidden unobserved object part ', 'open new possibility interaction object scene  instance virtual robotic agent ', 'address task  propose 3dsic  new datadriven approach jointly detects object instance predicts completed geometry ', 'core idea 3dsic novel endtoend 3d neural network architecture leverage joint color geometry feature learning ', 'fullyconvolutional nature 3d network enables efficient inference semantic instance completion 3d scan scale large indoor environment single forward pas ', 'series evaluation  evaluate real synthetic scan benchmark data  outperform stateoftheart approach 15 map  05 scannet  18 map  05 suncg ']","This paper introduces the task of semantic instance completion: from an incomplete RGB-D scan of a scene, we aim to detect the individual object instances comprising the scene and infer their complete object geometry., This enables a semantically meaningful decomposition of a scanned scene into individual, complete 3D objects, including hidden and unobserved object parts., This will open up new possibilities for interactions with object in a scene, for instance for virtual or robotic agents., To address this task, we propose 3D-SIC, a new data-driven approach that jointly detects object instances and predicts their completed geometry., The core idea of 3D-SIC is a novel end-to-end 3D neural network architecture that leverages joint color and geometry feature learning., The fully-convolutional nature of our 3D network enables efficient inference of semantic instance completion for 3D scans at scale of large indoor environments in a single forward pass., In a series evaluation, we evaluate on both real and synthetic scan benchmark data, where we outperform state-of-the-art approaches by over 15 in mAP@0.5 on ScanNet, and over 18 in mAP@0.5 on SUNCG.",16,5.466292134831461,11.125
374,"['Style transfer usually refers to the task of applying color and texture information from a specific style image to a given content image while preserving the structure of the latter.', 'Here we tackle the more generic problem of semantic style transfer: given two unpaired collections of images, we aim to learn a mapping between the corpus-level style of each collection, while preserving semantic content shared across the two domains.', 'We introduce XGAN (""Cross-GAN""), a dual adversarial autoencoder, which captures a shared representation of the common domain semantic content in an unsupervised way, while jointly learning the domain-to-domain image translations in both directions.  ', 'We exploit ideas from the domain adaptation literature and define a semantic consistency loss which encourages the model to preserve semantics in the learned embedding space.', 'We report promising qualitative results for the task of face-to-cartoon translation.', 'The cartoon dataset we collected for this purpose will also be released as a new benchmark for semantic style transfer.']","[0, 0, 0, 0, 0, 1]","[0.19999998807907104, 0.21052631735801697, 0.28070175647735596, 0.23999999463558197, 0.21621620655059814, 0.4000000059604645]",rkWN3g-AZ,"['XGAN is an unsupervised model for feature-level image-to-image translation applied to semantic style transfer problems such as the face-to-cartoon task, for which we introduce a new dataset.', 'This paper proposes a new GAN-based model for unpaired image-to-image translation similar to DTN']","['style transfer usually refers task applying color texture information specific style image given content image preserving structure latter ', 'tackle generic problem semantic style transfer  given two unpaired collection image  aim learn mapping corpuslevel style collection  preserving semantic content shared across two domain ', 'introduce xgan   crossgan    dual adversarial autoencoder  capture shared representation common domain semantic content unsupervised way  jointly learning domaintodomain image translation direction ', 'exploit idea domain adaptation literature define semantic consistency loss encourages model preserve semantics learned embedding space ', 'report promising qualitative result task facetocartoon translation ', 'cartoon dataset collected purpose also released new benchmark semantic style transfer ']","Style transfer usually refers to the task of applying color and texture information from a specific style image to a given content image while preserving the structure of the latter., Here we tackle the more generic problem of semantic style transfer: given two unpaired collections of images, we aim to learn a mapping between the corpus-level style of each collection, while preserving semantic content shared across the two domains., We introduce XGAN (""Cross-GAN""), a dual adversarial autoencoder, which captures a shared representation of the common domain semantic content in an unsupervised way, while jointly learning the domain-to-domain image translations in both directions.  , We exploit ideas from the domain adaptation literature and define a semantic consistency loss which encourages the model to preserve semantics in the learned embedding space., We report promising qualitative results for the task of face-to-cartoon translation., The cartoon dataset we collected for this purpose will also be released as a new benchmark for semantic style transfer.",11,5.660377358490566,14.454545454545455
375,"['Training neural networks on large datasets can be accelerated by distributing the workload over a network of machines.', 'As datasets grow ever larger, networks of hundreds or thousands of machines become economically viable.', 'The time cost of communicating gradients limits the effectiveness of using such large machine counts, as may the increased chance of network faults.', 'We explore a particularly simple algorithm for robust, communication-efficient learning---signSGD.', 'Workers transmit only the sign of their gradient vector to a server, and the overall update is decided by a majority vote.', 'This algorithm uses 32x less communication per iteration than full-precision, distributed SGD.', 'Under natural conditions verified by experiment, we prove that signSGD converges in the large and mini-batch settings, establishing convergence for a parameter regime of Adam as a byproduct.', 'Aggregating sign gradients by majority vote means that no individual worker has too much power.', 'We prove that unlike SGD, majority vote is robust when up to 50% of workers behave adversarially.', 'The class of adversaries we consider includes as special cases those that invert or randomise their gradient estimate.', 'On the practical side, we built our distributed training system in Pytorch.', 'Benchmarking against the state of the art collective communications library (NCCL), our framework---with the parameter server housed entirely on one machine---led to a 25% reduction in time for training resnet50 on Imagenet when using 15 AWS p3.2xlarge machines.']","[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.08695651590824127, 0.0, 0.0416666604578495, 0.10526315122842789, 0.5, 0.09999999403953552, 0.1818181723356247, 0.1860465109348297, 0.2666666507720947, 0.08695651590824127, 0.09999999403953552, 0.0937499925494194]",BJxhijAcY7,"['Workers send gradient signs to the server, and the update is decided by majority vote. We show that this algorithm is convergent, communication efficient and fault tolerant, both in theory and in practice.', 'Presents a distributed implementation of signSGD with majority vote as aggregation.']","['training neural network large datasets accelerated distributing workload network machine ', 'datasets grow ever larger  network hundred thousand machine become economically viable ', 'time cost communicating gradient limit effectiveness using large machine count  may increased chance network fault ', 'explore particularly simple algorithm robust  communicationefficient learning  signsgd ', 'worker transmit sign gradient vector server  overall update decided majority vote ', 'algorithm us 32x le communication per iteration fullprecision  distributed sgd ', 'natural condition verified experiment  prove signsgd converges large minibatch setting  establishing convergence parameter regime adam byproduct ', 'aggregating sign gradient majority vote mean individual worker much power ', 'prove unlike sgd  majority vote robust 50  worker behave adversarially ', 'class adversary consider includes special case invert randomise gradient estimate ', 'practical side  built distributed training system pytorch ', 'benchmarking state art collective communication library  nccl   framework  parameter server housed entirely one machine  led 25  reduction time training resnet50 imagenet using 15 aws p32xlarge machine ']","Training neural networks on large datasets can be accelerated by distributing the workload over a network of machines., As datasets grow ever larger, networks of hundreds or thousands of machines become economically viable., The time cost of communicating gradients limits the effectiveness of using such large machine counts, as may the increased chance of network faults., We explore a particularly simple algorithm for robust, communication-efficient learning---signSGD., Workers transmit only the sign of their gradient vector to a server, and the overall update is decided by a majority vote., This algorithm uses 32x less communication per iteration than full-precision, distributed SGD., Under natural conditions verified by experiment, we prove that signSGD converges in the large and mini-batch settings, establishing convergence for a parameter regime of Adam as a byproduct., Aggregating sign gradients by majority vote means that no individual worker has too much power., We prove that unlike SGD, majority vote is robust when up to 50% of workers behave adversarially., The class of adversaries we consider includes as special cases those that invert or randomise their gradient estimate., On the practical side, we built our distributed training system in Pytorch., Benchmarking against the state of the art collective communications library (NCCL), our framework---with the parameter server housed entirely on one machine---led to a 25% reduction in time for training resnet50 on Imagenet when using 15 AWS p3.2xlarge machines.",22,5.675438596491228,10.363636363636363
376,"['Profiling cellular phenotypes from microscopic imaging can provide meaningful biological information resulting from various factors affecting the cells.', 'One motivating application is drug development: morphological cell features can be captured from images, from which similarities between different drugs applied at different dosages can be quantified.', 'The general approach is to find a function mapping the images to an embedding space of manageable dimensionality whose geometry captures relevant features of the input images.', 'An important known issue for such methods is separating relevant biological signal from nuisance variation.', 'For example, the embedding vectors tend to be more correlated for cells that were cultured and imaged during the same week than for cells from a different week, despite having identical drug compounds applied in both cases.', 'In this case, the particular batch a set of experiments were conducted in constitutes the domain of the data; an ideal set of image embeddings should contain only the relevant biological information (e.g. drug effects).', ""We develop a general framework for adjusting the image embeddings in order to `forget' domain-specific information while preserving relevant biological information."", 'To do this, we minimize a loss function based on distances between marginal distributions (such as the Wasserstein distance) of embeddings across domains for each replicated treatment.', 'For the dataset presented, the replicated treatment is the negative control.', 'We find that for our transformed embeddings (1) the underlying geometric structure is not only preserved but the embeddings also carry improved biological signal (2) less domain-specific information is present.']","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.06451612710952759, 0.05405404791235924, 0.05405404791235924, 0.27586206793785095, 0.0833333283662796, 0.22727271914482117, 0.4117647111415863, 0.1463414579629898, 0.0, 0.24390242993831635]",H18uzzWAZ,"['We correct nuisance variation for image embeddings across different domains, preserving only relevant information.', 'Discusses a method for adjusting image embeddings in order tease apart technical variation from biological signal.', 'The authors present a method to remove domain-specific information while preserving the relevant biological information by training a network that minimizes the Wasserstein distance between distrbutions.']","['profiling cellular phenotype microscopic imaging provide meaningful biological information resulting various factor affecting cell ', 'one motivating application drug development  morphological cell feature captured image  similarity different drug applied different dosage quantified ', 'general approach find function mapping image embedding space manageable dimensionality whose geometry capture relevant feature input image ', 'important known issue method separating relevant biological signal nuisance variation ', 'example  embedding vector tend correlated cell cultured imaged week cell different week  despite identical drug compound applied case ', 'case  particular batch set experiment conducted constitutes domain data  ideal set image embeddings contain relevant biological information  eg  drug effect  ', 'develop general framework adjusting image embeddings order  forget  domainspecific information preserving relevant biological information ', ' minimize loss function based distance marginal distribution  wasserstein distance  embeddings across domain replicated treatment ', 'dataset presented  replicated treatment negative control ', 'find transformed embeddings  1  underlying geometric structure preserved embeddings also carry improved biological signal  2  le domainspecific information present ']","Profiling cellular phenotypes from microscopic imaging can provide meaningful biological information resulting from various factors affecting the cells., One motivating application is drug development: morphological cell features can be captured from images, from which similarities between different drugs applied at different dosages can be quantified., The general approach is to find a function mapping the images to an embedding space of manageable dimensionality whose geometry captures relevant features of the input images., An important known issue for such methods is separating relevant biological signal from nuisance variation., For example, the embedding vectors tend to be more correlated for cells that were cultured and imaged during the same week than for cells from a different week, despite having identical drug compounds applied in both cases., In this case, the particular batch a set of experiments were conducted in constitutes the domain of the data; an ideal set of image embeddings should contain only the relevant biological information (e.g. drug effects)., We develop a general framework for adjusting the image embeddings in order to `forget' domain-specific information while preserving relevant biological information., To do this, we minimize a loss function based on distances between marginal distributions (such as the Wasserstein distance) of embeddings across domains for each replicated treatment., For the dataset presented, the replicated treatment is the negative control., We find that for our transformed embeddings (1) the underlying geometric structure is not only preserved but the embeddings also carry improved biological signal (2) less domain-specific information is present.",16,5.911290322580645,14.588235294117647
377,"['This paper presents a Mutual Information Neural Estimator (MINE) that is linearly scalable in dimensionality as well as in sample size.', 'MINE is  back-propable and we prove that it is strongly consistent.', 'We illustrate a handful of applications in which MINE is succesfully applied  to enhance the property of generative models in both unsupervised and supervised settings.', 'We apply our framework to estimate the information bottleneck, and apply it in tasks related to supervised classification problems.', 'Our results  demonstrate substantial added flexibility and improvement in these settings.\n']","[1, 0, 0, 0, 0]","[0.27586206793785095, 0.09999999403953552, 0.12121211737394333, 0.2222222238779068, 0.1818181723356247]",rJHOuiqaf,['A scalable in sample size and dimensions mutual information estimator.'],"['paper present mutual information neural estimator  mine  linearly scalable dimensionality well sample size ', 'mine backpropable prove strongly consistent ', 'illustrate handful application mine succesfully applied enhance property generative model unsupervised supervised setting ', 'apply framework estimate information bottleneck  apply task related supervised classification problem ', 'result demonstrate substantial added flexibility improvement setting ']","This paper presents a Mutual Information Neural Estimator (MINE) that is linearly scalable in dimensionality as well as in sample size., MINE is  back-propable and we prove that it is strongly consistent., We illustrate a handful of applications in which MINE is succesfully applied  to enhance the property of generative models in both unsupervised and supervised settings., We apply our framework to estimate the information bottleneck, and apply it in tasks related to supervised classification problems., Our results  demonstrate substantial added flexibility and improvement in these settings.
",6,5.793103448275862,14.5
378,"[' Reinforcement learning methods have recently achieved impressive results on a wide range of control problems.', 'However, especially with complex inputs, they still require an extensive amount of training data in order to converge to a meaningful solution.', 'This limitation largely prohibits  their usage for complex input spaces such as video signals, and it is still impossible to use it for a number of complex problems in a real world environments, including many of those for video based control.', 'Supervised learning, on the contrary, is capable of learning on a relatively small number of samples, however it does not take into account reward-based control policies and is not capable to provide independent control policies.  ', 'In this article we propose a model-free control method, which uses a combination of reinforcement and supervised learning for autonomous control and paves the way towards policy based control in real world environments.', 'We use SpeedDreams/TORCS video game to demonstrate that our approach requires much less samples (hundreds of thousands against millions or tens of millions) comparing to the state-of-the-art reinforcement learning techniques on similar data, and at the same time overcomes both supervised and reinforcement learning approaches in terms of quality.', 'Additionally, we demonstrate the applicability of the method to MuJoCo control problems.']","[0, 0, 0, 0, 1, 0, 0]","[0.12121211737394333, 0.10256409645080566, 0.19230768084526062, 0.25531914830207825, 0.2978723347187042, 0.2666666507720947, 0.13793103396892548]",BkeC_J-R-,"['The new combination of reinforcement and supervised learning, dramatically decreasing the number of required samples for training on video', 'This paper proposes leveraging labelled controlled data to accelerate reinforcement-based learning of a control policy']","['reinforcement learning method recently achieved impressive result wide range control problem ', 'however  especially complex input  still require extensive amount training data order converge meaningful solution ', 'limitation largely prohibits usage complex input space video signal  still impossible use number complex problem real world environment  including many video based control ', 'supervised learning  contrary  capable learning relatively small number sample  however take account rewardbased control policy capable provide independent control policy ', 'article propose modelfree control method  us combination reinforcement supervised learning autonomous control pave way towards policy based control real world environment ', 'use speeddreamstorcs video game demonstrate approach requires much le sample  hundred thousand million ten million  comparing stateoftheart reinforcement learning technique similar data  time overcomes supervised reinforcement learning approach term quality ', 'additionally  demonstrate applicability method mujoco control problem ']"," Reinforcement learning methods have recently achieved impressive results on a wide range of control problems., However, especially with complex inputs, they still require an extensive amount of training data in order to converge to a meaningful solution., This limitation largely prohibits  their usage for complex input spaces such as video signals, and it is still impossible to use it for a number of complex problems in a real world environments, including many of those for video based control., Supervised learning, on the contrary, is capable of learning on a relatively small number of samples, however it does not take into account reward-based control policies and is not capable to provide independent control policies.  , In this article we propose a model-free control method, which uses a combination of reinforcement and supervised learning for autonomous control and paves the way towards policy based control in real world environments., We use SpeedDreams/TORCS video game to demonstrate that our approach requires much less samples (hundreds of thousands against millions or tens of millions) comparing to the state-of-the-art reinforcement learning techniques on similar data, and at the same time overcomes both supervised and reinforcement learning approaches in terms of quality., Additionally, we demonstrate the applicability of the method to MuJoCo control problems.",17,5.63768115942029,12.176470588235293
379,"['A typical experiment to study cognitive function is to train animals to perform tasks, while the researcher records the electrical activity of the animals neurons.', 'The main obstacle faced, when using this type of electrophysiological experiment to uncover the circuit mechanisms underlying complex behaviors, is our incomplete access to relevant circuits in the brain.', 'One promising approach is to model neural circuits using an artificial neural network (ANN), which can provide complete access to the neural circuits responsible for a behavior.', 'More recently, reinforcement learning models have been adopted to understand the functions of cortico-basal ganglia circuits as reward-based learning has been found in mammalian brain.', 'In this paper, we propose a Biologically-plausible Actor-Critic with Episodic Memory (B-ACEM) framework to model a prefrontal cortex-basal ganglia-hippocampus (PFC-BG) circuit, which is verified to capture the behavioral findings from a well-known perceptual decision-making task, i.e., random dots motion discrimination.', 'This B-ACEM framework links neural computation to behaviors, on which we can explore how episodic memory should be considered to govern future decision.', 'Experiments are conducted using different settings of the episodic memory and results show that all patterns of episodic memories can speed up learning.', 'In particular, salient events are prioritized to propagate reward information and guide decisions.', 'Our B-ACEM framework and the built-on experiments give inspirations to both designs for more standard decision-making models in biological system and a more biologically-plausible ANN.']","[0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.0, 0.045454539358615875, 0.0952380895614624, 0.04999999329447746, 0.25, 0.1538461446762085, 0.15789473056793213, 0.0, 0.14999999105930328]",BJl4pA4Kwr,['Fast learning via episodic memory verified by a biologically plausible framework for prefrontal cortex-basal ganglia-hippocampus (PFC-BG) circuit'],"['typical experiment study cognitive function train animal perform task  researcher record electrical activity animal neuron ', 'main obstacle faced  using type electrophysiological experiment uncover circuit mechanism underlying complex behavior  incomplete access relevant circuit brain ', 'one promising approach model neural circuit using artificial neural network  ann   provide complete access  neural circuit  responsible behavior ', 'recently  reinforcement learning model adopted understand function corticobasal ganglion circuit rewardbased learning found mammalian brain ', 'paper  propose biologicallyplausible actorcritic episodic memory  bacem  framework model prefrontal cortexbasal gangliahippocampus  pfcbg  circuit  verified capture behavioral finding wellknown perceptual decisionmaking task  ie  random dot motion discrimination ', 'bacem framework link neural computation behavior  explore episodic memory considered govern future decision ', 'experiment conducted using different setting episodic memory result show pattern episodic memory speed learning ', 'particular  salient event prioritized propagate reward information guide decision ', 'bacem framework builton experiment give inspiration design standard decisionmaking model biological system biologicallyplausible ann ']","A typical experiment to study cognitive function is to train animals to perform tasks, while the researcher records the electrical activity of the animals neurons., The main obstacle faced, when using this type of electrophysiological experiment to uncover the circuit mechanisms underlying complex behaviors, is our incomplete access to relevant circuits in the brain., One promising approach is to model neural circuits using an artificial neural network (ANN), which can provide complete access to the neural circuits responsible for a behavior., More recently, reinforcement learning models have been adopted to understand the functions of cortico-basal ganglia circuits as reward-based learning has been found in mammalian brain., In this paper, we propose a Biologically-plausible Actor-Critic with Episodic Memory (B-ACEM) framework to model a prefrontal cortex-basal ganglia-hippocampus (PFC-BG) circuit, which is verified to capture the behavioral findings from a well-known perceptual decision-making task, i.e., random dots motion discrimination., This B-ACEM framework links neural computation to behaviors, on which we can explore how episodic memory should be considered to govern future decision., Experiments are conducted using different settings of the episodic memory and results show that all patterns of episodic memories can speed up learning., In particular, salient events are prioritized to propagate reward information and guide decisions., Our B-ACEM framework and the built-on experiments give inspirations to both designs for more standard decision-making models in biological system and a more biologically-plausible ANN.",20,6.108695652173913,11.5
380,"['Understanding the representational power of Deep Neural Networks (DNNs) and how their structural properties (e.g., depth, width, type of activation unit) affect the functions they can compute, has been an important yet challenging question in deep learning and approximation theory.', 'In a seminal paper, Telgarsky high- lighted the benefits of depth by presenting a family of functions (based on sim- ple triangular waves) for which DNNs achieve zero classification error, whereas shallow networks with fewer than exponentially many nodes incur constant error.', 'Even though Telgarskys work reveals the limitations of shallow neural networks, it doesnt inform us on why these functions are difficult to represent and in fact he states it as a tantalizing open question to characterize those functions that cannot be well-approximated by smaller depths.\n', 'In this work, we point to a new connection between DNNs expressivity and Sharkovskys Theorem from dynamical systems, that enables us to characterize the depth-width trade-offs of ReLU networks for representing functions based on the presence of a generalized notion of fixed points, called periodic points (a fixed point is a point of period 1).', 'Motivated by our observation that the triangle waves used in Telgarskys work contain points of period 3  a period that is special in that it implies chaotic behaviour based on the celebrated result by Li-Yorke  we proceed to give general lower bounds for the width needed to represent periodic functions as a function of the depth.', 'Technically, the crux of our approach is based on an eigenvalue analysis of the dynamical systems associated with such functions.']","[0, 0, 0, 1, 0, 0]","[0.08955223113298416, 0.1764705777168274, 0.22535210847854614, 0.767123281955719, 0.1621621549129486, 0.1304347813129425]",BJe55gBtvH,"['In this work, we point to a new connection between DNNs expressivity and Sharkovskys Theorem from dynamical systems, that enables us to characterize the depth-width trade-offs of ReLU networks ', 'Shows how the expressive power of NN depends on its depth and width, furthering the understanding of the benefit of deep nets for representing certain function classes.', 'The authors derive depth-width tradeoff conditions for when relu networks are able to represent periodic functions using dynamical systems analysis.']","['understanding representational power deep neural network  dnns  structural property  eg  depth  width  type activation unit  affect function compute  important yet challenging question deep learning approximation theory ', 'seminal paper  telgarsky high lighted benefit depth presenting family function  based sim ple triangular wave  dnns achieve zero classification error  whereas shallow network fewer exponentially many node incur constant error ', 'even though telgarsky  work reveals limitation shallow neural network   inform u function difficult represent fact state tantalizing open question characterize function wellapproximated smaller depth ', 'work  point new connection dnns expressivity sharkovsky  theorem dynamical system  enables u characterize depthwidth tradeoff relu network representing function based presence generalized notion fixed point  called periodic point  fixed point point period 1  ', 'motivated observation triangle wave used telgarsky  work contain point period 3  period special implies chaotic behaviour based celebrated result liyorke  proceed give general lower bound width needed represent periodic function function depth ', 'technically  crux approach based eigenvalue analysis dynamical system associated function ']","Understanding the representational power of Deep Neural Networks (DNNs) and how their structural properties (e.g., depth, width, type of activation unit) affect the functions they can compute, has been an important yet challenging question in deep learning and approximation theory., In a seminal paper, Telgarsky high- lighted the benefits of depth by presenting a family of functions (based on sim- ple triangular waves) for which DNNs achieve zero classification error, whereas shallow networks with fewer than exponentially many nodes incur constant error., Even though Telgarskys work reveals the limitations of shallow neural networks, it doesnt inform us on why these functions are difficult to represent and in fact he states it as a tantalizing open question to characterize those functions that cannot be well-approximated by smaller depths.
, In this work, we point to a new connection between DNNs expressivity and Sharkovskys Theorem from dynamical systems, that enables us to characterize the depth-width trade-offs of ReLU networks for representing functions based on the presence of a generalized notion of fixed points, called periodic points (a fixed point is a point of period 1)., Motivated by our observation that the triangle waves used in Telgarskys work contain points of period 3  a period that is special in that it implies chaotic behaviour based on the celebrated result by Li-Yorke  we proceed to give general lower bounds for the width needed to represent periodic functions as a function of the depth., Technically, the crux of our approach is based on an eigenvalue analysis of the dynamical systems associated with such functions.",17,5.357692307692307,15.294117647058824
381,"['We investigate low-bit quantization to reduce computational cost of deep neural network (DNN) based keyword spotting (KWS).', 'We propose approaches to further reduce quantization bits via integrating quantization into keyword spotting model training, which we refer to as quantization-aware training.', 'Our experimental results on large dataset indicate that quantization-aware training can recover performance models quantized to lower bits representations.', 'By combining quantization-aware training and weight matrix factorization, we are able to significantly reduce model size and computation for small-footprint keyword spotting, while maintaining performance.']","[1, 0, 0, 0]","[0.5294117331504822, 0.3684210479259491, 0.2222222238779068, 0.24390242993831635]",rJxVxiiDoX,"['We investigate quantization-aware training in very low-bit quantized keyword spotters to reduce the cost of on-device keyword spotting.', 'This submission proposes a combination of low-rank decomposition and quanitization approach to compress DNN models for keyword spotting.']","['investigate lowbit quantization reduce computational cost deep neural network  dnn  based keyword spotting  kw  ', 'propose approach reduce quantization bit via integrating quantization keyword spotting model training  refer quantizationaware training ', 'experimental result large dataset indicate quantizationaware training recover performance model quantized lower bit representation ', 'combining quantizationaware training weight matrix factorization  able significantly reduce model size computation smallfootprint keyword spotting  maintaining performance ']","We investigate low-bit quantization to reduce computational cost of deep neural network (DNN) based keyword spotting (KWS)., We propose approaches to further reduce quantization bits via integrating quantization into keyword spotting model training, which we refer to as quantization-aware training., Our experimental results on large dataset indicate that quantization-aware training can recover performance models quantized to lower bits representations., By combining quantization-aware training and weight matrix factorization, we are able to significantly reduce model size and computation for small-footprint keyword spotting, while maintaining performance.",7,6.833333333333333,12.0
382,"['Single-cell RNA-sequencing (scRNA-seq) is a powerful tool for analyzing biological systems.', 'However, due to biological and technical noise, quantifying the effects of multiple experimental conditions presents an analytical challenge.', 'To overcome this challenge, we developed MELD: Manifold Enhancement of Latent Dimensions.', 'MELD leverages tools from graph signal processing to learn a latent dimension within the data scoring the prototypicality of each datapoint with respect to experimental or control conditions.', 'We call this dimension the Enhanced Experimental Signal (EES).', 'MELD learns the EES by filtering the noisy categorical experimental label in the graph frequency domain to recover a smooth signal with continuous values.', 'This method can be used to identify signature genes that vary between conditions and identify which cell types are most affected by a given perturbation.', 'We demonstrate the advantages of MELD analysis in two biological datasets, including T-cell activation in response to antibody-coated beads and treatment of human pancreatic islet cells with interferon gamma.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.06896550953388214, 0.277777761220932, 0.06666666269302368, 0.3181818127632141, 0.07407406717538834, 0.25, 0.0476190410554409, 0.13333332538604736]",HyxA1i0NOE,"['A novel graph signal processing framework for quantifying the effects of experimental perturbations in single cell biomedical data.', 'This paper introduces several methods to process experimental results on biological cells and proposes a MELD algorithm mapping hard group assignments to soft assignments, allowing relevant groups of cells to be clustered.']","['singlecell rnasequencing  scrnaseq  powerful tool analyzing biological system ', 'however  due biological technical noise  quantifying effect multiple experimental condition present analytical challenge ', 'overcome challenge  developed meld  manifold enhancement latent dimension ', 'meld leverage tool graph signal processing learn latent dimension within data scoring prototypicality datapoint respect experimental control condition ', 'call dimension enhanced experimental signal  ee  ', 'meld learns ee filtering noisy categorical experimental label graph frequency domain recover smooth signal continuous value ', 'method used identify signature gene vary condition identify cell type affected given perturbation ', 'demonstrate advantage meld analysis two biological datasets  including tcell activation response antibodycoated bead treatment human pancreatic islet cell interferon gamma ']","Single-cell RNA-sequencing (scRNA-seq) is a powerful tool for analyzing biological systems., However, due to biological and technical noise, quantifying the effects of multiple experimental conditions presents an analytical challenge., To overcome this challenge, we developed MELD: Manifold Enhancement of Latent Dimensions., MELD leverages tools from graph signal processing to learn a latent dimension within the data scoring the prototypicality of each datapoint with respect to experimental or control conditions., We call this dimension the Enhanced Experimental Signal (EES)., MELD learns the EES by filtering the noisy categorical experimental label in the graph frequency domain to recover a smooth signal with continuous values., This method can be used to identify signature genes that vary between conditions and identify which cell types are most affected by a given perturbation., We demonstrate the advantages of MELD analysis in two biological datasets, including T-cell activation in response to antibody-coated beads and treatment of human pancreatic islet cells with interferon gamma.",12,6.006410256410256,13.0
383,"['Models of user behavior are critical inputs in many prescriptive settings and can be viewed as decision rules that transform state information available to the user into actions.', 'Gaussian processes (GPs), as well as nonlinear extensions thereof, provide a flexible framework to learn user models in conjunction with approximate Bayesian inference.', 'However, the resulting models may not be interpretable in general.', 'We propose decision-rule GPs (DRGPs) that apply GPs in a transformed space defined by decision rules that have immediate interpretability to practitioners.', 'We illustrate this modeling tool on a real application and show that structural variational inference techniques can be used with DRGPs.', 'We find that DRGPs outperform the direct use of GPs in terms of out-of-sample performance.']","[0, 0, 0, 1, 0, 0]","[0.21276594698429108, 0.2857142686843872, 0.06666666269302368, 0.5, 0.1463414579629898, 0.11764705181121826]",rke5qJ3NYB,['We propose a class of user models based on using Gaussian processes applied to a transformed space defined by decision rules'],"['model user behavior critical input many prescriptive setting viewed decision rule transform state information available user action ', 'gaussian process  gps   well nonlinear extension thereof  provide flexible framework learn user model conjunction approximate bayesian inference ', 'however  resulting model may interpretable general ', 'propose decisionrule gps  drgps  apply gps transformed space defined decision rule immediate interpretability practitioner ', 'illustrate modeling tool real application show structural variational inference technique used drgps ', 'find drgps outperform direct use gps term outofsample performance ']","Models of user behavior are critical inputs in many prescriptive settings and can be viewed as decision rules that transform state information available to the user into actions., Gaussian processes (GPs), as well as nonlinear extensions thereof, provide a flexible framework to learn user models in conjunction with approximate Bayesian inference., However, the resulting models may not be interpretable in general., We propose decision-rule GPs (DRGPs) that apply GPs in a transformed space defined by decision rules that have immediate interpretability to practitioners., We illustrate this modeling tool on a real application and show that structural variational inference techniques can be used with DRGPs., We find that DRGPs outperform the direct use of GPs in terms of out-of-sample performance.",9,5.689075630252101,13.222222222222221
384,"['While Bayesian optimization (BO) has achieved great success in optimizing expensive-to-evaluate black-box functions, especially tuning hyperparameters of neural networks, methods such as random search (Li et al., 2016) and multi-fidelity BO (e.g. Klein et al. (2017)) that exploit cheap approximations, e.g. training on a smaller training data or with fewer iterations, can outperform standard BO approaches that use only full-fidelity observations.', 'In this paper, we propose a novel Bayesian optimization algorithm, the continuous-fidelity knowledge gradient (cfKG) method, that can be used when fidelity is controlled by one or more continuous settings such as training data size and the number of training iterations.', 'cfKG characterizes the value of the information gained by sampling a point at a given fidelity, choosing to sample at the point and fidelity with the largest value per unit cost.', 'Furthermore, cfKG can be generalized, following Wu et al. (2017), to settings where derivatives are available in the optimization process, e.g. large-scale kernel learning, and where more than one point can be evaluated simultaneously.', 'Numerical experiments show that cfKG outperforms state-of-art algorithms when optimizing synthetic functions, tuning convolutional neural networks (CNNs) on CIFAR-10 and SVHN, and in large-scale kernel learning.']","[0, 1, 0, 0, 0]","[0.138888880610466, 0.18867924809455872, 0.10526315122842789, 0.043478257954120636, 0.05128204822540283]",SknC0bW0-,"['We propose a Bayes-optimal Bayesian optimization algorithm for hyperparameter tuning by exploiting cheap approximations.', 'Studies hyperparameter-optimization by Bayesian optimization, using the Knowledge Gradient framework and allowing the Bayesian optimizer to tune fidelity against cost.']","['bayesian optimization  bo  achieved great success optimizing expensivetoevaluate blackbox function  especially tuning hyperparameters neural network  method random search  li et al  2016  multifidelity bo  eg  klein et al   2017   exploit cheap approximation  eg  training smaller training data fewer iteration  outperform standard bo approach use fullfidelity observation ', 'paper  propose novel bayesian optimization algorithm  continuousfidelity knowledge gradient  cfkg  method  used fidelity controlled one continuous setting training data size number training iteration ', 'cfkg characterizes value information gained sampling point given fidelity  choosing sample point fidelity largest value per unit cost ', 'furthermore  cfkg generalized  following wu et al   2017   setting derivative available optimization process  eg  largescale kernel learning  one point evaluated simultaneously ', 'numerical experiment show cfkg outperforms stateofart algorithm optimizing synthetic function  tuning convolutional neural network  cnns  cifar10 svhn  largescale kernel learning ']","While Bayesian optimization (BO) has achieved great success in optimizing expensive-to-evaluate black-box functions, especially tuning hyperparameters of neural networks, methods such as random search (Li et al., 2016) and multi-fidelity BO (e.g. Klein et al. (2017)) that exploit cheap approximations, e.g. training on a smaller training data or with fewer iterations, can outperform standard BO approaches that use only full-fidelity observations., In this paper, we propose a novel Bayesian optimization algorithm, the continuous-fidelity knowledge gradient (cfKG) method, that can be used when fidelity is controlled by one or more continuous settings such as training data size and the number of training iterations., cfKG characterizes the value of the information gained by sampling a point at a given fidelity, choosing to sample at the point and fidelity with the largest value per unit cost., Furthermore, cfKG can be generalized, following Wu et al. (2017), to settings where derivatives are available in the optimization process, e.g. large-scale kernel learning, and where more than one point can be evaluated simultaneously., Numerical experiments show that cfKG outperforms state-of-art algorithms when optimizing synthetic functions, tuning convolutional neural networks (CNNs) on CIFAR-10 and SVHN, and in large-scale kernel learning.",21,5.901554404145077,7.423076923076923
385,"['Neural networks trained only to optimize for training accuracy can often be fooled by adversarial examples --- slightly perturbed inputs misclassified with high confidence.', 'Verification of networks enables us to gauge their vulnerability to such adversarial examples.', 'We formulate verification of piecewise-linear neural networks as a mixed integer program.', 'On a representative task of finding minimum adversarial distortions, our verifier is two to three orders of magnitude quicker than the state-of-the-art.', 'We achieve this computational speedup via tight formulations for non-linearities, as well as a novel presolve algorithm that makes full use of all information available.', 'The computational speedup allows us to verify properties on convolutional and residual networks with over 100,000 ReLUs --- several orders of magnitude more than networks previously verified by any complete verifier.', 'In particular, we determine for the first time the exact adversarial accuracy of an MNIST classifier to perturbations with bounded l- norm =0.1: for this classifier, we find an adversarial example for 4.38% of samples, and a certificate of robustness to norm-bounded perturbations for the remainder.', 'Across all robust training procedures and network architectures considered, and for both the MNIST and CIFAR-10 datasets, we are able to certify more samples than the state-of-the-art and find more adversarial examples than a strong first-order attack.']","[0, 0, 0, 0, 0, 0, 0, 1]","[0.11999999731779099, 0.15789473056793213, 0.21052631735801697, 0.2978723347187042, 0.11999999731779099, 0.2857142686843872, 0.22580644488334656, 0.42105263471603394]",HyGIdiRqtm,"['We efficiently verify the robustness of deep neural models with over 100,000 ReLUs, certifying more samples than the state-of-the-art and finding more adversarial examples than a strong first-order attack.', 'Performs a careful study of mixed integer linear programming approaches for verifying robustness of neural networks to adversarial perturbations and proposes three enhancements to MILP formulations of neural network verification.']","['neural network trained optimize training accuracy often fooled adversarial example   slightly perturbed input misclassified high confidence ', 'verification network enables u gauge vulnerability adversarial example ', 'formulate verification piecewiselinear neural network mixed integer program ', 'representative task finding minimum adversarial distortion  verifier two three order magnitude quicker stateoftheart ', 'achieve computational speedup via tight formulation nonlinearities  well novel presolve algorithm make full use information available ', 'computational speedup allows u verify property convolutional residual network 100000 relus   several order magnitude network previously verified complete verifier ', 'particular  determine first time exact adversarial accuracy mnist classifier perturbation bounded l norm 01  classifier  find adversarial example 438  sample  certificate robustness normbounded perturbation remainder ', 'across robust training procedure network architecture considered  mnist cifar10 datasets  able certify sample stateoftheart find adversarial example strong firstorder attack ']","Neural networks trained only to optimize for training accuracy can often be fooled by adversarial examples --- slightly perturbed inputs misclassified with high confidence., Verification of networks enables us to gauge their vulnerability to such adversarial examples., We formulate verification of piecewise-linear neural networks as a mixed integer program., On a representative task of finding minimum adversarial distortions, our verifier is two to three orders of magnitude quicker than the state-of-the-art., We achieve this computational speedup via tight formulations for non-linearities, as well as a novel presolve algorithm that makes full use of all information available., The computational speedup allows us to verify properties on convolutional and residual networks with over 100,000 ReLUs --- several orders of magnitude more than networks previously verified by any complete verifier., In particular, we determine for the first time the exact adversarial accuracy of an MNIST classifier to perturbations with bounded l- norm =0.1: for this classifier, we find an adversarial example for 4.38% of samples, and a certificate of robustness to norm-bounded perturbations for the remainder., Across all robust training procedures and network architectures considered, and for both the MNIST and CIFAR-10 datasets, we are able to certify more samples than the state-of-the-art and find more adversarial examples than a strong first-order attack.",15,5.885714285714286,14.0
386,"['Uncertainty estimation is an essential step in the evaluation of the robustness for deep learning models in computer vision, especially when applied in risk-sensitive areas.', 'However, most state-of-the-art deep learning models either fail to obtain uncertainty estimation or need significant modification (e.g., formulating a proper Bayesian treatment) to obtain it.', 'None of the previous methods are able to take an arbitrary model off the shelf and generate uncertainty estimation without retraining or redesigning it.', 'To address this gap, we perform the first systematic exploration into training-free uncertainty estimation. \n', 'We propose three simple and scalable methods to analyze the variance of output from a trained network under tolerable perturbations: infer-transformation, infer-noise, and infer-dropout.', 'They operate solely during inference, without the need to re-train, re-design, or fine-tune the model, as typically required by other state-of-the-art uncertainty estimation methods.', 'Surprisingly, even without involving such perturbations in training, our methods produce comparable or even better uncertainty estimation when compared to other training-required state-of-the-art methods.', 'Last but not least, we demonstrate that the uncertainty from our proposed methods can be used to improve the neural network training.\n']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.10256409645080566, 0.2857142686843872, 0.44999998807907104, 0.1249999925494194, 0.14999999105930328, 0.29999998211860657, 0.307692289352417, 0.1538461446762085]",Sye9lyHKwB,"['A set of methods to obtain uncertainty estimation of any given model without re-designing, re-training, or to fine-tuning it.', 'Describes several approaches for measuring uncertainty in arbitrary neural networks when there is an absence of distortion during training.']","['uncertainty estimation essential step evaluation robustness deep learning model computer vision  especially applied risksensitive area ', 'however  stateoftheart deep learning model either fail obtain uncertainty estimation need significant modification  eg  formulating proper bayesian treatment  obtain ', 'none previous method able take arbitrary model shelf generate uncertainty estimation without retraining redesigning ', 'address gap  perform first systematic exploration trainingfree uncertainty estimation ', 'propose three simple scalable method analyze variance output trained network tolerable perturbation  infertransformation  infernoise  inferdropout ', 'operate solely inference  without need retrain  redesign  finetune model  typically required stateoftheart uncertainty estimation method ', 'surprisingly  even without involving perturbation training  method produce comparable even better uncertainty estimation compared trainingrequired stateoftheart method ', 'last least  demonstrate uncertainty proposed method used improve neural network training ']","Uncertainty estimation is an essential step in the evaluation of the robustness for deep learning models in computer vision, especially when applied in risk-sensitive areas., However, most state-of-the-art deep learning models either fail to obtain uncertainty estimation or need significant modification (e.g., formulating a proper Bayesian treatment) to obtain it., None of the previous methods are able to take an arbitrary model off the shelf and generate uncertainty estimation without retraining or redesigning it., To address this gap, we perform the first systematic exploration into training-free uncertainty estimation. 
, We propose three simple and scalable methods to analyze the variance of output from a trained network under tolerable perturbations: infer-transformation, infer-noise, and infer-dropout., They operate solely during inference, without the need to re-train, re-design, or fine-tune the model, as typically required by other state-of-the-art uncertainty estimation methods., Surprisingly, even without involving such perturbations in training, our methods produce comparable or even better uncertainty estimation when compared to other training-required state-of-the-art methods., Last but not least, we demonstrate that the uncertainty from our proposed methods can be used to improve the neural network training.
",21,6.269230769230769,8.666666666666666
387,"['Capturing spatiotemporal dynamics is an essential topic in video recognition.', 'In this paper, we present learnable higher-order operation as a generic family of building blocks for capturing higher-order correlations from high dimensional input video space.', 'We prove that several successful architectures for visual classification tasks are in the family of higher-order neural networks, theoretical and experimental analysis demonstrates their underlying mechanism is higher-order.  ', 'On the task of video recognition, even using RGB only without fine-tuning with other video datasets, our higher-order models can achieve results on par with or better than the existing state-of-the-art methods on both Something-Something (V1 and V2) and Charades datasets.']","[0, 1, 0, 0]","[0.0, 0.12903225421905518, 0.05714285373687744, 0.0]",ryezBaNKDB,"['Proposed higher order operation for context learning', ""Proposes a new 3D convolutional block which convolves video input with its context, based on the assumpton that relevant context is present around the image's object.""]","['capturing spatiotemporal dynamic essential topic video recognition ', 'paper  present learnable higherorder operation generic family building block capturing higherorder correlation high dimensional input video space ', 'prove several successful architecture visual classification task family higherorder neural network  theoretical experimental analysis demonstrates underlying mechanism higherorder ', 'task video recognition  even using rgb without finetuning video datasets  higherorder model achieve result par better existing stateoftheart method somethingsomething  v1 v2  charade datasets ']","Capturing spatiotemporal dynamics is an essential topic in video recognition., In this paper, we present learnable higher-order operation as a generic family of building blocks for capturing higher-order correlations from high dimensional input video space., We prove that several successful architectures for visual classification tasks are in the family of higher-order neural networks, theoretical and experimental analysis demonstrates their underlying mechanism is higher-order.  , On the task of video recognition, even using RGB only without fine-tuning with other video datasets, our higher-order models can achieve results on par with or better than the existing state-of-the-art methods on both Something-Something (V1 and V2) and Charades datasets.",8,6.221153846153846,13.0
388,"['Presently the most successful approaches to semi-supervised learning are based on consistency regularization, whereby a model is trained to be robust to small perturbations of its inputs and parameters.', 'To understand consistency regularization, we conceptually explore how loss geometry interacts with training procedures.', 'The consistency loss dramatically improves generalization performance over supervised-only training; however, we show that SGD struggles to converge on the consistency loss and continues to make large steps that lead to changes in predictions on the test data.', 'Motivated by these observations, we propose to train consistency-based methods with Stochastic Weight Averaging (SWA), a recent approach which averages weights along the trajectory of SGD with a modified learning rate schedule.', 'We also propose fast-SWA, which further accelerates convergence by averaging multiple points within each cycle of a cyclical learning rate schedule.', 'With weight averaging, we achieve the best known semi-supervised results on CIFAR-10 and CIFAR-100, over many different quantities of labeled training data.', 'For example, we achieve 5.0% error on CIFAR-10 with only 4000 labels, compared to the previous best result in the literature of 6.3%.']","[1, 0, 0, 0, 0, 0, 0]","[0.24137930572032928, 0.04444444179534912, 0.19354838132858276, 0.19672130048274994, 0.1538461446762085, 0.15094339847564697, 0.145454540848732]",rkgKBhA5Y7,"['Consistency-based models for semi-supervised learning do not converge to a single point but continue to explore a diverse set of plausible solutions on the perimeter of a flat region. Weight averaging helps improve generalization performance.', 'The paper proposes to apply Stochastic Weight Averaging to the semi-supervised learning context, arguing that the semi-supervised MT/Pi models are especially amenable to SWA and propose fast SWA to speed up training.']","['presently successful approach semisupervised learning based consistency regularization  whereby model trained robust small perturbation input parameter ', 'understand consistency regularization  conceptually explore loss geometry interacts training procedure ', 'consistency loss dramatically improves generalization performance supervisedonly training  however  show sgd struggle converge consistency loss continues make large step lead change prediction test data ', 'motivated observation  propose train consistencybased method stochastic weight averaging  swa   recent approach average weight along trajectory sgd modified learning rate schedule ', 'also propose fastswa  accelerates convergence averaging multiple point within cycle cyclical learning rate schedule ', 'weight averaging  achieve best known semisupervised result cifar10 cifar100  many different quantity labeled training data ', 'example  achieve 50  error cifar10 4000 label  compared previous best result literature 63  ']","Presently the most successful approaches to semi-supervised learning are based on consistency regularization, whereby a model is trained to be robust to small perturbations of its inputs and parameters., To understand consistency regularization, we conceptually explore how loss geometry interacts with training procedures., The consistency loss dramatically improves generalization performance over supervised-only training; however, we show that SGD struggles to converge on the consistency loss and continues to make large steps that lead to changes in predictions on the test data., Motivated by these observations, we propose to train consistency-based methods with Stochastic Weight Averaging (SWA), a recent approach which averages weights along the trajectory of SGD with a modified learning rate schedule., We also propose fast-SWA, which further accelerates convergence by averaging multiple points within each cycle of a cyclical learning rate schedule., With weight averaging, we achieve the best known semi-supervised results on CIFAR-10 and CIFAR-100, over many different quantities of labeled training data., For example, we achieve 5.0% error on CIFAR-10 with only 4000 labels, compared to the previous best result in the literature of 6.3%.",17,5.93854748603352,10.529411764705882
389,"[""In this paper, we find that by designing a novel loss function entitled, ''tracking loss'', Convolutional Neural Network (CNN) based object detectors can be successfully converted to well-performed visual trackers without any extra computational cost."", 'This property is preferable to visual tracking where annotated video sequences for training are always absent, because rich features learned by detectors from still images could be utilized by dynamic trackers.', 'It also avoids extra machinery such as feature engineering and feature aggregation proposed in previous studies.', 'Tracking loss achieves this property by exploiting the internal structure of feature maps within the detection network and treating different feature points discriminatively.', 'Such structure allows us to simultaneously consider discrimination quality and bounding box accuracy which is found to be crucial to the success.', 'We also propose a network compression method to accelerate tracking speed without performance reduction.', 'That also verifies tracking loss will remain highly effective even if the network is drastically compressed.', 'Furthermore, if we employ a carefully designed tracking loss ensemble, the tracker would be much more robust and accurate.', 'Evaluation results show that our trackers (including the ensemble tracker and two baseline trackers), outperform all state-of-the-art methods on VOT 2016 Challenge in terms of Expected Average Overlap (EAO) and robustness.', 'We will make the code publicly available.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.23529411852359772, 0.08695651590824127, 0.0, 0.1621621549129486, 0.1111111044883728, 0.19999998807907104, 0.1249999925494194, 0.22857142984867096, 0.1304347813129425, 0.17391303181648254]",H1lzcXfknm,['We successfully convert a popular detector RPN to a well-performed tracker from the viewpoint of loss function.'],"['paper  find designing novel loss function entitled   tracking loss   convolutional neural network  cnn  based object detector successfully converted wellperformed visual tracker without extra computational cost ', 'property preferable visual tracking annotated video sequence training always absent  rich feature learned detector still image could utilized dynamic tracker ', 'also avoids extra machinery feature engineering feature aggregation proposed previous study ', 'tracking loss achieves property exploiting internal structure feature map within detection network treating different feature point discriminatively ', 'structure allows u simultaneously consider discrimination quality bounding box accuracy found crucial success ', 'also propose network compression method accelerate tracking speed without performance reduction ', 'also verifies tracking loss remain highly effective even network drastically compressed ', 'furthermore  employ carefully designed tracking loss ensemble  tracker would much robust accurate ', 'evaluation result show tracker  including ensemble tracker two baseline tracker   outperform stateoftheart method vot 2016 challenge term expected average overlap  eao  robustness ', 'make code publicly available ']","In this paper, we find that by designing a novel loss function entitled, ''tracking loss'', Convolutional Neural Network (CNN) based object detectors can be successfully converted to well-performed visual trackers without any extra computational cost., This property is preferable to visual tracking where annotated video sequences for training are always absent, because rich features learned by detectors from still images could be utilized by dynamic trackers., It also avoids extra machinery such as feature engineering and feature aggregation proposed in previous studies., Tracking loss achieves this property by exploiting the internal structure of feature maps within the detection network and treating different feature points discriminatively., Such structure allows us to simultaneously consider discrimination quality and bounding box accuracy which is found to be crucial to the success., We also propose a network compression method to accelerate tracking speed without performance reduction., That also verifies tracking loss will remain highly effective even if the network is drastically compressed., Furthermore, if we employ a carefully designed tracking loss ensemble, the tracker would be much more robust and accurate., Evaluation results show that our trackers (including the ensemble tracker and two baseline trackers), outperform all state-of-the-art methods on VOT 2016 Challenge in terms of Expected Average Overlap (EAO) and robustness., We will make the code publicly available.",17,5.97196261682243,12.588235294117647
390,"['We study the problem of semantic code repair, which can be broadly defined as automatically fixing non-syntactic bugs in source code.', 'The majority of past work in semantic code repair assumed access to unit tests against which candidate repairs could be validated.', 'In contrast, the goal here is to develop a strong statistical model to accurately predict both bug locations and exact fixes without access to information about the intended correct behavior of the program.', 'Achieving such a goal requires a robust contextual repair model, which we train on a large corpus of real-world source code that has been augmented with synthetically injected bugs.', 'Our framework adopts a two-stage approach where first a large set of repair candidates are generated by rule-based processors, and then these candidates are scored by a statistical model using a novel neural network architecture which we refer to as Share, Specialize, and Compete.', 'Specifically, the architecture (1) generates a  shared encoding of the source code using an RNN over the abstract syntax tree, (2) scores each candidate repair using specialized network modules, and (3) then normalizes these scores together so they can compete against one another in comparable probability space.', 'We evaluate our model on a real-world test set gathered from GitHub containing four common categories of bugs.', 'Our model is able to predict the exact correct repair 41% of the time with a single guess, compared to 13% accuracy for an attentional sequence-to-sequence model.']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.052631575614213943, 0.307692289352417, 0.21276594698429108, 0.04444443807005882, 0.2181818187236786, 0.09836065024137497, 0.0, 0.1428571343421936]",r1hsJCe0Z,"['A neural architecture for scoring and ranking program repair candidates to perform semantic program repair statically without access to unit tests.', 'Presents a neural network architecture consisting of the share, specialize and compete parts for repairing code in four cases.']","['study problem semantic code repair  broadly defined automatically fixing nonsyntactic bug source code ', 'majority past work semantic code repair assumed access unit test candidate repair could validated ', 'contrast  goal develop strong statistical model accurately predict bug location exact fix without access information intended correct behavior program ', 'achieving goal requires robust contextual repair model  train large corpus realworld source code augmented synthetically injected bug ', 'framework adopts twostage approach first large set repair candidate generated rulebased processor  candidate scored statistical model using novel neural network architecture refer share  specialize  compete ', 'specifically  architecture  1  generates shared encoding source code using rnn abstract syntax tree   2  score candidate repair using specialized network module   3  normalizes score together compete one another comparable probability space ', 'evaluate model realworld test set gathered github containing four common category bug ', 'model able predict exact correct repair 41  time single guess  compared 13  accuracy attentional sequencetosequence model ']","We study the problem of semantic code repair, which can be broadly defined as automatically fixing non-syntactic bugs in source code., The majority of past work in semantic code repair assumed access to unit tests against which candidate repairs could be validated., In contrast, the goal here is to develop a strong statistical model to accurately predict both bug locations and exact fixes without access to information about the intended correct behavior of the program., Achieving such a goal requires a robust contextual repair model, which we train on a large corpus of real-world source code that has been augmented with synthetically injected bugs., Our framework adopts a two-stage approach where first a large set of repair candidates are generated by rule-based processors, and then these candidates are scored by a statistical model using a novel neural network architecture which we refer to as Share, Specialize, and Compete., Specifically, the architecture (1) generates a  shared encoding of the source code using an RNN over the abstract syntax tree, (2) scores each candidate repair using specialized network modules, and (3) then normalizes these scores together so they can compete against one another in comparable probability space., We evaluate our model on a real-world test set gathered from GitHub containing four common categories of bugs., Our model is able to predict the exact correct repair 41% of the time with a single guess, compared to 13% accuracy for an attentional sequence-to-sequence model.",18,5.304166666666666,13.333333333333334
391,"['Deep networks were recently suggested to face the odds between accuracy (on clean natural images) and robustness (on adversarially perturbed images) (Tsipras et al., 2019).', 'Such a dilemma is shown to be rooted in the inherently higher sample complexity (Schmidt et al., 2018) and/or model capacity (Nakkiran, 2019), for learning a high-accuracy and robust classifier.', 'In view of that, give a classification task, growing the model capacity appears to help draw a win-win between accuracy and robustness, yet at the expense of model size and latency, therefore posing challenges for resource-constrained applications.', 'Is it possible to co-design model accuracy, robustness and efficiency to achieve their triple wins?', 'This paper studies multi-exit networks associated with input-adaptive efficient inference, showing their strong promise in achieving a sweet point"" in co-optimizing model accuracy, robustness, and efficiency.', 'Our proposed solution, dubbed Robust Dynamic Inference Networks (RDI-Nets), allows for each input (either clean or adversarial) to adaptively choose one of the multiple output layers (early branches or the final one) to output its prediction.', 'That multi-loss adaptivity adds new variations and flexibility to adversarial attacks and defenses, on which we present a systematical investigation.', 'We show experimentally that by equipping existing backbones with such robust adaptive inference, the resulting RDI-Nets can achieve better accuracy and robustness, yet with over 30% computational savings, compared to the defended original models.\n']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.1538461446762085, 0.13333332538604736, 0.12765957415103912, 0.9655172228813171, 0.25, 0.04255318641662598, 0.11764705181121826, 0.1249999925494194]",rJgzzJHtDB,"['Is it possible to co-design model accuracy, robustness and efficiency to achieve their triple wins? Yes!', 'Exploits input-adaptive multiple early-exits for the field of adversarial attack and defense, reducing the average inference complexity without conflicting the larger capacity assumption.']","['deep network recently suggested face odds accuracy  clean natural image  robustness  adversarially perturbed image   tsipras et al  2019  ', 'dilemma shown rooted inherently higher sample complexity  schmidt et al  2018  andor model capacity  nakkiran  2019   learning highaccuracy robust classifier ', 'view  give classification task  growing model capacity appears help draw winwin accuracy robustness  yet expense model size latency  therefore posing challenge resourceconstrained application ', 'possible codesign model accuracy  robustness efficiency achieve triple win ', 'paper study multiexit network associated inputadaptive efficient inference  showing strong promise achieving  sweet point  cooptimizing model accuracy  robustness  efficiency ', 'proposed solution  dubbed robust dynamic inference network  rdinets   allows input  either clean adversarial  adaptively choose one multiple output layer  early branch final one  output prediction ', 'multiloss adaptivity add new variation flexibility adversarial attack defense  present systematical investigation ', 'show experimentally equipping existing backbone robust adaptive inference  resulting rdinets achieve better accuracy robustness  yet 30  computational saving  compared defended original model ']","Deep networks were recently suggested to face the odds between accuracy (on clean natural images) and robustness (on adversarially perturbed images) (Tsipras et al., 2019)., Such a dilemma is shown to be rooted in the inherently higher sample complexity (Schmidt et al., 2018) and/or model capacity (Nakkiran, 2019), for learning a high-accuracy and robust classifier., In view of that, give a classification task, growing the model capacity appears to help draw a win-win between accuracy and robustness, yet at the expense of model size and latency, therefore posing challenges for resource-constrained applications., Is it possible to co-design model accuracy, robustness and efficiency to achieve their triple wins?, This paper studies multi-exit networks associated with input-adaptive efficient inference, showing their strong promise in achieving a sweet point"" in co-optimizing model accuracy, robustness, and efficiency., Our proposed solution, dubbed Robust Dynamic Inference Networks (RDI-Nets), allows for each input (either clean or adversarial) to adaptively choose one of the multiple output layers (early branches or the final one) to output its prediction., That multi-loss adaptivity adds new variations and flexibility to adversarial attacks and defenses, on which we present a systematical investigation., We show experimentally that by equipping existing backbones with such robust adaptive inference, the resulting RDI-Nets can achieve better accuracy and robustness, yet with over 30% computational savings, compared to the defended original models.
",26,5.946188340807175,8.576923076923077
392,"['Although deep convolutional networks have achieved improved performance in many natural language tasks, they have been treated as black boxes because they are difficult to interpret.', 'Especially, little is known about how they represent language in their intermediate layers.', 'In an attempt to understand the representations of deep convolutional networks trained on language tasks, we show that individual units are selectively responsive to specific morphemes, words, and phrases, rather than responding to arbitrary and uninterpretable patterns.', 'In order to quantitatively analyze such intriguing phenomenon, we propose a concept alignment method based on how units respond to replicated text.', 'We conduct analyses with different architectures on multiple datasets for classification and translation tasks and provide new insights into how deep models understand natural language.']","[0, 0, 1, 0, 0]","[0.23255813121795654, 0.1249999925494194, 0.4150943458080292, 0.09999999403953552, 0.1860465109348297]",BJec2Mfosm,"['We show that individual units in CNN representations learned in NLP tasks are selectively responsive to specific natural language concepts.', 'Uses grammatical units of natural language that preserve meanings to show that the units of deep CNNs learned in NLP tasks could act as a natural language concept detector.']","['although deep convolutional network achieved improved performance many natural language task  treated black box difficult interpret ', 'especially  little known represent language intermediate layer ', 'attempt understand representation deep convolutional network trained language task  show individual unit selectively responsive specific morpheme  word  phrase  rather responding arbitrary uninterpretable pattern ', 'order quantitatively analyze intriguing phenomenon  propose concept alignment method based unit respond replicated text ', 'conduct analysis different architecture multiple datasets classification translation task provide new insight deep model understand natural language ']","Although deep convolutional networks have achieved improved performance in many natural language tasks, they have been treated as black boxes because they are difficult to interpret., Especially, little is known about how they represent language in their intermediate layers., In an attempt to understand the representations of deep convolutional networks trained on language tasks, we show that individual units are selectively responsive to specific morphemes, words, and phrases, rather than responding to arbitrary and uninterpretable patterns., In order to quantitatively analyze such intriguing phenomenon, we propose a concept alignment method based on how units respond to replicated text., We conduct analyses with different architectures on multiple datasets for classification and translation tasks and provide new insights into how deep models understand natural language.",12,6.105691056910569,10.25
393,"['\nWe study the problem of building models that disentangle independent factors of variation.', 'Such models encode features that can efficiently be used for classification and to transfer attributes between different images in image synthesis.', 'As data we use a weakly labeled training set, where labels indicate what single factor has changed between two data samples, although the relative value of the change is unknown.', 'This labeling is of particular interest as it may be readily available without annotation costs.', 'We introduce an autoencoder model and train it through constraints on image pairs and triplets.', 'We show the role of feature dimensionality and adversarial training theoretically and experimentally.', 'We formally prove the existence of the reference ambiguity, which is inherently present in the disentangling task when weakly labeled data is used.', 'The numerical value of a factor has different meaning in different reference frames.', 'When the reference depends on other factors, transferring that factor becomes ambiguous.', 'We demonstrate experimentally that the proposed model can successfully transfer attributes on several datasets, but show also cases when the reference ambiguity occurs.\n']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.25806450843811035, 0.14999999105930328, 0.1702127605676651, 0.11764705181121826, 0.060606054961681366, 0.19354838132858276, 0.25641024112701416, 0.19354838132858276, 0.12903225421905518, 0.0952380895614624]",SkmiegW0b,"['It is a mostly theoretical paper that describes the challenges in disentangling factors of variation, using autoencoders and GAN.', 'This paper considers disentangling factors of variation in images, shows that in general, without further assumptions, one cannot tell apart two different variation factors, and suggests a novel AE+GAN architecture to try and disentangle variation factors.', 'This paper studies the challenges of disentangling independent factors of variation under weakly labeled data and introduces the term reference ambiguity for data point mapping.']","['study problem building model disentangle independent factor variation ', 'model encode feature efficiently used classification transfer attribute different image image synthesis ', 'data use weakly labeled training set  label indicate single factor changed two data sample  although relative value change unknown ', 'labeling particular interest may readily available without annotation cost ', 'introduce autoencoder model train constraint image pair triplet ', 'show role feature dimensionality adversarial training theoretically experimentally ', 'formally prove existence reference ambiguity  inherently present disentangling task weakly labeled data used ', 'numerical value factor different meaning different reference frame ', 'reference depends factor  transferring factor becomes ambiguous ', 'demonstrate experimentally proposed model successfully transfer attribute several datasets  show also case reference ambiguity occurs ']","
We study the problem of building models that disentangle independent factors of variation., Such models encode features that can efficiently be used for classification and to transfer attributes between different images in image synthesis., As data we use a weakly labeled training set, where labels indicate what single factor has changed between two data samples, although the relative value of the change is unknown., This labeling is of particular interest as it may be readily available without annotation costs., We introduce an autoencoder model and train it through constraints on image pairs and triplets., We show the role of feature dimensionality and adversarial training theoretically and experimentally., We formally prove the existence of the reference ambiguity, which is inherently present in the disentangling task when weakly labeled data is used., The numerical value of a factor has different meaning in different reference frames., When the reference depends on other factors, transferring that factor becomes ambiguous., We demonstrate experimentally that the proposed model can successfully transfer attributes on several datasets, but show also cases when the reference ambiguity occurs.
",15,5.735955056179775,11.866666666666667
394,"['In information retrieval, learning to rank constructs a machine-based ranking model which given a query, sorts the search results by their degree of relevance or importance to the query.', 'Neural networks have been successfully applied to this problem, and in this paper, we propose an attention-based deep neural network which better incorporates different embeddings of the queries and search results with an attention-based mechanism.', 'This model also applies a decoder mechanism to learn the ranks of the search results in a listwise fashion.', 'The embeddings are trained with convolutional neural networks or the word2vec model.', 'We demonstrate the performance of this model with image retrieval and text querying data sets.']","[0, 1, 0, 0, 0]","[0.1764705777168274, 0.20512820780277252, 0.07999999821186066, 0.19999998807907104, 0.17391303181648254]",BJgxzlSFvr,"['learning to rank with several embeddings and attentions', 'Proposes to use attention to combine multiple input representations for both query and search results in the learning to rank task.']","['information retrieval  learning rank construct machinebased ranking model given query  sort search result degree relevance importance query ', 'neural network successfully applied problem  paper  propose attentionbased deep neural network better incorporates different embeddings query search result attentionbased mechanism ', 'model also applies decoder mechanism learn rank search result listwise fashion ', 'embeddings trained convolutional neural network word2vec model ', 'demonstrate performance model image retrieval text querying data set ']","In information retrieval, learning to rank constructs a machine-based ranking model which given a query, sorts the search results by their degree of relevance or importance to the query., Neural networks have been successfully applied to this problem, and in this paper, we propose an attention-based deep neural network which better incorporates different embeddings of the queries and search results with an attention-based mechanism., This model also applies a decoder mechanism to learn the ranks of the search results in a listwise fashion., The embeddings are trained with convolutional neural networks or the word2vec model., We demonstrate the performance of this model with image retrieval and text querying data sets.",9,5.545454545454546,12.222222222222221
395,"['Computational neuroscience aims to fit reliable models of in vivo neural activity and interpret them as abstract computations.', 'Recent work has shown that functional diversity of neurons may be limited to that of relatively few cell types; other work has shown that incorporating constraints into artificial neural networks (ANNs) can improve their ability to mimic neural data.', 'Here we develop an algorithm that takes as input recordings of neural activity and returns clusters of neurons by cell type and models of neural activity constrained by these clusters.', 'The resulting models are both more predictive and more interpretable, revealing the contributions of functional cell types to neural computation and ultimately informing the design of future ANNs.']","[0, 0, 1, 0]","[0.29999998211860657, 0.18867923319339752, 0.8888888955116272, 0.21739129722118378]",SJl24XtLIB,['We developed an algorithm that takes as input recordings of neural activity and returns clusters of neurons by cell type and models of neural activity constrained by these clusters.'],"['computational neuroscience aim fit reliable model vivo neural activity interpret abstract computation ', 'recent work shown functional diversity neuron may limited relatively cell type  work shown incorporating constraint artificial neural network  anns  improve ability mimic neural data ', 'develop algorithm take input recording neural activity return cluster neuron cell type model neural activity constrained cluster ', 'resulting model predictive interpretable  revealing contribution functional cell type neural computation ultimately informing design future anns ']","Computational neuroscience aims to fit reliable models of in vivo neural activity and interpret them as abstract computations., Recent work has shown that functional diversity of neurons may be limited to that of relatively few cell types; other work has shown that incorporating constraints into artificial neural networks (ANNs) can improve their ability to mimic neural data., Here we develop an algorithm that takes as input recordings of neural activity and returns clusters of neurons by cell type and models of neural activity constrained by these clusters., The resulting models are both more predictive and more interpretable, revealing the contributions of functional cell types to neural computation and ultimately informing the design of future ANNs.",5,5.6,23.0
396,"['Graph Neural Networks (GNNs) are a powerful representational tool for solving problems on graph-structured inputs.', 'In almost all cases so far, however, they have been applied to directly recovering a final solution from raw inputs, without explicit guidance on how to structure their problem-solving.', ""Here, instead, we focus on learning in the space of algorithms: we train several state-of-the-art GNN architectures to imitate individual steps of classical graph algorithms, parallel (breadth-first search, Bellman-Ford) as well as sequential (Prim's algorithm)."", 'As graph algorithms usually rely on making discrete decisions within neighbourhoods, we hypothesise that maximisation-based message passing neural networks are best-suited for such objectives, and validate this claim empirically.', 'We also demonstrate how learning in the space of algorithms can yield new opportunities for positive transfer between tasks---showing how learning a shortest-path algorithm can be substantially improved when simultaneously learning a reachability algorithm.']","[0, 0, 1, 0, 0]","[0.0, 0.08695651590824127, 0.23999999463558197, 0.1702127605676651, 0.08695651590824127]",SkgKO0EtvS,"['We supervise graph neural networks to imitate intermediate and step-wise outputs of classical graph algorithms, recovering highly favourable insights.', 'Suggests training neural networks to imitate graph algorithms by learning primitives and subroutines rather than the final output.']","['graph neural network  gnns  powerful representational tool solving problem graphstructured input ', 'almost case far  however  applied directly recovering final solution raw input  without explicit guidance structure problemsolving ', ' instead  focus learning space algorithm  train several stateoftheart gnn architecture imitate individual step classical graph algorithm  parallel  breadthfirst search  bellmanford  well sequential  prim algorithm  ', 'graph algorithm usually rely making discrete decision within neighbourhood  hypothesise maximisationbased message passing neural network bestsuited objective  validate claim empirically ', 'also demonstrate learning space algorithm yield new opportunity positive transfer task  showing learning shortestpath algorithm substantially improved simultaneously learning reachability algorithm ']","Graph Neural Networks (GNNs) are a powerful representational tool for solving problems on graph-structured inputs., In almost all cases so far, however, they have been applied to directly recovering a final solution from raw inputs, without explicit guidance on how to structure their problem-solving., Here, instead, we focus on learning in the space of algorithms: we train several state-of-the-art GNN architectures to imitate individual steps of classical graph algorithms, parallel (breadth-first search, Bellman-Ford) as well as sequential (Prim's algorithm)., As graph algorithms usually rely on making discrete decisions within neighbourhoods, we hypothesise that maximisation-based message passing neural networks are best-suited for such objectives, and validate this claim empirically., We also demonstrate how learning in the space of algorithms can yield new opportunities for positive transfer between tasks---showing how learning a shortest-path algorithm can be substantially improved when simultaneously learning a reachability algorithm.",14,6.345070422535211,10.142857142857142
397,"['Prospection is an important part of how humans come up with new task plans, but has not been explored in depth in robotics.', 'Predicting multiple task-level is a challenging problem that involves capturing both task semantics and continuous variability over the state of the world.', 'Ideally, we would combine the ability of machine learning to leverage big data for learning the semantics of a task, while using techniques from task planning to reliably generalize to new environment.', 'In this work, we propose a method for learning a model encoding just such a representation for task planning.', 'We learn a neural net that encodes the k most likely outcomes from high level actions from a given world.', 'Our approach creates comprehensible task plans that allow us to predict changes to the environment many time steps into the future.', 'We demonstrate this approach via application to a stacking task in a cluttered environment, where the robot must select between different colored blocks while avoiding obstacles, in order to perform a task.', 'We also show results on a simple navigation task.', 'Our algorithm generates realistic image and pose predictions at multiple points in a given task.\n']","[0, 0, 0, 0, 0, 0, 0, 1, 0]","[0.0555555522441864, 0.0, 0.04878048226237297, 0.06666666269302368, 0.0624999962747097, 0.0, 0.04878048226237297, 0.08695651590824127, 0.0]",rkh-agjMG,"['We describe an architecture for generating diverse hypotheses for intermediate goals during robotic manipulation tasks.', 'Evaluates the quality of a proposed generative predictive model to generate plans for robot execution.', 'This paper proposes a method for learning a high-level transition function that is useful for task planning.']","['prospection important part human come new task plan  explored depth robotics ', 'predicting multiple tasklevel challenging problem involves capturing task semantics continuous variability state world ', 'ideally  would combine ability machine learning leverage big data learning semantics task  using technique task planning reliably generalize new environment ', 'work  propose method learning model encoding representation task planning ', 'learn neural net encodes k likely outcome high level action given world ', 'approach creates comprehensible task plan allow u predict change environment many time step future ', 'demonstrate approach via application stacking task cluttered environment  robot must select different colored block avoiding obstacle  order perform task ', 'also show result simple navigation task ', 'algorithm generates realistic image pose prediction multiple point given task ']","Prospection is an important part of how humans come up with new task plans, but has not been explored in depth in robotics., Predicting multiple task-level is a challenging problem that involves capturing both task semantics and continuous variability over the state of the world., Ideally, we would combine the ability of machine learning to leverage big data for learning the semantics of a task, while using techniques from task planning to reliably generalize to new environment., In this work, we propose a method for learning a model encoding just such a representation for task planning., We learn a neural net that encodes the k most likely outcomes from high level actions from a given world., Our approach creates comprehensible task plans that allow us to predict changes to the environment many time steps into the future., We demonstrate this approach via application to a stacking task in a cluttered environment, where the robot must select between different colored blocks while avoiding obstacles, in order to perform a task., We also show results on a simple navigation task., Our algorithm generates realistic image and pose predictions at multiple points in a given task.
",15,5.103626943005182,12.866666666666667
398,"['Adaptive gradient algorithms perform gradient-based updates using the history of gradients and are ubiquitous in training deep neural networks.', 'While adaptive gradient methods theory is well understood for minimization problems, the underlying factors driving their empirical success in min-max problems such as GANs remain unclear.', 'In this paper, we aim at bridging  this gap from both theoretical and empirical perspectives.', 'First, we analyze a variant of Optimistic Stochastic Gradient (OSG) proposed in~\\citep{daskalakis2017training} for solving a class of non-convex non-concave min-max problem and establish $O(\\epsilon^{-4})$ complexity for finding $\\epsilon$-first-order stationary point, in which the algorithm only requires invoking one stochastic first-order oracle while enjoying state-of-the-art iteration complexity achieved by stochastic extragradient method by~\\citep{iusem2017extragradient}.', 'Then we propose an adaptive variant of OSG named Optimistic Adagrad (OAdagrad) and reveal an \\emph{improved} adaptive complexity $\\widetilde{O}\\left(\\epsilon^{-\\frac{2}{1-\\alpha}}\\right)$~\\footnote{Here $\\widetilde{O}(\\cdot)$ compresses a logarithmic factor of $\\epsilon$.', '}, where $\\alpha$ characterizes the growth rate of the cumulative stochastic gradient and $0\\leq \\alpha\\leq 1/2$.', 'To the best of our knowledge, this is the first work for establishing adaptive complexity in non-convex non-concave min-max optimization.', 'Empirically, our experiments show that indeed adaptive gradient algorithms outperform their non-adaptive counterparts in GAN training.', 'Moreover, this observation can be explained by the slow growth rate of the cumulative stochastic gradient, as observed empirically.']","[0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.20408162474632263, 0.3214285671710968, 0.09090908616781235, 0.23376622796058655, 0.11320754140615463, 0.17777776718139648, 0.2857142686843872, 0.260869562625885, 0.1666666567325592]",SJxIm0VtwH,"['This paper provides novel analysis of adaptive gradient algorithms for solving non-convex non-concave min-max problems as GANs, and explains the reason why adaptive gradient methods outperform its non-adaptive counterparts by empirical studies.', 'Develops algorithms for the solution of variational inequalities in the stochastic setting, proposing a variation of the extragradient method.']","['adaptive gradient algorithm perform gradientbased update using history gradient ubiquitous training deep neural network ', 'adaptive gradient method theory well understood minimization problem  underlying factor driving empirical success minmax problem gans remain unclear ', 'paper  aim bridging gap theoretical empirical perspective ', 'first  analyze variant optimistic stochastic gradient  osg  proposed incitep  daskalakis2017training  solving class nonconvex nonconcave minmax problem establish   epsilon  4    complexity finding  epsilon  firstorder stationary point  algorithm requires invoking one stochastic firstorder oracle enjoying stateoftheart iteration complexity achieved stochastic extragradient method bycitep  iusem2017extragradient  ', 'propose adaptive variant osg named optimistic adagrad  oadagrad  reveal emph  improved  adaptive complexity  widetilde   left  epsilon  frac  2   1alpha   right   footnote   widetilde    cdot   compress logarithmic factor  epsilon  ', '   alpha  characterizes growth rate cumulative stochastic gradient  0leq alphaleq 12  ', 'best knowledge  first work establishing adaptive complexity nonconvex nonconcave minmax optimization ', 'empirically  experiment show indeed adaptive gradient algorithm outperform nonadaptive counterpart gan training ', 'moreover  observation explained slow growth rate cumulative stochastic gradient  observed empirically ']","Adaptive gradient algorithms perform gradient-based updates using the history of gradients and are ubiquitous in training deep neural networks., While adaptive gradient methods theory is well understood for minimization problems, the underlying factors driving their empirical success in min-max problems such as GANs remain unclear., In this paper, we aim at bridging  this gap from both theoretical and empirical perspectives., First, we analyze a variant of Optimistic Stochastic Gradient (OSG) proposed in~\citep{daskalakis2017training} for solving a class of non-convex non-concave min-max problem and establish $O(\epsilon^{-4})$ complexity for finding $\epsilon$-first-order stationary point, in which the algorithm only requires invoking one stochastic first-order oracle while enjoying state-of-the-art iteration complexity achieved by stochastic extragradient method by~\citep{iusem2017extragradient}., Then we propose an adaptive variant of OSG named Optimistic Adagrad (OAdagrad) and reveal an \emph{improved} adaptive complexity $\widetilde{O}\left(\epsilon^{-\frac{2}{1-\alpha}}\right)$~\footnote{Here $\widetilde{O}(\cdot)$ compresses a logarithmic factor of $\epsilon$., }, where $\alpha$ characterizes the growth rate of the cumulative stochastic gradient and $0\leq \alpha\leq 1/2$., To the best of our knowledge, this is the first work for establishing adaptive complexity in non-convex non-concave min-max optimization., Empirically, our experiments show that indeed adaptive gradient algorithms outperform their non-adaptive counterparts in GAN training., Moreover, this observation can be explained by the slow growth rate of the cumulative stochastic gradient, as observed empirically.",18,7.090909090909091,11.61111111111111
399,"['We consider the problem of unsupervised learning of a low dimensional, interpretable, latent state of a video containing a moving object.', 'The problem of distilling dynamics from pixels has been extensively considered through the lens of graphical/state space models that exploit Markov structure for cheap computation and structured graphical model priors for enforcing interpretability on latent representations.', 'We take a step towards extending these approaches by discarding the Markov structure; instead, repurposing the recently proposed Gaussian Process Prior Variational Autoencoder for learning sophisticated latent trajectories.', 'We describe the model and perform experiments on a synthetic dataset and see that the model reliably reconstructs smooth dynamics exhibiting U-turns and loops.', 'We also observe that this model may be trained without any beta-annealing or freeze-thaw of training parameters.', 'Training is performed purely end-to-end on the unmodified evidence lower bound objective.', 'This is in contrast to previous works, albeit for slightly different use cases, where application specific training tricks are often required.']","[1, 0, 0, 0, 0, 0, 0]","[0.25641024112701416, 0.1428571343421936, 0.20408162474632263, 0.1428571343421936, 0.10256409645080566, 0.05882352590560913, 0.0]",ryxItJn4FH,['We learn sohpisticated trajectories of an object purely from pixels with a toy video dataset by using a VAE structure with a Gaussian process prior.'],"['consider problem unsupervised learning low dimensional  interpretable  latent state video containing moving object ', 'problem distilling dynamic pixel extensively considered lens graphicalstate space model exploit markov structure cheap computation structured graphical model prior enforcing interpretability latent representation ', 'take step towards extending approach discarding markov structure  instead  repurposing recently proposed gaussian process prior variational autoencoder learning sophisticated latent trajectory ', 'describe model perform experiment synthetic dataset see model reliably reconstructs smooth dynamic exhibiting uturns loop ', 'also observe model may trained without betaannealing freezethaw training parameter ', 'training performed purely endtoend unmodified evidence lower bound objective ', 'contrast previous work  albeit slightly different use case  application specific training trick often required ']","We consider the problem of unsupervised learning of a low dimensional, interpretable, latent state of a video containing a moving object., The problem of distilling dynamics from pixels has been extensively considered through the lens of graphical/state space models that exploit Markov structure for cheap computation and structured graphical model priors for enforcing interpretability on latent representations., We take a step towards extending these approaches by discarding the Markov structure; instead, repurposing the recently proposed Gaussian Process Prior Variational Autoencoder for learning sophisticated latent trajectories., We describe the model and perform experiments on a synthetic dataset and see that the model reliably reconstructs smooth dynamics exhibiting U-turns and loops., We also observe that this model may be trained without any beta-annealing or freeze-thaw of training parameters., Training is performed purely end-to-end on the unmodified evidence lower bound objective., This is in contrast to previous works, albeit for slightly different use cases, where application specific training tricks are often required.",12,6.163522012578617,13.25
400,"['Dreams and our ability to recall them are among the most puzzling questions in sleep research.', 'Specifically, putative differences in brain network dynamics between individuals with high versus low dream recall rates, are still poorly understood.', 'In this study, we addressed this question as a classification problem where we applied deep convolutional networks (CNN) to sleep EEG recordings to predict whether subjects belonged to the high or low dream recall group (HDR and LDR resp.).', 'Our model achieves significant accuracy levels across all the sleep stages, thereby indicating subtle signatures of dream recall in the sleep microstructure.', 'We also visualized the feature space to inspect the subject-specificity of the learned features, thus ensuring that the network captured population level differences.', 'Beyond being the first study to apply deep learning to sleep EEG in order to classify HDR and LDR, guided backpropagation allowed us to visualize the most discriminant features in each sleep stage.', 'The significance of these findings and future directions are discussed.']","[0, 0, 0, 0, 1, 0, 0]","[0.1764705777168274, 0.15789473056793213, 0.18518517911434174, 0.21052631735801697, 0.2631579041481018, 0.08888888359069824, 0.1428571343421936]",rJeT47F8Lr,"['We investigate the neural basis of dream recall using convolutional neural network and feature visualization techniques, like tSNE and guided-backpropagation.']","['dream ability recall among puzzling question sleep research ', 'specifically  putative difference brain network dynamic individual high versus low dream recall rate  still poorly understood ', 'study  addressed question classification problem applied deep convolutional network  cnn  sleep eeg recording predict whether subject belonged high low dream recall group  hdr ldr resp   ', 'model achieves significant accuracy level across sleep stage  thereby indicating subtle signature dream recall sleep microstructure ', 'also visualized feature space inspect subjectspecificity learned feature  thus ensuring network captured population level difference ', 'beyond first study apply deep learning sleep eeg order classify hdr ldr  guided backpropagation allowed u visualize discriminant feature sleep stage ', 'significance finding future direction discussed ']","Dreams and our ability to recall them are among the most puzzling questions in sleep research., Specifically, putative differences in brain network dynamics between individuals with high versus low dream recall rates, are still poorly understood., In this study, we addressed this question as a classification problem where we applied deep convolutional networks (CNN) to sleep EEG recordings to predict whether subjects belonged to the high or low dream recall group (HDR and LDR resp.)., Our model achieves significant accuracy levels across all the sleep stages, thereby indicating subtle signatures of dream recall in the sleep microstructure., We also visualized the feature space to inspect the subject-specificity of the learned features, thus ensuring that the network captured population level differences., Beyond being the first study to apply deep learning to sleep EEG in order to classify HDR and LDR, guided backpropagation allowed us to visualize the most discriminant features in each sleep stage., The significance of these findings and future directions are discussed.",13,5.601226993865031,11.714285714285714
401,"['This paper considers multi-agent reinforcement learning (MARL) in networked system control.', 'Specifically, each agent learns a decentralized control policy based on local observations and messages from connected neighbors.', 'We formulate such a networked MARL (NMARL) problem as a spatiotemporal Markov decision process and introduce a spatial discount factor to stabilize the training of each local agent.', 'Further, we propose a new differentiable communication protocol, called NeurComm, to reduce information loss and non-stationarity in NMARL.', 'Based on experiments in realistic NMARL scenarios of adaptive traffic signal control and cooperative adaptive cruise control, an appropriate spatial discount factor effectively enhances the learning curves of non-communicative MARL algorithms, while NeurComm outperforms existing communication protocols in both learning efficiency and control performance.']","[1, 0, 0, 0, 0]","[0.4000000059604645, 0.19354838132858276, 0.14999999105930328, 0.25, 0.11538460850715637]",Syx7A3NFvH,"['This paper proposes a new formulation and a new communication protocol for networked multi-agent control problems', ""Concerned with N-MARL's where agents update their policy based only on messages from neighboring nodes, showing that introducing a spatial discount factor stabilizes learning.""]","['paper considers multiagent reinforcement learning  marl  networked system control ', 'specifically  agent learns decentralized control policy based local observation message connected neighbor ', 'formulate networked marl  nmarl  problem spatiotemporal markov decision process introduce spatial discount factor stabilize training local agent ', ' propose new differentiable communication protocol  called neurcomm  reduce information loss nonstationarity nmarl ', 'based experiment realistic nmarl scenario adaptive traffic signal control cooperative adaptive cruise control  appropriate spatial discount factor effectively enhances learning curve noncommunicative marl algorithm  neurcomm outperforms existing communication protocol learning efficiency control performance ']","This paper considers multi-agent reinforcement learning (MARL) in networked system control., Specifically, each agent learns a decentralized control policy based on local observations and messages from connected neighbors., We formulate such a networked MARL (NMARL) problem as a spatiotemporal Markov decision process and introduce a spatial discount factor to stabilize the training of each local agent., Further, we propose a new differentiable communication protocol, called NeurComm, to reduce information loss and non-stationarity in NMARL., Based on experiments in realistic NMARL scenarios of adaptive traffic signal control and cooperative adaptive cruise control, an appropriate spatial discount factor effectively enhances the learning curves of non-communicative MARL algorithms, while NeurComm outperforms existing communication protocols in both learning efficiency and control performance.",11,6.584745762711864,10.727272727272727
402,"['Variational Bayesian Inference is a popular methodology for approximating posterior distributions over Bayesian neural network weights.', 'Recent work developing this class of methods has explored ever richer parameterizations of the approximate posterior in the hope of improving performance.', 'In contrast, here we share a curious experimental finding that suggests instead restricting the variational distribution to a more compact parameterization.', 'For a variety of deep Bayesian neural networks trained using Gaussian mean-field variational inference, we find that the posterior standard deviations consistently exhibit strong low-rank structure after convergence.', ""This means that by decomposing these variational parameters into a low-rank factorization, we can make our variational approximation more compact without decreasing the models' performance."", 'Furthermore, we find that such factorized parameterizations improve the signal-to-noise ratio of stochastic gradient estimates of the variational lower bound, resulting in faster convergence.']","[0, 0, 0, 0, 0, 1]","[0.0, 0.0476190410554409, 0.04651162400841713, 0.039215680211782455, 0.12765957415103912, 0.13333332538604736]",SJezFk2VYH,"['Mean field VB uses twice as many parameters; we tie variance parameters in mean field VB without any loss in ELBO, gaining speed and lower variance gradients.']","['variational bayesian inference popular methodology approximating posterior distribution bayesian neural network weight ', 'recent work developing class method explored ever richer parameterizations approximate posterior hope improving performance ', 'contrast  share curious experimental finding suggests instead restricting variational distribution compact parameterization ', 'variety deep bayesian neural network trained using gaussian meanfield variational inference  find posterior standard deviation consistently exhibit strong lowrank structure convergence ', 'mean decomposing variational parameter lowrank factorization  make variational approximation compact without decreasing model  performance ', 'furthermore  find factorized parameterizations improve signaltonoise ratio stochastic gradient estimate variational lower bound  resulting faster convergence ']","Variational Bayesian Inference is a popular methodology for approximating posterior distributions over Bayesian neural network weights., Recent work developing this class of methods has explored ever richer parameterizations of the approximate posterior in the hope of improving performance., In contrast, here we share a curious experimental finding that suggests instead restricting the variational distribution to a more compact parameterization., For a variety of deep Bayesian neural networks trained using Gaussian mean-field variational inference, we find that the posterior standard deviations consistently exhibit strong low-rank structure after convergence., This means that by decomposing these variational parameters into a low-rank factorization, we can make our variational approximation more compact without decreasing the models' performance., Furthermore, we find that such factorized parameterizations improve the signal-to-noise ratio of stochastic gradient estimates of the variational lower bound, resulting in faster convergence.",11,6.661764705882353,12.363636363636363
403,"['Aspect extraction in online product reviews is a key task in sentiment analysis and opinion mining.', 'Training supervised neural networks for aspect extraction is not possible when ground truth aspect labels are not available, while the unsupervised neural topic models fail to capture the particular aspects of interest.', 'In this work, we propose a weakly supervised approach for training neural networks for aspect extraction in cases where only a small set of seed words, i.e., keywords that describe an aspect, are available.', 'Our main contributions are as follows.', 'First, we show that current weakly supervised networks fail to leverage the predictive power of the available seed words by comparing them to a simple bag-of-words classifier.  ', 'Second, we propose a distillation approach for aspect extraction where the seed words are considered by the bag-of-words classifier (teacher) and distilled to the parameters of a neural network (student).', 'Third, we show that regularization encourages the student to consider non-seed words for classification and, as a result, the student outperforms the teacher, which only considers the seed words.', 'Finally, we empirically show that our proposed distillation approach outperforms (by up to 34.4% in F1 score) previous weakly supervised approaches for aspect extraction in six domains of Amazon product reviews.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.13333332538604736, 0.23255813121795654, 0.3265306055545807, 0.0952380895614624, 0.1463414579629898, 0.2380952388048172, 0.1538461446762085, 0.1304347813129425]",HyxoAoxOwN,"['We effectively leverage a few keywords as weak supervision for training neural networks for aspect extraction.', 'Discusses a variant of knowledge distillation which uses a ""teacher"" based on a bag-of-words classifier with seed words and a ""student"" which is an embedding-based neural network.']","['aspect extraction online product review key task sentiment analysis opinion mining ', 'training supervised neural network aspect extraction possible ground truth aspect label available  unsupervised neural topic model fail capture particular aspect interest ', 'work  propose weakly supervised approach training neural network aspect extraction case small set seed word  ie  keywords describe aspect  available ', 'main contribution follows ', 'first  show current weakly supervised network fail leverage predictive power available seed word comparing simple bagofwords classifier ', 'second  propose distillation approach aspect extraction seed word considered bagofwords classifier  teacher  distilled parameter neural network  student  ', 'third  show regularization encourages student consider nonseed word classification  result  student outperforms teacher  considers seed word ', 'finally  empirically show proposed distillation approach outperforms  344  f1 score  previous weakly supervised approach aspect extraction six domain amazon product review ']","Aspect extraction in online product reviews is a key task in sentiment analysis and opinion mining., Training supervised neural networks for aspect extraction is not possible when ground truth aspect labels are not available, while the unsupervised neural topic models fail to capture the particular aspects of interest., In this work, we propose a weakly supervised approach for training neural networks for aspect extraction in cases where only a small set of seed words, i.e., keywords that describe an aspect, are available., Our main contributions are as follows., First, we show that current weakly supervised networks fail to leverage the predictive power of the available seed words by comparing them to a simple bag-of-words classifier.  , Second, we propose a distillation approach for aspect extraction where the seed words are considered by the bag-of-words classifier (teacher) and distilled to the parameters of a neural network (student)., Third, we show that regularization encourages the student to consider non-seed words for classification and, as a result, the student outperforms the teacher, which only considers the seed words., Finally, we empirically show that our proposed distillation approach outperforms (by up to 34.4% in F1 score) previous weakly supervised approaches for aspect extraction in six domains of Amazon product reviews.",20,5.5512195121951216,10.25
404,"['Forming perceptual groups and individuating objects in visual scenes is an essential step towards visual intelligence.', 'This ability is thought to arise in the brain from computations implemented by bottom-up, horizontal, and top-down connections between neurons.', 'However, the relative contributions of these connections to perceptual grouping are poorly understood.', 'We address this question by systematically evaluating neural network architectures featuring combinations of these connections on two synthetic visual tasks, which stress low-level ""Gestalt"" vs. high-level object cues for perceptual grouping.', 'We show that increasing the difficulty of either task strains learning for networks that rely solely on bottom-up processing.', 'Horizontal connections resolve this limitation on tasks with Gestalt cues by supporting incremental spatial propagation of activities, whereas top-down connections rescue learning on tasks with high-level object cues by modifying coarse predictions about the position of the target object.', 'Our findings dissociate the computational roles of bottom-up, horizontal and top-down connectivity, and demonstrate how a model featuring all of these interactions can more flexibly learn to form perceptual groups.']","[0, 0, 1, 0, 0, 0, 0]","[0.1875, 0.21621620655059814, 0.2666666507720947, 0.1666666567325592, 0.05714285373687744, 0.12765957415103912, 0.13333332538604736]",HJxrVA4FDS,"['Horizontal and top-down feedback connections are responsible for complementary perceptual grouping strategies in biological and recurrent vision systems.', 'Using neural networks as a computational model of the brain, examines the efficiency of different strategies for solving two visual challenges.']","['forming perceptual group individuating object visual scene essential step towards visual intelligence ', 'ability thought arise brain computation implemented bottomup  horizontal  topdown connection neuron ', 'however  relative contribution connection perceptual grouping poorly understood ', 'address question systematically evaluating neural network architecture featuring combination connection two synthetic visual task  stress lowlevel  gestalt  v highlevel object cue perceptual grouping ', 'show increasing difficulty either task strain learning network rely solely bottomup processing ', 'horizontal connection resolve limitation task gestalt cue supporting incremental spatial propagation activity  whereas topdown connection rescue learning task highlevel object cue modifying coarse prediction position target object ', 'finding dissociate computational role bottomup  horizontal topdown connectivity  demonstrate model featuring interaction flexibly learn form perceptual group ']","Forming perceptual groups and individuating objects in visual scenes is an essential step towards visual intelligence., This ability is thought to arise in the brain from computations implemented by bottom-up, horizontal, and top-down connections between neurons., However, the relative contributions of these connections to perceptual grouping are poorly understood., We address this question by systematically evaluating neural network architectures featuring combinations of these connections on two synthetic visual tasks, which stress low-level ""Gestalt"" vs. high-level object cues for perceptual grouping., We show that increasing the difficulty of either task strains learning for networks that rely solely on bottom-up processing., Horizontal connections resolve this limitation on tasks with Gestalt cues by supporting incremental spatial propagation of activities, whereas top-down connections rescue learning on tasks with high-level object cues by modifying coarse predictions about the position of the target object., Our findings dissociate the computational roles of bottom-up, horizontal and top-down connectivity, and demonstrate how a model featuring all of these interactions can more flexibly learn to form perceptual groups.",14,6.339285714285714,12.0
405,"['Generative adversarial networks have seen rapid development in recent years and have led to remarkable improvements in generative modelling of images.', 'However, their application in the audio domain has received limited attention,\nand autoregressive models, such as WaveNet, remain the state of the art in generative modelling of audio signals such as human speech.', 'To address this paucity, we introduce GAN-TTS, a Generative Adversarial Network for Text-to-Speech.\n', 'Our architecture is composed of a conditional feed-forward generator producing raw speech audio, and an ensemble of discriminators which operate on random windows of different sizes.', 'The discriminators analyse the audio both in terms of general realism, as well as how well the audio corresponds to the utterance that should be pronounced.  ', 'To measure the performance of GAN-TTS, we employ both subjective human evaluation (MOS - Mean Opinion Score), as well as novel quantitative metrics (Frchet DeepSpeech Distance and Kernel DeepSpeech Distance), which we find to be well correlated with MOS.', 'We show that GAN-TTS is capable of generating high-fidelity speech with naturalness comparable to the state-of-the-art models, and unlike autoregressive models, it is highly parallelisable thanks to an efficient feed-forward generator.', 'Listen to GAN-TTS reading this abstract at http://tiny.cc/gantts.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.0555555522441864, 0.0, 0.4516128897666931, 0.09756097197532654, 0.0, 0.1538461446762085, 0.04444443807005882, 0.0]",r1gfQgSFDr,"['We introduce GAN-TTS, a Generative Adversarial Network for Text-to-Speech, which achieves Mean Opinion Score (MOS) 4.2.', 'Solves the GAN challenge in raw waveform synthesis and begins to close the existing performance gap between autoregressive models and GANs for raw audios.']","['generative adversarial network seen rapid development recent year led remarkable improvement generative modelling image ', 'however  application audio domain received limited attention  autoregressive model  wavenet  remain state art generative modelling audio signal human speech ', 'address paucity  introduce gantts  generative adversarial network texttospeech ', 'architecture composed conditional feedforward generator producing raw speech audio  ensemble discriminator operate random window different size ', 'discriminator analyse audio term general realism  well well audio corresponds utterance pronounced ', 'measure performance gantts  employ subjective human evaluation  mo  mean opinion score   well novel quantitative metric  frchet deepspeech distance kernel deepspeech distance   find well correlated mo ', 'show gantts capable generating highfidelity speech naturalness comparable stateoftheart model  unlike autoregressive model  highly parallelisable thanks efficient feedforward generator ', 'listen gantts reading abstract http  tinyccgantts ']","Generative adversarial networks have seen rapid development in recent years and have led to remarkable improvements in generative modelling of images., However, their application in the audio domain has received limited attention,
and autoregressive models, such as WaveNet, remain the state of the art in generative modelling of audio signals such as human speech., To address this paucity, we introduce GAN-TTS, a Generative Adversarial Network for Text-to-Speech.
, Our architecture is composed of a conditional feed-forward generator producing raw speech audio, and an ensemble of discriminators which operate on random windows of different sizes., The discriminators analyse the audio both in terms of general realism, as well as how well the audio corresponds to the utterance that should be pronounced.  , To measure the performance of GAN-TTS, we employ both subjective human evaluation (MOS - Mean Opinion Score), as well as novel quantitative metrics (Frchet DeepSpeech Distance and Kernel DeepSpeech Distance), which we find to be well correlated with MOS., We show that GAN-TTS is capable of generating high-fidelity speech with naturalness comparable to the state-of-the-art models, and unlike autoregressive models, it is highly parallelisable thanks to an efficient feed-forward generator., Listen to GAN-TTS reading this abstract at http://tiny.cc/gantts.",20,5.8578680203045685,9.85
406,"['This paper proposes a Pruning in Training (PiT) framework of learning to reduce the parameter size of networks.', 'Different from existing works, our PiT framework employs the sparse penalties to train networks and thus help rank the importance of weights and filters.', 'Our PiT algorithms can directly prune the network without any fine-tuning.', 'The pruned networks can still achieve comparable performance to the original networks.', 'In particular, we introduce the (Group) Lasso-type Penalty (L-P /GL-P), and (Group) Split LBI Penalty (S-P / GS-P) to regularize the networks, and a pruning strategy proposed  is used in help prune the network.', 'We conduct the extensive experiments on MNIST, Cifar-10, and miniImageNet.', 'The results validate the efficacy of our proposed methods.', 'Remarkably, on MNIST dataset, our PiT framework can save 17.5% parameter size of LeNet-5, which achieves the 98.47% recognition accuracy.']","[1, 0, 0, 0, 0, 0, 0, 0]","[0.19354838132858276, 0.1666666567325592, 0.1599999964237213, 0.07999999821186066, 0.1860465109348297, 0.0, 0.08695651590824127, 0.0555555522441864]",r1GgDj0cKX,"['we propose an algorithm of learning to prune network by enforcing structure sparsity penalties', 'This paper introduces an approach to pruning while training a network using lasso and split LBI penalties']","['paper proposes pruning training  pit  framework learning reduce parameter size network ', 'different existing work  pit framework employ sparse penalty train network thus help rank importance weight filter ', 'pit algorithm directly prune network without finetuning ', 'pruned network still achieve comparable performance original network ', 'particular  introduce  group  lassotype penalty  lp glp    group  split lbi penalty  sp  gsp  regularize network  pruning strategy proposed used help prune network ', 'conduct extensive experiment mnist  cifar10  miniimagenet ', 'result validate efficacy proposed method ', 'remarkably  mnist dataset  pit framework save 175  parameter size lenet5  achieves 9847  recognition accuracy ']","This paper proposes a Pruning in Training (PiT) framework of learning to reduce the parameter size of networks., Different from existing works, our PiT framework employs the sparse penalties to train networks and thus help rank the importance of weights and filters., Our PiT algorithms can directly prune the network without any fine-tuning., The pruned networks can still achieve comparable performance to the original networks., In particular, we introduce the (Group) Lasso-type Penalty (L-P /GL-P), and (Group) Split LBI Penalty (S-P / GS-P) to regularize the networks, and a pruning strategy proposed  is used in help prune the network., We conduct the extensive experiments on MNIST, Cifar-10, and miniImageNet., The results validate the efficacy of our proposed methods., Remarkably, on MNIST dataset, our PiT framework can save 17.5% parameter size of LeNet-5, which achieves the 98.47% recognition accuracy.",17,5.528985507246377,8.117647058823529
407,"['We first pose the Unsupervised Continual Learning (UCL) problem: learning salient representations from a non-stationary stream of unlabeled data in which the number of object classes varies with time.', 'Given limited labeled data just before inference, those representations can also be associated with specific object types to perform classification.', 'To solve the UCL problem, we propose an architecture that involves a single module, called Self-Taught Associative Memory (STAM), which loosely models the function of a cortical column in the mammalian brain.', 'Hierarchies of STAM modules learn based on a combination of Hebbian learning, online clustering, detection of novel patterns and forgetting outliers, and top-down predictions.', 'We illustrate the operation of STAMs in the context of learning handwritten digits in a continual manner with only 3-12 labeled examples per class.', 'STAMs suggest a promising direction to solve the UCL problem without catastrophic forgetting.']","[0, 0, 0, 0, 0, 1]","[0.2380952388048172, 0.0, 0.22727271914482117, 0.1111111044883728, 0.277777761220932, 0.2857142686843872]",SJxakiC4u4,"['We introduce unsupervised continual learning (UCL) and a neuro-inspired architecture that solves the UCL problem.', 'Proposes using hierachies of STAM modules to solve the UCL problem, providing evidence that the representations the modules learn are well-suited for few-shot classification.']","['first pose unsupervised continual learning  ucl  problem  learning salient representation nonstationary stream unlabeled data number object class varies time ', 'given limited labeled data inference  representation also associated specific object type perform classification ', 'solve ucl problem  propose architecture involves single module  called selftaught associative memory  stam   loosely model function cortical column mammalian brain ', 'hierarchy stam module learn based combination hebbian learning  online clustering  detection novel pattern forgetting outlier  topdown prediction ', 'illustrate operation stams context learning handwritten digit continual manner 312 labeled example per class ', 'stams suggest promising direction solve ucl problem without catastrophic forgetting ']","We first pose the Unsupervised Continual Learning (UCL) problem: learning salient representations from a non-stationary stream of unlabeled data in which the number of object classes varies with time., Given limited labeled data just before inference, those representations can also be associated with specific object types to perform classification., To solve the UCL problem, we propose an architecture that involves a single module, called Self-Taught Associative Memory (STAM), which loosely models the function of a cortical column in the mammalian brain., Hierarchies of STAM modules learn based on a combination of Hebbian learning, online clustering, detection of novel patterns and forgetting outliers, and top-down predictions., We illustrate the operation of STAMs in the context of learning handwritten digits in a continual manner with only 3-12 labeled examples per class., STAMs suggest a promising direction to solve the UCL problem without catastrophic forgetting.",13,5.830985915492958,10.923076923076923
408,"['Recent advances have made it possible to create deep complex-valued neural networks.', 'Despite this progress, the potential power of fully complex intermediate computations and representations has not yet been explored for many challenging learning problems.', 'Building on recent advances, we propose a novel mechanism for extracting signals in the frequency domain.', 'As a case study, we perform audio source separation in the Fourier domain.', 'Our extraction mechanism could be regarded as a local ensembling method that combines a complex-valued convolutional version of Feature-Wise Linear Modulation (FiLM) and a signal averaging operation.', 'We also introduce a new explicit amplitude and phase-aware loss, which is scale and time invariant, taking into account the complex-valued components of the spectrogram.', 'Using the Wall Street Journal Dataset, we compare our phase-aware loss to several others that operate both in the time and frequency domains and demonstrate the effectiveness of our proposed signal extraction method and proposed loss.', 'When operating in the complex-valued frequency domain, our deep complex-valued network substantially outperforms its real-valued counterparts even with half the depth and a third of the parameters.', ""Our proposed mechanism improves significantly deep complex-valued networks' performance and we demonstrate the usefulness of its regularizing effect.""]","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.0, 0.06451612710952759, 0.1666666567325592, 0.2857142686843872, 0.0, 0.06451612710952759, 0.10810810327529907, 0.1249999925494194, 0.07692307233810425]",BylB4kBtwB,"['New Signal Extraction Method in the Fourier Domain', 'Contributes a complex-valued convolutional version of the Feature-Wise Linear Modulation which allows parameter optimization and designs a loss which takes into account magnitude and phase.']","['recent advance made possible create deep complexvalued neural network ', 'despite progress  potential power fully complex intermediate computation representation yet explored many challenging learning problem ', 'building recent advance  propose novel mechanism extracting signal frequency domain ', 'case study  perform audio source separation fourier domain ', 'extraction mechanism could regarded local ensembling method combine complexvalued convolutional version featurewise linear modulation  film  signal averaging operation ', 'also introduce new explicit amplitude phaseaware loss  scale time invariant  taking account complexvalued component spectrogram ', 'using wall street journal dataset  compare phaseaware loss several others operate time frequency domain demonstrate effectiveness proposed signal extraction method proposed loss ', 'operating complexvalued frequency domain  deep complexvalued network substantially outperforms realvalued counterpart even half depth third parameter ', 'proposed mechanism improves significantly deep complexvalued network  performance demonstrate usefulness regularizing effect ']","Recent advances have made it possible to create deep complex-valued neural networks., Despite this progress, the potential power of fully complex intermediate computations and representations has not yet been explored for many challenging learning problems., Building on recent advances, we propose a novel mechanism for extracting signals in the frequency domain., As a case study, we perform audio source separation in the Fourier domain., Our extraction mechanism could be regarded as a local ensembling method that combines a complex-valued convolutional version of Feature-Wise Linear Modulation (FiLM) and a signal averaging operation., We also introduce a new explicit amplitude and phase-aware loss, which is scale and time invariant, taking into account the complex-valued components of the spectrogram., Using the Wall Street Journal Dataset, we compare our phase-aware loss to several others that operate both in the time and frequency domains and demonstrate the effectiveness of our proposed signal extraction method and proposed loss., When operating in the complex-valued frequency domain, our deep complex-valued network substantially outperforms its real-valued counterparts even with half the depth and a third of the parameters., Our proposed mechanism improves significantly deep complex-valued networks' performance and we demonstrate the usefulness of its regularizing effect.",16,6.025380710659898,12.3125
409,"['It is challenging to disentangle an object into two orthogonal spaces of content and style since each can influence the visual observation in a different and unpredictable way.', 'It is rare for one to have access to a large number of data to help separate the influences.', 'In this paper, we present a novel framework to learn this disentangled representation in a completely unsupervised manner.', 'We address this problem in a two-branch Autoencoder framework.', 'For the structural content branch, we project the latent factor into a soft structured point tensor and constrain it with losses derived from prior knowledge.', 'This encourages the branch to distill geometry information.', 'Another branch learns the complementary style information.', ""The two branches form an effective framework that can disentangle object's content-style representation without any human annotation."", 'We evaluate our approach on four image datasets, on which we demonstrate the superior disentanglement and visual analogy quality both in synthesized and real-world data.', 'We are able to generate photo-realistic images with 256x256 resolution that are clearly disentangled in content and style.']","[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.3478260934352875, 0.2222222238779068, 0.6857143044471741, 0.2857142686843872, 0.1860465109348297, 0.14814814925193787, 0.1538461446762085, 0.1111111044883728, 0.1904761791229248, 0.3888888955116272]",SkgsQ8LK_E,"['We present a novel framework to learn the disentangled representation of content and style in a completely unsupervised manner. ', ""Propose model based on autoencoder framework to disentangle an object's representation, results show that model can produce representations capturing content and style.""]","['challenging disentangle object two orthogonal space content style since influence visual observation different unpredictable way ', 'rare one access large number data help separate influence ', 'paper  present novel framework learn disentangled representation completely unsupervised manner ', 'address problem twobranch autoencoder framework ', 'structural content branch  project latent factor soft structured point tensor constrain loss derived prior knowledge ', 'encourages branch distill geometry information ', 'another branch learns complementary style information ', 'two branch form effective framework disentangle object contentstyle representation without human annotation ', 'evaluate approach four image datasets  demonstrate superior disentanglement visual analogy quality synthesized realworld data ', 'able generate photorealistic image 256x256 resolution clearly disentangled content style ']","It is challenging to disentangle an object into two orthogonal spaces of content and style since each can influence the visual observation in a different and unpredictable way., It is rare for one to have access to a large number of data to help separate the influences., In this paper, we present a novel framework to learn this disentangled representation in a completely unsupervised manner., We address this problem in a two-branch Autoencoder framework., For the structural content branch, we project the latent factor into a soft structured point tensor and constrain it with losses derived from prior knowledge., This encourages the branch to distill geometry information., Another branch learns the complementary style information., The two branches form an effective framework that can disentangle object's content-style representation without any human annotation., We evaluate our approach on four image datasets, on which we demonstrate the superior disentanglement and visual analogy quality both in synthesized and real-world data., We are able to generate photo-realistic images with 256x256 resolution that are clearly disentangled in content and style.",13,5.655172413793103,13.384615384615385
410,"['We develop the Y-learner for estimating heterogeneous treatment effects in experimental and observational studies.', 'The Y-learner is designed to leverage the abilities of neural networks to optimize multiple objectives and continually update, which allows for better pooling of underlying feature information between treatment and control groups.', 'We evaluate the Y-learner on three test problems: (1) A set of six simulated data benchmarks from the literature.', '(2) A real-world large-scale experiment on voter persuasion.', '(3) A task from the literature that estimates artificially generated treatment effects on MNIST didgits.', 'The Y-learner achieves state of the art results on two of the three tasks.', 'On the MNIST task, it gets the second best results.']","[1, 0, 0, 0, 0, 0, 0]","[0.19354838132858276, 0.17391303181648254, 0.17142856121063232, 0.0, 0.1249999925494194, 0.13793103396892548, 0.07692307233810425]",ryxnDoRcK7,"['We develop a CATE estimation strategy that takes advantage some of the intriguing properties of neural networks. ', 'Shows improvements to X-learner by modeling the treatment response function, the control response function, and the mapping from imputed treatment effect to the conditional average treatment effect, as neural networks.', 'The authors propose the Y-learner to estimate conditional average treatment effect(CATE), which simultaneously updates the parameters of the outcome functions and the CATE estimator.']","['develop ylearner estimating heterogeneous treatment effect experimental observational study ', 'ylearner designed leverage ability neural network optimize multiple objective continually update  allows better pooling underlying feature information treatment control group ', 'evaluate ylearner three test problem   1  set six simulated data benchmark literature ', ' 2  realworld largescale experiment voter persuasion ', ' 3  task literature estimate artificially generated treatment effect mnist didgits ', 'ylearner achieves state art result two three task ', 'mnist task  get second best result ']","We develop the Y-learner for estimating heterogeneous treatment effects in experimental and observational studies., The Y-learner is designed to leverage the abilities of neural networks to optimize multiple objectives and continually update, which allows for better pooling of underlying feature information between treatment and control groups., We evaluate the Y-learner on three test problems: (1) A set of six simulated data benchmarks from the literature., (2) A real-world large-scale experiment on voter persuasion., (3) A task from the literature that estimates artificially generated treatment effects on MNIST didgits., The Y-learner achieves state of the art results on two of the three tasks., On the MNIST task, it gets the second best results.",9,5.705357142857143,12.444444444444445
411,"['With the rapid proliferation of IoT devices, our cyberspace is nowadays dominated by billions of low-cost computing nodes, which expose an unprecedented heterogeneity to our computing systems.', 'Dynamic analysis, one of the most effective approaches to finding software bugs, has become paralyzed due to the lack of a generic emulator capable of running diverse previously-unseen firmware.', 'In recent years, we have witnessed devastating security breaches targeting IoT devices.', 'These security concerns have significantly hamstrung further evolution of IoT technology.', 'In this work, we present Laelaps, a device emulator specifically designed to run diverse software on low-cost IoT devices.', 'We do not encode into our emulator any specific information about a device.', 'Instead, Laelaps infers the expected behavior of firmware via symbolic-execution-assisted peripheral emulation and generates proper inputs to steer concrete execution on the fly.', 'This unique design feature makes Laelaps the first generic device emulator capable of running diverse firmware with no a priori knowledge about the target device.', 'To demonstrate the capabilities of Laelaps, we deployed two popular dynamic analysis techniques---fuzzing testing and dynamic symbolic execution---on top of our emulator.', 'We successfully identified both self-injected and real-world vulnerabilities.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]",rylaZ6iIDr,['Device-agnostic Firmware Execution'],"['rapid proliferation iot device  cyberspace nowadays dominated billion lowcost computing node  expose unprecedented heterogeneity computing system ', 'dynamic analysis  one effective approach finding software bug  become paralyzed due lack generic emulator capable running diverse previouslyunseen firmware ', 'recent year  witnessed devastating security breach targeting iot device ', 'security concern significantly hamstrung evolution iot technology ', 'work  present laelaps  device emulator specifically designed run diverse software lowcost iot device ', 'encode emulator specific information device ', 'instead  laelaps infers expected behavior firmware via symbolicexecutionassisted peripheral emulation generates proper input steer concrete execution fly ', 'unique design feature make laelaps first generic device emulator capable running diverse firmware priori knowledge target device ', 'demonstrate capability laelaps  deployed two popular dynamic analysis technique  fuzzing testing dynamic symbolic execution  top emulator ', 'successfully identified selfinjected realworld vulnerability ']","With the rapid proliferation of IoT devices, our cyberspace is nowadays dominated by billions of low-cost computing nodes, which expose an unprecedented heterogeneity to our computing systems., Dynamic analysis, one of the most effective approaches to finding software bugs, has become paralyzed due to the lack of a generic emulator capable of running diverse previously-unseen firmware., In recent years, we have witnessed devastating security breaches targeting IoT devices., These security concerns have significantly hamstrung further evolution of IoT technology., In this work, we present Laelaps, a device emulator specifically designed to run diverse software on low-cost IoT devices., We do not encode into our emulator any specific information about a device., Instead, Laelaps infers the expected behavior of firmware via symbolic-execution-assisted peripheral emulation and generates proper inputs to steer concrete execution on the fly., This unique design feature makes Laelaps the first generic device emulator capable of running diverse firmware with no a priori knowledge about the target device., To demonstrate the capabilities of Laelaps, we deployed two popular dynamic analysis techniques---fuzzing testing and dynamic symbolic execution---on top of our emulator., We successfully identified both self-injected and real-world vulnerabilities.",19,6.126984126984127,9.947368421052632
412,"['Deep neural models, such as convolutional and recurrent networks, achieve phenomenal results over spatial data such as images and text.\n', 'However, when considering tabular data, gradient boosting of decision trees (GBDT) remains the method of choice.\n', 'Aiming to bridge this gap, we propose \\emph{deep neural forests} (DNF)\n', '--  a novel architecture that combines elements from decision trees as well as dense residual connections. \n', 'We present the results of extensive empirical study in which we examine the performance of GBDTs, DNFs and (deep) fully-connected networks. \n', 'These results indicate that DNFs achieve comparable results to GBDTs on tabular data, and open the door to end-to-end neural modeling of multi-modal data.', 'To this end, we present a successful application of DNFs as part of a hybrid architecture for a multi-modal driving scene understanding classification task.']","[0, 1, 0, 0, 0, 0, 0]","[0.05882352590560913, 0.3125, 0.0, 0.3125, 0.1666666567325592, 0.21052631735801697, 0.1621621549129486]",Syg9YyBFvS,"['An architecture for tabular data, which emulates branches of decision trees and uses dense residual connectivity ', 'This paper proposes deep neural forest, an algorithm which targets tabular data and integrates strong points of gradient boosting of decision trees.', 'A novel neural network architecture mimicking how decision forests work to tackle the general problem of training deep models for tabular data and showcasing effectiveness on par with GBDT.']","['deep neural model  convolutional recurrent network  achieve phenomenal result spatial data image text ', 'however  considering tabular data  gradient boosting decision tree  gbdt  remains method choice ', 'aiming bridge gap  propose emph  deep neural forest   dnf ', ' novel architecture combine element decision tree well dense residual connection ', 'present result extensive empirical study examine performance gbdts  dnfs  deep  fullyconnected network ', 'result indicate dnfs achieve comparable result gbdts tabular data  open door endtoend neural modeling multimodal data ', 'end  present successful application dnfs part hybrid architecture multimodal driving scene understanding classification task ']","Deep neural models, such as convolutional and recurrent networks, achieve phenomenal results over spatial data such as images and text.
, However, when considering tabular data, gradient boosting of decision trees (GBDT) remains the method of choice.
, Aiming to bridge this gap, we propose \emph{deep neural forests} (DNF)
, --  a novel architecture that combines elements from decision trees as well as dense residual connections. 
, We present the results of extensive empirical study in which we examine the performance of GBDTs, DNFs and (deep) fully-connected networks. 
, These results indicate that DNFs achieve comparable results to GBDTs on tabular data, and open the door to end-to-end neural modeling of multi-modal data., To this end, we present a successful application of DNFs as part of a hybrid architecture for a multi-modal driving scene understanding classification task.",15,5.590909090909091,8.8
413,"['Hyperparameter tuning is one of the most time-consuming workloads in deep learning.', 'State-of-the-art optimizers, such as AdaGrad, RMSProp and Adam, reduce this labor by adaptively tuning an individual learning rate for each variable.', 'Recently researchers have shown renewed interest in simpler methods like momentum SGD as they may yield better results.', 'Motivated by this trend, we ask: can simple adaptive methods, based on SGD perform as well or better?', 'We revisit the momentum SGD algorithm and show that hand-tuning a single learning rate and momentum makes it competitive with Adam.', 'We then analyze its robustness to learning rate misspecification and objective curvature variation.', 'Based on these insights, we design YellowFin, an automatic tuner for momentum and learning rate in SGD.', 'YellowFin optionally uses a negative-feedback loop to compensate for the momentum dynamics in asynchronous settings on the fly.', 'We empirically show YellowFin can converge in fewer iterations than Adam on ResNets and LSTMs for image recognition, language modeling and constituency parsing, with a speedup of up to $3.28$x in synchronous and up to $2.69$x in asynchronous settings.']","[0, 0, 0, 0, 0, 0, 1, 0, 0]","[0.1599999964237213, 0.23529411852359772, 0.12903225421905518, 0.12903225421905518, 0.375, 0.23076923191547394, 0.4000000059604645, 0.13333332538604736, 0.1249999925494194]",SyrGJYlRZ,"['YellowFin is an SGD based optimizer with both momentum and learning rate adaptivity.', 'Proposes a method to automatically tuning the momentum parameter in momentum SGD methods, which achieves better results and fast convergence speed that state-of-the-art Adam algorithm.']","['hyperparameter tuning one timeconsuming workload deep learning ', 'stateoftheart optimizers  adagrad  rmsprop adam  reduce labor adaptively tuning individual learning rate variable ', 'recently researcher shown renewed interest simpler method like momentum sgd may yield better result ', 'motivated trend  ask  simple adaptive method  based sgd perform well better ', 'revisit momentum sgd algorithm show handtuning single learning rate momentum make competitive adam ', 'analyze robustness learning rate misspecification objective curvature variation ', 'based insight  design yellowfin  automatic tuner momentum learning rate sgd ', 'yellowfin optionally us negativefeedback loop compensate momentum dynamic asynchronous setting fly ', 'empirically show yellowfin converge fewer iteration adam resnets lstms image recognition  language modeling constituency parsing  speedup  328  x synchronous  269  x asynchronous setting ']","Hyperparameter tuning is one of the most time-consuming workloads in deep learning., State-of-the-art optimizers, such as AdaGrad, RMSProp and Adam, reduce this labor by adaptively tuning an individual learning rate for each variable., Recently researchers have shown renewed interest in simpler methods like momentum SGD as they may yield better results., Motivated by this trend, we ask: can simple adaptive methods, based on SGD perform as well or better?, We revisit the momentum SGD algorithm and show that hand-tuning a single learning rate and momentum makes it competitive with Adam., We then analyze its robustness to learning rate misspecification and objective curvature variation., Based on these insights, we design YellowFin, an automatic tuner for momentum and learning rate in SGD., YellowFin optionally uses a negative-feedback loop to compensate for the momentum dynamics in asynchronous settings on the fly., We empirically show YellowFin can converge in fewer iterations than Adam on ResNets and LSTMs for image recognition, language modeling and constituency parsing, with a speedup of up to $3.28$x in synchronous and up to $2.69$x in asynchronous settings.",18,5.570621468926554,9.833333333333334
414,"['Robustness and security of machine learning (ML) systems are intertwined, wherein a non-robust ML system (classifiers, regressors, etc.) can be subject to attacks using a wide variety of exploits.', 'With the advent of scalable deep learning methodologies, a lot of emphasis has been put on the robustness of supervised, unsupervised and reinforcement learning algorithms.', 'Here, we study the robustness of the latent space of a deep variational autoencoder (dVAE), an unsupervised generative framework, to show that it is indeed possible to perturb the latent space, flip the class predictions and keep the classification probability approximately equal before and after an attack.', 'This means that an agent that looks at the outputs of a decoder would remain oblivious to an attack.']","[0, 0, 1, 0]","[0.1428571343421936, 0.17142856121063232, 0.23076923191547394, 0.19354838132858276]",B1tExikAW,"['Adversarial attacks on the latent space of variational autoencoders to change the semantic meaning of inputs', 'This paper concerns security and machine learning and proposes a man-in-middle attack that alters the VAE encoding of input data so that decoded output will be misclassified.']","['robustness security machine learning  ml  system intertwined  wherein nonrobust ml system  classifier  regressors  etc   subject attack using wide variety exploit ', 'advent scalable deep learning methodology  lot emphasis put robustness supervised  unsupervised reinforcement learning algorithm ', ' study robustness latent space deep variational autoencoder  dvae   unsupervised generative framework  show indeed possible perturb latent space  flip class prediction keep classification probability approximately equal attack ', 'mean agent look output decoder would remain oblivious attack ']","Robustness and security of machine learning (ML) systems are intertwined, wherein a non-robust ML system (classifiers, regressors, etc.) can be subject to attacks using a wide variety of exploits., With the advent of scalable deep learning methodologies, a lot of emphasis has been put on the robustness of supervised, unsupervised and reinforcement learning algorithms., Here, we study the robustness of the latent space of a deep variational autoencoder (dVAE), an unsupervised generative framework, to show that it is indeed possible to perturb the latent space, flip the class predictions and keep the classification probability approximately equal before and after an attack., This means that an agent that looks at the outputs of a decoder would remain oblivious to an attack.",13,5.425,8.571428571428571
415,"['Graph-based dependency parsing consists of two steps: first, an encoder produces a feature representation for each parsing substructure of the input sentence, which is then used to compute a score for the substructure; and second, a decoder} finds the parse tree whose substructures have the largest total score.', 'Over the past few years, powerful neural techniques have been introduced into the encoding step which substantially increases parsing accuracies.', 'However, advanced decoding techniques, in particular high-order decoding, have seen a decline in usage.', 'It is widely believed that contextualized features produced by neural encoders can help capture high-order decoding information and hence diminish the need for a high-order decoder.', 'In this paper, we empirically evaluate the combinations of different neural and non-neural encoders with first- and second-order decoders and provide a comprehensive analysis about the effectiveness of these combinations with varied training data sizes.', 'We find that: first, when there is large training data, a strong neural encoder with first-order decoding is sufficient to achieve high parsing accuracy and only slightly lags behind the combination of neural encoding and second-order decoding; second, with small training data, a non-neural encoder with a second-order decoder outperforms the other combinations in most cases.   ']","[0, 0, 0, 0, 1, 0]","[0.18518517911434174, 0.11764705181121826, 0.0, 0.14999999105930328, 0.22727271914482117, 0.13333332538604736]",r1ehEgHKwH,"['An empirical study that examines the effectiveness of different encoder-decoder combinations for the task of dependency parsing', 'Empirically analyzes various encoders, decoders, and their dependencies for graph-based dependency parsing.']","['graphbased dependency parsing consists two step  first  encoder produce feature representation parsing substructure input sentence  used compute score substructure  second  decoder  find parse tree whose substructure largest total score ', 'past year  powerful neural technique introduced encoding step substantially increase parsing accuracy ', 'however  advanced decoding technique  particular highorder decoding  seen decline usage ', 'widely believed contextualized feature produced neural encoders help capture highorder decoding information hence diminish need highorder decoder ', 'paper  empirically evaluate combination different neural nonneural encoders first secondorder decoder provide comprehensive analysis effectiveness combination varied training data size ', 'find  first  large training data  strong neural encoder firstorder decoding sufficient achieve high parsing accuracy slightly lag behind combination neural encoding secondorder decoding  second  small training data  nonneural encoder secondorder decoder outperforms combination case ']","Graph-based dependency parsing consists of two steps: first, an encoder produces a feature representation for each parsing substructure of the input sentence, which is then used to compute a score for the substructure; and second, a decoder} finds the parse tree whose substructures have the largest total score., Over the past few years, powerful neural techniques have been introduced into the encoding step which substantially increases parsing accuracies., However, advanced decoding techniques, in particular high-order decoding, have seen a decline in usage., It is widely believed that contextualized features produced by neural encoders can help capture high-order decoding information and hence diminish the need for a high-order decoder., In this paper, we empirically evaluate the combinations of different neural and non-neural encoders with first- and second-order decoders and provide a comprehensive analysis about the effectiveness of these combinations with varied training data sizes., We find that: first, when there is large training data, a strong neural encoder with first-order decoding is sufficient to achieve high parsing accuracy and only slightly lags behind the combination of neural encoding and second-order decoding; second, with small training data, a non-neural encoder with a second-order decoder outperforms the other combinations in most cases.   ",18,5.85929648241206,11.055555555555555
416,"['Meta-learning will be crucial to creating lifelong, generalizable AI.', 'In practice, however, it is hard to define the meta-training task distribution that is used to train meta-learners.', 'If made too small, tasks are too similar for a model to meaningfully generalize.', 'If made too large, generalization becomes incredibly difficult.', 'We argue that both problems can be alleviated by introducing a teacher model that controls the sequence of tasks that a meta-learner is trained on.', 'This teacher model is incentivized to start the student meta-learner on simple tasks then adaptively increase task difficulty in response to student progress.', 'While this approach has been previously studied in curriculum generation, our main contribution is in extending it to meta-learning.']","[0, 1, 0, 0, 0, 0, 0]","[0.0, 0.1818181723356247, 0.0, 0.0, 0.0714285671710968, 0.0, 0.0]",rJeG45HsnV,['Teacher that trains meta-learners like humans'],"['metalearning crucial creating lifelong  generalizable ai ', 'practice  however  hard define metatraining task distribution used train metalearners ', 'made small  task similar model meaningfully generalize ', 'made large  generalization becomes incredibly difficult ', 'argue problem alleviated introducing teacher model control sequence task metalearner trained ', 'teacher model incentivized start student metalearner simple task adaptively increase task difficulty response student progress ', 'approach previously studied curriculum generation  main contribution extending metalearning ']","Meta-learning will be crucial to creating lifelong, generalizable AI., In practice, however, it is hard to define the meta-training task distribution that is used to train meta-learners., If made too small, tasks are too similar for a model to meaningfully generalize., If made too large, generalization becomes incredibly difficult., We argue that both problems can be alleviated by introducing a teacher model that controls the sequence of tasks that a meta-learner is trained on., This teacher model is incentivized to start the student meta-learner on simple tasks then adaptively increase task difficulty in response to student progress., While this approach has been previously studied in curriculum generation, our main contribution is in extending it to meta-learning.",13,5.594827586206897,8.923076923076923
417,"['Using higher order knowledge to reduce training data has become a popular research topic.', 'However, the ability for available methods to draw effective decision boundaries is still limited: when training set is small, neural networks will be biased to certain labels.', 'Based on this observation, we consider constraining output probability distribution as higher order domain knowledge.', 'We design a novel algorithm that jointly optimizes output probability distribution on a clustered embedding space to make neural networks draw effective decision boundaries.  ', 'While directly applying probability constraint is not effective, users need to provide additional very weak supervisions: mark some batches that have output distribution greatly differ from target probability distribution.', 'We use experiments to empirically prove that our model can converge to an accuracy higher than other state-of-art semi-supervised learning models with less high quality labeled training examples.']","[0, 0, 0, 1, 0, 0]","[0.07407406717538834, 0.10526315122842789, 0.2142857164144516, 0.4324324131011963, 0.20000000298023224, 0.14999999105930328]",r1esys0Nd4,"['We introduce an embedding space approach to constrain neural network output probability distribution.', 'This paper introduces a method to perform semi-supervised learning with deep neural networks, and the model achieves relatively high accuracy, given a small training size.', 'This paper incorporates label distribution into model learning when a limited number of training instances is available, and proposes two techniques for handling the problem of output label distribution being wrongly biased.']","['using higher order knowledge reduce training data become popular research topic ', 'however  ability available method draw effective decision boundary still limited  training set small  neural network biased certain label ', 'based observation  consider constraining output probability distribution higher order domain knowledge ', 'design novel algorithm jointly optimizes output probability distribution clustered embedding space make neural network draw effective decision boundary ', 'directly applying probability constraint effective  user need provide additional weak supervision  mark batch output distribution greatly differ target probability distribution ', 'use experiment empirically prove model converge accuracy higher stateofart semisupervised learning model le high quality labeled training example ']","Using higher order knowledge to reduce training data has become a popular research topic., However, the ability for available methods to draw effective decision boundaries is still limited: when training set is small, neural networks will be biased to certain labels., Based on this observation, we consider constraining output probability distribution as higher order domain knowledge., We design a novel algorithm that jointly optimizes output probability distribution on a clustered embedding space to make neural networks draw effective decision boundaries.  , While directly applying probability constraint is not effective, users need to provide additional very weak supervisions: mark some batches that have output distribution greatly differ from target probability distribution., We use experiments to empirically prove that our model can converge to an accuracy higher than other state-of-art semi-supervised learning models with less high quality labeled training examples.",10,6.109489051094891,13.7
418,"['We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy).  ', 'Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus.', 'We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis.  ', 'We also present an analysis showing that exposing the deep internals of the pretrained network is crucial, allowing downstream models to mix different types of semi-supervision signals.\n']","[1, 0, 0, 0]","[0.37931033968925476, 0.22727271914482117, 0.3396226465702057, 0.21276594698429108]",SJTCsqMUf,['We introduce a new type of deep contextualized word representation that significantly improves the state of the art for a range of challenging NLP tasks.'],"['introduce new type deep contextualized word representation model  1  complex characteristic word use  eg  syntax semantics    2  us vary across linguistic context  ie  model polysemy  ', 'word vector learned function internal state deep bidirectional language model  bilm   pretrained large text corpus ', 'show representation easily added existing model significantly improve state art across six challenging nlp problem  including question answering  textual entailment sentiment analysis ', 'also present analysis showing exposing deep internals pretrained network crucial  allowing downstream model mix different type semisupervision signal ']","We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy).  , Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus., We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis.  , We also present an analysis showing that exposing the deep internals of the pretrained network is crucial, allowing downstream models to mix different types of semi-supervision signals.
",11,5.603305785123967,11.0
419,"['This work addresses the long-standing problem of robust event localization in the presence of temporally of misaligned labels in the training data.', 'We propose a novel versatile loss function that generalizes a number of training regimes from standard fully-supervised cross-entropy to count-based weakly-supervised learning.', 'Unlike classical models which are constrained to strictly fit the annotations during training, our soft localization learning approach relaxes the reliance on the exact position of labels instead.', 'Training with this new loss function exhibits strong robustness to temporal misalignment of labels, thus alleviating the burden of precise annotation of temporal sequences.', 'We demonstrate state-of-the-art performance against standard benchmarks in a number of challenging experiments and further show that robustness to label noise is not achieved at the expense of raw performance.']","[1, 0, 0, 0, 0]","[0.6111111044883728, 0.29999998211860657, 0.17777776718139648, 0.25, 0.1702127605676651]",SylUzpNFDS,"['This work introduces a novel loss function for the robust training of temporal localization DNN in the presence of misaligned labels.', 'A new loss for training models that predict where events occur in a training sequence with noisy labels by comparing smoothed label and prediction sequence.']","['work address longstanding problem robust event localization presence temporally misaligned label training data ', 'propose novel versatile loss function generalizes number training regime standard fullysupervised crossentropy countbased weaklysupervised learning ', 'unlike classical model constrained strictly fit annotation training  soft localization learning approach relaxes reliance exact position label instead ', 'training new loss function exhibit strong robustness temporal misalignment label  thus alleviating burden precise annotation temporal sequence ', 'demonstrate stateoftheart performance standard benchmark number challenging experiment show robustness label noise achieved expense raw performance ']","This work addresses the long-standing problem of robust event localization in the presence of temporally of misaligned labels in the training data., We propose a novel versatile loss function that generalizes a number of training regimes from standard fully-supervised cross-entropy to count-based weakly-supervised learning., Unlike classical models which are constrained to strictly fit the annotations during training, our soft localization learning approach relaxes the reliance on the exact position of labels instead., Training with this new loss function exhibits strong robustness to temporal misalignment of labels, thus alleviating the burden of precise annotation of temporal sequences., We demonstrate state-of-the-art performance against standard benchmarks in a number of challenging experiments and further show that robustness to label noise is not achieved at the expense of raw performance.",7,6.166666666666667,18.0
420,"['The driving force behind deep networks is their ability to compactly represent rich classes of functions.', 'The primary notion for formally reasoning about this phenomenon is expressive efficiency, which refers to a situation where one network must grow unfeasibly large in order to replicate functions of another.', 'To date, expressive efficiency analyses focused on the architectural feature of depth, showing that deep networks are representationally superior to shallow ones.', 'In this paper we study the expressive efficiency brought forth by connectivity, motivated by the observation that modern networks interconnect their layers in elaborate ways.', 'We focus on dilated convolutional networks, a family of deep models delivering state of the art performance in sequence processing tasks.', 'By introducing and analyzing the concept of mixed tensor decompositions, we prove that interconnecting dilated convolutional networks can lead to expressive efficiency.', 'In particular, we show that even a single connection between intermediate layers can already lead to an almost quadratic gap, which in large-scale settings typically makes the difference between a model that is practical and one that is not.', 'Empirical evaluation demonstrates how the expressive efficiency of connectivity, similarly to that of depth, translates into gains in accuracy.', 'This leads us to believe that expressive efficiency may serve a key role in developing new tools for deep network design.']","[0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.21052631735801697, 0.1538461446762085, 0.27272728085517883, 0.2222222238779068, 0.2380952388048172, 0.6363636255264282, 0.1428571343421936, 0.25, 0.1395348757505417]",S1JHhv6TW,"['We introduce the notion of mixed tensor decompositions, and use it to prove that interconnecting dilated convolutional networks boosts their expressive power.', 'This paper theoretically validates that interconnecting networks with different dilations can lead to expressive efficiency using mixed tensor decomposition.', 'The authors study dilated convolutional networks and show that intertwining two dilated convolutional networks A and B at various stages is more expressively efficient than not intertwining.', ""Shows that the WaveNet's structural assumption of a single perfect binary tree is hindering its performance and that WaveNet-like architectures with more complex mixed tree structures perform better.""]","['driving force behind deep network ability compactly represent rich class function ', 'primary notion formally reasoning phenomenon expressive efficiency  refers situation one network must grow unfeasibly large order replicate function another ', 'date  expressive efficiency analysis focused architectural feature depth  showing deep network representationally superior shallow one ', 'paper study expressive efficiency brought forth connectivity  motivated observation modern network interconnect layer elaborate way ', 'focus dilated convolutional network  family deep model delivering state art performance sequence processing task ', 'introducing analyzing concept mixed tensor decomposition  prove interconnecting dilated convolutional network lead expressive efficiency ', 'particular  show even single connection intermediate layer already lead almost quadratic gap  largescale setting typically make difference model practical one ', 'empirical evaluation demonstrates expressive efficiency connectivity  similarly depth  translates gain accuracy ', 'lead u believe expressive efficiency may serve key role developing new tool deep network design ']","The driving force behind deep networks is their ability to compactly represent rich classes of functions., The primary notion for formally reasoning about this phenomenon is expressive efficiency, which refers to a situation where one network must grow unfeasibly large in order to replicate functions of another., To date, expressive efficiency analyses focused on the architectural feature of depth, showing that deep networks are representationally superior to shallow ones., In this paper we study the expressive efficiency brought forth by connectivity, motivated by the observation that modern networks interconnect their layers in elaborate ways., We focus on dilated convolutional networks, a family of deep models delivering state of the art performance in sequence processing tasks., By introducing and analyzing the concept of mixed tensor decompositions, we prove that interconnecting dilated convolutional networks can lead to expressive efficiency., In particular, we show that even a single connection between intermediate layers can already lead to an almost quadratic gap, which in large-scale settings typically makes the difference between a model that is practical and one that is not., Empirical evaluation demonstrates how the expressive efficiency of connectivity, similarly to that of depth, translates into gains in accuracy., This leads us to believe that expressive efficiency may serve a key role in developing new tools for deep network design.",19,5.7407407407407405,11.368421052631579
421,"['We apply multi-task learning to image classification tasks on MNIST-like datasets.', 'MNIST dataset has been referred to as the {\\em drosophila} of machine learning and has been the testbed of many learning theories.', 'The NotMNIST dataset and the FashionMNIST dataset have been created with the MNIST dataset as reference.', 'In this work, we exploit these MNIST-like datasets for multi-task learning.', 'The datasets are pooled together for learning the parameters of joint classification networks.', 'Then the learned parameters are used as the initial parameters to retrain disjoint classification networks.', 'The baseline recognition model are all-convolution neural networks.', 'Without multi-task learning, the recognition accuracies for MNIST, NotMNIST and FashionMNIST are 99.56\\%, 97.22\\% and 94.32\\% respectively.', 'With multi-task learning to pre-train the networks, the recognition accuracies are respectively 99.70\\%, 97.46\\% and 95.25\\%.', 'The results re-affirm that multi-task learning framework, even with data with different genres, does lead to significant improvement.\n']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.2857142686843872, 0.09999999403953552, 0.0, 0.2857142686843872, 0.125, 0.0, 0.0, 0.09090908616781235, 0.190476194024086, 0.190476194024086]",S1PWi_lC-,"['multi-task learning works ', 'This paper presents a multi-task neural network for classification on MNIST-like datasets']","['apply multitask learning image classification task mnistlike datasets ', 'mnist dataset referred  em drosophila  machine learning testbed many learning theory ', 'notmnist dataset fashionmnist dataset created mnist dataset reference ', 'work  exploit mnistlike datasets multitask learning ', 'datasets pooled together learning parameter joint classification network ', 'learned parameter used initial parameter retrain disjoint classification network ', 'baseline recognition model allconvolution neural network ', 'without multitask learning  recognition accuracy mnist  notmnist fashionmnist 9956   9722  9432  respectively ', 'multitask learning pretrain network  recognition accuracy respectively 9970   9746  9525  ', 'result reaffirm multitask learning framework  even data different genre  lead significant improvement ']","We apply multi-task learning to image classification tasks on MNIST-like datasets., MNIST dataset has been referred to as the {\em drosophila} of machine learning and has been the testbed of many learning theories., The NotMNIST dataset and the FashionMNIST dataset have been created with the MNIST dataset as reference., In this work, we exploit these MNIST-like datasets for multi-task learning., The datasets are pooled together for learning the parameters of joint classification networks., Then the learned parameters are used as the initial parameters to retrain disjoint classification networks., The baseline recognition model are all-convolution neural networks., Without multi-task learning, the recognition accuracies for MNIST, NotMNIST and FashionMNIST are 99.56\%, 97.22\% and 94.32\% respectively., With multi-task learning to pre-train the networks, the recognition accuracies are respectively 99.70\%, 97.46\% and 95.25\%., The results re-affirm that multi-task learning framework, even with data with different genres, does lead to significant improvement.
",18,6.197278911564626,8.166666666666666
422,"['Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network.', 'To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization.', 'This approach provides us with a broad and unifying view on much prior work on this topic.', 'Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal.', 'In particular, they specify a concrete security guarantee that would protect against a well-defined class of adversaries.', 'These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks.', 'They also suggest robustness against a first-order adversary as a natural security guarantee.', 'We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.22641508281230927, 0.19512194395065308, 0.09756097197532654, 0.19999998807907104, 0.24390242993831635, 0.2857142686843872, 0.10810810327529907, 0.260869562625885]",rJzIBfZAb,"['We provide a principled, optimization-based re-look at the notion of adversarial examples, and develop methods that produce models that are adversarially robust against a wide range of adversaries.', 'Investigates a minimax formulation of deep network learning to increase their robustness, using projected gradient descent as the main adversary. ', 'This paper proposes to look at making neural networks resistant to adversarial loss through the framework of saddle-point problems. ']","['recent work demonstrated neural network vulnerable adversarial example  ie  input almost indistinguishable natural data yet classified incorrectly network ', 'address problem  study adversarial robustness neural network lens robust optimization ', 'approach provides u broad unifying view much prior work topic ', 'principled nature also enables u identify method training attacking neural network reliable  certain sense  universal ', 'particular  specify concrete security guarantee would protect welldefined class adversary ', 'method let u train network significantly improved resistance wide range adversarial attack ', 'also suggest robustness firstorder adversary natural security guarantee ', 'believe robustness welldefined class adversary important stepping stone towards fully resistant deep learning model ']","Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network., To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization., This approach provides us with a broad and unifying view on much prior work on this topic., Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal., In particular, they specify a concrete security guarantee that would protect against a well-defined class of adversaries., These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks., They also suggest robustness against a first-order adversary as a natural security guarantee., We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models.",14,5.743589743589744,11.142857142857142
423,"['In recent years there has been a rapid increase in classification methods on graph structured data.', 'Both in graph kernels and graph neural networks, one of the implicit assumptions of successful state-of-the-art models was that incorporating graph isomorphism features into the architecture leads to better empirical performance.', 'However, as we discover in this work, commonly used data sets for graph classification have repeating instances which cause the problem of isomorphism bias, i.e. artificially increasing the accuracy of the models by memorizing target information from the training set.', 'This prevents fair competition of the algorithms and raises a question of the validity of the obtained results.', 'We analyze 54 data sets, previously extensively used for graph-related tasks, on the existence of isomorphism bias, give a set of recommendations to machine learning practitioners to properly set up their models, and open source new data sets for the future experiments.']","[0, 0, 1, 0, 0]","[0.1666666567325592, 0.21276594698429108, 0.28070175647735596, 0.23529411852359772, 0.178571417927742]",rJlUhhVYvS,"['Many graph classification data sets have duplicates, thus raising questions about generalization abilities and fair comparison of the models. ', 'The authors discuss isomorphism bias in graph datasets, the overfitting effect in learning networks whenever graph isomorphism features are incorporated within the model, theoretically analogous to data leakage effects.']","['recent year rapid increase classification method graph structured data ', 'graph kernel graph neural network  one implicit assumption successful stateoftheart model incorporating graph isomorphism feature architecture lead better empirical performance ', 'however  discover work  commonly used data set graph classification repeating instance cause problem isomorphism bias  ie  artificially increasing accuracy model memorizing target information training set ', 'prevents fair competition algorithm raise question validity obtained result ', 'analyze 54 data set  previously extensively used graphrelated task  existence isomorphism bias  give set recommendation machine learning practitioner properly set model  open source new data set future experiment ']","In recent years there has been a rapid increase in classification methods on graph structured data., Both in graph kernels and graph neural networks, one of the implicit assumptions of successful state-of-the-art models was that incorporating graph isomorphism features into the architecture leads to better empirical performance., However, as we discover in this work, commonly used data sets for graph classification have repeating instances which cause the problem of isomorphism bias, i.e. artificially increasing the accuracy of the models by memorizing target information from the training set., This prevents fair competition of the algorithms and raises a question of the validity of the obtained results., We analyze 54 data sets, previously extensively used for graph-related tasks, on the existence of isomorphism bias, give a set of recommendations to machine learning practitioners to properly set up their models, and open source new data sets for the future experiments.",13,5.625850340136054,10.5
424,"['Imitation learning, followed by reinforcement learning algorithms, is a promising paradigm to solve complex control tasks sample-efficiently.', 'However, learning from demonstrations often suffers from the covariate shift problem, which results\n', 'in cascading errors of the learned policy.', 'We introduce a notion of conservatively extrapolated value functions, which provably lead to policies with self-correction.', 'We design an algorithm Value Iteration with Negative Sampling (VINS) that practically learns such value functions with conservative extrapolation.', 'We show that VINS can correct mistakes of the behavioral cloning policy on simulated robotics benchmark tasks.', 'We also propose the algorithm of using VINS to initialize a reinforcement learning algorithm, which is shown to outperform prior works in sample efficiency.']","[0, 0, 0, 1, 0, 0, 0]","[0.08695651590824127, 0.09756097197532654, 0.1111111044883728, 0.5777778029441833, 0.1702127605676651, 0.21739129722118378, 0.23076923191547394]",rke-f6NKvS,"['We introduce a notion of conservatively-extrapolated value functions, which provably lead to policies that can self-correct to stay close to the demonstration states, and learn them with a novel negative sampling technique.', 'An algorithm called value iteration with negative sampling to address the covariate shift problem in imitation learning.']","['imitation learning  followed reinforcement learning algorithm  promising paradigm solve complex control task sampleefficiently ', 'however  learning demonstration often suffers covariate shift problem  result', 'cascading error learned policy ', 'introduce notion conservatively extrapolated value function  provably lead policy selfcorrection ', 'design algorithm value iteration negative sampling  vins  practically learns value function conservative extrapolation ', 'show vins correct mistake behavioral cloning policy simulated robotics benchmark task ', 'also propose algorithm using vins initialize reinforcement learning algorithm  shown outperform prior work sample efficiency ']","Imitation learning, followed by reinforcement learning algorithms, is a promising paradigm to solve complex control tasks sample-efficiently., However, learning from demonstrations often suffers from the covariate shift problem, which results
, in cascading errors of the learned policy., We introduce a notion of conservatively extrapolated value functions, which provably lead to policies with self-correction., We design an algorithm Value Iteration with Negative Sampling (VINS) that practically learns such value functions with conservative extrapolation., We show that VINS can correct mistakes of the behavioral cloning policy on simulated robotics benchmark tasks., We also propose the algorithm of using VINS to initialize a reinforcement learning algorithm, which is shown to outperform prior works in sample efficiency.",13,6.238938053097345,8.692307692307692
425,"['A structured understanding of our world in terms of objects, relations, and hierarchies is an important component of human cognition.', 'Learning such a structured world model from raw sensory data remains a challenge.', 'As a step towards this goal, we introduce Contrastively-trained Structured World Models (C-SWMs).', 'C-SWMs utilize a contrastive approach for representation learning in environments with compositional structure.', 'We structure each state embedding as a set of object representations and their relations, modeled by a graph neural network.', 'This allows objects to be discovered from raw pixel observations without direct supervision as part of the learning process.', 'We evaluate C-SWMs on compositional environments involving multiple interacting objects that can be manipulated independently by an agent, simple Atari games, and a multi-object physics simulation.', 'Our experiments demonstrate that C-SWMs can overcome limitations of models based on pixel reconstruction and outperform typical representatives of this model class in highly structured environments, while learning interpretable object-based representations.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.15789473056793213, 0.25, 0.3636363446712494, 0.060606054961681366, 0.25641024112701416, 0.20512819290161133, 0.1304347813129425, 0.19999998807907104]",H1gax6VtDB,"['Contrastively-trained Structured World Models (C-SWMs) learn object-oriented state representations and a relational model of an environment from raw pixel input.', 'The authors overcome the problem of using pixel-based losses in the construction and learning of structured world models by using a contrastive latent space.']","['structured understanding world term object  relation  hierarchy important component human cognition ', 'learning structured world model raw sensory data remains challenge ', 'step towards goal  introduce contrastivelytrained structured world model  cswms  ', 'cswms utilize contrastive approach representation learning environment compositional structure ', 'structure state embedding set object representation relation  modeled graph neural network ', 'allows object discovered raw pixel observation without direct supervision part learning process ', 'evaluate cswms compositional environment involving multiple interacting object manipulated independently agent  simple atari game  multiobject physic simulation ', 'experiment demonstrate cswms overcome limitation model based pixel reconstruction outperform typical representative model class highly structured environment  learning interpretable objectbased representation ']","A structured understanding of our world in terms of objects, relations, and hierarchies is an important component of human cognition., Learning such a structured world model from raw sensory data remains a challenge., As a step towards this goal, we introduce Contrastively-trained Structured World Models (C-SWMs)., C-SWMs utilize a contrastive approach for representation learning in environments with compositional structure., We structure each state embedding as a set of object representations and their relations, modeled by a graph neural network., This allows objects to be discovered from raw pixel observations without direct supervision as part of the learning process., We evaluate C-SWMs on compositional environments involving multiple interacting objects that can be manipulated independently by an agent, simple Atari games, and a multi-object physics simulation., Our experiments demonstrate that C-SWMs can overcome limitations of models based on pixel reconstruction and outperform typical representatives of this model class in highly structured environments, while learning interpretable object-based representations.",15,6.258064516129032,10.333333333333334
426,"['Neural machine translation (NMT) models learn representations containing substantial linguistic information.', 'However, it is not clear if such information is fully distributed or if some of it can be attributed to individual neurons.', 'We develop unsupervised methods for discovering important neurons in NMT models.', 'Our methods rely on the intuition that different models learn similar properties, and do not require any costly external supervision.', 'We show experimentally that translation quality depends on the discovered neurons, and find that many of them capture common linguistic phenomena.', 'Finally, we show how to control NMT translations in predictable ways, by modifying activations of individual neurons.']","[0, 0, 1, 0, 0, 0]","[0.0, 0.06666666269302368, 0.5454545617103577, 0.12903225421905518, 0.06451612710952759, 0.2142857164144516]",S1M7wGssim,"['Unsupervised methods for finding, analyzing, and controlling important neurons in NMT', 'This work proposes finding ""meaningful"" neurons in Neural Machine Translation models by ranking based on correlation between pairs of models, different epochs, or different datasets, and proposes a controlling mechanism for the models.']","['neural machine translation  nmt  model learn representation containing substantial linguistic information ', 'however  clear information fully distributed attributed individual neuron ', 'develop unsupervised method discovering important neuron nmt model ', 'method rely intuition different model learn similar property  require costly external supervision ', 'show experimentally translation quality depends discovered neuron  find many capture common linguistic phenomenon ', 'finally  show control nmt translation predictable way  modifying activation individual neuron ']","Neural machine translation (NMT) models learn representations containing substantial linguistic information., However, it is not clear if such information is fully distributed or if some of it can be attributed to individual neurons., We develop unsupervised methods for discovering important neurons in NMT models., Our methods rely on the intuition that different models learn similar properties, and do not require any costly external supervision., We show experimentally that translation quality depends on the discovered neurons, and find that many of them capture common linguistic phenomena., Finally, we show how to control NMT translations in predictable ways, by modifying activations of individual neurons.",11,5.9411764705882355,9.272727272727273
427,"['Computations for the softmax function in neural network models are expensive when the number of output classes is large.', 'This can become a significant issue in both training and inference for such models.', 'In this paper, we present Doubly Sparse Softmax (DS-Softmax), Sparse Mixture of Sparse of Sparse Experts, to improve the efficiency for softmax inference.', 'During training, our method learns a two-level class hierarchy by dividing entire output class space into several partially overlapping experts.', 'Each expert is responsible for a learned subset of the output class space and each output class only belongs to a small number of those experts.', 'During inference, our method quickly locates the most probable expert to compute small-scale softmax.', 'Our method is learning-based and requires no knowledge of the output class partition space a priori.', 'We empirically evaluate our method on several real-world tasks and demonstrate that we can achieve significant computation reductions without loss of']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.20512819290161133, 0.11428570747375488, 0.44999998807907104, 0.14999999105930328, 0.1860465109348297, 0.17142856121063232, 0.10810810327529907, 0.0952380895614624]",BJGMMlGKj7,"['We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. ', 'The paper proposes the new Softmax algorithm implementation with two hierarchical levels of sparsity which speeds up the operation in language modeling.']","['computation softmax function neural network model expensive number output class large ', 'become significant issue training inference model ', 'paper  present doubly sparse softmax  dssoftmax   sparse mixture sparse sparse expert  improve efficiency softmax inference ', 'training  method learns twolevel class hierarchy dividing entire output class space several partially overlapping expert ', 'expert responsible learned subset output class space output class belongs small number expert ', 'inference  method quickly locates probable expert compute smallscale softmax ', 'method learningbased requires knowledge output class partition space priori ', 'empirically evaluate method several realworld task demonstrate achieve significant computation reduction without loss']","Computations for the softmax function in neural network models are expensive when the number of output classes is large., This can become a significant issue in both training and inference for such models., In this paper, we present Doubly Sparse Softmax (DS-Softmax), Sparse Mixture of Sparse of Sparse Experts, to improve the efficiency for softmax inference., During training, our method learns a two-level class hierarchy by dividing entire output class space into several partially overlapping experts., Each expert is responsible for a learned subset of the output class space and each output class only belongs to a small number of those experts., During inference, our method quickly locates the most probable expert to compute small-scale softmax., Our method is learning-based and requires no knowledge of the output class partition space a priori., We empirically evaluate our method on several real-world tasks and demonstrate that we can achieve significant computation reductions without loss of",13,5.522875816993464,11.76923076923077
428,"[""Our work presents empirical evidence that layer rotation, i.e. the evolution across training of the cosine distance between each layer's weight vector and its initialization, constitutes an impressively consistent indicator of generalization performance."", ""Compared to previously studied indicators of generalization, we show that layer rotation has the additional benefit of being easily monitored and controlled, as well as having a network-independent optimum: the training procedures during which all layers' weights reach a cosine distance of 1 from their initialization consistently outperform other configurations -by up to 20% test accuracy."", 'Finally, our results also suggest that the study of layer rotation can provide a unified framework to explain the impact of weight decay and adaptive gradient methods on generalization.']","[1, 0, 0]","[0.6666666865348816, 0.18666666746139526, 0.1538461446762085]",B1g4DEB234,"[""This paper presents empirical evidence supporting the discovery of an indicator of generalization: the evolution across training of the cosine distance between each layer's weight vector and its initialization.""]","['work present empirical evidence layer rotation  ie  evolution across training cosine distance layer weight vector initialization  constitutes impressively consistent indicator generalization performance ', 'compared previously studied indicator generalization  show layer rotation additional benefit easily monitored controlled  well networkindependent optimum  training procedure layer  weight reach cosine distance 1 initialization consistently outperform configuration 20  test accuracy ', 'finally  result also suggest study layer rotation provide unified framework explain impact weight decay adaptive gradient method generalization ']","Our work presents empirical evidence that layer rotation, i.e. the evolution across training of the cosine distance between each layer's weight vector and its initialization, constitutes an impressively consistent indicator of generalization performance., Compared to previously studied indicators of generalization, we show that layer rotation has the additional benefit of being easily monitored and controlled, as well as having a network-independent optimum: the training procedures during which all layers' weights reach a cosine distance of 1 from their initialization consistently outperform other configurations -by up to 20% test accuracy., Finally, our results also suggest that the study of layer rotation can provide a unified framework to explain the impact of weight decay and adaptive gradient methods on generalization.",8,6.02542372881356,13.11111111111111
429,"[""Models of code can learn distributed representations of a program's syntax and semantics to predict many non-trivial properties of a program."", 'Recent state-of-the-art models leverage highly structured representations of programs, such as trees, graphs and paths therein (e.g. data-flow relations), which are precise and abundantly available for code.', 'This provides a strong inductive bias towards semantically meaningful relations, yielding more generalizable representations than classical sequence-based models.', 'Unfortunately, these models primarily rely on graph-based message passing to represent relations in code, which makes them de facto local due to the high cost of message-passing steps, quite in contrast to modern, global sequence-based models, such as the Transformer.', 'In this work, we bridge this divide between global and structured models by introducing two new hybrid model families that are both global and incorporate structural bias: Graph Sandwiches, which wrap traditional (gated) graph message-passing layers in sequential message-passing layers; and Graph Relational Embedding Attention Transformers (GREAT for short), which bias traditional Transformers with relational information from graph edge types.', 'By studying a popular, non-trivial program repair task, variable-misuse identification, we explore the relative merits of traditional and hybrid model families for code representation.', 'Starting with a  graph-based model that already improves upon the prior state-of-the-art for this task by 20%, we show that our proposed hybrid models improve an additional 10-15%, while training both faster and using fewer parameters.']","[1, 0, 0, 0, 0, 0, 0]","[0.3636363446712494, 0.1904761791229248, 0.12121211737394333, 0.07843136787414551, 0.1230769231915474, 0.1538461446762085, 0.07999999821186066]",B1lnbRNtwr,"['Models of source code that combine global and structural features learn more powerful representations of programs.', 'A new method to model the source code for the bug repairing task using a sandwich model like [RNN GNN RNN] which significantly improves localization and repair accuracy.']","['model code learn distributed representation program syntax semantics predict many nontrivial property program ', 'recent stateoftheart model leverage highly structured representation program  tree  graph path therein  eg  dataflow relation   precise abundantly available code ', 'provides strong inductive bias towards semantically meaningful relation  yielding generalizable representation classical sequencebased model ', 'unfortunately  model primarily rely graphbased message passing represent relation code  make de facto local due high cost messagepassing step  quite contrast modern  global sequencebased model  transformer ', 'work  bridge divide global structured model introducing two new hybrid model family global incorporate structural bias  graph sandwich  wrap traditional  gated  graph messagepassing layer sequential messagepassing layer  graph relational embedding attention transformer  great short   bias traditional transformer relational information graph edge type ', 'studying popular  nontrivial program repair task  variablemisuse identification  explore relative merit traditional hybrid model family code representation ', 'starting graphbased model already improves upon prior stateoftheart task 20   show proposed hybrid model improve additional 1015   training faster using fewer parameter ']","Models of code can learn distributed representations of a program's syntax and semantics to predict many non-trivial properties of a program., Recent state-of-the-art models leverage highly structured representations of programs, such as trees, graphs and paths therein (e.g. data-flow relations), which are precise and abundantly available for code., This provides a strong inductive bias towards semantically meaningful relations, yielding more generalizable representations than classical sequence-based models., Unfortunately, these models primarily rely on graph-based message passing to represent relations in code, which makes them de facto local due to the high cost of message-passing steps, quite in contrast to modern, global sequence-based models, such as the Transformer., In this work, we bridge this divide between global and structured models by introducing two new hybrid model families that are both global and incorporate structural bias: Graph Sandwiches, which wrap traditional (gated) graph message-passing layers in sequential message-passing layers; and Graph Relational Embedding Attention Transformers (GREAT for short), which bias traditional Transformers with relational information from graph edge types., By studying a popular, non-trivial program repair task, variable-misuse identification, we explore the relative merits of traditional and hybrid model families for code representation., Starting with a  graph-based model that already improves upon the prior state-of-the-art for this task by 20%, we show that our proposed hybrid models improve an additional 10-15%, while training both faster and using fewer parameters.",24,6.225663716814159,9.04
430,"['Recurrent neural networks (RNNs) are particularly well-suited for modeling long-term dependencies in sequential data, but are notoriously hard to train because the error backpropagated in time either vanishes or explodes at an exponential rate.', ""While a number of works attempt to mitigate this effect through gated recurrent units, skip-connections, parametric constraints and design choices, we propose a novel incremental RNN (iRNN), where hidden state vectors keep track of incremental changes, and as such approximate state-vector increments of Rosenblatt's (1962) continuous-time RNNs."", 'iRNN exhibits identity gradients and is able to account for long-term dependencies (LTD).', 'We show that our method is computationally efficient overcoming overheads of many existing methods that attempt to improve RNN training, while suffering no performance degradation.', 'We demonstrate the utility of our approach with extensive experiments and show competitive performance against standard LSTMs on LTD and other non-LTD tasks.\n']","[0, 1, 0, 0, 0]","[0.039215680211782455, 0.09836065024137497, 0.0624999962747097, 0.04651162400841713, 0.0952380895614624]",HylpqA4FwS,"['Incremental-RNNs resolves exploding/vanishing gradient problem by updating state vectors based on difference between previous state and that predicted by an ODE.', 'The authors address the problem of signal propagation in recurrent neural networks by building an attractor system for the signal transition and checking whether it converges to an equilibrium. ']","['recurrent neural network  rnns  particularly wellsuited modeling longterm dependency sequential data  notoriously hard train error backpropagated time either vanishes explodes exponential rate ', 'number work attempt mitigate effect gated recurrent unit  skipconnections  parametric constraint design choice  propose novel incremental rnn  irnn   hidden state vector keep track incremental change  approximate statevector increment rosenblatt  1962  continuoustime rnns ', 'irnn exhibit identity gradient able account longterm dependency  ltd  ', 'show method computationally efficient overcoming overhead many existing method attempt improve rnn training  suffering performance degradation ', 'demonstrate utility approach extensive experiment show competitive performance standard lstms ltd nonltd task ']","Recurrent neural networks (RNNs) are particularly well-suited for modeling long-term dependencies in sequential data, but are notoriously hard to train because the error backpropagated in time either vanishes or explodes at an exponential rate., While a number of works attempt to mitigate this effect through gated recurrent units, skip-connections, parametric constraints and design choices, we propose a novel incremental RNN (iRNN), where hidden state vectors keep track of incremental changes, and as such approximate state-vector increments of Rosenblatt's (1962) continuous-time RNNs., iRNN exhibits identity gradients and is able to account for long-term dependencies (LTD)., We show that our method is computationally efficient overcoming overheads of many existing methods that attempt to improve RNN training, while suffering no performance degradation., We demonstrate the utility of our approach with extensive experiments and show competitive performance against standard LSTMs on LTD and other non-LTD tasks.
",12,6.133802816901408,11.833333333333334
431,"['Recent empirical results on over-parameterized deep networks are marked by a striking absence of the classic U-shaped test error curve: test error keeps decreasing in wider networks.', 'Researchers are actively working on bridging this discrepancy by proposing better complexity measures.', 'Instead, we directly measure prediction bias and variance for four classification and regression tasks on modern deep networks.', 'We find that both bias and variance can decrease as the number of parameters grows.', 'Qualitatively, the phenomenon persists over a number of gradient-based optimizers.', 'To better understand the role of optimization, we decompose the total variance into variance due to training set sampling and variance due to initialization.', 'Variance due to initialization is significant in the under-parameterized regime.', 'In the over-parameterized regime, total variance is much lower and dominated by variance due to sampling.', 'We provide theoretical analysis in a simplified setting that is consistent with our empirical findings.']","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.09756097197532654, 0.0, 0.1764705777168274, 0.25, 0.14814814925193787, 0.1666666567325592, 0.07407406717538834, 0.1875, 0.1875]",B1guPVr2h4,['We provide evidence against classical claims about the bias-variance tradeoff and propose a novel decomposition for variance.'],"['recent empirical result overparameterized deep network marked striking absence classic ushaped test error curve  test error keep decreasing wider network ', 'researcher actively working bridging discrepancy proposing better complexity measure ', 'instead  directly measure prediction bias variance four classification regression task modern deep network ', 'find bias variance decrease number parameter grows ', 'qualitatively  phenomenon persists number gradientbased optimizers ', 'better understand role optimization  decompose total variance variance due training set sampling variance due initialization ', 'variance due initialization significant underparameterized regime ', 'overparameterized regime  total variance much lower dominated variance due sampling ', 'provide theoretical analysis simplified setting consistent empirical finding ']","Recent empirical results on over-parameterized deep networks are marked by a striking absence of the classic U-shaped test error curve: test error keeps decreasing in wider networks., Researchers are actively working on bridging this discrepancy by proposing better complexity measures., Instead, we directly measure prediction bias and variance for four classification and regression tasks on modern deep networks., We find that both bias and variance can decrease as the number of parameters grows., Qualitatively, the phenomenon persists over a number of gradient-based optimizers., To better understand the role of optimization, we decompose the total variance into variance due to training set sampling and variance due to initialization., Variance due to initialization is significant in the under-parameterized regime., In the over-parameterized regime, total variance is much lower and dominated by variance due to sampling., We provide theoretical analysis in a simplified setting that is consistent with our empirical findings.",13,5.9324324324324325,11.384615384615385
432,"['Real world images often contain large amounts of private / sensitive information that should be carefully protected without reducing their utilities.', 'In this paper, we propose a privacy-preserving deep learning framework with a learnable ob- fuscator for the image classification task.', 'Our framework consists of three mod- els: learnable obfuscator, classifier and reconstructor.', 'The learnable obfuscator is used to remove the sensitive information in the images and extract the feature maps from them.', 'The reconstructor plays the role as an attacker, which tries to recover the image from the feature maps extracted by the obfuscator.', 'In order to best protect users privacy in images, we design an adversarial training methodol- ogy for our framework to optimize the obfuscator.', 'Through extensive evaluations on real world datasets, both the numerical metrics and the visualization results demonstrate that our framework is qualified to protect users privacy and achieve a relatively high accuracy on the image classification task.']","[0, 0, 0, 0, 0, 0, 1]","[0.09999999403953552, 0.31578946113586426, 0.12903225421905518, 0.10810810327529907, 0.052631575614213943, 0.1463414579629898, 0.3529411852359772]",rklvnjRqY7,"[""We proposed a novel deep learning image classification framework that can both accurately classify images and protect users' privacy."", 'This paper proposes a framework which preserves the private information in the image and doesnt compromise the usability of the image.', 'This current work suggests using adversarial networks to obfuscate images and thus allow collecting them without privacy concerns to use them for training machine learning models.']","['real world image often contain large amount private  sensitive information carefully protected without reducing utility ', 'paper  propose privacypreserving deep learning framework learnable ob fuscator image classification task ', 'framework consists three mod el  learnable obfuscator  classifier reconstructor ', 'learnable obfuscator used remove sensitive information image extract feature map ', 'reconstructor play role attacker  try recover image feature map extracted obfuscator ', 'order best protect user  privacy image  design adversarial training methodol ogy framework optimize obfuscator ', 'extensive evaluation real world datasets  numerical metric visualization result demonstrate framework qualified protect user  privacy achieve relatively high accuracy image classification task ']","Real world images often contain large amounts of private / sensitive information that should be carefully protected without reducing their utilities., In this paper, we propose a privacy-preserving deep learning framework with a learnable ob- fuscator for the image classification task., Our framework consists of three mod- els: learnable obfuscator, classifier and reconstructor., The learnable obfuscator is used to remove the sensitive information in the images and extract the feature maps from them., The reconstructor plays the role as an attacker, which tries to recover the image from the feature maps extracted by the obfuscator., In order to best protect users privacy in images, we design an adversarial training methodol- ogy for our framework to optimize the obfuscator., Through extensive evaluations on real world datasets, both the numerical metrics and the visualization results demonstrate that our framework is qualified to protect users privacy and achieve a relatively high accuracy on the image classification task.",12,5.688311688311688,12.833333333333334
433,"['Bitcoin is a virtual coinage system that enables users to trade virtually free of a central trusted authority.', 'All transactions on the Bitcoin blockchain are publicly available for viewing, yet as Bitcoin is built mainly for security its original structure does not allow for direct analysis of address transactions. \n', 'Existing analysis methods of the Bitcoin blockchain can be complicated, computationally expensive or inaccurate.', 'We propose a computationally efficient model to analyze bitcoin blockchain addresses and allow for their use with existing machine learning algorithms.', 'We compare our approach against Multi Level Sequence Learners (MLSLs), one of the best performing models on bitcoin address data.']","[0, 0, 0, 1, 0]","[0.0833333283662796, 0.05714285373687744, 0.0, 0.2142857164144516, 0.0]",SJlJegHFvH,"['a 2vec model for cryptocurrency transaction graphs', 'The paper proposes to use an autoencoder, networkX, and node2Vec to predict whether a Bitcoin address will become empty after a year, but the results are worse than an existing baseline.']","['bitcoin virtual coinage system enables user trade virtually free central trusted authority ', 'transaction bitcoin blockchain publicly available viewing  yet bitcoin built mainly security  original structure allow direct analysis address transaction ', 'existing analysis method bitcoin blockchain complicated  computationally expensive inaccurate ', 'propose computationally efficient model analyze bitcoin blockchain address allow use existing machine learning algorithm ', 'compare approach multi level sequence learner  mlsls   one best performing model bitcoin address data ']","Bitcoin is a virtual coinage system that enables users to trade virtually free of a central trusted authority., All transactions on the Bitcoin blockchain are publicly available for viewing, yet as Bitcoin is built mainly for security its original structure does not allow for direct analysis of address transactions. 
, Existing analysis methods of the Bitcoin blockchain can be complicated, computationally expensive or inaccurate., We propose a computationally efficient model to analyze bitcoin blockchain addresses and allow for their use with existing machine learning algorithms., We compare our approach against Multi Level Sequence Learners (MLSLs), one of the best performing models on bitcoin address data.",8,5.826923076923077,13.0
434,"['Despite remarkable empirical success, the training dynamics of generative adversarial networks (GAN), which involves solving a minimax game using stochastic gradients, is still poorly understood.', 'In this work, we analyze last-iterate convergence of simultaneous gradient descent (simGD) and its variants under the assumption of convex-concavity, guided by a continuous-time analysis with differential equations.', 'First, we show that simGD, as is, converges with stochastic sub-gradients under strict convexity in the primal variable.', 'Second, we generalize optimistic simGD to accommodate an optimism rate separate from the learning rate and show its convergence with full gradients.', 'Finally, we present anchored simGD, a new method, and show convergence with stochastic subgradients.']","[1, 0, 0, 0, 0]","[0.1621621549129486, 0.10256409645080566, 0.13333332538604736, 0.060606054961681366, 0.1538461446762085]",BygIjTNtPr,"['Convergence proof of stochastic sub-gradients method and variations on convex-concave minimax problems', 'An anaysis of simultaneous stochastic subgradient, simultaneous gradient with optimism, and simultaneous gradient with anchoring in the context of minmax convex concave games.', 'This paper analyzes the dynamics of stochastic gradient descent when applied to convex-concave games, as well as GD with optimism and a new anchored GD algorithm that converges under weaker assumptions than SGD or SGD with optimism.']","['despite remarkable empirical success  training dynamic generative adversarial network  gan   involves solving minimax game using stochastic gradient  still poorly understood ', 'work  analyze lastiterate convergence simultaneous gradient descent  simgd  variant assumption convexconcavity  guided continuoustime analysis differential equation ', 'first  show simgd   converges stochastic subgradients strict convexity primal variable ', 'second  generalize optimistic simgd accommodate optimism rate separate learning rate show convergence full gradient ', 'finally  present anchored simgd  new method  show convergence stochastic subgradients ']","Despite remarkable empirical success, the training dynamics of generative adversarial networks (GAN), which involves solving a minimax game using stochastic gradients, is still poorly understood., In this work, we analyze last-iterate convergence of simultaneous gradient descent (simGD) and its variants under the assumption of convex-concavity, guided by a continuous-time analysis with differential equations., First, we show that simGD, as is, converges with stochastic sub-gradients under strict convexity in the primal variable., Second, we generalize optimistic simGD to accommodate an optimism rate separate from the learning rate and show its convergence with full gradients., Finally, we present anchored simGD, a new method, and show convergence with stochastic subgradients.",17,6.205607476635514,6.294117647058823
435,"['Small spacecraft now have precise attitude control systems available commercially, allowing them to slew in 3 degrees of freedom, and capture images within short notice.', 'When combined with appropriate software, this agility can significantly increase response rate, revisit time and coverage.', 'In prior work, we have demonstrated an algorithmic framework that combines orbital mechanics, attitude control and scheduling optimization to plan the time-varying, full-body orientation of agile, small spacecraft in a constellation.', 'The proposed schedule optimization would run at the ground station autonomously, and the resultant schedules uplinked to the spacecraft for execution.', 'The algorithm is generalizable over small steerable spacecraft, control capability, sensor specs, imaging requirements, and regions of interest.', 'In this article, we modify the algorithm to run onboard small spacecraft, such that the constellation can make time-sensitive decisions to slew and capture images autonomously, without ground control.', 'We have developed a communication module based on Delay/Disruption Tolerant Networking (DTN) for onboard data management and routing among the satellites, which will work in conjunction with the other modules to optimize the schedule of agile communication and steering.', 'We then apply this preliminary framework on representative constellations to simulate targeted measurements of episodic precipitation events and subsequent urban floods.', 'The command and control efficiency of our agile algorithm is compared to non-agile (11.3x improvement) and non-DTN (21% improvement) constellations.']","[0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.1395348757505417, 0.05882352590560913, 0.2857142686843872, 0.1621621549129486, 0.1111111044883728, 0.08888888359069824, 0.18867924809455872, 0.25641024112701416, 0.1621621549129486]",rJeDNZq5FE,"['We propose an algorithmic framework to schedule constellations of small spacecraft with 3-DOF re-orientation capabilities, networked with inter-sat links.', 'This paper proposes a communication module to optimize the schedule of communication for the problem of spacecraft constellations, and compares the algorithm in distributed and centralized settings.']","['small spacecraft precise attitude control system available commercially  allowing slew 3 degree freedom  capture image within short notice ', 'combined appropriate software  agility significantly increase response rate  revisit time coverage ', 'prior work  demonstrated algorithmic framework combine orbital mechanic  attitude control scheduling optimization plan timevarying  fullbody orientation agile  small spacecraft constellation ', 'proposed schedule optimization would run ground station autonomously  resultant schedule uplinked spacecraft execution ', 'algorithm generalizable small steerable spacecraft  control capability  sensor spec  imaging requirement  region interest ', 'article  modify algorithm run onboard small spacecraft  constellation make timesensitive decision slew capture image autonomously  without ground control ', 'developed communication module based delaydisruption tolerant networking  dtn  onboard data management routing among satellite  work conjunction module optimize schedule agile communication steering ', 'apply preliminary framework representative constellation simulate targeted measurement episodic precipitation event subsequent urban flood ', 'command control efficiency agile algorithm compared nonagile  113x improvement  nondtn  21  improvement  constellation ']","Small spacecraft now have precise attitude control systems available commercially, allowing them to slew in 3 degrees of freedom, and capture images within short notice., When combined with appropriate software, this agility can significantly increase response rate, revisit time and coverage., In prior work, we have demonstrated an algorithmic framework that combines orbital mechanics, attitude control and scheduling optimization to plan the time-varying, full-body orientation of agile, small spacecraft in a constellation., The proposed schedule optimization would run at the ground station autonomously, and the resultant schedules uplinked to the spacecraft for execution., The algorithm is generalizable over small steerable spacecraft, control capability, sensor specs, imaging requirements, and regions of interest., In this article, we modify the algorithm to run onboard small spacecraft, such that the constellation can make time-sensitive decisions to slew and capture images autonomously, without ground control., We have developed a communication module based on Delay/Disruption Tolerant Networking (DTN) for onboard data management and routing among the satellites, which will work in conjunction with the other modules to optimize the schedule of agile communication and steering., We then apply this preliminary framework on representative constellations to simulate targeted measurements of episodic precipitation events and subsequent urban floods., The command and control efficiency of our agile algorithm is compared to non-agile (11.3x improvement) and non-DTN (21% improvement) constellations.",26,6.259090909090909,8.461538461538462
436,"['Importance sampling (IS) is a standard Monte Carlo (MC) tool to compute information about random variables such as moments or quantiles with unknown distributions.  ', 'IS is \nasymptotically consistent as the number of MC samples, and hence deltas (particles) that parameterize the density estimate, go to infinity.', 'However, retaining infinitely many particles is intractable.', 'We propose a scheme for only keeping a \\emph{finite representative subset} of particles and their augmented importance weights that is \\emph{nearly consistent}. To do so in {an online manner}, we approximate importance sampling in two ways.  ', 'First, we replace the deltas by kernels, yielding kernel density estimates (KDEs).  ', 'Second, we sequentially project KDEs onto nearby lower-dimensional subspaces.', 'We characterize the asymptotic bias of this scheme as determined by a compression parameter and kernel bandwidth, which yields a tunable tradeoff between consistency and memory.', 'In experiments,  we observe a favorable tradeoff between memory and accuracy, providing for the first time near-consistent compressions of arbitrary posterior distributions.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.11764705181121826, 0.0, 0.0, 0.1860465109348297, 0.0, 0.0, 0.12121211737394333, 0.06451612710952759]",H1lSFJ34FH,['We proposed a novel compressed kernelized importance sampling algorithm.'],"['importance sampling   standard monte carlo  mc  tool compute information random variable moment quantiles unknown distribution ', 'asymptotically consistent number mc sample  hence delta  particle  parameterize density estimate  go infinity ', 'however  retaining infinitely many particle intractable ', 'propose scheme keeping emph  finite representative subset  particle augmented importance weight emph  nearly consistent    online manner   approximate importance sampling two way ', 'first  replace delta kernel  yielding kernel density estimate  kdes  ', 'second  sequentially project kdes onto nearby lowerdimensional subspace ', 'characterize asymptotic bias scheme determined compression parameter kernel bandwidth  yield tunable tradeoff consistency memory ', 'experiment  observe favorable tradeoff memory accuracy  providing first time nearconsistent compression arbitrary posterior distribution ']","Importance sampling (IS) is a standard Monte Carlo (MC) tool to compute information about random variables such as moments or quantiles with unknown distributions.  , IS is 
asymptotically consistent as the number of MC samples, and hence deltas (particles) that parameterize the density estimate, go to infinity., However, retaining infinitely many particles is intractable., We propose a scheme for only keeping a \emph{finite representative subset} of particles and their augmented importance weights that is \emph{nearly consistent}. To do so in {an online manner}, we approximate importance sampling in two ways.  , First, we replace the deltas by kernels, yielding kernel density estimates (KDEs).  , Second, we sequentially project KDEs onto nearby lower-dimensional subspaces., We characterize the asymptotic bias of this scheme as determined by a compression parameter and kernel bandwidth, which yields a tunable tradeoff between consistency and memory., In experiments,  we observe a favorable tradeoff between memory and accuracy, providing for the first time near-consistent compressions of arbitrary posterior distributions.",18,6.050632911392405,8.31578947368421
437,"['We study the following three fundamental problems about ridge regression: (1) what is the structure of the estimator?', '(2) how to correctly use cross-validation to choose the regularization parameter?', 'and (3) how to accelerate computation without losing too much accuracy?', 'We consider the three problems in a unified large-data linear model.', 'We give a precise representation of ridge regression as a covariance matrix-dependent linear combination of the true parameter and the noise. \n', 'We study the bias of $K$-fold cross-validation for choosing the regularization parameter, and propose a simple bias-correction.', 'We analyze the accuracy of primal and dual sketching for ridge regression, showing they are surprisingly accurate.', 'Our results are illustrated by simulations and by analyzing empirical data.']","[1, 0, 0, 0, 0, 0, 0, 0]","[0.4117647111415863, 0.1428571343421936, 0.06896550953388214, 0.27586206793785095, 0.37837836146354675, 0.4117647111415863, 0.34285715222358704, 0.0714285671710968]",HklRwaEKwB,"['We study the structure of ridge regression in a high-dimensional asymptotic framework, and get insights about cross-validation and sketching.', 'A theoretical study of ridge regression by exploiting a new asymptotic characterisation of the ridge regression estimator.']","['study following three fundamental problem ridge regression   1  structure estimator ', ' 2  correctly use crossvalidation choose regularization parameter ', ' 3  accelerate computation without losing much accuracy ', 'consider three problem unified largedata linear model ', 'give precise representation ridge regression covariance matrixdependent linear combination true parameter noise ', 'study bias  k  fold crossvalidation choosing regularization parameter  propose simple biascorrection ', 'analyze accuracy primal dual sketching ridge regression  showing surprisingly accurate ', 'result illustrated simulation analyzing empirical data ']","We study the following three fundamental problems about ridge regression: (1) what is the structure of the estimator?, (2) how to correctly use cross-validation to choose the regularization parameter?, and (3) how to accelerate computation without losing too much accuracy?, We consider the three problems in a unified large-data linear model., We give a precise representation of ridge regression as a covariance matrix-dependent linear combination of the true parameter and the noise. 
, We study the bias of $K$-fold cross-validation for choosing the regularization parameter, and propose a simple bias-correction., We analyze the accuracy of primal and dual sketching for ridge regression, showing they are surprisingly accurate., Our results are illustrated by simulations and by analyzing empirical data.",10,5.837606837606837,11.7
438,"['Attention mechanisms have advanced the state of the art in several machine learning tasks.', 'Despite significant empirical gains, there is a lack of theoretical analyses on understanding their effectiveness.', 'In this paper, we address this problem by studying the landscape of population and empirical loss functions of attention-based neural networks.', 'Our results show that, under mild assumptions, every local minimum of a two-layer global attention model has low prediction error, and attention models require lower sample complexity than models not employing attention.', 'We then extend our analyses to the popular self-attention model, proving that they deliver consistent predictions with a more expressive class of functions.', 'Additionally, our theoretical results provide several guidelines for designing attention mechanisms.', 'Our findings are validated with satisfactory experimental results on MNIST and IMDB reviews dataset.']","[0, 0, 1, 0, 0, 0, 0]","[0.1764705777168274, 0.1111111044883728, 0.3499999940395355, 0.11999999731779099, 0.22727271914482117, 0.0624999962747097, 0.11428570747375488]",BylDrRNKvH,"['We analyze the loss landscape of neural networks with attention and explain why attention is helpful in training neural networks to achieve good performance.', 'This paper proves from the theoretical perspective that attention networks can generalize better than non-attention baselines for fixed-attention (single-layer and multi-layer) and self-attention in the single layer setting.']","['attention mechanism advanced state art several machine learning task ', 'despite significant empirical gain  lack theoretical analysis understanding effectiveness ', 'paper  address problem studying landscape population empirical loss function attentionbased neural network ', 'result show  mild assumption  every local minimum twolayer global attention model low prediction error  attention model require lower sample complexity model employing attention ', 'extend analysis popular selfattention model  proving deliver consistent prediction expressive class function ', 'additionally  theoretical result provide several guideline designing attention mechanism ', 'finding validated satisfactory experimental result mnist imdb review dataset ']","Attention mechanisms have advanced the state of the art in several machine learning tasks., Despite significant empirical gains, there is a lack of theoretical analyses on understanding their effectiveness., In this paper, we address this problem by studying the landscape of population and empirical loss functions of attention-based neural networks., Our results show that, under mild assumptions, every local minimum of a two-layer global attention model has low prediction error, and attention models require lower sample complexity than models not employing attention., We then extend our analyses to the popular self-attention model, proving that they deliver consistent predictions with a more expressive class of functions., Additionally, our theoretical results provide several guidelines for designing attention mechanisms., Our findings are validated with satisfactory experimental results on MNIST and IMDB reviews dataset.",14,6.1,9.285714285714286
439,"['Recent advances in deep learning techniques has shown the usefulness of the deep neural networks in extracting features required to perform the task at hand.\n', 'However, these features learnt are in particular helpful only for the initial task.', 'This is due to the fact that the features learnt are very task specific and does not capture the most general and task agnostic features of the input.\n', 'In fact the way humans are seen to learn is by disentangling features which task agnostic.', 'This indicates that leaning task agnostic features by disentangling only the most informative features from the input data.\n', 'Recently Variational Auto-Encoders (VAEs) have shown to be the de-facto models to capture the latent variables in a generative sense.\n', 'As these latent features can be represented as continuous and/or discrete variables, this indicates us to use VAE with a mixture of continuous and discrete variables for the latent space.\n', 'We achieve this by performing our experiments using a modified version of joint-vae to learn the disentangled features.\n']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.0, 0.1111111044883728, 0.0, 0.0, 0.0, 0.0, 0.060606058686971664, 0.0]",r1gFDS8aHB,['Mixture Model for Neural Disentanglement'],"['recent advance deep learning technique shown usefulness deep neural network extracting feature required perform task hand ', 'however  feature learnt particular helpful initial task ', 'due fact feature learnt task specific capture general task agnostic feature input ', 'fact way human seen learn disentangling feature task agnostic ', 'indicates leaning task agnostic feature disentangling informative feature input data ', 'recently variational autoencoders  vaes  shown defacto model capture latent variable generative sense ', 'latent feature represented continuous andor discrete variable  indicates u use vae mixture continuous discrete variable latent space ', 'achieve performing experiment using modified version jointvae learn disentangled feature ']","Recent advances in deep learning techniques has shown the usefulness of the deep neural networks in extracting features required to perform the task at hand.
, However, these features learnt are in particular helpful only for the initial task., This is due to the fact that the features learnt are very task specific and does not capture the most general and task agnostic features of the input.
, In fact the way humans are seen to learn is by disentangling features which task agnostic., This indicates that leaning task agnostic features by disentangling only the most informative features from the input data.
, Recently Variational Auto-Encoders (VAEs) have shown to be the de-facto models to capture the latent variables in a generative sense.
, As these latent features can be represented as continuous and/or discrete variables, this indicates us to use VAE with a mixture of continuous and discrete variables for the latent space.
, We achieve this by performing our experiments using a modified version of joint-vae to learn the disentangled features.
",10,5.238095238095238,16.8
440,"['To improve how neural networks function it is crucial to understand their learning process.', 'The information bottleneck theory of deep learning proposes that neural networks achieve good generalization by compressing their representations to disregard information that is not relevant to the task.', 'However, empirical evidence for this theory is conflicting, as compression was only observed when networks used saturating activation functions.', 'In contrast, networks with non-saturating activation functions achieved comparable levels of task performance but did not show compression.', 'In this paper we developed more robust mutual information estimation techniques, that adapt to hidden activity of neural networks and produce more sensitive measurements of activations from all functions, especially unbounded functions.', 'Using these adaptive estimation techniques, we explored compression in networks with a range of different activation functions.', 'With two improved methods of estimation, firstly, we show that saturation of the activation function is not required for compression, and the amount of compression varies between different activation functions.', 'We also find that there is a large amount of variation in compression between different network initializations.', 'Secondary, we see that L2 regularization leads to significantly increased compression, while preventing overfitting.', 'Finally, we show that only compression of the last layer is positively correlated with generalization.']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.11764705181121826, 0.13333332538604736, 0.307692289352417, 0.31578946113586426, 0.3199999928474426, 0.3243243098258972, 0.21739129722118378, 0.1621621549129486, 0.05882352590560913, 0.11428570747375488]",SkeZisA5t7,"['We developed robust mutual information estimates for DNNs and used them to observe compression in networks with non-saturating activation functions', 'This paper studied the popular belief that deep neural networks do information compression for supervised tasks', 'This paper proposes a method for the estimation of mutual information for networks with unbounded activation functions and the use of L2 regularization to induce more compression.']","['improve neural network function crucial understand learning process ', 'information bottleneck theory deep learning proposes neural network achieve good generalization compressing representation disregard information relevant task ', 'however  empirical evidence theory conflicting  compression observed network used saturating activation function ', 'contrast  network nonsaturating activation function achieved comparable level task performance show compression ', 'paper developed robust mutual information estimation technique  adapt hidden activity neural network produce sensitive measurement activation function  especially unbounded function ', 'using adaptive estimation technique  explored compression network range different activation function ', 'two improved method estimation  firstly  show saturation activation function required compression  amount compression varies different activation function ', 'also find large amount variation compression different network initialization ', 'secondary  see l2 regularization lead significantly increased compression  preventing overfitting ', 'finally  show compression last layer positively correlated generalization ']","To improve how neural networks function it is crucial to understand their learning process., The information bottleneck theory of deep learning proposes that neural networks achieve good generalization by compressing their representations to disregard information that is not relevant to the task., However, empirical evidence for this theory is conflicting, as compression was only observed when networks used saturating activation functions., In contrast, networks with non-saturating activation functions achieved comparable levels of task performance but did not show compression., In this paper we developed more robust mutual information estimation techniques, that adapt to hidden activity of neural networks and produce more sensitive measurements of activations from all functions, especially unbounded functions., Using these adaptive estimation techniques, we explored compression in networks with a range of different activation functions., With two improved methods of estimation, firstly, we show that saturation of the activation function is not required for compression, and the amount of compression varies between different activation functions., We also find that there is a large amount of variation in compression between different network initializations., Secondary, we see that L2 regularization leads to significantly increased compression, while preventing overfitting., Finally, we show that only compression of the last layer is positively correlated with generalization.",22,6.25,9.272727272727273
441,"['In this work, we address the problem of musical timbre transfer, where the goal is to manipulate the timbre of a sound sample from one instrument to match another instrument while preserving other musical content, such as pitch, rhythm, and loudness.', 'In principle, one could apply image-based style transfer techniques to a time-frequency representation of an audio signal, but this depends on having a representation that allows independent manipulation of timbre as well as high-quality waveform generation.', 'We introduce TimbreTron, a method for musical timbre transfer which applies image domain style transfer to a time-frequency representation of the audio signal, and then produces a high-quality waveform using a conditional WaveNet synthesizer.', 'We show that the Constant Q Transform (CQT) representation is particularly well-suited to convolutional architectures due to its approximate pitch equivariance.', 'Based on human perceptual evaluations, we confirmed that TimbreTron recognizably transferred the timbre while otherwise preserving the musical content, for both monophonic and polyphonic samples.', 'We made an accompanying demo video here: https://www.cs.toronto.edu/~huang/TimbreTron/index.html which we strongly encourage you to watch before reading the paper.']","[0, 0, 1, 0, 0, 0]","[0.15686273574829102, 0.2448979616165161, 0.4680851101875305, 0.10810810327529907, 0.24390242993831635, 0.09999999403953552]",S1lvm305YQ,"['We present the TimbreTron, a pipeline for perfoming high-quality timbre transfer on musical waveforms using CQT-domain style transfer.', 'A method for converting recordings of a specific musical instrument to another by applying CycleGAN, developed for image style transfer, to transfer spectrograms.', 'The authors use multiple techniques/tools to enable neural timbre transfer (converting music from one instrument to another) without paired training examples. ', 'Describes a model for musical timbre transfer with the results indicating that the proposed system is effective for pitch and tempo transfer, as well as timbre adaptation.']","['work  address problem musical timbre transfer  goal manipulate timbre sound sample one instrument match another instrument preserving musical content  pitch  rhythm  loudness ', 'principle  one could apply imagebased style transfer technique timefrequency representation audio signal  depends representation allows independent manipulation timbre well highquality waveform generation ', 'introduce timbretron  method musical timbre transfer applies  image  domain style transfer timefrequency representation audio signal  produce highquality waveform using conditional wavenet synthesizer ', 'show constant q transform  cqt  representation particularly wellsuited convolutional architecture due approximate pitch equivariance ', 'based human perceptual evaluation  confirmed timbretron recognizably transferred timbre otherwise preserving musical content  monophonic polyphonic sample ', 'made accompanying demo video  http  wwwcstorontoeduhuangtimbretronindexhtml strongly encourage watch reading paper ']","In this work, we address the problem of musical timbre transfer, where the goal is to manipulate the timbre of a sound sample from one instrument to match another instrument while preserving other musical content, such as pitch, rhythm, and loudness., In principle, one could apply image-based style transfer techniques to a time-frequency representation of an audio signal, but this depends on having a representation that allows independent manipulation of timbre as well as high-quality waveform generation., We introduce TimbreTron, a method for musical timbre transfer which applies image domain style transfer to a time-frequency representation of the audio signal, and then produces a high-quality waveform using a conditional WaveNet synthesizer., We show that the Constant Q Transform (CQT) representation is particularly well-suited to convolutional architectures due to its approximate pitch equivariance., Based on human perceptual evaluations, we confirmed that TimbreTron recognizably transferred the timbre while otherwise preserving the musical content, for both monophonic and polyphonic samples., We made an accompanying demo video here: https://www.cs.toronto.edu/~huang/TimbreTron/index.html which we strongly encourage you to watch before reading the paper.",17,6.1875,10.352941176470589
442,"['Neuromorphic hardware tends to pose limits on the connectivity of deep networks that one can run on them.', 'But also generic hardware and software implementations of deep learning run more efficiently for sparse networks.', 'Several methods exist for pruning connections of a neural network after it was trained without connectivity constraints.', 'We present an algorithm, DEEP R, that enables us to train directly a sparsely connected neural network.', 'DEEP R automatically rewires the network during supervised training so that connections are there where they are most needed for the task, while its total number is all the time strictly bounded.', 'We demonstrate that DEEP R can be used to train very sparse feedforward and recurrent neural networks on standard benchmark tasks with just a minor loss in performance.', 'DEEP R is based on a rigorous theoretical foundation that views rewiring as stochastic sampling of network configurations from a posterior.']","[1, 0, 0, 0, 0, 0, 0]","[0.3333333432674408, 0.09756097197532654, 0.1428571343421936, 0.2857142686843872, 0.2222222238779068, 0.30188679695129395, 0.13333332538604736]",BJ_wN01C-,"['The paper presents Deep Rewiring, an algorithm that can be used to train deep neural networks when the network connectivity is severely constrained during training.', 'An approach to implement deep learning directly on sparsely connected graphs, allowing networks to be trained efficiently online and for fast and flexible learning.', 'The authors provide a simple algorithm capable of training with limited memory']","['neuromorphic hardware tends pose limit connectivity deep network one run ', 'also generic hardware software implementation deep learning run efficiently sparse network ', 'several method exist pruning connection neural network trained without connectivity constraint ', 'present algorithm  deep r  enables u train directly sparsely connected neural network ', 'deep r automatically rewires network supervised training connection needed task  total number time strictly bounded ', 'demonstrate deep r used train sparse feedforward recurrent neural network standard benchmark task minor loss performance ', 'deep r based rigorous theoretical foundation view rewiring stochastic sampling network configuration posterior ']","Neuromorphic hardware tends to pose limits on the connectivity of deep networks that one can run on them., But also generic hardware and software implementations of deep learning run more efficiently for sparse networks., Several methods exist for pruning connections of a neural network after it was trained without connectivity constraints., We present an algorithm, DEEP R, that enables us to train directly a sparsely connected neural network., DEEP R automatically rewires the network during supervised training so that connections are there where they are most needed for the task, while its total number is all the time strictly bounded., We demonstrate that DEEP R can be used to train very sparse feedforward and recurrent neural networks on standard benchmark tasks with just a minor loss in performance., DEEP R is based on a rigorous theoretical foundation that views rewiring as stochastic sampling of network configurations from a posterior.",10,5.355704697986577,14.9
443,"[""Deep learning's success has led to larger and larger models to handle more and more complex tasks; trained models can contain millions of parameters."", 'These large models are compute- and memory-intensive, which makes it a challenge to deploy them with minimized latency, throughput, and storage requirements.', 'Some model compression methods have been successfully applied on image classification and detection or language models, but there has been very little work compressing generative adversarial networks (GANs) performing complex tasks.', 'In this paper, we show that a standard model compression technique, weight pruning, cannot be applied to GANs using existing methods.', 'We then develop a self-supervised compression technique which uses the trained discriminator to supervise the training of a compressed generator.', 'We show that this framework has a compelling performance to high degrees of sparsity, generalizes well to new tasks and models, and enables meaningful comparisons between different pruning granularities.']","[0, 0, 0, 0, 0, 1]","[0.16326530277729034, 0.11764705181121826, 0.19999998807907104, 0.2745097875595093, 0.1249999925494194, 0.28070175647735596]",Skl8EkSFDr,"['Existing pruning methods fail when applied to GANs tackling complex tasks, so we present a simple and robust method to prune generators that works well for a wide variety of networks and tasks.', 'The authors propose a modification to the classic distillation method for the task of compressing a network to address the failure of previous solutions when applied to generative adversarial networks.']","['deep learning success led larger larger model handle complex task  trained model contain million parameter ', 'large model compute memoryintensive  make challenge deploy minimized latency  throughput  storage requirement ', 'model compression method successfully applied image classification detection language model  little work compressing generative adversarial network  gans  performing complex task ', 'paper  show standard model compression technique  weight pruning  applied gans using existing method ', 'develop selfsupervised compression technique us trained discriminator supervise training compressed generator ', 'show framework compelling performance high degree sparsity  generalizes well new task model  enables meaningful comparison different pruning granularity ']","Deep learning's success has led to larger and larger models to handle more and more complex tasks; trained models can contain millions of parameters., These large models are compute- and memory-intensive, which makes it a challenge to deploy them with minimized latency, throughput, and storage requirements., Some model compression methods have been successfully applied on image classification and detection or language models, but there has been very little work compressing generative adversarial networks (GANs) performing complex tasks., In this paper, we show that a standard model compression technique, weight pruning, cannot be applied to GANs using existing methods., We then develop a self-supervised compression technique which uses the trained discriminator to supervise the training of a compressed generator., We show that this framework has a compelling performance to high degrees of sparsity, generalizes well to new tasks and models, and enables meaningful comparisons between different pruning granularities.",15,5.91156462585034,9.8
444,"['Large-scale distributed training requires significant communication bandwidth for gradient exchange that limits the scalability of multi-node training, and requires expensive high-bandwidth network infrastructure.', 'The situation gets even worse with distributed training on mobile devices (federated learning), which suffers from higher latency, lower throughput, and intermittent poor connections.', 'In this paper, we find 99.9% of the gradient exchange in distributed SGD is redundant, and propose Deep Gradient Compression (DGC) to greatly reduce the communication bandwidth.', 'To preserve accuracy during compression, DGC employs four methods: momentum correction, local gradient clipping, momentum factor masking, and warm-up training.', 'We have applied Deep Gradient Compression to image classification, speech recognition, and language modeling with multiple datasets including Cifar10, ImageNet, Penn Treebank, and Librispeech Corpus.', 'On these scenarios, Deep Gradient Compression achieves a gradient compression ratio from 270x to 600x without losing accuracy, cutting the gradient size of ResNet-50 from 97MB to 0.35MB, and for DeepSpeech from 488MB to 0.74MB.', 'Deep gradient compression enables large-scale distributed training on inexpensive commodity 1Gbps Ethernet and facilitates distributed training on mobile.']","[0, 0, 1, 0, 0, 0, 0]","[0.30434781312942505, 0.0416666604578495, 0.5882353186607361, 0.09302324801683426, 0.0, 0.1818181723356247, 0.10256409645080566]",SkhQHMW0W,"['we find 99.9% of the gradient exchange in distributed SGD is redundant; we reduce the communication bandwidth by two orders of magnitude without losing accuracy. ', 'This paper proposes additional improvement over gradient dropping to improve communication efficiency']","['largescale distributed training requires significant communication bandwidth gradient exchange limit scalability multinode training  requires expensive highbandwidth network infrastructure ', 'situation get even worse distributed training mobile device  federated learning   suffers higher latency  lower throughput  intermittent poor connection ', 'paper  find 999  gradient exchange distributed sgd redundant  propose deep gradient compression  dgc  greatly reduce communication bandwidth ', 'preserve accuracy compression  dgc employ four method  momentum correction  local gradient clipping  momentum factor masking  warmup training ', 'applied deep gradient compression image classification  speech recognition  language modeling multiple datasets including cifar10  imagenet  penn treebank  librispeech corpus ', 'scenario  deep gradient compression achieves gradient compression ratio 270x 600x without losing accuracy  cutting gradient size resnet50 97mb 035mb  deepspeech 488mb 074mb ', 'deep gradient compression enables largescale distributed training inexpensive commodity 1gbps ethernet facilitates distributed training mobile ']","Large-scale distributed training requires significant communication bandwidth for gradient exchange that limits the scalability of multi-node training, and requires expensive high-bandwidth network infrastructure., The situation gets even worse with distributed training on mobile devices (federated learning), which suffers from higher latency, lower throughput, and intermittent poor connections., In this paper, we find 99.9% of the gradient exchange in distributed SGD is redundant, and propose Deep Gradient Compression (DGC) to greatly reduce the communication bandwidth., To preserve accuracy during compression, DGC employs four methods: momentum correction, local gradient clipping, momentum factor masking, and warm-up training., We have applied Deep Gradient Compression to image classification, speech recognition, and language modeling with multiple datasets including Cifar10, ImageNet, Penn Treebank, and Librispeech Corpus., On these scenarios, Deep Gradient Compression achieves a gradient compression ratio from 270x to 600x without losing accuracy, cutting the gradient size of ResNet-50 from 97MB to 0.35MB, and for DeepSpeech from 488MB to 0.74MB., Deep gradient compression enables large-scale distributed training on inexpensive commodity 1Gbps Ethernet and facilitates distributed training on mobile.",25,6.563953488372093,6.88
445,"['Image-to-image translation has recently received significant attention due to advances in deep learning.', 'Most works focus on learning either a one-to-one mapping in an unsupervised way or a many-to-many mapping in a supervised way.', 'However, a more practical setting is many-to-many mapping in an unsupervised way, which is harder due to the lack of supervision and the complex inner- and cross-domain variations.', 'To alleviate these issues, we propose the Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) network which conditions the translation process on an exemplar image in the target domain.', 'We assume that an image comprises of a content component which is shared across domains, and a style component specific to each domain.', 'Under the guidance of an exemplar from the target domain we apply Adaptive Instance Normalization to the shared content component, which allows us to transfer the style information of the target domain to the source domain.', 'To avoid semantic inconsistencies during translation that naturally appear due to the large inner- and cross-domain variations, we introduce the concept of feature masks that provide coarse semantic guidance without requiring the use of any semantic labels.', 'Experimental results on various datasets show that EGSC-IT does not only translate the source image to diverse instances in the target domain, but also preserves the semantic consistency during the process.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.1666666567325592, 0.1538461446762085, 0.1666666567325592, 0.8799999952316284, 0.22727271914482117, 0.25, 0.07407406717538834, 0.23529411852359772]",S1lTg3RqYQ,"['We propose the Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) network which conditions the translation process on an exemplar image in the target domain.', 'Discusses a core failing and need for I2I translation models.', 'The paper explores the idea that an image has two components and applies an attention model where the feature masks that steer the translation process do not require semantic labels']","['imagetoimage translation recently received significant attention due advance deep learning ', 'work focus learning either onetoone mapping unsupervised way manytomany mapping supervised way ', 'however  practical setting manytomany mapping unsupervised way  harder due lack supervision complex inner crossdomain variation ', 'alleviate issue  propose exemplar guided  semantically consistent imagetoimage translation  egscit  network condition translation process exemplar image target domain ', 'assume image comprises content component shared across domain  style component specific domain ', 'guidance exemplar target domain apply adaptive instance normalization shared content component  allows u transfer style information target domain source domain ', 'avoid semantic inconsistency translation naturally appear due large inner crossdomain variation  introduce concept feature mask provide coarse semantic guidance without requiring use semantic label ', 'experimental result various datasets show egscit translate source image diverse instance target domain  also preserve semantic consistency process ']","Image-to-image translation has recently received significant attention due to advances in deep learning., Most works focus on learning either a one-to-one mapping in an unsupervised way or a many-to-many mapping in a supervised way., However, a more practical setting is many-to-many mapping in an unsupervised way, which is harder due to the lack of supervision and the complex inner- and cross-domain variations., To alleviate these issues, we propose the Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) network which conditions the translation process on an exemplar image in the target domain., We assume that an image comprises of a content component which is shared across domains, and a style component specific to each domain., Under the guidance of an exemplar from the target domain we apply Adaptive Instance Normalization to the shared content component, which allows us to transfer the style information of the target domain to the source domain., To avoid semantic inconsistencies during translation that naturally appear due to the large inner- and cross-domain variations, we introduce the concept of feature masks that provide coarse semantic guidance without requiring the use of any semantic labels., Experimental results on various datasets show that EGSC-IT does not only translate the source image to diverse instances in the target domain, but also preserves the semantic consistency during the process.",15,5.623853211009174,14.533333333333333
446,"['Deep neural networks can learn meaningful representations of data.', 'However, these representations are hard to interpret.', 'For example, visualizing a latent layer is generally only possible for at most three dimensions.', 'Neural networks are able to learn and benefit from much higher dimensional representations but these are not visually interpretable because nodes have arbitrary ordering within a layer.', 'Here, we utilize the ability of the human observer to identify patterns in structured representations to visualize higher dimensions.', 'To do so, we propose a class of regularizations we call \\textit{Graph Spectral Regularizations} that impose graph-structure on latent layers.', 'This is achieved by treating activations as signals on a predefined graph and constraining those activations using graph filters, such as low pass and wavelet-like filters.', 'This framework allows for any kind of graph as well as filter to achieve a wide range of structured regularizations depending on the inference needs of the data.', 'First, we show a synthetic example that the graph-structured layer can reveal topological features of the data.', 'Next, we show that a smoothing regularization can impose semantically consistent ordering of nodes when applied to capsule nets.', 'Further, we show that the graph-structured layer, using wavelet-like spatially localized filters, can form localized receptive fields for improved image and biomedical data interpretation.', 'In other words, the mapping between latent layer, neurons and the output space becomes clear due to the localization of the activations.', 'Finally, we show that when structured as a grid, the representations create coherent images that allow for image-processing techniques such as convolutions.']","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.09999999403953552, 0.0, 0.07692307233810425, 0.0, 0.0, 0.13333332538604736, 0.12121211737394333, 0.17142856121063232, 0.0, 0.0, 0.11764705181121826, 0.0, 0.06451612710952759]",B1lnjo05Km,"['Imposing graph structure on neural network layers for improved visual interpretability.', 'A novel regularizer to impose graph structure upon hidden layers of a Neural Network to improve the interpretability of hidden representations.', 'Highlights the contribution of graph spectral regularizer to the interpretability of neural networks.']","['deep neural network learn meaningful representation data ', 'however  representation hard interpret ', 'example  visualizing latent layer generally possible three dimension ', 'neural network able learn benefit much higher dimensional representation visually interpretable node arbitrary ordering within layer ', ' utilize ability human observer identify pattern structured representation visualize higher dimension ', ' propose class regularization call textit  graph spectral regularization  impose graphstructure latent layer ', 'achieved treating activation signal predefined graph constraining activation using graph filter  low pas waveletlike filter ', 'framework allows kind graph well filter achieve wide range structured regularization depending inference need data ', 'first  show synthetic example graphstructured layer reveal topological feature data ', 'next  show smoothing regularization impose semantically consistent ordering node applied capsule net ', ' show graphstructured layer  using waveletlike spatially localized filter  form localized receptive field improved image biomedical data interpretation ', 'word  mapping latent layer  neuron output space becomes clear due localization activation ', 'finally  show structured grid  representation create coherent image allow imageprocessing technique convolution ']","Deep neural networks can learn meaningful representations of data., However, these representations are hard to interpret., For example, visualizing a latent layer is generally only possible for at most three dimensions., Neural networks are able to learn and benefit from much higher dimensional representations but these are not visually interpretable because nodes have arbitrary ordering within a layer., Here, we utilize the ability of the human observer to identify patterns in structured representations to visualize higher dimensions., To do so, we propose a class of regularizations we call \textit{Graph Spectral Regularizations} that impose graph-structure on latent layers., This is achieved by treating activations as signals on a predefined graph and constraining those activations using graph filters, such as low pass and wavelet-like filters., This framework allows for any kind of graph as well as filter to achieve a wide range of structured regularizations depending on the inference needs of the data., First, we show a synthetic example that the graph-structured layer can reveal topological features of the data., Next, we show that a smoothing regularization can impose semantically consistent ordering of nodes when applied to capsule nets., Further, we show that the graph-structured layer, using wavelet-like spatially localized filters, can form localized receptive fields for improved image and biomedical data interpretation., In other words, the mapping between latent layer, neurons and the output space becomes clear due to the localization of the activations., Finally, we show that when structured as a grid, the representations create coherent images that allow for image-processing techniques such as convolutions.",27,5.764705882352941,9.444444444444445
447,"['Text generation is ubiquitous in many NLP tasks, from summarization, to dialogue and machine translation.', 'The dominant parametric approach is based on locally normalized models which predict one word at a time.', 'While these work remarkably well, they are plagued by exposure bias due to the greedy nature of the generation process.', 'In this work, we investigate un-normalized energy-based models (EBMs) which operate not at the token but at the sequence level.', 'In order to make training tractable, we first work in the residual of a pretrained locally normalized language model and second we train using noise contrastive estimation.', 'Furthermore, since the EBM works at the sequence level, we can leverage pretrained bi-directional contextual representations, such as BERT and RoBERTa.', 'Our experiments on two large language modeling datasets show that residual EBMs yield lower perplexity compared to locally normalized baselines.', 'Moreover, generation via importance sampling is very efficient and of higher quality than the baseline models according to human evaluation.']","[0, 0, 0, 0, 1, 0, 0, 0]","[0.09999999403953552, 0.0952380895614624, 0.13636362552642822, 0.09302324801683426, 0.2745097875595093, 0.13333332538604736, 0.2666666507720947, 0.2222222238779068]",B1l4SgHKDH,"['We show that Energy-Based models when trained on the residual of an auto-regressive language model can be used effectively and efficiently to generate text. ', 'A proposed Residual Energy-based Model (EBM) for text generation which operates at the sentence level, and can therefore leverage BERT, and achieves lower perplexity and is preferred by human evaluation.']","['text generation ubiquitous many nlp task  summarization  dialogue machine translation ', 'dominant parametric approach based locally normalized model predict one word time ', 'work remarkably well  plagued exposure bias due greedy nature generation process ', 'work  investigate unnormalized energybased model  ebms  operate token sequence level ', 'order make training tractable  first work residual pretrained locally normalized language model second train using noise contrastive estimation ', 'furthermore  since ebm work sequence level  leverage pretrained bidirectional contextual representation  bert roberta ', 'experiment two large language modeling datasets show residual ebms yield lower perplexity compared locally normalized baseline ', 'moreover  generation via importance sampling efficient higher quality baseline model according human evaluation ']","Text generation is ubiquitous in many NLP tasks, from summarization, to dialogue and machine translation., The dominant parametric approach is based on locally normalized models which predict one word at a time., While these work remarkably well, they are plagued by exposure bias due to the greedy nature of the generation process., In this work, we investigate un-normalized energy-based models (EBMs) which operate not at the token but at the sequence level., In order to make training tractable, we first work in the residual of a pretrained locally normalized language model and second we train using noise contrastive estimation., Furthermore, since the EBM works at the sequence level, we can leverage pretrained bi-directional contextual representations, such as BERT and RoBERTa., Our experiments on two large language modeling datasets show that residual EBMs yield lower perplexity compared to locally normalized baselines., Moreover, generation via importance sampling is very efficient and of higher quality than the baseline models according to human evaluation.",17,5.63125,9.411764705882353
448,"['We investigate the robustness properties of image recognition models equipped with two features inspired by human vision, an explicit episodic memory and a shape bias, at the ImageNet scale.', 'As reported in previous work, we show that an explicit episodic memory improves the robustness of image recognition models against small-norm adversarial perturbations under some threat models.', 'It does not, however, improve the robustness against more natural, and typically larger, perturbations.', 'Learning more robust features during training appears to be necessary for robustness in this second sense.', 'We show that features derived from a model that was encouraged to learn global, shape-based representations (Geirhos et al., 2019) do not only improve the robustness against natural perturbations, but when used in conjunction with an episodic memory, they also provide additional robustness against adversarial perturbations.', 'Finally, we address three important design choices for the episodic memory: memory size, dimensionality of the memories and the retrieval method.', 'We show that to make the episodic memory more compact, it is preferable to reduce the number of memories by clustering them, instead of reducing their dimensionality.']","[1, 0, 0, 0, 0, 0, 0]","[0.2380952388048172, 0.19999998807907104, 0.0714285671710968, 0.06666666269302368, 0.03448275476694107, 0.060606054961681366, 0.10526315122842789]",HylYtaVtwS,"['systematic study of large-scale cache-based image recognition models, focusing particularly on their robustness properties', 'This paper proposed to use memory cache to improve robustness against adversarial image examples, and concluded that using a large continous cache is not superior to hard attention.']","['investigate robustness property image recognition model equipped two feature inspired human vision  explicit episodic memory shape bias  imagenet scale ', 'reported previous work  show explicit episodic memory improves robustness image recognition model smallnorm adversarial perturbation threat model ', ' however  improve robustness natural  typically larger  perturbation ', 'learning robust feature training appears necessary robustness second sense ', 'show feature derived model encouraged learn global  shapebased representation  geirhos et al  2019  improve robustness natural perturbation  used conjunction episodic memory  also provide additional robustness adversarial perturbation ', 'finally  address three important design choice episodic memory  memory size  dimensionality memory retrieval method ', 'show make episodic memory compact  preferable reduce number memory clustering  instead reducing dimensionality ']","We investigate the robustness properties of image recognition models equipped with two features inspired by human vision, an explicit episodic memory and a shape bias, at the ImageNet scale., As reported in previous work, we show that an explicit episodic memory improves the robustness of image recognition models against small-norm adversarial perturbations under some threat models., It does not, however, improve the robustness against more natural, and typically larger, perturbations., Learning more robust features during training appears to be necessary for robustness in this second sense., We show that features derived from a model that was encouraged to learn global, shape-based representations (Geirhos et al., 2019) do not only improve the robustness against natural perturbations, but when used in conjunction with an episodic memory, they also provide additional robustness against adversarial perturbations., Finally, we address three important design choices for the episodic memory: memory size, dimensionality of the memories and the retrieval method., We show that to make the episodic memory more compact, it is preferable to reduce the number of memories by clustering them, instead of reducing their dimensionality.",22,5.777777777777778,8.181818181818182
449,"['Group convolutional neural networks (G-CNNs) can be used to improve classical CNNs by equipping them with the geometric structure of groups.', 'Central in the success of G-CNNs is the lifting of feature maps to higher dimensional disentangled representations, in which data characteristics are effectively learned, geometric data-augmentations are made obsolete, and predictable behavior under geometric transformations (equivariance) is guaranteed via group theory.', 'Currently, however, the practical implementations of G-CNNs are limited to either discrete groups (that leave the grid intact) or continuous compact groups such as rotations (that enable the use of Fourier theory).', 'In this paper we lift these limitations and propose a modular framework for the design and implementation of G-CNNs for arbitrary Lie groups.', 'In our approach the differential structure of Lie groups is used to expand convolution kernels in a generic basis of B-splines that is defined on the Lie algebra.', 'This leads to a flexible framework that enables localized, atrous, and deformable convolutions in G-CNNs by means of respectively localized, sparse and non-uniform B-spline expansions.', 'The impact and potential of our approach is studied on two benchmark datasets: cancer detection in histopathology slides (PCam dataset) in which rotation equivariance plays a key role and facial landmark localization (CelebA dataset) in which scale equivariance is important.', 'In both cases, G-CNN architectures outperform their classical 2D counterparts and the added value of atrous and localized group convolutions is studied in detail.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.20512819290161133, 0.15094339847564697, 0.17777776718139648, 0.307692289352417, 0.2380952388048172, 0.2926829159259796, 0.11764705181121826, 0.04878048226237297]",H1gBhkBFDH,"['The paper describes a flexible framework for building CNNs that are equivariant to a large class of transformations groups.', 'A framework for building group CNN with an arbitrary Lie group G, which shows superiority over a CNN in tumor classification and landmark localization. ']","['group convolutional neural network  gcnns  used improve classical cnns equipping geometric structure group ', 'central success gcnns lifting feature map higher dimensional disentangled representation  data characteristic effectively learned  geometric dataaugmentations made obsolete  predictable behavior geometric transformation  equivariance  guaranteed via group theory ', 'currently  however  practical implementation gcnns limited either discrete group  leave grid intact  continuous compact group rotation  enable use fourier theory  ', 'paper lift limitation propose modular framework design implementation gcnns arbitrary lie group ', 'approach differential structure lie group used expand convolution kernel generic basis bsplines defined lie algebra ', 'lead flexible framework enables localized  atrous  deformable convolution gcnns mean respectively localized  sparse nonuniform bspline expansion ', 'impact potential approach studied two benchmark datasets  cancer detection histopathology slide  pcam dataset  rotation equivariance play key role facial landmark localization  celeba dataset  scale equivariance important ', 'case  gcnn architecture outperform classical 2d counterpart added value atrous localized group convolution studied detail ']","Group convolutional neural networks (G-CNNs) can be used to improve classical CNNs by equipping them with the geometric structure of groups., Central in the success of G-CNNs is the lifting of feature maps to higher dimensional disentangled representations, in which data characteristics are effectively learned, geometric data-augmentations are made obsolete, and predictable behavior under geometric transformations (equivariance) is guaranteed via group theory., Currently, however, the practical implementations of G-CNNs are limited to either discrete groups (that leave the grid intact) or continuous compact groups such as rotations (that enable the use of Fourier theory)., In this paper we lift these limitations and propose a modular framework for the design and implementation of G-CNNs for arbitrary Lie groups., In our approach the differential structure of Lie groups is used to expand convolution kernels in a generic basis of B-splines that is defined on the Lie algebra., This leads to a flexible framework that enables localized, atrous, and deformable convolutions in G-CNNs by means of respectively localized, sparse and non-uniform B-spline expansions., The impact and potential of our approach is studied on two benchmark datasets: cancer detection in histopathology slides (PCam dataset) in which rotation equivariance plays a key role and facial landmark localization (CelebA dataset) in which scale equivariance is important., In both cases, G-CNN architectures outperform their classical 2D counterparts and the added value of atrous and localized group convolutions is studied in detail.",17,5.833333333333333,13.764705882352942
450,"[' Global feature pooling is a modern variant of feature pooling providing better interpretatability and regularization.', 'Although alternative pooling methods exist (eg. max, lp norm, stochastic), the averaging operation is still the dominating global pooling scheme in popular models.', 'As fine-grained recognition requires learning subtle, discriminative features, we consider the question: is average pooling the optimal strategy?', ""We first ask: ``is there a difference between features learned by global average and max pooling?'' Visualization and quantitative analysis show that max pooling encourages learning features of different spatial scales."", ""We then ask ``is there a single global feature pooling variant that's most suitable for fine-grained recognition?'' A thorough evaluation of nine representative pooling algorithms finds that: max pooling outperforms average pooling consistently across models, datasets, and image resolutions; it does so by reducing the generalization gap; and generalized pooling's performance increases almost monotonically as it changes from average to max."", ""We finally ask: ``what's the best way to combine two heterogeneous pooling schemes?'' Common strategies struggle because of potential gradient conflict but the ``freeze-and-train'' trick works best."", 'We also find that post-global batch normalization helps with faster convergence and improves model performance consistently.']","[0, 0, 0, 0, 1, 0, 0]","[0.1599999964237213, 0.12121211737394333, 0.06896550953388214, 0.14999999105930328, 0.1818181723356247, 0.10810810327529907, 0.0]",H1lkCTVFwB,"['A benchmark of nine representative global pooling schemes reveals some interesting findings.', 'For fine-grained classification tasks, this paper validated that maxpooling would encourage sparser feature maps than and outperform avgpooling. ']","['global feature pooling modern variant feature pooling providing better interpretatability regularization ', 'although alternative pooling method exist  eg  max  lp norm  stochastic   averaging operation still dominating global pooling scheme popular model ', 'finegrained recognition requires learning subtle  discriminative feature  consider question  average pooling optimal strategy ', 'first ask   difference feature learned global average max pooling   visualization quantitative analysis show max pooling encourages learning feature different spatial scale ', 'ask  single global feature pooling variant suitable finegrained recognition   thorough evaluation nine representative pooling algorithm find  max pooling outperforms average pooling consistently across model  datasets  image resolution  reducing generalization gap  generalized pooling performance increase almost monotonically change average max ', 'finally ask   best way combine two heterogeneous pooling scheme   common strategy struggle potential gradient conflict  freezeandtrain  trick work best ', 'also find postglobal batch normalization help faster convergence improves model performance consistently ']"," Global feature pooling is a modern variant of feature pooling providing better interpretatability and regularization., Although alternative pooling methods exist (eg. max, lp norm, stochastic), the averaging operation is still the dominating global pooling scheme in popular models., As fine-grained recognition requires learning subtle, discriminative features, we consider the question: is average pooling the optimal strategy?, We first ask: ``is there a difference between features learned by global average and max pooling?'' Visualization and quantitative analysis show that max pooling encourages learning features of different spatial scales., We then ask ``is there a single global feature pooling variant that's most suitable for fine-grained recognition?'' A thorough evaluation of nine representative pooling algorithms finds that: max pooling outperforms average pooling consistently across models, datasets, and image resolutions; it does so by reducing the generalization gap; and generalized pooling's performance increases almost monotonically as it changes from average to max., We finally ask: ``what's the best way to combine two heterogeneous pooling schemes?'' Common strategies struggle because of potential gradient conflict but the ``freeze-and-train'' trick works best., We also find that post-global batch normalization helps with faster convergence and improves model performance consistently.",14,6.37696335078534,10.61111111111111
451,"['We present a technique to improve the generalization of deep representations learned on small labeled datasets by introducing self-supervised tasks as auxiliary loss functions.', 'Although recent research has shown benefits of self-supervised learning (SSL) on large unlabeled datasets, its utility on small datasets is unknown.', 'We find that SSL reduces the relative error rate of few-shot meta-learners by 4%-27%, even when the datasets are small and only utilizing images within the datasets.', 'The improvements are greater when the training set is smaller or the task is more challenging.', 'Though the benefits of SSL may increase with larger training sets, we observe that SSL can have a negative impact on performance when there is a domain shift between distribution of images used for meta-learning and SSL.', 'Based on this analysis we present a technique that automatically select images for SSL from a large, generic pool of unlabeled images for a given dataset using a domain classifier that provides further improvements.', 'We present results using several meta-learners and self-supervised tasks across datasets with varying degrees of domain shifts and label sizes to characterize the effectiveness of SSL for few-shot learning.']","[0, 0, 1, 0, 0, 0, 0]","[0.1599999964237213, 0.17391303181648254, 0.2800000011920929, 0.25, 0.20338982343673706, 0.1111111044883728, 0.18867923319339752]",HkenPn4KPH,"['Self-supervision improves few-shot recognition on small and challenging datasets without relying on extra data; Extra data helps only when it is from the same or similar domain.', 'An empirical study of different self-supervised learning (SSL) methods, showing SSL helps more when the dataset is harder, that domain matters for training, and a method to choose samples from an unlabeled dataset. ']","['present technique improve generalization deep representation learned small labeled datasets introducing selfsupervised task auxiliary loss function ', 'although recent research shown benefit selfsupervised learning  ssl  large unlabeled datasets  utility small datasets unknown ', 'find ssl reduces relative error rate fewshot metalearners 4  27   even datasets small utilizing image within datasets ', 'improvement greater training set smaller task challenging ', 'though benefit ssl may increase larger training set  observe ssl negative impact performance domain shift distribution image used metalearning ssl ', 'based analysis present technique automatically select image ssl large  generic pool unlabeled image given dataset using domain classifier provides improvement ', 'present result using several metalearners selfsupervised task across datasets varying degree domain shift label size characterize effectiveness ssl fewshot learning ']","We present a technique to improve the generalization of deep representations learned on small labeled datasets by introducing self-supervised tasks as auxiliary loss functions., Although recent research has shown benefits of self-supervised learning (SSL) on large unlabeled datasets, its utility on small datasets is unknown., We find that SSL reduces the relative error rate of few-shot meta-learners by 4%-27%, even when the datasets are small and only utilizing images within the datasets., The improvements are greater when the training set is smaller or the task is more challenging., Though the benefits of SSL may increase with larger training sets, we observe that SSL can have a negative impact on performance when there is a domain shift between distribution of images used for meta-learning and SSL., Based on this analysis we present a technique that automatically select images for SSL from a large, generic pool of unlabeled images for a given dataset using a domain classifier that provides further improvements., We present results using several meta-learners and self-supervised tasks across datasets with varying degrees of domain shifts and label sizes to characterize the effectiveness of SSL for few-shot learning.",11,5.526595744680851,17.09090909090909
452,"['Abstraction of Markov Decision Processes is a useful tool for solving complex problems, as it can ignore unimportant aspects of an environment, simplifying the process of learning an optimal policy.', 'In this paper, we propose a new algorithm for finding abstract MDPs in environments with continuous state spaces.', 'It is based on MDP homomorphisms, a structure-preserving mapping between MDPs.', ""We demonstrate our algorithm's ability to learns abstractions from collected experience and show how to reuse the abstractions to guide exploration in new tasks the agent encounters."", 'Our novel task transfer method beats a baseline based on a deep Q-network.']","[0, 0, 0, 1, 0]","[0.04651162400841713, 0.1764705777168274, 0.0, 0.3589743673801422, 0.0]",B1gVRi0qFQ,"['We create abstract models of environments from experience and use them to learn new tasks faster.', 'A methodology that uses the idea of MDP homomorphisms to transform a complex MDP with a continuous state space to a simpler one.']","['abstraction markov decision process useful tool solving complex problem  ignore unimportant aspect environment  simplifying process learning optimal policy ', 'paper  propose new algorithm finding abstract mdps environment continuous state space ', 'based mdp homomorphism  structurepreserving mapping mdps ', 'demonstrate algorithm ability learns abstraction collected experience show reuse abstraction guide exploration new task agent encounter ', 'novel task transfer method beat baseline based deep qnetwork ']","Abstraction of Markov Decision Processes is a useful tool for solving complex problems, as it can ignore unimportant aspects of an environment, simplifying the process of learning an optimal policy., In this paper, we propose a new algorithm for finding abstract MDPs in environments with continuous state spaces., It is based on MDP homomorphisms, a structure-preserving mapping between MDPs., We demonstrate our algorithm's ability to learns abstractions from collected experience and show how to reuse the abstractions to guide exploration in new tasks the agent encounters., Our novel task transfer method beats a baseline based on a deep Q-network.",9,5.525252525252525,11.0
453,"['A number of recent methods to understand neural networks have focused on quantifying the role of individual features.  ', 'One such method, NetDissect identifies interpretable features of a model using the Broden dataset of visual semantic labels (colors, materials, textures, objects and scenes).  ', 'Given the recent rise of a number of action recognition datasets, we propose extending the Broden dataset to include actions to better analyze learned action models.  ', 'We describe the annotation process, results from interpreting action recognition models on the extended Broden dataset and examine interpretable feature paths to help us understand the conceptual hierarchy used to classify an action.']","[0, 0, 0, 1]","[0.15789473056793213, 0.13636362552642822, 0.1860465109348297, 0.6122449040412903]",rkxyny2qaE,['We expand Network Dissection to include action interpretation and examine interpretable feature paths to understand the conceptual hierarchy used to classify an action.'],"['number recent method understand neural network focused quantifying role individual feature ', 'one method  netdissect identifies interpretable feature model using broden dataset visual semantic label  color  material  texture  object scene  ', 'given recent rise number action recognition datasets  propose extending broden dataset include action better analyze learned action model ', 'describe annotation process  result interpreting action recognition model extended broden dataset examine interpretable feature path help u understand conceptual hierarchy used classify action ']","A number of recent methods to understand neural networks have focused on quantifying the role of individual features.  , One such method, NetDissect identifies interpretable features of a model using the Broden dataset of visual semantic labels (colors, materials, textures, objects and scenes).  , Given the recent rise of a number of action recognition datasets, we propose extending the Broden dataset to include actions to better analyze learned action models.  , We describe the annotation process, results from interpreting action recognition models on the extended Broden dataset and examine interpretable feature paths to help us understand the conceptual hierarchy used to classify an action.",10,5.801980198019802,10.1
454,"['Automatic melody generation for pop music has been a long-time aspiration for\n', 'both AI researchers and musicians.', 'However, learning to generate euphonious\n', 'melody has turned out to be highly challenging due to a number of factors.', 'Representation\n', 'of multivariate property of notes has been one of the primary challenges.\n', 'It is also difficult to remain in the permissible spectrum of musical variety, outside\n', 'of which would be perceived as a plain random play without auditory pleasantness.\n', 'Observing the conventional structure of pop music poses further challenges.\n', 'In this paper, we propose to represent each note and its properties as a unique\n', 'word, thus lessening the prospect of misalignments between the properties, as\n', 'well as reducing the complexity of learning.', 'We also enforce regularization policies\n', 'on the range of notes, thus encouraging the generated melody to stay close\n', 'to what humans would find easy to follow.', 'Furthermore, we generate melody\n', 'conditioned on song part information, thus replicating the overall structure of a\n', 'full song.', 'Experimental results demonstrate that our model can generate auditorily\n', 'pleasant songs that are more indistinguishable from human-written ones than\n', 'previous models.']","[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.20689654350280762, 0.08695651590824127, 0.08695651590824127, 0.19354838132858276, 0.13793103396892548, 0.1249999925494194, 0.1249999925494194, 0.06896550953388214, 0.3030303120613098, 0.1428571343421936, 0.07999999821186066, 0.08695651590824127, 0.19999998807907104, 0.07999999821186066, 0.09090908616781235, 0.13333332538604736, 0.14814814925193787, 0.0]",ryEJWe2HM,"['We propose a novel model to represent notes and their properties, which can enhance the automatic melody generation.', 'This paper proposes a generative model of symbolic (MIDI) melody in western popular music which jointly encodes note symbols with timing and duration information to form musical ""words"".', 'The paper proposes to facilitate generation of melody by representing notes as ""words"", representing all of the note\'s properties and thus allowing the generation of musical ""sentences"".']","['automatic melody generation pop music longtime aspiration', 'ai researcher musician ', 'however  learning generate euphonious', 'melody turned highly challenging due number factor ', 'representation', 'multivariate property note one primary challenge ', 'also difficult remain permissible spectrum musical variety  outside', 'would perceived plain random play without auditory pleasantness ', 'observing conventional structure pop music pose challenge ', 'paper  propose represent note property unique', ' word   thus lessening prospect misalignment property ', 'well reducing complexity learning ', 'also enforce regularization policy', 'range note  thus encouraging generated melody stay close', 'human would find easy follow ', 'furthermore  generate melody', 'conditioned song part information  thus replicating overall structure', 'full song ', 'experimental result demonstrate model generate auditorily', 'pleasant song indistinguishable humanwritten one', 'previous model ']","Automatic melody generation for pop music has been a long-time aspiration for
, both AI researchers and musicians., However, learning to generate euphonious
, melody has turned out to be highly challenging due to a number of factors., Representation
, of multivariate property of notes has been one of the primary challenges.
, It is also difficult to remain in the permissible spectrum of musical variety, outside
, of which would be perceived as a plain random play without auditory pleasantness.
, Observing the conventional structure of pop music poses further challenges.
, In this paper, we propose to represent each note and its properties as a unique
, word, thus lessening the prospect of misalignments between the properties, as
, well as reducing the complexity of learning., We also enforce regularization policies
, on the range of notes, thus encouraging the generated melody to stay close
, to what humans would find easy to follow., Furthermore, we generate melody
, conditioned on song part information, thus replicating the overall structure of a
, full song., Experimental results demonstrate that our model can generate auditorily
, pleasant songs that are more indistinguishable from human-written ones than
, previous models.",28,5.565217391304348,6.571428571428571
455,"['Depth is a key component of Deep Neural Networks (DNNs), however, designing depth is heuristic and requires many human efforts.', 'We propose AutoGrow to automate depth discovery in DNNs: starting from a shallow seed architecture, AutoGrow grows new layers if the growth improves the accuracy; otherwise, stops growing and thus discovers the depth.', 'We propose robust growing and stopping policies to generalize to different network architectures and datasets.', 'Our experiments show that by applying the same policy to different network architectures, AutoGrow can always discover near-optimal depth on various datasets of MNIST, FashionMNIST, SVHN, CIFAR10, CIFAR100 and ImageNet.', 'For example, in terms of accuracy-computation trade-off, AutoGrow discovers a better depth combination in ResNets than human experts.', 'Our AutoGrow is efficient.', 'It discovers depth within similar time of training a single DNN.']","[0, 1, 0, 0, 0, 0, 0]","[0.0624999962747097, 0.2380952388048172, 0.07692307233810425, 0.1860465109348297, 0.13333332538604736, 0.0, 0.0833333283662796]",S1x0CnEtvB,"['A method that automatically grows layers in neural networks to discover optimal depth.', ""A framework to interleave training a shallower network and adding new layers which provides insights into the paradigm of 'growing networks'.""]","['depth key component deep neural network  dnns   however  designing depth heuristic requires many human effort ', 'propose autogrow automate depth discovery dnns  starting shallow seed architecture  autogrow grows new layer growth improves accuracy  otherwise  stop growing thus discovers depth ', 'propose robust growing stopping policy generalize different network architecture datasets ', 'experiment show applying policy different network architecture  autogrow always discover nearoptimal depth various datasets mnist  fashionmnist  svhn  cifar10  cifar100 imagenet ', 'example  term accuracycomputation tradeoff  autogrow discovers better depth combination resnets human expert ', 'autogrow efficient ', 'discovers depth within similar time training single dnn ']","Depth is a key component of Deep Neural Networks (DNNs), however, designing depth is heuristic and requires many human efforts., We propose AutoGrow to automate depth discovery in DNNs: starting from a shallow seed architecture, AutoGrow grows new layers if the growth improves the accuracy; otherwise, stops growing and thus discovers the depth., We propose robust growing and stopping policies to generalize to different network architectures and datasets., Our experiments show that by applying the same policy to different network architectures, AutoGrow can always discover near-optimal depth on various datasets of MNIST, FashionMNIST, SVHN, CIFAR10, CIFAR100 and ImageNet., For example, in terms of accuracy-computation trade-off, AutoGrow discovers a better depth combination in ResNets than human experts., Our AutoGrow is efficient., It discovers depth within similar time of training a single DNN.",18,5.809160305343512,7.277777777777778
456,"['Given the importance of remote sensing, surprisingly little attention has been paid to it by the representation learning community.', 'To address it and to speed up innovation in this domain, we provide simplified access to 5 diverse remote sensing datasets in a standardized form.', 'We specifically explore in-domain representation learning and address the question of ""what characteristics should a dataset have to be a good source for remote sensing representation learning"".', 'The established baselines achieve state-of-the-art performance on these datasets. \n']","[0, 0, 1, 0]","[0.29629629850387573, 0.1875, 0.4117647111415863, 0.10526315122842789]",BJx_JAVKDB,"['Exploration of in-domain representation learning for remote sensing datasets.', 'This paper provided several standardized remote sensing data sets and showed that in-domain representation could produce better baseline results for remote sensing compared to fine-tuning on ImageNet or learning from scratch.']","['given importance remote sensing  surprisingly little attention paid representation learning community ', 'address speed innovation domain  provide simplified access 5 diverse remote sensing datasets standardized form ', 'specifically explore indomain representation learning address question  characteristic dataset good source remote sensing representation learning  ', 'established baseline achieve stateoftheart performance datasets ']","Given the importance of remote sensing, surprisingly little attention has been paid to it by the representation learning community., To address it and to speed up innovation in this domain, we provide simplified access to 5 diverse remote sensing datasets in a standardized form., We specifically explore in-domain representation learning and address the question of ""what characteristics should a dataset have to be a good source for remote sensing representation learning""., The established baselines achieve state-of-the-art performance on these datasets. 
",6,5.925,13.333333333333334
457,"['Generative seq2seq dialogue systems are trained to predict the next word in dialogues that have already occurred.', 'They can learn from large unlabeled conversation datasets, build a deep understanding of conversational context, and generate a wide variety of responses.', 'This flexibility comes at the cost of control.', 'Undesirable responses in the training data will be reproduced by the model at inference time, and longer generations often dont make sense.', 'Instead of generating responses one word at a time, we train a classifier to choose from a predefined list of full responses.', 'The classifier is trained on (conversation context, response class) pairs, where each response class is a noisily labeled group of interchangeable responses.', 'At inference, we generate the exemplar response associated with the predicted response class.', 'Experts can edit and improve these exemplar responses over time without retraining the classifier or invalidating old training data.\n', 'Human evaluation of 775 unseen doctor/patient conversations shows that this tradeoff improves responses.', 'Only 12% of our discriminative approachs responses are worse than the doctors response in the same conversational context, compared to 18% for the generative model.', 'A discriminative model trained without any manual labeling of response classes achieves equal performance to the generative model.']","[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.11428570747375488, 0.10526315122842789, 0.07692307233810425, 0.20512819290161133, 0.5, 0.21052631735801697, 0.06896550953388214, 0.21052631735801697, 0.06451612710952759, 0.1463414579629898, 0.11428570747375488]",H1xk6AEFwr,"['Avoid generating responses one word at a time by using weak supervision to training a classifier  to pick a full response.', 'A way to generate responses for medical dialog using a classifier to select from expert-curated responses based on the conversation context.']","['generative seq2seq dialogue system trained predict next word dialogue already occurred ', 'learn large unlabeled conversation datasets  build deep understanding conversational context  generate wide variety response ', 'flexibility come cost control ', 'undesirable response training data reproduced model inference time  longer generation often  make sense ', 'instead generating response one word time  train classifier choose predefined list full response ', 'classifier trained  conversation context  response class  pair  response class noisily labeled group interchangeable response ', 'inference  generate exemplar response associated predicted response class ', 'expert edit improve exemplar response time without retraining classifier invalidating old training data ', 'human evaluation 775 unseen doctorpatient conversation show tradeoff improves response ', '12  discriminative approach  response worse doctor  response conversational context  compared 18  generative model ', 'discriminative model trained without manual labeling response class achieves equal performance generative model ']","Generative seq2seq dialogue systems are trained to predict the next word in dialogues that have already occurred., They can learn from large unlabeled conversation datasets, build a deep understanding of conversational context, and generate a wide variety of responses., This flexibility comes at the cost of control., Undesirable responses in the training data will be reproduced by the model at inference time, and longer generations often dont make sense., Instead of generating responses one word at a time, we train a classifier to choose from a predefined list of full responses., The classifier is trained on (conversation context, response class) pairs, where each response class is a noisily labeled group of interchangeable responses., At inference, we generate the exemplar response associated with the predicted response class., Experts can edit and improve these exemplar responses over time without retraining the classifier or invalidating old training data.
, Human evaluation of 775 unseen doctor/patient conversations shows that this tradeoff improves responses., Only 12% of our discriminative approachs responses are worse than the doctors response in the same conversational context, compared to 18% for the generative model., A discriminative model trained without any manual labeling of response classes achieves equal performance to the generative model.",19,5.781094527363184,10.578947368421053
458,"['There is a previously identified equivalence between wide fully connected neural networks (FCNs) and Gaussian processes (GPs).', 'This equivalence enables, for instance, test set predictions that would have resulted from a fully Bayesian, infinitely wide trained FCN to be computed without ever instantiating the FCN, but by instead evaluating the corresponding GP.', 'In this work, we derive an analogous equivalence for multi-layer convolutional neural networks (CNNs) both with and without pooling layers, and achieve state of the art results on CIFAR10 for GPs without trainable kernels.', 'We also introduce a Monte Carlo method to estimate the GP corresponding to a given neural network architecture, even in cases where the analytic form has too many terms to be computationally feasible. \n\n', 'Surprisingly, in the absence of pooling layers, the GPs corresponding to CNNs with and without weight sharing are identical.', 'As a consequence, translation equivariance, beneficial in finite channel CNNs trained with stochastic gradient descent (SGD), is guaranteed to play no role in the Bayesian treatment of the infinite channel limit - a qualitative difference between the two regimes that is not present in the FCN case.', 'We confirm experimentally, that while in some scenarios the performance of SGD-trained finite CNNs approaches that of the corresponding GPs as the channel count increases, with careful tuning SGD-trained CNNs can significantly outperform their corresponding GPs, suggesting advantages from SGD training compared to fully Bayesian parameter estimation.']","[0, 1, 0, 0, 0, 0, 0]","[0.1428571343421936, 0.17777776718139648, 0.0, 0.0, 0.06896550953388214, 0.11999999731779099, 0.15686273574829102]",B1g30j0qF7,"['Finite-width SGD trained CNNs vs. infinitely wide fully Bayesian CNNs. Who wins?', 'The paper establishes a connection between infinite channel Bayesian convolutional neural network and Gaussian processes.']","['previously identified equivalence wide fully connected neural network  fcns  gaussian process  gps  ', 'equivalence enables  instance  test set prediction would resulted fully bayesian  infinitely wide trained fcn computed without ever instantiating fcn  instead evaluating corresponding gp ', 'work  derive analogous equivalence multilayer convolutional neural network  cnns  without pooling layer  achieve state art result cifar10 gps without trainable kernel ', 'also introduce monte carlo method estimate gp corresponding given neural network architecture  even case analytic form many term computationally feasible ', 'surprisingly  absence pooling layer  gps corresponding cnns without weight sharing identical ', 'consequence  translation equivariance  beneficial finite channel cnns trained stochastic gradient descent  sgd   guaranteed play role bayesian treatment infinite channel limit  qualitative difference two regime present fcn case ', 'confirm experimentally  scenario performance sgdtrained finite cnns approach corresponding gps channel count increase  careful tuning sgdtrained cnns significantly outperform corresponding gps  suggesting advantage sgd training compared fully bayesian parameter estimation ']","There is a previously identified equivalence between wide fully connected neural networks (FCNs) and Gaussian processes (GPs)., This equivalence enables, for instance, test set predictions that would have resulted from a fully Bayesian, infinitely wide trained FCN to be computed without ever instantiating the FCN, but by instead evaluating the corresponding GP., In this work, we derive an analogous equivalence for multi-layer convolutional neural networks (CNNs) both with and without pooling layers, and achieve state of the art results on CIFAR10 for GPs without trainable kernels., We also introduce a Monte Carlo method to estimate the GP corresponding to a given neural network architecture, even in cases where the analytic form has too many terms to be computationally feasible. 

, Surprisingly, in the absence of pooling layers, the GPs corresponding to CNNs with and without weight sharing are identical., As a consequence, translation equivariance, beneficial in finite channel CNNs trained with stochastic gradient descent (SGD), is guaranteed to play no role in the Bayesian treatment of the infinite channel limit - a qualitative difference between the two regimes that is not present in the FCN case., We confirm experimentally, that while in some scenarios the performance of SGD-trained finite CNNs approaches that of the corresponding GPs as the channel count increases, with careful tuning SGD-trained CNNs can significantly outperform their corresponding GPs, suggesting advantages from SGD training compared to fully Bayesian parameter estimation.",22,5.676724137931035,10.545454545454545
459,"['Bayesian inference promises to ground and improve the performance of deep neural networks.', 'It promises to be robust to overfitting, to simplify the training procedure and the space of hyperparameters, and to provide a calibrated measure of uncertainty that can enhance decision making, agent exploration and prediction fairness.\n', 'Markov Chain Monte Carlo (MCMC) methods enable Bayesian inference by generating samples from the posterior distribution over model parameters.\n', 'Despite the theoretical advantages of Bayesian inference and the similarity between MCMC and optimization methods, the performance of sampling methods has so far lagged behind  optimization methods for large scale deep learning tasks.\n', 'We aim to fill this gap and introduce ATMC, an adaptive noise MCMC algorithm that estimates and is able to sample from the posterior of a neural network.\n', 'ATMC dynamically adjusts the amount of momentum and noise applied to each parameter update in order to compensate for the use of stochastic gradients.\n', 'We use a ResNet architecture without batch normalization to test ATMC on the Cifar10 benchmark and the large scale ImageNet benchmark and show that, despite the  absence of batch normalization, ATMC outperforms a strong optimization baseline in terms of both classification accuracy and test log-likelihood.', 'We show that ATMC is intrinsically robust to overfitting on the training data and that ATMC provides a better calibrated measure of uncertainty compared to the optimization baseline.']","[0, 0, 0, 0, 0, 0, 1, 0]","[0.2222222238779068, 0.1395348757505417, 0.05882352590560913, 0.1428571343421936, 0.1463414579629898, 0.1111111044883728, 0.2857142686843872, 0.21052631735801697]",rklFh34Kwr,"['We scale Bayesian Inference to ImageNet classification and achieve competitive results accuracy and uncertainty calibration.', 'An adaptive noise MCMC algorithm for image classification that dynamically adjusts the momentum and noise applied to each parameter update, and is robust to overfitting and provides an uncertainty measure with predictions. ']","['bayesian inference promise ground improve performance deep neural network ', 'promise robust overfitting  simplify training procedure space hyperparameters  provide calibrated measure uncertainty enhance decision making  agent exploration prediction fairness ', 'markov chain monte carlo  mcmc  method enable bayesian inference generating sample posterior distribution model parameter ', 'despite theoretical advantage bayesian inference similarity mcmc optimization method  performance sampling method far lagged behind optimization method large scale deep learning task ', 'aim fill gap introduce atmc  adaptive noise mcmc algorithm estimate able sample posterior neural network ', 'atmc dynamically adjusts amount momentum noise applied parameter update order compensate use stochastic gradient ', 'use resnet architecture without batch normalization test atmc cifar10 benchmark large scale imagenet benchmark show  despite absence batch normalization  atmc outperforms strong optimization baseline term classification accuracy test loglikelihood ', 'show atmc intrinsically robust overfitting training data atmc provides better calibrated measure uncertainty compared optimization baseline ']","Bayesian inference promises to ground and improve the performance of deep neural networks., It promises to be robust to overfitting, to simplify the training procedure and the space of hyperparameters, and to provide a calibrated measure of uncertainty that can enhance decision making, agent exploration and prediction fairness.
, Markov Chain Monte Carlo (MCMC) methods enable Bayesian inference by generating samples from the posterior distribution over model parameters.
, Despite the theoretical advantages of Bayesian inference and the similarity between MCMC and optimization methods, the performance of sampling methods has so far lagged behind  optimization methods for large scale deep learning tasks.
, We aim to fill this gap and introduce ATMC, an adaptive noise MCMC algorithm that estimates and is able to sample from the posterior of a neural network.
, ATMC dynamically adjusts the amount of momentum and noise applied to each parameter update in order to compensate for the use of stochastic gradients.
, We use a ResNet architecture without batch normalization to test ATMC on the Cifar10 benchmark and the large scale ImageNet benchmark and show that, despite the  absence of batch normalization, ATMC outperforms a strong optimization baseline in terms of both classification accuracy and test log-likelihood., We show that ATMC is intrinsically robust to overfitting on the training data and that ATMC provides a better calibrated measure of uncertainty compared to the optimization baseline.",15,5.64,15.0
460,"['Now GANs can generate more and more realistic face images that can easily fool human beings.  ', 'In contrast, a common convolutional neural network(CNN), e.g. ResNet-18, can achieve more than 99.9% accuracy in discerning fake/real faces if training and testing faces are from the same source.', 'In this paper, we performed both human studies and CNN experiments, which led us to two important findings.', 'One finding is that the textures of fake faces are substantially different from real ones.', 'CNNs can capture local image texture information for recognizing fake/real face, while such cues are easily overlooked by humans.', 'The other finding is that global image texture information is more robust to image editing and generalizable to fake faces from different GANs and datasets.', 'Based on the above findings, we propose  a  novel  architecture  coined  as  Gram-Net,  which  incorporates  Gram Block in multiple semantic levels to extract global image texture representations.', 'Experimental results demonstrate that our Gram-Net performs better than existing approaches for fake face detection.  ', 'Especially, our Gram-Net is more robust to image editing, e.g.  downsampling, JPEG compression, blur, and noise.  ', 'More importantly, our Gram-Net generalizes significantly better in detecting fake faces from GAN models not seen in the training phase.']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.09090908616781235, 0.03389830142259598, 0.04255318641662598, 0.22727271914482117, 0.0833333283662796, 0.2800000011920929, 0.1428571343421936, 0.17777776718139648, 0.08510638028383255, 0.1249999925494194]",HyxcZT4KwB,"['An empirical study on fake images reveals that texture is an important cue that current fake images differ from real images. Our improved model capturing global texture statistics shows better cross-GAN fake image detection performance.', 'The paper proposes a way to improve model performance for fake face detection in images generated by a GAN to be more generalizable based on texture information.']","['gans generate realistic face image easily fool human being ', 'contrast  common convolutional neural network  cnn   eg  resnet18  achieve 999  accuracy discerning fakereal face training testing face source ', 'paper  performed human study cnn experiment  led u two important finding ', 'one finding texture fake face substantially different real one ', 'cnns capture local image texture information recognizing fakereal face  cue easily overlooked human ', 'finding global image texture information robust image editing generalizable fake face different gans datasets ', 'based finding  propose novel architecture coined gramnet  incorporates  gram block  multiple semantic level extract global image texture representation ', 'experimental result demonstrate gramnet performs better existing approach fake face detection ', 'especially  gramnet robust image editing  eg  downsampling  jpeg compression  blur  noise ', 'importantly  gramnet generalizes significantly better detecting fake face gan model seen training phase ']","Now GANs can generate more and more realistic face images that can easily fool human beings.  , In contrast, a common convolutional neural network(CNN), e.g. ResNet-18, can achieve more than 99.9% accuracy in discerning fake/real faces if training and testing faces are from the same source., In this paper, we performed both human studies and CNN experiments, which led us to two important findings., One finding is that the textures of fake faces are substantially different from real ones., CNNs can capture local image texture information for recognizing fake/real face, while such cues are easily overlooked by humans., The other finding is that global image texture information is more robust to image editing and generalizable to fake faces from different GANs and datasets., Based on the above findings, we propose  a  novel  architecture  coined  as  Gram-Net,  which  incorporates  Gram Block in multiple semantic levels to extract global image texture representations., Experimental results demonstrate that our Gram-Net performs better than existing approaches for fake face detection.  , Especially, our Gram-Net is more robust to image editing, e.g.  downsampling, JPEG compression, blur, and noise.  , More importantly, our Gram-Net generalizes significantly better in detecting fake faces from GAN models not seen in the training phase.",24,5.58,7.6923076923076925
461,"['The Wasserstein probability metric has received much attention from the machine learning community.', 'Unlike the Kullback-Leibler divergence, which strictly measures change in probability, the Wasserstein metric reflects the underlying geometry between outcomes.', 'The value of being sensitive to this geometry has been demonstrated, among others, in ordinal regression and generative modelling, and most recently in reinforcement learning.', 'In this paper we describe three natural properties of probability divergences that we believe reflect requirements from machine learning: sum invariance, scale sensitivity, and unbiased sample gradients.', 'The Wasserstein metric possesses the first two properties but, unlike the Kullback-Leibler divergence, does not possess the third.', 'We provide empirical evidence suggesting this is a serious issue in practice.', 'Leveraging insights from probabilistic forecasting we propose an alternative to the Wasserstein metric, the Cramr distance.', 'We show that the Cramr distance possesses all three desired properties, combining the best of the Wasserstein and Kullback-Leibler divergences.', 'We give empirical results on a number of domains comparing these three divergences.', 'To illustrate the practical relevance of the Cramr distance we design a new algorithm, the Cramr Generative Adversarial Network (GAN), and show that it has a number of desirable properties over the related Wasserstein GAN.\n']","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.1666666567325592, 0.09999999403953552, 0.1304347813129425, 0.04081632196903229, 0.1538461446762085, 0.05714285373687744, 0.21052631735801697, 0.19512194395065308, 0.0, 0.15094339847564697]",S1m6h21Cb,"['The Wasserstein distance is hard to minimize with stochastic gradient descent, while the Cramer distance can be optimized easily and works just as well.', 'The manuscript proposes to use the Cramer distance to act as a loss when optimizing an objective function using stochastic gradient descent because it has unbiased sample gradients.', 'The contribution of the article is related to performance criteria, in particular to the Wasserstein/Mallows metric']","['wasserstein probability metric received much attention machine learning community ', 'unlike kullbackleibler divergence  strictly measure change probability  wasserstein metric reflects underlying geometry outcome ', 'value sensitive geometry demonstrated  among others  ordinal regression generative modelling  recently reinforcement learning ', 'paper describe three natural property probability divergence believe reflect requirement machine learning  sum invariance  scale sensitivity  unbiased sample gradient ', 'wasserstein metric posse first two property  unlike kullbackleibler divergence  posse third ', 'provide empirical evidence suggesting serious issue practice ', 'leveraging insight probabilistic forecasting propose alternative wasserstein metric  cramr distance ', 'show cramr distance posse three desired property  combining best wasserstein kullbackleibler divergence ', 'give empirical result number domain comparing three divergence ', 'illustrate practical relevance cramr distance design new algorithm  cramr generative adversarial network  gan   show number desirable property related wasserstein gan ']","The Wasserstein probability metric has received much attention from the machine learning community., Unlike the Kullback-Leibler divergence, which strictly measures change in probability, the Wasserstein metric reflects the underlying geometry between outcomes., The value of being sensitive to this geometry has been demonstrated, among others, in ordinal regression and generative modelling, and most recently in reinforcement learning., In this paper we describe three natural properties of probability divergences that we believe reflect requirements from machine learning: sum invariance, scale sensitivity, and unbiased sample gradients., The Wasserstein metric possesses the first two properties but, unlike the Kullback-Leibler divergence, does not possess the third., We provide empirical evidence suggesting this is a serious issue in practice., Leveraging insights from probabilistic forecasting we propose an alternative to the Wasserstein metric, the Cramr distance., We show that the Cramr distance possesses all three desired properties, combining the best of the Wasserstein and Kullback-Leibler divergences., We give empirical results on a number of domains comparing these three divergences., To illustrate the practical relevance of the Cramr distance we design a new algorithm, the Cramr Generative Adversarial Network (GAN), and show that it has a number of desirable properties over the related Wasserstein GAN.
",23,6.151515151515151,8.608695652173912
462,"['We humans have an innate understanding of the asymmetric progression of time, which we use to efficiently and safely perceive and manipulate our environment.', 'Drawing inspiration from that, we approach the problem of learning an arrow of time in a Markov (Decision) Process.', 'We illustrate how a learned arrow of time can capture salient information about the environment, which in turn can be used to measure reachability, detect side-effects and to obtain an intrinsic reward signal.', 'Finally, we propose a simple yet effective algorithm to parameterize the problem at hand and learn an arrow of time with a function approximator (here, a deep neural network).', 'Our empirical results span a selection of discrete and continuous environments, and demonstrate for a class of stochastic processes that the learned arrow of time agrees reasonably well with a well known notion of an arrow of time due to Jordan, Kinderlehrer and Otto (1998).']","[0, 0, 1, 0, 0]","[0.27272728085517883, 0.25, 0.5660377144813538, 0.3265306055545807, 0.2857142686843872]",rylJkpEtwS,"['We learn the arrow of time for MDPs and use it to measure reachability, detect side-effects and obtain a curiosity reward signal. ', 'This work proposes the h-potential as a solution to an objective that measures state-transition asymmetry in an MDP.']","['human innate understanding asymmetric progression time  use efficiently safely perceive manipulate environment ', 'drawing inspiration  approach problem learning arrow time markov  decision  process ', 'illustrate learned arrow time capture salient information environment  turn used measure reachability  detect sideeffects obtain intrinsic reward signal ', 'finally  propose simple yet effective algorithm parameterize problem hand learn arrow time function approximator   deep neural network  ', 'empirical result span selection discrete continuous environment  demonstrate class stochastic process learned arrow time agrees reasonably well well known notion arrow time due jordan  kinderlehrer otto  1998  ']","We humans have an innate understanding of the asymmetric progression of time, which we use to efficiently and safely perceive and manipulate our environment., Drawing inspiration from that, we approach the problem of learning an arrow of time in a Markov (Decision) Process., We illustrate how a learned arrow of time can capture salient information about the environment, which in turn can be used to measure reachability, detect side-effects and to obtain an intrinsic reward signal., Finally, we propose a simple yet effective algorithm to parameterize the problem at hand and learn an arrow of time with a function approximator (here, a deep neural network)., Our empirical results span a selection of discrete and continuous environments, and demonstrate for a class of stochastic processes that the learned arrow of time agrees reasonably well with a well known notion of an arrow of time due to Jordan, Kinderlehrer and Otto (1998).",13,5.1866666666666665,11.538461538461538
463,"['We formulate stochastic gradient descent (SGD) as a novel factorised Bayesian filtering problem, in which each parameter is inferred separately, conditioned on the corresopnding backpropagated gradient.  ', 'Inference in this setting naturally gives rise to BRMSprop and BAdam: Bayesian variants of RMSprop and Adam.  ', 'Remarkably, the Bayesian approach recovers many features of state-of-the-art adaptive SGD methods, including amongst others root-mean-square normalization, Nesterov acceleration and AdamW.  As such, the Bayesian approach provides one explanation for the empirical effectiveness of state-of-the-art adaptive SGD algorithms.  ', 'Empirically comparing BRMSprop and BAdam with naive RMSprop and Adam on MNIST, we find that Bayesian methods have the potential to considerably reduce test loss and classification error.']","[0, 1, 0, 0]","[0.23529411852359772, 0.3333333432674408, 0.25, 0.19607841968536377]",BygREjC9YQ,"['We formulated SGD as a Bayesian filtering problem, and show that this gives rise to RMSprop, Adam, AdamW, NAG and other features of state-of-the-art adaptive methods', 'The paper analyzes stochastic gradient descent through Bayesian filtering as a framework for analyzing adaptive methods.', 'The authors attempt to unify existing adaptive gradient methods under the Bayesian filtering framework with the dynamical prior']","['formulate stochastic gradient descent  sgd  novel factorised bayesian filtering problem  parameter inferred separately  conditioned corresopnding backpropagated gradient ', 'inference setting naturally give rise brmsprop badam  bayesian variant rmsprop adam ', 'remarkably  bayesian approach recovers many feature stateoftheart adaptive sgd method  including amongst others rootmeansquare normalization  nesterov acceleration adamw   bayesian approach provides one explanation empirical effectiveness stateoftheart adaptive sgd algorithm ', 'empirically comparing brmsprop badam naive rmsprop adam mnist  find bayesian method potential considerably reduce test loss classification error ']","We formulate stochastic gradient descent (SGD) as a novel factorised Bayesian filtering problem, in which each parameter is inferred separately, conditioned on the corresopnding backpropagated gradient.  , Inference in this setting naturally gives rise to BRMSprop and BAdam: Bayesian variants of RMSprop and Adam.  , Remarkably, the Bayesian approach recovers many features of state-of-the-art adaptive SGD methods, including amongst others root-mean-square normalization, Nesterov acceleration and AdamW.  As such, the Bayesian approach provides one explanation for the empirical effectiveness of state-of-the-art adaptive SGD algorithms.  , Empirically comparing BRMSprop and BAdam with naive RMSprop and Adam on MNIST, we find that Bayesian methods have the potential to considerably reduce test loss and classification error.",11,6.467889908256881,9.083333333333334
464,"['Data augmentation (DA) has been widely utilized to improve generalization in training deep neural networks.', 'Recently, human-designed data augmentation has been gradually replaced by automatically learned augmentation policy.', 'Through finding the best policy in well-designed search space of data augmentation, AutoAugment (Cubuk et al., 2019) can significantly improve validation accuracy on image classification tasks.', 'However, this approach is not computationally practical for large-scale problems.', 'In this paper, we develop an adversarial method to arrive at a computationally-affordable solution called Adversarial AutoAugment, which can simultaneously optimize target related object and augmentation policy search loss.', 'The augmentation policy network attempts to increase the training loss of a target network through generating adversarial augmentation policies, while the target network can learn more robust features from harder examples to improve the generalization.', 'In contrast to prior work, we reuse the computation in target network training for policy evaluation, and dispense with the retraining of the target network.', 'Compared to AutoAugment, this leads to about 12x reduction in computing cost and 11x shortening in time overhead on ImageNet.', 'We show experimental results of our approach on CIFAR-10/CIFAR-100, ImageNet, and demonstrate significant performance improvements over state-of-the-art.', 'On CIFAR-10, we achieve a top-1 test error of 1.36%, which is the currently best performing single model.', 'On ImageNet, we achieve a leading performance of top-1 accuracy 79.40% on ResNet-50 and 80.00% on ResNet-50-D without extra data.']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.25, 0.13793103396892548, 0.1818181723356247, 0.0, 0.17391303181648254, 0.4000000059604645, 0.21052631735801697, 0.05714285373687744, 0.11764705181121826, 0.1666666567325592, 0.15789473056793213]",ByxdUySKvS,"['We introduce the idea of adversarial learning into automatic data augmentation to improve the generalization  of a targe network.', 'A technique called Adversarial AutoAugment which dynamically learns good data augmentation policies during training using an adversarial approach.']","['data augmentation  da  widely utilized improve generalization training deep neural network ', 'recently  humandesigned data augmentation gradually replaced automatically learned augmentation policy ', 'finding best policy welldesigned search space data augmentation  autoaugment  cubuk et al  2019  significantly improve validation accuracy image classification task ', 'however  approach computationally practical largescale problem ', 'paper  develop adversarial method arrive computationallyaffordable solution called adversarial autoaugment  simultaneously optimize target related object augmentation policy search loss ', 'augmentation policy network attempt increase training loss target network generating adversarial augmentation policy  target network learn robust feature harder example improve generalization ', 'contrast prior work  reuse computation target network training policy evaluation  dispense retraining target network ', 'compared autoaugment  lead 12x reduction computing cost 11x shortening time overhead imagenet ', 'show experimental result approach cifar10cifar100  imagenet  demonstrate significant performance improvement stateoftheart ', 'cifar10  achieve top1 test error 136   currently best performing single model ', 'imagenet  achieve leading performance top1 accuracy 7940  resnet50 8000  resnet50d without extra data ']","Data augmentation (DA) has been widely utilized to improve generalization in training deep neural networks., Recently, human-designed data augmentation has been gradually replaced by automatically learned augmentation policy., Through finding the best policy in well-designed search space of data augmentation, AutoAugment (Cubuk et al., 2019) can significantly improve validation accuracy on image classification tasks., However, this approach is not computationally practical for large-scale problems., In this paper, we develop an adversarial method to arrive at a computationally-affordable solution called Adversarial AutoAugment, which can simultaneously optimize target related object and augmentation policy search loss., The augmentation policy network attempts to increase the training loss of a target network through generating adversarial augmentation policies, while the target network can learn more robust features from harder examples to improve the generalization., In contrast to prior work, we reuse the computation in target network training for policy evaluation, and dispense with the retraining of the target network., Compared to AutoAugment, this leads to about 12x reduction in computing cost and 11x shortening in time overhead on ImageNet., We show experimental results of our approach on CIFAR-10/CIFAR-100, ImageNet, and demonstrate significant performance improvements over state-of-the-art., On CIFAR-10, we achieve a top-1 test error of 1.36%, which is the currently best performing single model., On ImageNet, we achieve a leading performance of top-1 accuracy 79.40% on ResNet-50 and 80.00% on ResNet-50-D without extra data.",26,6.1798245614035086,8.76923076923077
465,"['In this study we focus on first-order meta-learning algorithms that aim to learn a parameter initialization of a network which can quickly adapt to new concepts, given a few examples.', 'We investigate two approaches to enhance generalization and speed of learning of such algorithms, particularly expanding on the Reptile (Nichol et al., 2018) algorithm.', 'We introduce a novel regularization technique called meta-step gradient pruning and also investigate the effects of increasing the depth of network architectures in first-order meta-learning.', 'We present an empirical evaluation of both approaches, where we match benchmark few-shot image classification results with 10 times fewer iterations using Mini-ImageNet dataset and with the use of deeper networks, we attain accuracies that surpass the current benchmarks of few-shot image classification using Omniglot dataset.']","[0, 1, 0, 0]","[0.260869562625885, 0.3720930218696594, 0.1904761791229248, 0.2545454502105713]",rJlzbihzdE,"['The study introduces two approaches to enhance generalization of first-order meta-learning and presents empirical evaluation on few-shot image classification.', 'The paper presents an empirical study of the first-order meta-learning Reptile algorithm, investigating a proposed regularization technique and deeper networks']","['study focus firstorder metalearning algorithm aim learn parameter initialization network quickly adapt new concept  given example ', 'investigate two approach enhance generalization speed learning algorithm  particularly expanding reptile  nichol et al  2018  algorithm ', 'introduce novel regularization technique called metastep gradient pruning also investigate effect increasing depth network architecture firstorder metalearning ', 'present empirical evaluation approach  match benchmark fewshot image classification result 10 time fewer iteration using miniimagenet dataset use deeper network  attain accuracy surpass current benchmark fewshot image classification using omniglot dataset ']","In this study we focus on first-order meta-learning algorithms that aim to learn a parameter initialization of a network which can quickly adapt to new concepts, given a few examples., We investigate two approaches to enhance generalization and speed of learning of such algorithms, particularly expanding on the Reptile (Nichol et al., 2018) algorithm., We introduce a novel regularization technique called meta-step gradient pruning and also investigate the effects of increasing the depth of network architectures in first-order meta-learning., We present an empirical evaluation of both approaches, where we match benchmark few-shot image classification results with 10 times fewer iterations using Mini-ImageNet dataset and with the use of deeper networks, we attain accuracies that surpass the current benchmarks of few-shot image classification using Omniglot dataset.",9,5.944,13.88888888888889
466,"['In this paper, we propose the use of in-training matrix factorization to reduce the model size for neural machine translation.', 'Using in-training matrix factorization, parameter matrices may be decomposed into the products of smaller matrices, which can compress large machine translation architectures by vastly reducing the number of learnable parameters.', 'We apply in-training matrix factorization to different layers of standard neural architectures and show that in-training factorization is capable of reducing nearly 50% of learnable parameters without any associated loss in BLEU score.', 'Further, we find that in-training matrix factorization is especially powerful on embedding layers, providing a simple and effective method to curtail the number of parameters with minimal impact on model performance, and, at times, an increase in performance.']","[1, 0, 0, 0]","[0.380952388048172, 0.15686273574829102, 0.19230768084526062, 0.19999998807907104]",HJg0_eBFwB,"['This paper proposes using matrix factorization at training time for neural machine translation, which can reduce model size and decrease training time without harming performance.', 'This paper proposes to compress models using matrix factorization during training for deep neural networks of machine translation.']","['paper  propose use intraining matrix factorization reduce model size neural machine translation ', 'using intraining matrix factorization  parameter matrix may decomposed product smaller matrix  compress large machine translation architecture vastly reducing number learnable parameter ', 'apply intraining matrix factorization different layer standard neural architecture show intraining factorization capable reducing nearly 50  learnable parameter without associated loss bleu score ', ' find intraining matrix factorization especially powerful embedding layer  providing simple effective method curtail number parameter minimal impact model performance   time  increase performance ']","In this paper, we propose the use of in-training matrix factorization to reduce the model size for neural machine translation., Using in-training matrix factorization, parameter matrices may be decomposed into the products of smaller matrices, which can compress large machine translation architectures by vastly reducing the number of learnable parameters., We apply in-training matrix factorization to different layers of standard neural architectures and show that in-training factorization is capable of reducing nearly 50% of learnable parameters without any associated loss in BLEU score., Further, we find that in-training matrix factorization is especially powerful on embedding layers, providing a simple and effective method to curtail the number of parameters with minimal impact on model performance, and, at times, an increase in performance.",12,5.983471074380165,10.083333333333334
467,"['Though state-of-the-art sentence representation models can perform tasks requiring significant knowledge of grammar, it is an open question how best to evaluate their grammatical knowledge.', 'We explore five experimental methods inspired by prior work evaluating pretrained sentence representation models.', 'We use a single linguistic phenomenon, negative polarity item (NPI) licensing, as a case study for our experiments.', ""NPIs like 'any' are grammatical only if they appear in a licensing environment like negation ('Sue doesn't have any cats' vs. '*Sue has any cats')."", 'This phenomenon is challenging because of the variety of NPI licensing environments that exist.', 'We introduce an artificially generated dataset that manipulates key features of NPI licensing for the experiments.', 'We find that BERT has significant knowledge of these features, but its success varies widely across different experimental methods.', ""We conclude that a variety of methods is necessary to reveal all relevant aspects of a model's grammatical knowledge in a given domain.\n""]","[0, 0, 1, 0, 0, 0, 0, 0]","[0.0, 0.06666666269302368, 0.24242423474788666, 0.1538461446762085, 0.0, 0.0624999962747097, 0.17142856121063232, 0.1621621549129486]",H1lok1JylS,['Different methods for analyzing BERT suggest different (but compatible) conclusions in a case study on NPIs.'],"['though stateoftheart sentence representation model perform task requiring significant knowledge grammar  open question best evaluate grammatical knowledge ', 'explore five experimental method inspired prior work evaluating pretrained sentence representation model ', 'use single linguistic phenomenon  negative polarity item  npi  licensing  case study experiment ', 'npis like  grammatical appear licensing environment like negation  sue nt cat  v   sue cat   ', 'phenomenon challenging variety npi licensing environment exist ', 'introduce artificially generated dataset manipulates key feature npi licensing experiment ', 'find bert significant knowledge feature  success varies widely across different experimental method ', 'conclude variety method necessary reveal relevant aspect model grammatical knowledge given domain ']","Though state-of-the-art sentence representation models can perform tasks requiring significant knowledge of grammar, it is an open question how best to evaluate their grammatical knowledge., We explore five experimental methods inspired by prior work evaluating pretrained sentence representation models., We use a single linguistic phenomenon, negative polarity item (NPI) licensing, as a case study for our experiments., NPIs like 'any' are grammatical only if they appear in a licensing environment like negation ('Sue doesn't have any cats' vs. '*Sue has any cats')., This phenomenon is challenging because of the variety of NPI licensing environments that exist., We introduce an artificially generated dataset that manipulates key features of NPI licensing for the experiments., We find that BERT has significant knowledge of these features, but its success varies widely across different experimental methods., We conclude that a variety of methods is necessary to reveal all relevant aspects of a model's grammatical knowledge in a given domain.
",12,5.7727272727272725,12.833333333333334
468,"['The primate visual system builds robust, multi-purpose representations of the external world in order to support several diverse downstream cortical processes.', 'Such representations are required to be invariant to the sensory inconsistencies caused by dynamically varying lighting, local texture distortion, etc.', 'A key architectural feature combating such environmental irregularities is long-range horizontal connections that aid the perception of the global form of objects.', 'In this work, we explore the introduction of such horizontal connections into standard deep convolutional networks; we present V1Net -- a novel convolutional-recurrent unit that models linear and nonlinear horizontal inhibitory and excitatory connections inspired by primate visual cortical connectivity.', 'We introduce the Texturized Challenge -- a new benchmark to evaluate object recognition performance under perceptual noise -- which we use to evaluate V1Net against an array of carefully selected control models with/without recurrent processing.', 'Additionally, we present results from an ablation study of V1Net demonstrating the utility of diverse neurally inspired horizontal connections for state-of-the-art AI systems on the task of object boundary detection from natural images.', 'We also present the emergence of several biologically plausible horizontal connectivity patterns, namely center-on surround-off, association fields and border-ownership connectivity patterns in a V1Net model trained to perform boundary detection on natural images from the Berkeley Segmentation Dataset 500 (BSDS500).', 'Our findings suggest an increased representational similarity between V1Net and biological visual systems, and highlight the importance of neurally inspired recurrent contextual processing principles for learning visual representations that are robust to perceptual noise and furthering the state-of-the-art in computer vision.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.1702127605676651, 0.08888888359069824, 0.08695651590824127, 0.4516128897666931, 0.24137930572032928, 0.1818181723356247, 0.15625, 0.2539682388305664]",Hyg4kkHKwH,"['In this work, we present V1Net -- a novel recurrent neural network modeling cortical horizontal connections that give rise to robust visual representations through perceptual grouping.', 'The authors propose to modify a convolutional variant of LSTM to include horizontal connections inspired by known interactions in visual cortex.']","['primate visual system build robust  multipurpose representation external world order support several diverse downstream cortical process ', 'representation required invariant sensory inconsistency caused dynamically varying lighting  local texture distortion  etc ', 'key architectural feature combating environmental irregularity  longrange horizontal connection  aid perception global form object ', 'work  explore introduction horizontal connection standard deep convolutional network  present v1net  novel convolutionalrecurrent unit model linear nonlinear horizontal inhibitory excitatory connection inspired primate visual cortical connectivity ', 'introduce texturized challenge  new benchmark evaluate object recognition performance perceptual noise  use evaluate v1net array carefully selected control model withwithout recurrent processing ', 'additionally  present result ablation study v1net demonstrating utility diverse neurally inspired horizontal connection stateoftheart ai system task object boundary detection natural image ', 'also present emergence several biologically plausible horizontal connectivity pattern  namely centeron surroundoff  association field borderownership connectivity pattern v1net model trained perform boundary detection natural image berkeley segmentation dataset 500  bsds500  ', 'finding suggest increased representational similarity v1net biological visual system  highlight importance neurally inspired recurrent contextual processing principle learning visual representation robust perceptual noise furthering stateoftheart computer vision ']","The primate visual system builds robust, multi-purpose representations of the external world in order to support several diverse downstream cortical processes., Such representations are required to be invariant to the sensory inconsistencies caused by dynamically varying lighting, local texture distortion, etc., A key architectural feature combating such environmental irregularities is long-range horizontal connections that aid the perception of the global form of objects., In this work, we explore the introduction of such horizontal connections into standard deep convolutional networks; we present V1Net -- a novel convolutional-recurrent unit that models linear and nonlinear horizontal inhibitory and excitatory connections inspired by primate visual cortical connectivity., We introduce the Texturized Challenge -- a new benchmark to evaluate object recognition performance under perceptual noise -- which we use to evaluate V1Net against an array of carefully selected control models with/without recurrent processing., Additionally, we present results from an ablation study of V1Net demonstrating the utility of diverse neurally inspired horizontal connections for state-of-the-art AI systems on the task of object boundary detection from natural images., We also present the emergence of several biologically plausible horizontal connectivity patterns, namely center-on surround-off, association fields and border-ownership connectivity patterns in a V1Net model trained to perform boundary detection on natural images from the Berkeley Segmentation Dataset 500 (BSDS500)., Our findings suggest an increased representational similarity between V1Net and biological visual systems, and highlight the importance of neurally inspired recurrent contextual processing principles for learning visual representations that are robust to perceptual noise and furthering the state-of-the-art in computer vision.",16,6.555555555555555,15.75
469,"['Humans understand novel sentences by composing meanings and roles of core language components.', 'In contrast, neural network models for natural language modeling fail when such compositional generalization is required.', 'The main contribution of this paper is to hypothesize that language compositionality is a form of group-equivariance.', 'Based on this hypothesis, we propose a set of tools for constructing equivariant sequence-to-sequence models.', 'Throughout a variety of experiments on the SCAN tasks, we analyze the behavior of existing models under the lens of equivariance, and demonstrate that our equivariant architecture is able to achieve the type compositional generalization required in human language understanding.']","[0, 0, 0, 1, 0]","[0.14814814925193787, 0.19999998807907104, 0.13793103396892548, 0.27586206793785095, 0.2448979616165161]",SylVNerFvr,"['We propose a link between permutation equivariance and compositional generalization, and provide equivariant language models', 'This work focuses on learning locally equivariant representations and functions over input/output words for the purposes of SCAN task.']","['human understand novel sentence composing meaning role core language component ', 'contrast  neural network model natural language modeling fail compositional generalization required ', 'main contribution paper hypothesize language compositionality form groupequivariance ', 'based hypothesis  propose set tool constructing equivariant sequencetosequence model ', 'throughout variety experiment scan task  analyze behavior existing model lens equivariance  demonstrate equivariant architecture able achieve type compositional generalization required human language understanding ']","Humans understand novel sentences by composing meanings and roles of core language components., In contrast, neural network models for natural language modeling fail when such compositional generalization is required., The main contribution of this paper is to hypothesize that language compositionality is a form of group-equivariance., Based on this hypothesis, we propose a set of tools for constructing equivariant sequence-to-sequence models., Throughout a variety of experiments on the SCAN tasks, we analyze the behavior of existing models under the lens of equivariance, and demonstrate that our equivariant architecture is able to achieve the type compositional generalization required in human language understanding.",9,6.128712871287129,11.222222222222221
470,"['Variational inference (VI) is a popular approach for approximate Bayesian inference that is particularly promising for highly parameterized models such as deep neural networks.  ', 'A key challenge of variational inference is to approximate the posterior over model parameters with a distribution that is simpler and tractable yet sufficiently expressive.', 'In this work, we propose a method for training highly flexible variational distributions by starting with a coarse approximation and iteratively refining it.', 'Each refinement step makes cheap, local adjustments and only requires optimization of simple variational families.', 'We demonstrate theoretically that our method always improves a bound on the approximation (the Evidence Lower BOund) and observe this empirically across a variety of benchmark tasks.  ', 'In experiments, our method consistently outperforms recent variational inference methods for deep learning in terms of log-likelihood and the ELBO.  ', 'We see that the gains are further amplified on larger scale models, significantly outperforming standard VI and deep ensembles on residual networks on CIFAR10.']","[0, 1, 0, 0, 0, 0, 0]","[0.1463414579629898, 0.23255813121795654, 0.04878048226237297, 0.1764705777168274, 0.08695651590824127, 0.19999998807907104, 0.09756097197532654]",rkglZyHtvH,"['The paper proposes an algorithm to increase the flexibility of the variational posterior in Bayesian neural networks through iterative optimization.', 'A method for training flexible variational posterior distributions, applied to Bayesian neural nets to perform variation inference (VI) over the weights.']","['variational inference  vi  popular approach approximate bayesian inference particularly promising highly parameterized model deep neural network ', 'key challenge variational inference approximate posterior model parameter distribution simpler tractable yet sufficiently expressive ', 'work  propose method training highly flexible variational distribution starting coarse approximation iteratively refining ', 'refinement step make cheap  local adjustment requires optimization simple variational family ', 'demonstrate theoretically method always improves bound approximation  evidence lower bound  observe empirically across variety benchmark task ', 'experiment  method consistently outperforms recent variational inference method deep learning term loglikelihood elbo ', 'see gain amplified larger scale model  significantly outperforming standard vi deep ensemble residual network cifar10 ']","Variational inference (VI) is a popular approach for approximate Bayesian inference that is particularly promising for highly parameterized models such as deep neural networks.  , A key challenge of variational inference is to approximate the posterior over model parameters with a distribution that is simpler and tractable yet sufficiently expressive., In this work, we propose a method for training highly flexible variational distributions by starting with a coarse approximation and iteratively refining it., Each refinement step makes cheap, local adjustments and only requires optimization of simple variational families., We demonstrate theoretically that our method always improves a bound on the approximation (the Evidence Lower BOund) and observe this empirically across a variety of benchmark tasks.  , In experiments, our method consistently outperforms recent variational inference methods for deep learning in terms of log-likelihood and the ELBO.  , We see that the gains are further amplified on larger scale models, significantly outperforming standard VI and deep ensembles on residual networks on CIFAR10.",11,6.031645569620253,14.363636363636363
471,"['In this paper, we propose a residual non-local attention network for high-quality image restoration.', 'Without considering the uneven distribution of information in the corrupted images, previous methods are restricted by local convolutional operation and equal treatment of spatial- and channel-wise features.', 'To address this issue, we design local and non-local attention blocks to extract features that capture the long-range dependencies between pixels and pay more attention to the challenging parts.', 'Specifically, we design trunk branch and (non-)local mask branch in each (non-)local attention block.', 'The trunk branch is used to extract hierarchical features.', 'Local and non-local mask branches aim to adaptively rescale these hierarchical features with mixed attentions.', 'The local mask branch concentrates on more local structures with convolutional operations, while non-local attention considers more about long-range dependencies in the whole feature map.', 'Furthermore, we propose residual local and non-local attention learning to train the very deep network, which further enhance the representation ability of the network.', 'Our proposed method can be generalized for various image restoration applications, such as image denoising, demosaicing, compression artifacts reduction, and super-resolution.', 'Experiments demonstrate that our method obtains comparable or better results compared with recently leading methods quantitatively and visually.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.29999998211860657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23076923191547394, 0.0]",HkeGhoA5FX,"['New state-of-the-art framework for image restoration', 'The paper proposes a convolutional neural network architecture that includes blocks for local and non-local attention mechanisms, which are claimed to be responsible for achieving excellent results in four image restoration applications.', 'This paper proposes a residual non-local attention network for image restoration']","['paper  propose residual nonlocal attention network highquality image restoration ', 'without considering uneven distribution information corrupted image  previous method restricted local convolutional operation equal treatment spatial channelwise feature ', 'address issue  design local nonlocal attention block extract feature capture longrange dependency pixel pay attention challenging part ', 'specifically  design trunk branch  non  local mask branch  non  local attention block ', 'trunk branch used extract hierarchical feature ', 'local nonlocal mask branch aim adaptively rescale hierarchical feature mixed attention ', 'local mask branch concentrate local structure convolutional operation  nonlocal attention considers longrange dependency whole feature map ', 'furthermore  propose residual local nonlocal attention learning train deep network  enhance representation ability network ', 'proposed method generalized various image restoration application  image denoising  demosaicing  compression artifact reduction  superresolution ', 'experiment demonstrate method obtains comparable better result compared recently leading method quantitatively visually ']","In this paper, we propose a residual non-local attention network for high-quality image restoration., Without considering the uneven distribution of information in the corrupted images, previous methods are restricted by local convolutional operation and equal treatment of spatial- and channel-wise features., To address this issue, we design local and non-local attention blocks to extract features that capture the long-range dependencies between pixels and pay more attention to the challenging parts., Specifically, we design trunk branch and (non-)local mask branch in each (non-)local attention block., The trunk branch is used to extract hierarchical features., Local and non-local mask branches aim to adaptively rescale these hierarchical features with mixed attentions., The local mask branch concentrates on more local structures with convolutional operations, while non-local attention considers more about long-range dependencies in the whole feature map., Furthermore, we propose residual local and non-local attention learning to train the very deep network, which further enhance the representation ability of the network., Our proposed method can be generalized for various image restoration applications, such as image denoising, demosaicing, compression artifacts reduction, and super-resolution., Experiments demonstrate that our method obtains comparable or better results compared with recently leading methods quantitatively and visually.",21,6.362244897959184,9.333333333333334
472,"['Most approaches to learning action planning models heavily rely on a significantly large volume of training samples or plan observations.', 'In this paper, we adopt a different approach based on deductive learning from domain-specific knowledge, specifically from logic formulae that specify constraints about the possible states of a given domain.', 'The minimal input observability required by our approach is a single example composed of a full initial state and a partial goal state.', 'We will show that exploiting specific domain knowledge enables to constrain the space of possible action models as well as to complete partial observations, both of which turn out helpful to learn good-quality action models.']","[0, 0, 0, 1]","[0.1538461446762085, 0.21276594698429108, 0.20512819290161133, 0.25]",B1xbgWIcPV,"['Hybrid approach to model acquisition that compensates a lack of available data with domain specific knowledge provided by experts', 'A domain acquisition approach that considers using a different representation for the partial domain model by using schematic mutex relations in place of pre/post conditions.']","['approach learning action planning model heavily rely significantly large volume training sample plan observation ', 'paper  adopt different approach based deductive learning domainspecific knowledge  specifically logic formula specify constraint possible state given domain ', 'minimal input observability required approach single example composed full initial state partial goal state ', 'show exploiting specific domain knowledge enables constrain space possible action model well complete partial observation  turn helpful learn goodquality action model ']","Most approaches to learning action planning models heavily rely on a significantly large volume of training samples or plan observations., In this paper, we adopt a different approach based on deductive learning from domain-specific knowledge, specifically from logic formulae that specify constraints about the possible states of a given domain., The minimal input observability required by our approach is a single example composed of a full initial state and a partial goal state., We will show that exploiting specific domain knowledge enables to constrain the space of possible action models as well as to complete partial observations, both of which turn out helpful to learn good-quality action models.",7,5.518518518518518,15.428571428571429
473,"['We release the largest public ECG dataset of continuous raw signals for representation learning containing over 11k patients and 2 billion labelled beats.', 'Our goal is to enable semi-supervised ECG models to be made as well as to discover unknown subtypes of arrhythmia and anomalous ECG signal events.', 'To this end, we propose an unsupervised representation learning task, evaluated in a semi-supervised fashion.  ', 'We provide a set of baselines for different feature extractors that can be built upon.  ', 'Additionally, we perform qualitative evaluations on results from PCA embeddings, where we identify some clustering of known subtypes indicating the potential for representation learning in arrhythmia sub-type discovery.']","[1, 0, 0, 0, 0]","[0.2857142686843872, 0.09999999403953552, 0.05714285373687744, 0.11428570747375488, 0.08695651590824127]",BkgqL0EtPH,"['We release a dataset constructed from single-lead ECG data from 11,000 patients who were prescribed to use the {DEVICENAME}(TM) device.', 'This paper describes a large-scale ECG dataset the authors intend to publish and provides unsupervised analysis and visualization of the dataset.']","['release largest public ecg dataset continuous raw signal representation learning containing 11k patient 2 billion labelled beat ', 'goal enable semisupervised ecg model made well discover unknown subtypes arrhythmia anomalous ecg signal event ', 'end  propose unsupervised representation learning task  evaluated semisupervised fashion ', 'provide set baseline different feature extractor built upon ', 'additionally  perform qualitative evaluation result pca embeddings  identify clustering known subtypes indicating potential representation learning arrhythmia subtype discovery ']","We release the largest public ECG dataset of continuous raw signals for representation learning containing over 11k patients and 2 billion labelled beats., Our goal is to enable semi-supervised ECG models to be made as well as to discover unknown subtypes of arrhythmia and anomalous ECG signal events., To this end, we propose an unsupervised representation learning task, evaluated in a semi-supervised fashion.  , We provide a set of baselines for different feature extractors that can be built upon.  , Additionally, we perform qualitative evaluations on results from PCA embeddings, where we identify some clustering of known subtypes indicating the potential for representation learning in arrhythmia sub-type discovery.",9,5.745283018867925,11.777777777777779
474,"['As the basic building block of Convolutional Neural Networks (CNNs), the convolutional layer is designed to extract local patterns and lacks the ability to model global context in its nature.', 'Many efforts have been recently made to complement CNNs with the global modeling ability, especially by a family of works on global feature interaction.', 'In these works, the global context information is incorporated into local features before they are fed into convolutional layers.', ""However, research on neuroscience reveals that, besides influences changing the inputs to our neurons, the neurons' ability of modifying their functions dynamically according to context is essential for perceptual tasks, which has been overlooked in most of CNNs."", 'Motivated by this, we propose one novel Context-Gated Convolution (CGC) to explicitly modify the weights of convolutional layers adaptively under the guidance of global context.', 'As such, being aware of the global context, the modulated convolution kernel of our proposed CGC can better extract representative local patterns and compose discriminative features.', 'Moreover, our proposed CGC is lightweight, amenable to modern CNN architectures, and consistently improves the performance of CNNs according to extensive experiments on image classification, action recognition, and machine translation.']","[0, 0, 0, 0, 0, 1, 0]","[0.22641508281230927, 0.12244897335767746, 0.27272728085517883, 0.09836065024137497, 0.2857142686843872, 0.35999998450279236, 0.07407406717538834]",B1lFkRNKDS,"['A novel Context-Gated Convolution which incorporates global context information into CNNs by explicitly modulating convolution kernels, and thus captures more representative local patterns and extract discriminative features.', 'This paper uses global context to modulate the weights of convolutional layers and help CNNs capture more discriminative features with high performance and fewer parameters than feature map modulating.']","['basic building block convolutional neural network  cnns   convolutional layer designed extract local pattern lack ability model global context nature ', 'many effort recently made complement cnns global modeling ability  especially family work global feature interaction ', 'work  global context information incorporated local feature fed convolutional layer ', 'however  research neuroscience reveals  besides influence changing input neuron  neuron  ability modifying function dynamically according context essential perceptual task  overlooked cnns ', 'motivated  propose one novel contextgated convolution  cgc  explicitly modify weight convolutional layer adaptively guidance global context ', ' aware global context  modulated convolution kernel proposed cgc better extract representative local pattern compose discriminative feature ', 'moreover  proposed cgc lightweight  amenable modern cnn architecture  consistently improves performance cnns according extensive experiment image classification  action recognition  machine translation ']","As the basic building block of Convolutional Neural Networks (CNNs), the convolutional layer is designed to extract local patterns and lacks the ability to model global context in its nature., Many efforts have been recently made to complement CNNs with the global modeling ability, especially by a family of works on global feature interaction., In these works, the global context information is incorporated into local features before they are fed into convolutional layers., However, research on neuroscience reveals that, besides influences changing the inputs to our neurons, the neurons' ability of modifying their functions dynamically according to context is essential for perceptual tasks, which has been overlooked in most of CNNs., Motivated by this, we propose one novel Context-Gated Convolution (CGC) to explicitly modify the weights of convolutional layers adaptively under the guidance of global context., As such, being aware of the global context, the modulated convolution kernel of our proposed CGC can better extract representative local patterns and compose discriminative features., Moreover, our proposed CGC is lightweight, amenable to modern CNN architectures, and consistently improves the performance of CNNs according to extensive experiments on image classification, action recognition, and machine translation.",22,5.880208333333333,8.727272727272727
475,"['We analyze the trade-off between quantization noise and clipping distortion in low precision networks.', 'We identify the statistics of various tensors, and derive exact expressions for the mean-square-error degradation due to clipping.', 'By optimizing these expressions, we show marked improvements over standard quantization schemes that normally avoid clipping.', 'For example, just by choosing the accurate clipping values, more than 40\\% accuracy improvement is obtained for the quantization of VGG-16 to 4-bits of precision.', 'Our results have many applications for the quantization of neural networks at both training and inference time. \n']","[1, 0, 0, 0, 0]","[0.7027027010917664, 0.19999998807907104, 0.5641025304794312, 0.17391303181648254, 0.1463414579629898]",B1x33sC9KQ,"['We analyze the trade-off between quantization noise and clipping distortion in low precision networks, and show marked improvements over standard quantization schemes that normally avoid clipping', 'Derives a formula for finding the minimum and maximum clipping values for uniform quantization which minimize the square error resulting from quantization, for either a Laplace or Gaussian distribution over pre-quantized value.']","['analyze tradeoff quantization noise clipping distortion low precision network ', 'identify statistic various tensor  derive exact expression meansquareerror degradation due clipping ', 'optimizing expression  show marked improvement standard quantization scheme normally avoid clipping ', 'example  choosing accurate clipping value  40  accuracy improvement obtained quantization vgg16 4bits precision ', 'result many application quantization neural network training inference time ']","We analyze the trade-off between quantization noise and clipping distortion in low precision networks., We identify the statistics of various tensors, and derive exact expressions for the mean-square-error degradation due to clipping., By optimizing these expressions, we show marked improvements over standard quantization schemes that normally avoid clipping., For example, just by choosing the accurate clipping values, more than 40\% accuracy improvement is obtained for the quantization of VGG-16 to 4-bits of precision., Our results have many applications for the quantization of neural networks at both training and inference time. 
",9,6.011111111111111,10.0
476,"['Batch Normalization (BN) is one of the most widely used techniques in Deep Learning field.', 'But its performance can awfully degrade with insufficient batch size.', 'This weakness limits the usage of BN on many computer vision tasks like detection or segmentation, where batch size is usually small due to the constraint of memory consumption.', 'Therefore many modified normalization techniques have been proposed, which either fail to restore the performance of BN completely, or have to introduce additional nonlinear operations in inference procedure and increase huge consumption.', 'In this paper, we reveal that there are two extra batch statistics involved in backward propagation of BN, on which has never been well discussed before.', 'The extra batch statistics associated with gradients also can severely affect the training of deep neural network.', 'Based on our analysis, we propose a novel normalization method, named Moving Average Batch Normalization (MABN).', 'MABN can completely restore the performance of vanilla BN in small batch cases, without introducing any additional nonlinear operations in inference procedure.', 'We prove the benefits of MABN by both theoretical analysis and experiments.', 'Our experiments demonstrate the effectiveness of MABN in multiple computer vision tasks including ImageNet and COCO.', 'The code has been released in https://github.com/megvii-model/MABN.']","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.0, 0.1818181723356247, 0.20512820780277252, 0.0952380895614624, 0.052631575614213943, 0.06896550953388214, 0.2857142686843872, 0.12121211737394333, 0.0833333283662796, 0.0, 0.0]",SkgGjRVKDS,"['We propose a novel normalization method to handle small batch size cases.', 'A method to deal with the small batch size problem of BN which applies moving average operation without too much overhead and reduces the number of statistics of BN for better stability.']","['batch normalization  bn  one widely used technique deep learning field ', 'performance awfully degrade insufficient batch size ', 'weakness limit usage bn many computer vision task like detection segmentation  batch size usually small due constraint memory consumption ', 'therefore many modified normalization technique proposed  either fail restore performance bn completely  introduce additional nonlinear operation inference procedure increase huge consumption ', 'paper  reveal two extra batch statistic involved backward propagation bn  never well discussed ', 'extra batch statistic associated gradient also severely affect training deep neural network ', 'based analysis  propose novel normalization method  named moving average batch normalization  mabn  ', 'mabn completely restore performance vanilla bn small batch case  without introducing additional nonlinear operation inference procedure ', 'prove benefit mabn theoretical analysis experiment ', 'experiment demonstrate effectiveness mabn multiple computer vision task including imagenet coco ', 'code released http  githubcommegviimodelmabn ']","Batch Normalization (BN) is one of the most widely used techniques in Deep Learning field., But its performance can awfully degrade with insufficient batch size., This weakness limits the usage of BN on many computer vision tasks like detection or segmentation, where batch size is usually small due to the constraint of memory consumption., Therefore many modified normalization techniques have been proposed, which either fail to restore the performance of BN completely, or have to introduce additional nonlinear operations in inference procedure and increase huge consumption., In this paper, we reveal that there are two extra batch statistics involved in backward propagation of BN, on which has never been well discussed before., The extra batch statistics associated with gradients also can severely affect the training of deep neural network., Based on our analysis, we propose a novel normalization method, named Moving Average Batch Normalization (MABN)., MABN can completely restore the performance of vanilla BN in small batch cases, without introducing any additional nonlinear operations in inference procedure., We prove the benefits of MABN by both theoretical analysis and experiments., Our experiments demonstrate the effectiveness of MABN in multiple computer vision tasks including ImageNet and COCO., The code has been released in https://github.com/megvii-model/MABN.",19,5.797029702970297,10.631578947368421
477,"['We present a simple proof for the benefit of depth in multi-layer feedforward network with rectifed activation (``""depth separation"").', 'Specifically we present a sequence of classification problems f_i such that', '(a) for any fixed depth rectified network we can find an index m such that problems with index > m require exponential network width to fully represent the function f_m; and', '(b) for any problem f_m in the family, we present a concrete neural network with linear depth and bounded width that fully represents it.\n\n', 'While there are several previous work showing similar results, our proof uses substantially simpler tools and techniques, and should be accessible to undergraduate students in computer science and people with similar backgrounds.']","[1, 0, 0, 0, 0]","[0.2222222238779068, 0.0, 0.1111111044883728, 0.12121211737394333, 0.10810810327529907]",SkxEWgStDr,"['ReLU MLP depth seperation proof with gemoteric arguments', 'A proof that deeper networks need less units than shallower ones for a family of problems. ']","['present simple proof benefit depth multilayer feedforward network rectifed activation    depth separation   ', 'specifically present sequence classification problem fi', '  fixed depth rectified network find index problem index  require exponential network width fully represent function fm ', ' b  problem fm family  present concrete neural network linear depth bounded width fully represents ', 'several previous work showing similar result  proof us substantially simpler tool technique  accessible undergraduate student computer science people similar background ']","We present a simple proof for the benefit of depth in multi-layer feedforward network with rectifed activation (``""depth separation"")., Specifically we present a sequence of classification problems f_i such that, (a) for any fixed depth rectified network we can find an index m such that problems with index > m require exponential network width to fully represent the function f_m; and, (b) for any problem f_m in the family, we present a concrete neural network with linear depth and bounded width that fully represents it.

, While there are several previous work showing similar results, our proof uses substantially simpler tools and techniques, and should be accessible to undergraduate students in computer science and people with similar backgrounds.",8,5.410256410256411,14.625
478,"['The rich and accessible labeled data fuel the revolutionary success of deep learning.', 'Nonetheless, massive supervision remains a luxury for many real applications, boosting great interest in label-scarce techniques such as few-shot learning (FSL).', 'An intuitively feasible approach to FSL is to conduct data augmentation via synthesizing additional training samples.', 'The key to this approach is how to guarantee both discriminability and diversity of the synthesized samples.', 'In this paper, we propose a novel FSL model, called $\\textrm{D}^2$GAN, which synthesizes Diverse and Discriminative features based on Generative Adversarial Networks (GAN).', '$\\textrm{D}^2$GAN secures discriminability of the synthesized features by constraining them to have high correlation with real features of the same classes while low correlation with those of different classes.  ', 'Based on the observation that noise vectors that are closer in the latent code space are more likely to be collapsed into the same mode when mapped to feature space, $\\textrm{D}^2$GAN incorporates a novel anti-collapse regularization term, which encourages feature diversity by penalizing the ratio of the logarithmic similarity of two synthesized features and the logarithmic similarity of the latent codes generating them.', 'Experiments on three common benchmark datasets verify the effectiveness of $\\textrm{D}^2$GAN by comparing with the state-of-the-art.']","[1, 0, 0, 0, 0, 0, 0, 0]","[0.1538461446762085, 0.11764705181121826, 0.0714285671710968, 0.06896550953388214, 0.1111111044883728, 0.0555555522441864, 0.06557376682758331, 0.0714285671710968]",S1eof0VKwH,"['A new GAN based few-shot learning algorithm by synthesizing  diverse and discriminative Features', 'A meta-learning method that learns a generative model that can augment the support set of a few-shot learner which optimizes a combination of losses.']","['rich accessible labeled data fuel revolutionary success deep learning ', 'nonetheless  massive supervision remains luxury many real application  boosting great interest labelscarce technique fewshot learning  fsl  ', 'intuitively feasible approach fsl conduct data augmentation via synthesizing additional training sample ', 'key approach guarantee discriminability diversity synthesized sample ', 'paper  propose novel fsl model  called  textrm   2  gan  synthesizes diverse discriminative feature based generative adversarial network  gan  ', ' textrm   2  gan secures discriminability synthesized feature constraining high correlation real feature class low correlation different class ', 'based observation noise vector closer latent code space likely collapsed mode mapped feature space   textrm   2  gan incorporates novel anticollapse regularization term  encourages feature diversity penalizing ratio logarithmic similarity two synthesized feature logarithmic similarity latent code generating ', 'experiment three common benchmark datasets verify effectiveness  textrm   2  gan comparing stateoftheart ']","The rich and accessible labeled data fuel the revolutionary success of deep learning., Nonetheless, massive supervision remains a luxury for many real applications, boosting great interest in label-scarce techniques such as few-shot learning (FSL)., An intuitively feasible approach to FSL is to conduct data augmentation via synthesizing additional training samples., The key to this approach is how to guarantee both discriminability and diversity of the synthesized samples., In this paper, we propose a novel FSL model, called $\textrm{D}^2$GAN, which synthesizes Diverse and Discriminative features based on Generative Adversarial Networks (GAN)., $\textrm{D}^2$GAN secures discriminability of the synthesized features by constraining them to have high correlation with real features of the same classes while low correlation with those of different classes.  , Based on the observation that noise vectors that are closer in the latent code space are more likely to be collapsed into the same mode when mapped to feature space, $\textrm{D}^2$GAN incorporates a novel anti-collapse regularization term, which encourages feature diversity by penalizing the ratio of the logarithmic similarity of two synthesized features and the logarithmic similarity of the latent codes generating them., Experiments on three common benchmark datasets verify the effectiveness of $\textrm{D}^2$GAN by comparing with the state-of-the-art.",15,6.121212121212121,13.2
479,"['The lack of crisp mathematical models that capture the structure of real-world\n', 'data sets is a major obstacle to the detailed theoretical understanding of deep\n', 'neural networks.', 'Here, we first demonstrate the effect of structured data sets\n', 'by experimentally comparing the dynamics and the performance of two-layer\n', 'networks trained on two different data sets:', '(i) an unstructured synthetic data\nset containing random i.i.d. inputs, and', '(ii) a simple canonical data set such\n', 'as MNIST images.', 'Our analysis reveals two phenomena related to the dynamics of\n', 'the networks and their ability to generalise that only appear when training on\n', 'structured data sets.', 'Second, we introduce a generative model for data sets,\n', 'where high-dimensional inputs lie on a lower-dimensional manifold and have\n', 'labels that depend only on their position within this manifold.', 'We call it the\n', '*hidden manifold model* and we experimentally demonstrate that training\n', 'networks on data sets drawn from this model reproduces both the phenomena seen\n', 'during training on MNIST.']","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.1249999925494194, 0.1764705777168274, 0.19354838132858276, 0.06666666269302368, 0.1428571343421936, 0.1818181723356247, 0.1428571343421936, 0.0, 0.0, 0.1764705777168274, 0.1666666716337204, 0.4000000059604645, 0.12903225421905518, 0.12903225421905518, 0.07999999821186066, 0.20000000298023224, 0.3529411852359772, 0.0]",BJlisySYPS,"['We demonstrate how structure in data sets impacts neural networks and introduce a generative model for synthetic data sets that reproduces this impact.', 'The paper studies how different settings of data structure affect learning of neural networks and how to mimic behavior on real datasets when learning on a synthetic one.']","['lack crisp mathematical model capture structure realworld', 'data set major obstacle detailed theoretical understanding deep', 'neural network ', ' first demonstrate effect structured data set', 'experimentally comparing dynamic performance twolayer', 'network trained two different data set ', '  unstructured synthetic data set containing random iid  input ', ' ii  simple canonical data set', 'mnist image ', 'analysis reveals two phenomenon related dynamic', 'network ability generalise appear training', 'structured data set ', 'second  introduce generative model data set ', 'highdimensional input lie lowerdimensional manifold', 'label depend position within manifold ', 'call', ' hidden manifold model  experimentally demonstrate training', 'network data set drawn model reproduces phenomenon seen', 'training mnist ']","The lack of crisp mathematical models that capture the structure of real-world
, data sets is a major obstacle to the detailed theoretical understanding of deep
, neural networks., Here, we first demonstrate the effect of structured data sets
, by experimentally comparing the dynamics and the performance of two-layer
, networks trained on two different data sets:, (i) an unstructured synthetic data
set containing random i.i.d. inputs, and, (ii) a simple canonical data set such
, as MNIST images., Our analysis reveals two phenomena related to the dynamics of
, the networks and their ability to generalise that only appear when training on
, structured data sets., Second, we introduce a generative model for data sets,
, where high-dimensional inputs lie on a lower-dimensional manifold and have
, labels that depend only on their position within this manifold., We call it the
, *hidden manifold model* and we experimentally demonstrate that training
, networks on data sets drawn from this model reproduces both the phenomena seen
, during training on MNIST.",22,5.4625,6.956521739130435
480,"['In this paper, we study deep diagonal circulant neural networks, that is deep neural networks in which weight matrices are the product of diagonal and circulant ones.\n', 'Besides making a theoretical analysis of their expressivity, we introduced principled techniques for training these models: we devise an initialization scheme and proposed a smart use of non-linearity functions in order to train deep diagonal circulant networks. \n', 'Furthermore, we show that these networks outperform recently introduced deep networks with other types of structured layers.', 'We conduct a thorough experimental study to compare the performance of deep diagonal circulant networks with state of the art models based on structured matrices and with dense models.', 'We show that our models achieve better accuracy than other structured approaches while required 2x fewer weights as the next best approach.', 'Finally we train deep diagonal circulant networks to build a compact and accurate models on a real world video classification dataset with over 3.8 million training examples.']","[0, 0, 0, 0, 0, 1]","[0.42553192377090454, 0.24137930572032928, 0.25641024112701416, 0.375, 0.13333332538604736, 0.4399999976158142]",rygL4gStDS,"['We train deep neural networks based on diagonal and circulant matrices, and show that this type of networks are both compact and accurate on real world applications.', 'The authors provide a theoretical analysis of the expressive power of diagonal circulant neural networks (DCNN) and propose an initialization scheme for deep DCNNs.']","['paper  study deep diagonal circulant neural network  deep neural network weight matrix product diagonal circulant one ', 'besides making theoretical analysis expressivity  introduced principled technique training model  devise initialization scheme proposed smart use nonlinearity function order train deep diagonal circulant network ', 'furthermore  show network outperform recently introduced deep network type structured layer ', 'conduct thorough experimental study compare performance deep diagonal circulant network state art model based structured matrix dense model ', 'show model achieve better accuracy structured approach required 2x fewer weight next best approach ', 'finally train deep diagonal circulant network build compact accurate model real world video classification dataset 38 million training example ']","In this paper, we study deep diagonal circulant neural networks, that is deep neural networks in which weight matrices are the product of diagonal and circulant ones.
, Besides making a theoretical analysis of their expressivity, we introduced principled techniques for training these models: we devise an initialization scheme and proposed a smart use of non-linearity functions in order to train deep diagonal circulant networks. 
, Furthermore, we show that these networks outperform recently introduced deep networks with other types of structured layers., We conduct a thorough experimental study to compare the performance of deep diagonal circulant networks with state of the art models based on structured matrices and with dense models., We show that our models achieve better accuracy than other structured approaches while required 2x fewer weights as the next best approach., Finally we train deep diagonal circulant networks to build a compact and accurate models on a real world video classification dataset with over 3.8 million training examples.",10,5.610062893081761,15.9
481,"['Interpretability has largely focused on local explanations, i.e. explaining why a model made a particular prediction for a sample.', 'These explanations are appealing due to their simplicity and local fidelity.', 'However, they do not provide information about the general behavior of the model.', 'We propose to leverage model distillation to learn global additive explanations that describe the relationship between input features and model predictions.', 'These global explanations take the form of feature shapes, which are more expressive than feature attributions.', 'Through careful experimentation, we show qualitatively and quantitatively that global additive explanations are able to describe model behavior and yield insights about models such as neural nets.', 'A visualization of our approach applied to a neural net as it is trained is available at https://youtu.be/ErQYwNqzEdc']","[0, 0, 0, 1, 0, 0, 0]","[0.11999999731779099, 0.1395348757505417, 0.13636362552642822, 0.4313725531101227, 0.42553192377090454, 0.37931033968925476, 0.19999998807907104]",SJl8J30qFX,"['We propose to leverage model distillation to learn global additive explanations in the form of feature shapes (that are more expressive than feature attributions) for models such as neural nets trained on tabular data.', 'This paper incorporates Generalized Additive Models (GAMs) with model distillation to provide global explanations of neural nets.']","['interpretability largely focused local explanation  ie  explaining model made particular prediction sample ', 'explanation appealing due simplicity local fidelity ', 'however  provide information general behavior model ', 'propose leverage model distillation learn global additive explanation describe relationship input feature model prediction ', 'global explanation take form feature shape  expressive feature attribution ', 'careful experimentation  show qualitatively quantitatively global additive explanation able describe model behavior yield insight model neural net ', 'visualization approach applied neural net trained available http  youtubeerqywnqzedc']","Interpretability has largely focused on local explanations, i.e. explaining why a model made a particular prediction for a sample., These explanations are appealing due to their simplicity and local fidelity., However, they do not provide information about the general behavior of the model., We propose to leverage model distillation to learn global additive explanations that describe the relationship between input features and model predictions., These global explanations take the form of feature shapes, which are more expressive than feature attributions., Through careful experimentation, we show qualitatively and quantitatively that global additive explanations are able to describe model behavior and yield insights about models such as neural nets., A visualization of our approach applied to a neural net as it is trained is available at https://youtu.be/ErQYwNqzEdc",11,5.96,10.416666666666666
482,"['A lot of the recent success in natural language processing (NLP) has been driven by distributed vector representations of words trained on large amounts of text in an unsupervised manner.', 'These representations are typically used as general purpose features for words across a range of NLP problems.', 'However, extending this success to learning representations of sequences of words, such as sentences, remains an open problem.', 'Recent work has explored unsupervised as well as supervised learning techniques with different training objectives to learn general purpose fixed-length sentence representations.', 'In this work, we present a simple, effective multi-task learning framework for sentence representations that combines the inductive biases of diverse training objectives in a single model. \n', 'We train this model on several data sources with multiple training objectives on over 100 million sentences.', 'Extensive experiments demonstrate that sharing a single recurrent sentence encoder across weakly related tasks leads to consistent improvements over previous methods.', 'We present substantial improvements in the context of transfer learning and low-resource settings using our learned general-purpose representations.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.09756097197532654, 0.06451612710952759, 0.19354838132858276, 0.514285683631897, 0.39024388790130615, 0.19999998807907104, 0.11428570747375488, 0.1249999925494194]",B18WgG-CZ,"['A large-scale multi-task learning framework with diverse training objectives to learn fixed-length sentence representations', 'This paper is about learning sentence embeddings by combining several training signals: skip-thought, predicting translation, classifying entailment relationships, and predicting the constituent parse.']","['lot recent success natural language processing  nlp  driven distributed vector representation word trained large amount text unsupervised manner ', 'representation typically used general purpose feature word across range nlp problem ', 'however  extending success learning representation sequence word  sentence  remains open problem ', 'recent work explored unsupervised well supervised learning technique different training objective learn general purpose fixedlength sentence representation ', 'work  present simple  effective multitask learning framework sentence representation combine inductive bias diverse training objective single model ', 'train model several data source multiple training objective 100 million sentence ', 'extensive experiment demonstrate sharing single recurrent sentence encoder across weakly related task lead consistent improvement previous method ', 'present substantial improvement context transfer learning lowresource setting using learned generalpurpose representation ']","A lot of the recent success in natural language processing (NLP) has been driven by distributed vector representations of words trained on large amounts of text in an unsupervised manner., These representations are typically used as general purpose features for words across a range of NLP problems., However, extending this success to learning representations of sequences of words, such as sentences, remains an open problem., Recent work has explored unsupervised as well as supervised learning techniques with different training objectives to learn general purpose fixed-length sentence representations., In this work, we present a simple, effective multi-task learning framework for sentence representations that combines the inductive biases of diverse training objectives in a single model. 
, We train this model on several data sources with multiple training objectives on over 100 million sentences., Extensive experiments demonstrate that sharing a single recurrent sentence encoder across weakly related tasks leads to consistent improvements over previous methods., We present substantial improvements in the context of transfer learning and low-resource settings using our learned general-purpose representations.",13,6.141176470588236,13.076923076923077
483,"['In a time where neural networks are increasingly adopted in sensitive applications, algorithmic bias has emerged as an issue with moral implications.', 'While there are myriad ways that a system may be compromised by bias, systematically isolating and evaluating existing systems on such scenarios is non-trivial, i.e., bias may be subtle, natural and inherently difficult to quantify.', 'To this end, this paper proposes the first systematic study of benchmarking state-of-the-art neural models against biased scenarios.', 'More concretely, we postulate that the bias annotator problem can be approximated with neural models, i.e., we propose generative models of latent bias to deliberately and unfairly associate latent features to a specific class.', 'All in all, our framework provides a new way for principled quantification and evaluation of models against biased datasets.', 'Consequently, we find that state-of-the-art NLP models (e.g., BERT, RoBERTa, XLNET) are readily compromised by biased data.']","[0, 0, 0, 1, 0, 0]","[0.1621621549129486, 0.16326530277729034, 0.1875, 0.2978723347187042, 0.23529411852359772, 0.11764705181121826]",SyekUyrFPS,"['We propose a neural bias annotator to benchmark models on their robustness to biased text datasets.', 'A method to generate biased datasets for NLP, relying on a conditional adversarially regularized autoencoder (CARA).']","['time neural network increasingly adopted sensitive application  algorithmic bias emerged issue moral implication ', 'myriad way system may compromised bias  systematically isolating evaluating existing system scenario nontrivial  ie  bias may subtle  natural inherently difficult quantify ', 'end  paper proposes first systematic study benchmarking stateoftheart neural model biased scenario ', 'concretely  postulate bias annotator problem approximated neural model  ie  propose generative model latent bias deliberately unfairly associate latent feature specific class ', ' framework provides new way principled quantification evaluation model biased datasets ', 'consequently  find stateoftheart nlp model  eg  bert  roberta  xlnet  readily compromised biased data ']","In a time where neural networks are increasingly adopted in sensitive applications, algorithmic bias has emerged as an issue with moral implications., While there are myriad ways that a system may be compromised by bias, systematically isolating and evaluating existing systems on such scenarios is non-trivial, i.e., bias may be subtle, natural and inherently difficult to quantify., To this end, this paper proposes the first systematic study of benchmarking state-of-the-art neural models against biased scenarios., More concretely, we postulate that the bias annotator problem can be approximated with neural models, i.e., we propose generative models of latent bias to deliberately and unfairly associate latent features to a specific class., All in all, our framework provides a new way for principled quantification and evaluation of models against biased datasets., Consequently, we find that state-of-the-art NLP models (e.g., BERT, RoBERTa, XLNET) are readily compromised by biased data.",20,5.751724137931035,7.25
484,"['We consider the problem of topic modeling in a weakly semi-supervised setting.', 'In this scenario, we assume that the user knows a priori a subset of the topics she wants the model to learn and is able to provide a few exemplar documents for those topics.', 'In addition, while each document may typically consist of multiple topics, we do not assume that the user will identify all its topics exhaustively.\n      \n', 'Recent state-of-the-art topic models such as NVDM, referred to herein as Neural Topic Models (NTMs), fall under the variational autoencoder framework.', 'We extend NTMs to the weakly semi-supervised setting by using informative priors in the training objective.', 'After analyzing the effect of informative priors, we propose a simple modification of the NVDM model using a logit-normal posterior that we show achieves better alignment to user-desired topics versus other NTM models.']","[1, 0, 0, 0, 0, 0]","[0.23529411852359772, 0.07999999821186066, 0.08510638028383255, 0.1428571343421936, 0.1621621549129486, 0.23529411852359772]",BJlRKgkDwN,"['We propose supervising VAE-style topic models by intelligently adjusting the prior on a per document basis. We find a logit-normal posterior provides the best performance.', 'A flexible method of weakly supervising a topic model to achieve better alignment with user intuition.']","['consider problem topic modeling weakly semisupervised setting ', 'scenario  assume user know priori subset topic want model learn able provide exemplar document topic ', 'addition  document may typically consist multiple topic  assume user identify topic exhaustively ', 'recent stateoftheart topic model nvdm  referred herein neural topic model  ntms   fall variational autoencoder framework ', 'extend ntms weakly semisupervised setting using informative prior training objective ', 'analyzing effect informative prior  propose simple modification nvdm model using logitnormal posterior show achieves better alignment userdesired topic versus ntm model ']","We consider the problem of topic modeling in a weakly semi-supervised setting., In this scenario, we assume that the user knows a priori a subset of the topics she wants the model to learn and is able to provide a few exemplar documents for those topics., In addition, while each document may typically consist of multiple topics, we do not assume that the user will identify all its topics exhaustively.
      
, Recent state-of-the-art topic models such as NVDM, referred to herein as Neural Topic Models (NTMs), fall under the variational autoencoder framework., We extend NTMs to the weakly semi-supervised setting by using informative priors in the training objective., After analyzing the effect of informative priors, we propose a simple modification of the NVDM model using a logit-normal posterior that we show achieves better alignment to user-desired topics versus other NTM models.",12,5.25,11.666666666666666
485,"['Analyzing deep neural networks (DNNs) via information plane (IP) theory has gained tremendous attention recently as a tool to gain insight into, among others, their generalization ability.', 'However, it is by no means obvious how to estimate mutual information (MI) between each hidden layer and the input/desired output, to construct the IP.', 'For instance, hidden layers with many neurons require MI estimators with robustness towards the high dimensionality associated with such layers.', 'MI estimators should also be able to naturally handle convolutional layers, while at the same time being computationally tractable to scale to large networks.', 'None of the existing IP methods to date have been able to study truly deep Convolutional Neural Networks (CNNs), such as the e.g.\\ VGG-16.', ""In this paper, we propose an IP analysis using the new matrix--based R\\'enyi's entropy coupled with tensor kernels over convolutional layers, leveraging the power of kernel methods to represent properties of the probability distribution independently of the dimensionality of the data."", 'The obtained results shed new light on the previous literature concerning small-scale DNNs, however using a completely new approach.', 'Importantly, the new framework enables us to provide the first comprehensive IP analysis of contemporary large-scale DNNs and CNNs, investigating the different training phases and providing new insights into the training dynamics of large-scale neural networks.']","[0, 0, 0, 0, 0, 0, 0, 1]","[0.2222222238779068, 0.09756097197532654, 0.0, 0.14999999105930328, 0.0952380895614624, 0.23076923191547394, 0.0555555522441864, 0.260869562625885]",B1l0wp4tvr,"['First comprehensive information plane analysis of large scale deep neural networks using matrix based entropy and tensor kernels.', 'The authors propose a tensor-kernel based estimator for mutual information estimation between high-dimensional layers in a neural network.']","['analyzing deep neural network  dnns  via information plane  ip  theory gained tremendous attention recently tool gain insight  among others  generalization ability ', 'however  mean obvious estimate mutual information  mi  hidden layer inputdesired output  construct ip ', 'instance  hidden layer many neuron require mi estimator robustness towards high dimensionality associated layer ', 'mi estimator also able naturally handle convolutional layer  time computationally tractable scale large network ', 'none existing ip method date able study truly deep convolutional neural network  cnns   eg vgg16 ', 'paper  propose ip analysis using new matrix  based renyi entropy coupled tensor kernel convolutional layer  leveraging power kernel method represent property probability distribution independently dimensionality data ', 'obtained result shed new light previous literature concerning smallscale dnns  however using completely new approach ', 'importantly  new framework enables u provide first comprehensive ip analysis contemporary largescale dnns cnns  investigating different training phase providing new insight training dynamic largescale neural network ']","Analyzing deep neural networks (DNNs) via information plane (IP) theory has gained tremendous attention recently as a tool to gain insight into, among others, their generalization ability., However, it is by no means obvious how to estimate mutual information (MI) between each hidden layer and the input/desired output, to construct the IP., For instance, hidden layers with many neurons require MI estimators with robustness towards the high dimensionality associated with such layers., MI estimators should also be able to naturally handle convolutional layers, while at the same time being computationally tractable to scale to large networks., None of the existing IP methods to date have been able to study truly deep Convolutional Neural Networks (CNNs), such as the e.g.\ VGG-16., In this paper, we propose an IP analysis using the new matrix--based R\'enyi's entropy coupled with tensor kernels over convolutional layers, leveraging the power of kernel methods to represent properties of the probability distribution independently of the dimensionality of the data., The obtained results shed new light on the previous literature concerning small-scale DNNs, however using a completely new approach., Importantly, the new framework enables us to provide the first comprehensive IP analysis of contemporary large-scale DNNs and CNNs, investigating the different training phases and providing new insights into the training dynamics of large-scale neural networks.",20,5.726851851851852,10.8
486,"['Developing agents that can learn to follow natural language instructions has been an emerging research direction.', 'While being accessible and flexible, natural language instructions can sometimes be ambiguous even to humans.', 'To address this, we propose to utilize programs, structured in a formal language, as a precise and expressive way to specify tasks.', 'We then devise a modular framework that learns to perform a task specified by a program  as different circumstances give rise to diverse ways to accomplish the task, our framework can perceive which circumstance it is currently under, and instruct a multitask policy accordingly to fulfill each subtask of the overall task.', 'Experimental results on a 2D Minecraft environment not only demonstrate that the proposed framework learns to reliably accomplish program instructions and achieves zero-shot generalization to more complex instructions but also verify the efficiency of the proposed modulation mechanism for learning the multitask policy.', 'We also conduct an analysis comparing various models which learn from programs and natural language instructions in an end-to-end fashion.']","[0, 0, 0, 0, 1, 0]","[0.17142856121063232, 0.1764705777168274, 0.25641024112701416, 0.3492063581943512, 0.3571428656578064, 0.15789473056793213]",BkxUvnEYDH,"['We propose a modular framework that can accomplish tasks specified by programs and achieve zero-shot generalization to more complex tasks.', 'This paper investigates training RL agents with instructions and task decompositions formalized as programs, proposing a model for a program guided agent that interprets a program and proposes subgoals to an action module.']","['developing agent learn follow natural language instruction emerging research direction ', 'accessible flexible  natural language instruction sometimes ambiguous even human ', 'address  propose utilize program  structured formal language  precise expressive way specify task ', 'devise modular framework learns perform task specified program  different circumstance give rise diverse way accomplish task  framework perceive circumstance currently  instruct multitask policy accordingly fulfill subtask overall task ', 'experimental result 2d minecraft environment demonstrate proposed framework learns reliably accomplish program instruction achieves zeroshot generalization complex instruction also verify efficiency proposed modulation mechanism learning multitask policy ', 'also conduct analysis comparing various model learn program natural language instruction endtoend fashion ']","Developing agents that can learn to follow natural language instructions has been an emerging research direction., While being accessible and flexible, natural language instructions can sometimes be ambiguous even to humans., To address this, we propose to utilize programs, structured in a formal language, as a precise and expressive way to specify tasks., We then devise a modular framework that learns to perform a task specified by a program  as different circumstances give rise to diverse ways to accomplish the task, our framework can perceive which circumstance it is currently under, and instruct a multitask policy accordingly to fulfill each subtask of the overall task., Experimental results on a 2D Minecraft environment not only demonstrate that the proposed framework learns to reliably accomplish program instructions and achieves zero-shot generalization to more complex instructions but also verify the efficiency of the proposed modulation mechanism for learning the multitask policy., We also conduct an analysis comparing various models which learn from programs and natural language instructions in an end-to-end fashion.",12,5.715976331360947,14.083333333333334
487,"['We analyze the convergence of (stochastic) gradient descent algorithm for learning a convolutional filter with Rectified Linear Unit (ReLU) activation function.', 'Our analysis does not rely on any specific form of the input distribution and our proofs only use the definition of ReLU, in contrast with previous works that are restricted to standard Gaussian input.', 'We show that (stochastic) gradient descent with random initialization can learn the convolutional filter in polynomial time and the convergence rate depends on the smoothness of the input distribution and the closeness of patches.', 'To the best of our knowledge, this is the first recovery guarantee of gradient-based algorithms for convolutional filter on non-Gaussian input distributions.', 'Our theory also justifies the two-stage learning rate strategy in deep neural networks.', 'While our focus is theoretical, we also present experiments that justify our theoretical findings.']","[0, 0, 1, 0, 0, 0]","[0.4000000059604645, 0.04444444179534912, 0.4285714328289032, 0.11764705181121826, 0.07407406717538834, 0.0]",SkA-IE06W,"['We prove randomly initialized (stochastic) gradient descent learns a convolutional filter in polynomial time.', 'Studies the problem of learning a single convolutional filter using SGD and shows that under certain conditions, SGD learns a single convolutional filter.', 'This paper extends the Gaussian distribution assumption to a more general angular smoothness assumption, which covers a wider family of input distributions']","['analyze convergence  stochastic  gradient descent algorithm learning convolutional filter rectified linear unit  relu  activation function ', 'analysis rely specific form input distribution proof use definition relu  contrast previous work restricted standard gaussian input ', 'show  stochastic  gradient descent random initialization learn convolutional filter polynomial time convergence rate depends smoothness input distribution closeness patch ', 'best knowledge  first recovery guarantee gradientbased algorithm convolutional filter nongaussian input distribution ', 'theory also justifies twostage learning rate strategy deep neural network ', 'focus theoretical  also present experiment justify theoretical finding ']","We analyze the convergence of (stochastic) gradient descent algorithm for learning a convolutional filter with Rectified Linear Unit (ReLU) activation function., Our analysis does not rely on any specific form of the input distribution and our proofs only use the definition of ReLU, in contrast with previous works that are restricted to standard Gaussian input., We show that (stochastic) gradient descent with random initialization can learn the convolutional filter in polynomial time and the convergence rate depends on the smoothness of the input distribution and the closeness of patches., To the best of our knowledge, this is the first recovery guarantee of gradient-based algorithms for convolutional filter on non-Gaussian input distributions., Our theory also justifies the two-stage learning rate strategy in deep neural networks., While our focus is theoretical, we also present experiments that justify our theoretical findings.",9,5.782608695652174,15.333333333333334
488,"['Deep neural networks (DNNs) are widely adopted in real-world cognitive applications because of their high accuracy.', 'The robustness of DNN models, however, has been recently challenged by adversarial attacks where small disturbance on input samples may result in misclassification.', ""State-of-the-art defending algorithms, such as adversarial training or robust optimization, improve DNNs' resilience to adversarial attacks by paying high computational costs."", 'Moreover, these approaches are usually designed to defend one or a few known attacking techniques only.', 'The effectiveness to defend other types of attacking methods, especially those that have not yet been discovered or explored, cannot be guaranteed.', 'This work aims for a general approach of enhancing the robustness of DNN models under adversarial attacks.', 'In particular, we propose Bamboo -- the first data augmentation method designed for improving the general robustness of DNN without any hypothesis on the attacking algorithms.', 'Bamboo augments the training data set with a small amount of data uniformly sampled on a fixed radius ball around each training data and hence, effectively increase the distance between natural data points and decision boundary.', 'Our experiments show that Bamboo substantially improve the general robustness against arbitrary types of attacks and noises, achieving better results comparing to previous adversarial training methods, robust optimization methods and other data augmentation methods with the same amount of data points.']","[0, 0, 0, 0, 0, 0, 1, 0, 0]","[0.0555555522441864, 0.23255813121795654, 0.0, 0.1111111044883728, 0.1428571343421936, 0.3333333432674408, 0.8181818127632141, 0.16326530277729034, 0.2142857164144516]",H1zW13R5tm,"['The first data augmentation method specially designed for improving the general robustness of DNN without any hypothesis on the attacking algorithms.', 'Proposes a data augmentation training method to gain model robustness against adversarial perturbations, by augmenting uniformly random samples from a fixed-radius sphere centered at training data. ']","['deep neural network  dnns  widely adopted realworld cognitive application high accuracy ', 'robustness dnn model  however  recently challenged adversarial attack small disturbance input sample may result misclassification ', 'stateoftheart defending algorithm  adversarial training robust optimization  improve dnns  resilience adversarial attack paying high computational cost ', 'moreover  approach usually designed defend one known attacking technique ', 'effectiveness defend type attacking method  especially yet discovered explored  guaranteed ', 'work aim general approach enhancing robustness dnn model adversarial attack ', 'particular  propose bamboo  first data augmentation method designed improving general robustness dnn without hypothesis attacking algorithm ', 'bamboo augments training data set small amount data uniformly sampled fixed radius ball around training data hence  effectively increase distance natural data point decision boundary ', 'experiment show bamboo substantially improve general robustness arbitrary type attack noise  achieving better result comparing previous adversarial training method  robust optimization method data augmentation method amount data point ']","Deep neural networks (DNNs) are widely adopted in real-world cognitive applications because of their high accuracy., The robustness of DNN models, however, has been recently challenged by adversarial attacks where small disturbance on input samples may result in misclassification., State-of-the-art defending algorithms, such as adversarial training or robust optimization, improve DNNs' resilience to adversarial attacks by paying high computational costs., Moreover, these approaches are usually designed to defend one or a few known attacking techniques only., The effectiveness to defend other types of attacking methods, especially those that have not yet been discovered or explored, cannot be guaranteed., This work aims for a general approach of enhancing the robustness of DNN models under adversarial attacks., In particular, we propose Bamboo -- the first data augmentation method designed for improving the general robustness of DNN without any hypothesis on the attacking algorithms., Bamboo augments the training data set with a small amount of data uniformly sampled on a fixed radius ball around each training data and hence, effectively increase the distance between natural data points and decision boundary., Our experiments show that Bamboo substantially improve the general robustness against arbitrary types of attacks and noises, achieving better results comparing to previous adversarial training methods, robust optimization methods and other data augmentation methods with the same amount of data points.",20,5.940366972477064,10.9
489,"['The ability to synthesize realistic patterns of neural activity is crucial for studying neural information processing.', 'Here we used the Generative Adversarial Networks (GANs) framework to simulate the concerted activity of a population of neurons.\n', 'We adapted the Wasserstein-GAN variant to facilitate the generation of unconstrained neural population activity patterns while still benefiting from parameter sharing in the temporal domain.\n', 'We demonstrate that our proposed GAN, which we termed Spike-GAN, generates spike trains that match accurately the first- and second-order statistics of datasets of tens of neurons and also approximates well their higher-order statistics.', 'We applied Spike-GAN to a real dataset recorded from salamander retina and showed that it performs as well as state-of-the-art approaches based on the maximum entropy and the dichotomized Gaussian frameworks.', 'Importantly, Spike-GAN does not require to specify a priori the statistics to be matched by the model, and so constitutes a more flexible method than these alternative approaches.\n', ""Finally, we show how to exploit a trained Spike-GAN  to construct 'importance maps' to detect the most relevant statistical structures present in a spike train. \n"", 'Spike-GAN provides a powerful, easy-to-use technique for generating realistic spiking neural activity and for describing the most relevant features of the large-scale neural population recordings studied in modern systems neuroscience.\n']","[0, 0, 0, 0, 0, 0, 0, 1]","[0.3125, 0.22857142984867096, 0.3414634168148041, 0.08695651590824127, 0.13333332538604736, 0.1395348757505417, 0.3499999940395355, 0.4444444477558136]",r1VVsebAZ,"['Using Wasserstein-GANs to generate realistic neural activity and to detect the most relevant features present in neural population patterns.', 'A method for simulating spike trains from populations of neurons which match empirical data using a semi-convolutional GAN.', 'The paper proposes to use GANs for synthesizing realistic neural activity patterns']","['ability synthesize realistic pattern neural activity crucial studying neural information processing ', 'used generative adversarial network  gans  framework simulate concerted activity population neuron ', 'adapted wassersteingan variant facilitate generation unconstrained neural population activity pattern still benefiting parameter sharing temporal domain ', 'demonstrate proposed gan  termed spikegan  generates spike train match accurately first secondorder statistic datasets ten neuron also approximates well higherorder statistic ', 'applied spikegan real dataset recorded salamander retina showed performs well stateoftheart approach based maximum entropy dichotomized gaussian framework ', 'importantly  spikegan require specify priori statistic matched model  constitutes flexible method alternative approach ', 'finally  show exploit trained spikegan construct importance map  detect relevant statistical structure present spike train ', 'spikegan provides powerful  easytouse technique generating realistic spiking neural activity describing relevant feature largescale neural population recording studied modern system neuroscience ']","The ability to synthesize realistic patterns of neural activity is crucial for studying neural information processing., Here we used the Generative Adversarial Networks (GANs) framework to simulate the concerted activity of a population of neurons.
, We adapted the Wasserstein-GAN variant to facilitate the generation of unconstrained neural population activity patterns while still benefiting from parameter sharing in the temporal domain.
, We demonstrate that our proposed GAN, which we termed Spike-GAN, generates spike trains that match accurately the first- and second-order statistics of datasets of tens of neurons and also approximates well their higher-order statistics., We applied Spike-GAN to a real dataset recorded from salamander retina and showed that it performs as well as state-of-the-art approaches based on the maximum entropy and the dichotomized Gaussian frameworks., Importantly, Spike-GAN does not require to specify a priori the statistics to be matched by the model, and so constitutes a more flexible method than these alternative approaches.
, Finally, we show how to exploit a trained Spike-GAN  to construct 'importance maps' to detect the most relevant statistical structures present in a spike train. 
, Spike-GAN provides a powerful, easy-to-use technique for generating realistic spiking neural activity and for describing the most relevant features of the large-scale neural population recordings studied in modern systems neuroscience.
",14,6.0,14.857142857142858
490,"['Deep latent variable models have become a popular model choice due to the scalable learning algorithms introduced by (Kingma & Welling 2013, Rezende et al. 2014).', 'These approaches maximize a variational lower bound on the intractable log likelihood of the observed data.', 'Burda et al. (2015) introduced a multi-sample variational bound, IWAE, that is at least as tight as the standard variational lower bound and becomes increasingly tight as the number of samples increases.', 'Counterintuitively, the typical inference network gradient estimator for the IWAE bound performs poorly as the number of samples increases (Rainforth et al. 2018, Le et al. 2018).', 'Roeder et a.', '(2017) propose an improved gradient estimator, however, are unable to show it is unbiased.', 'We show that it is in fact biased and that the bias can be estimated efficiently with a second application of the reparameterization trick.', 'The doubly reparameterized gradient (DReG) estimator does not suffer as the number of samples increases, resolving the previously raised issues.', 'The same idea can be used to improve many recently introduced training techniques for latent variable models.', 'In particular, we show that this estimator reduces the variance of the IWAE gradient, the reweighted wake-sleep update (RWS) (Bornschein & Bengio 2014), and the jackknife variational inference (JVI) gradient (Nowozin 2018).', 'Finally, we show that this computationally efficient, drop-in estimator translates to improved performance for all three objectives on several modeling tasks.']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.05128204822540283, 0.0, 0.0, 0.0555555522441864, 0.0, 0.29629629850387573, 0.0, 0.1249999925494194, 0.06666666269302368, 0.0952380895614624, 0.1764705777168274]",HkG3e205K7,"['Doubly reparameterized gradient estimators provide unbiased variance reduction which leads to improved performance.', 'Author experimentally found that the estimator of the existing work(STL) is biased and proposes to reduce the bias to improve the gradient estimator of the ELBO.']","['deep latent variable model become popular model choice due scalable learning algorithm introduced  kingma  welling 2013  rezende et al  2014  ', 'approach maximize variational lower bound intractable log likelihood observed data ', 'burda et al   2015  introduced multisample variational bound  iwae  least tight standard variational lower bound becomes increasingly tight number sample increase ', 'counterintuitively  typical inference network gradient estimator iwae bound performs poorly number sample increase  rainforth et al  2018  le et al  2018  ', 'roeder et ', ' 2017  propose improved gradient estimator  however  unable show unbiased ', 'show fact biased bias estimated efficiently second application reparameterization trick ', 'doubly reparameterized gradient  dreg  estimator suffer number sample increase  resolving previously raised issue ', 'idea used improve many recently introduced training technique latent variable model ', 'particular  show estimator reduces variance iwae gradient  reweighted wakesleep update  rws   bornschein  bengio 2014   jackknife variational inference  jvi  gradient  nowozin 2018  ', 'finally  show computationally efficient  dropin estimator translates improved performance three objective several modeling task ']","Deep latent variable models have become a popular model choice due to the scalable learning algorithms introduced by (Kingma & Welling 2013, Rezende et al. 2014)., These approaches maximize a variational lower bound on the intractable log likelihood of the observed data., Burda et al. (2015) introduced a multi-sample variational bound, IWAE, that is at least as tight as the standard variational lower bound and becomes increasingly tight as the number of samples increases., Counterintuitively, the typical inference network gradient estimator for the IWAE bound performs poorly as the number of samples increases (Rainforth et al. 2018, Le et al. 2018)., Roeder et a., (2017) propose an improved gradient estimator, however, are unable to show it is unbiased., We show that it is in fact biased and that the bias can be estimated efficiently with a second application of the reparameterization trick., The doubly reparameterized gradient (DReG) estimator does not suffer as the number of samples increases, resolving the previously raised issues., The same idea can be used to improve many recently introduced training techniques for latent variable models., In particular, we show that this estimator reduces the variance of the IWAE gradient, the reweighted wake-sleep update (RWS) (Bornschein & Bengio 2014), and the jackknife variational inference (JVI) gradient (Nowozin 2018)., Finally, we show that this computationally efficient, drop-in estimator translates to improved performance for all three objectives on several modeling tasks.",24,5.568965517241379,8.285714285714286
491,"['Zeroth-order optimization is the process of minimizing an objective $f(x)$, given oracle access to evaluations at adaptively chosen inputs $x$.', 'In this paper, we present two simple yet powerful GradientLess Descent (GLD) algorithms that do not rely on an underlying gradient estimate and are numerically stable.', 'We analyze our algorithm from a novel geometric perspective and we show that for {\\it any monotone transform} of a smooth and strongly convex objective with latent dimension $k \\ge n$, we present a novel analysis that shows convergence within an $\\epsilon$-ball of the optimum in $O(kQ\\log(n)\\log(R/\\epsilon))$ evaluations, where the input dimension is $n$, $R$ is the diameter of the input space and $Q$ is the condition number.', 'Our rates are the first of its kind to be both', '1) poly-logarithmically dependent on dimensionality and', '2) invariant under monotone transformations.', 'We further leverage our geometric perspective to show that our analysis is optimal.', 'Both monotone invariance and its ability to utilize a low latent dimensionality are key to the empirical success of our algorithms, as demonstrated on synthetic and MuJoCo benchmarks.\n']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.10810810327529907, 0.1395348757505417, 0.1764705777168274, 0.0, 0.08695651590824127, 0.0, 0.13793103396892548, 0.09090908616781235]",Skep6TVYDB,"['Gradientless Descent is a provably efficient gradient-free algorithm that is monotone-invariant and fast for high-dimensional zero-th order optimization.', 'This paper proposes stable GradientLess Descent (GLD) algorithms that do not rely on gradient estimate.']","['zerothorder optimization process minimizing objective  f  x    given oracle access evaluation adaptively chosen input  x  ', 'paper  present two simple yet powerful gradientless descent  gld  algorithm rely underlying gradient estimate numerically stable ', 'analyze algorithm novel geometric perspective show  monotone transform  smooth strongly convex objective latent dimension  k ge n   present novel analysis show convergence within  epsilon  ball optimum   kqlog  n  log  repsilon    evaluation  input dimension  n    r  diameter input space  q  condition number ', 'rate first kind', '1  polylogarithmically dependent dimensionality', '2  invariant monotone transformation ', 'leverage geometric perspective show analysis optimal ', 'monotone invariance ability utilize low latent dimensionality key empirical success algorithm  demonstrated synthetic mujoco benchmark ']","Zeroth-order optimization is the process of minimizing an objective $f(x)$, given oracle access to evaluations at adaptively chosen inputs $x$., In this paper, we present two simple yet powerful GradientLess Descent (GLD) algorithms that do not rely on an underlying gradient estimate and are numerically stable., We analyze our algorithm from a novel geometric perspective and we show that for {\it any monotone transform} of a smooth and strongly convex objective with latent dimension $k \ge n$, we present a novel analysis that shows convergence within an $\epsilon$-ball of the optimum in $O(kQ\log(n)\log(R/\epsilon))$ evaluations, where the input dimension is $n$, $R$ is the diameter of the input space and $Q$ is the condition number., Our rates are the first of its kind to be both, 1) poly-logarithmically dependent on dimensionality and, 2) invariant under monotone transformations., We further leverage our geometric perspective to show that our analysis is optimal., Both monotone invariance and its ability to utilize a low latent dimensionality are key to the empirical success of our algorithms, as demonstrated on synthetic and MuJoCo benchmarks.
",14,5.508474576271187,12.642857142857142
492,"['Many processes can be concisely represented as a sequence of events leading from a starting state to an end state.', 'Given raw ingredients, and a finished cake, an experienced chef can surmise the recipe.', 'Building upon this intuition,  we propose a new class of visual generative models: goal-conditioned predictors (GCP).', 'Prior work on video generation largely focuses on prediction models that only observe frames from the beginning of the video.', 'GCP instead treats videos as start-goal transformations, making video generation easier by conditioning on the more informative context provided by the first and final frames.', ' Not only do existing forward prediction approaches synthesize better and longer videos when modified to become goal-conditioned,  but GCP models can also utilize structures that are not linear in time, to accomplish hierarchical prediction', '. To this end, we study both auto-regressive GCP models and novel tree-structured GCP models that generate frames recursively, splitting the video iteratively into finer and finer segments delineated by subgoals', '. In experiments across simulated and real datasets, our GCP methods generate high-quality sequences over long horizons', '.  Tree-structured GCPs are also substantially easier to parallelize than auto-regressive GCPs, making training  and  inference  very  efficient, and allowing the model to train on sequences that are thousands of frames in length.Finally, we demonstrate the utility of GCP approaches for imitation learning in the setting without access to expert actions', '. Videos are on the supplementary website: https://sites.google.com/view/video-gcp']","[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.12765957415103912, 0.1395348757505417, 0.4444444477558136, 0.17391303181648254, 0.1538461446762085, 0.13114753365516663, 0.1090909019112587, 0.13333332538604736, 0.1666666567325592, 0.10526315122842789]",B1g79grKPr,"['We propose a new class of visual generative models: goal-conditioned predictors. We show experimentally that conditioning on the goal allows to reduce uncertainty and produce predictions over much longer horizons.', 'This paper reformulates video prediction problem as interpolation instead of extrapolation by conditioning the prediction on the start and end (goal) frame, resulting in higher quality predictions.']","['many process concisely represented sequence event leading starting state end state ', 'given raw ingredient  finished cake  experienced chef surmise recipe ', 'building upon intuition  propose new class visual generative model  goalconditioned predictor  gcp  ', 'prior work video generation largely focus prediction model observe frame beginning video ', 'gcp instead treat video startgoal transformation  making video generation easier conditioning informative context provided first final frame ', 'existing forward prediction approach synthesize better longer video modified become goalconditioned  gcp model also utilize structure linear time  accomplish hierarchical prediction', ' end  study autoregressive gcp model novel treestructured gcp model generate frame recursively  splitting video iteratively finer finer segment delineated subgoals', ' experiment across simulated real datasets  gcp method generate highquality sequence long horizon', ' treestructured gcps also substantially easier parallelize autoregressive gcps  making training inference efficient  allowing model train sequence thousand frame lengthfinally  demonstrate utility gcp approach imitation learning setting without access expert action', ' video supplementary website  http  sitesgooglecomviewvideogcp']","Many processes can be concisely represented as a sequence of events leading from a starting state to an end state., Given raw ingredients, and a finished cake, an experienced chef can surmise the recipe., Building upon this intuition,  we propose a new class of visual generative models: goal-conditioned predictors (GCP)., Prior work on video generation largely focuses on prediction models that only observe frames from the beginning of the video., GCP instead treats videos as start-goal transformations, making video generation easier by conditioning on the more informative context provided by the first and final frames.,  Not only do existing forward prediction approaches synthesize better and longer videos when modified to become goal-conditioned,  but GCP models can also utilize structures that are not linear in time, to accomplish hierarchical prediction, . To this end, we study both auto-regressive GCP models and novel tree-structured GCP models that generate frames recursively, splitting the video iteratively into finer and finer segments delineated by subgoals, . In experiments across simulated and real datasets, our GCP methods generate high-quality sequences over long horizons, .  Tree-structured GCPs are also substantially easier to parallelize than auto-regressive GCPs, making training  and  inference  very  efficient, and allowing the model to train on sequences that are thousands of frames in length.Finally, we demonstrate the utility of GCP approaches for imitation learning in the setting without access to expert actions, . Videos are on the supplementary website: https://sites.google.com/view/video-gcp",22,5.838983050847458,9.076923076923077
493,"['Recent advances in computing technology and sensor design have made it easier to collect longitudinal or time series data from patients, resulting in a gigantic amount of available medical data.', 'Most of the medical time series lack annotations or even when the annotations are available they could be subjective and prone to human errors.', 'Earlier works have developed natural language processing techniques to extract concept annotations and/or clinical narratives from doctor notes.', 'However, these approaches are slow and do not use the accompanying medical time series data.', 'To address this issue, we introduce the problem of concept annotation for the medical time series data, i.e., the task of predicting and localizing medical concepts by using the time series data as input.', 'We propose Relational Multi-Instance Learning (RMIL) - a deep Multi Instance Learning framework based on recurrent neural networks, which uses pooling functions and attention mechanisms for the concept annotation tasks.', 'Empirical results on medical datasets show that our proposed models outperform various multi-instance learning models.']","[0, 0, 0, 0, 0, 1, 0]","[0.07547169178724289, 0.08510638028383255, 0.04651162400841713, 0.09999999403953552, 0.18518517911434174, 0.8888888955116272, 0.05128204822540283]",ByJbJwxCW,"['We propose a deep Multi Instance Learning framework based on recurrent neural networks which uses pooling functions and attention mechanisms for the concept annotation tasks.', 'The paper addresses the classification of medical time-series data and proposes to model the temporal relationship between the instances in each series using a recurrent neural network architecture. ', 'Proposes a novel Multiple Instance Learning (MIL) formulation called Relation MIL (RMIL), and discussed a number of its variants with LSTM, Bi-LSTM, S2S, etc. and explores integrating RMIL with various attention mechanisms, and demonstrates its usage on medical concept prediction from time series data. ']","['recent advance computing technology sensor design made easier collect longitudinal time series data patient  resulting gigantic amount available medical data ', 'medical time series lack annotation even annotation available could subjective prone human error ', 'earlier work developed natural language processing technique extract concept annotation andor clinical narrative doctor note ', 'however  approach slow use accompanying medical time series data ', 'address issue  introduce problem concept annotation medical time series data  ie  task predicting localizing medical concept using time series data input ', 'propose relational multiinstance learning  rmil   deep multi instance learning framework based recurrent neural network  us pooling function attention mechanism concept annotation task ', 'empirical result medical datasets show proposed model outperform various multiinstance learning model ']","Recent advances in computing technology and sensor design have made it easier to collect longitudinal or time series data from patients, resulting in a gigantic amount of available medical data., Most of the medical time series lack annotations or even when the annotations are available they could be subjective and prone to human errors., Earlier works have developed natural language processing techniques to extract concept annotations and/or clinical narratives from doctor notes., However, these approaches are slow and do not use the accompanying medical time series data., To address this issue, we introduce the problem of concept annotation for the medical time series data, i.e., the task of predicting and localizing medical concepts by using the time series data as input., We propose Relational Multi-Instance Learning (RMIL) - a deep Multi Instance Learning framework based on recurrent neural networks, which uses pooling functions and attention mechanisms for the concept annotation tasks., Empirical results on medical datasets show that our proposed models outperform various multi-instance learning models.",13,5.716867469879518,12.76923076923077
494,"['The embedding layers transforming input words into real vectors are the key components of deep neural networks used in natural language processing.', 'However, when the vocabulary is large, the corresponding weight matrices can be enormous, which precludes their deployment in a limited resource setting.', 'We introduce a novel way of parametrizing embedding layers based on the Tensor Train (TT) decomposition, which allows compressing the model significantly at the cost of a negligible drop or even a slight gain in performance.  ', 'We evaluate our method on a wide range of benchmarks in natural language processing and analyze the trade-off between performance and compression ratios for a wide range of architectures, from MLPs to LSTMs and Transformers.']","[0, 0, 1, 0]","[0.11428570747375488, 0.05882352590560913, 0.13333332538604736, 0.0476190447807312]",S1e4Q6EtDH,"['Embedding layers are factorized with Tensor Train decomposition to reduce their memory footprint.', 'This paper proposes a low-rank tensor decomposition model to parameterize the embedding matrix in Natural Language Processing (NLP), which compresses the network and sometimes increases test accuracy.']","['embedding layer transforming input word real vector key component deep neural network used natural language processing ', 'however  vocabulary large  corresponding weight matrix enormous  precludes deployment limited resource setting ', 'introduce novel way parametrizing embedding layer based tensor train  tt  decomposition  allows compressing model significantly cost negligible drop even slight gain performance ', 'evaluate method wide range benchmark natural language processing analyze tradeoff performance compression ratio wide range architecture  mlps lstms transformer ']","The embedding layers transforming input words into real vectors are the key components of deep neural networks used in natural language processing., However, when the vocabulary is large, the corresponding weight matrices can be enormous, which precludes their deployment in a limited resource setting., We introduce a novel way of parametrizing embedding layers based on the Tensor Train (TT) decomposition, which allows compressing the model significantly at the cost of a negligible drop or even a slight gain in performance.  , We evaluate our method on a wide range of benchmarks in natural language processing and analyze the trade-off between performance and compression ratios for a wide range of architectures, from MLPs to LSTMs and Transformers.",9,5.495652173913044,12.777777777777779
495,"['We note that common implementations of adaptive gradient algorithms, such as Adam, limit the potential benefit of weight decay regularization, because the weights do not decay multiplicatively (as would be expected for standard weight decay) but by an additive constant factor. \n', 'We propose a simple way to resolve this issue by decoupling weight decay and the optimization steps taken w.r.t. the loss function.', 'We provide empirical evidence that our proposed modification', '(i) \ndecouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam, and', ""(ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter).\n"", 'We also demonstrate that longer optimization runs require smaller weight decay values for optimal results and introduce a normalized variant of weight decay to reduce this dependence.', 'Finally, we propose a version of Adam with warm restarts (AdamWR) that has strong anytime performance while achieving state-of-the-art results on CIFAR-10 and ImageNet32x32. \n', 'Our source code will become available after the review process.']","[1, 0, 0, 0, 0, 0, 0, 0]","[0.2448979616165161, 0.11764705181121826, 0.0, 0.13333332538604736, 0.0, 0.1111111044883728, 0.0555555522441864, 0.0]",rk6qdGgCZ,"['Fixing weight decay regularization in adaptive gradient methods such as Adam', 'Proposes idea to decouple the weight decay from the number of steps taken by the optimization process.', 'The paper presents an alternative way to implement weight decay in Adam with empirical results shown', 'Investigates weight decay issues lied in the SGD variants and proposes the decoupling method between weight decay and the gradient-based update.']","['note common implementation adaptive gradient algorithm  adam  limit potential benefit weight decay regularization  weight decay multiplicatively  would expected standard weight decay  additive constant factor ', 'propose simple way resolve issue decoupling weight decay optimization step taken wrt  loss function ', 'provide empirical evidence proposed modification', '  decouples optimal choice weight decay factor setting learning rate standard sgd adam ', ' ii  substantially improves adam generalization performance  allowing compete sgd momentum image classification datasets  previously typically outperformed latter  ', 'also demonstrate longer optimization run require smaller weight decay value optimal result introduce normalized variant weight decay reduce dependence ', 'finally  propose version adam warm restarts  adamwr  strong anytime performance achieving stateoftheart result cifar10 imagenet32x32 ', 'source code become available review process ']","We note that common implementations of adaptive gradient algorithms, such as Adam, limit the potential benefit of weight decay regularization, because the weights do not decay multiplicatively (as would be expected for standard weight decay) but by an additive constant factor. 
, We propose a simple way to resolve this issue by decoupling weight decay and the optimization steps taken w.r.t. the loss function., We provide empirical evidence that our proposed modification, (i) 
decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam, and, (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter).
, We also demonstrate that longer optimization runs require smaller weight decay values for optimal results and introduce a normalized variant of weight decay to reduce this dependence., Finally, we propose a version of Adam with warm restarts (AdamWR) that has strong anytime performance while achieving state-of-the-art results on CIFAR-10 and ImageNet32x32. 
, Our source code will become available after the review process.",14,5.699453551912568,12.2
496,"['Lifelong learning is the problem of learning multiple consecutive tasks in a sequential manner where knowledge gained from previous tasks is retained and used for future learning.', 'It is essential towards the development of intelligent machines that can adapt to their surroundings.', 'In this work we focus on a lifelong learning approach to generative modeling where we continuously incorporate newly observed streaming distributions into our learnt model.', 'We do so through a student-teacher architecture which allows us to learn and preserve all the distributions seen so far without the need to retain the past data nor the past models.', 'Through the introduction of a novel cross-model regularizer, the student model leverages the information learnt by the teacher, which acts as a summary of everything seen till now.', 'The regularizer has the additional benefit of reducing the effect of catastrophic interference that appears when we learn over streaming data.', 'We demonstrate its efficacy on streaming distributions as well as its ability to learn a common latent representation across a complex transfer learning scenario.\n']","[0, 0, 0, 1, 0, 0, 0]","[0.1666666567325592, 0.0, 0.1621621549129486, 0.20512820780277252, 0.1111111044883728, 0.0624999962747097, 0.11428570747375488]",S1fduCl0b,['Lifelong distributional learning through a student-teacher architecture coupled with a cross model posterior regularizer.'],"['lifelong learning problem learning multiple consecutive task sequential manner knowledge gained previous task retained used future learning ', 'essential towards development intelligent machine adapt surroundings ', 'work focus lifelong learning approach generative modeling continuously incorporate newly observed streaming distribution learnt model ', 'studentteacher architecture allows u learn preserve distribution seen far without need retain past data past model ', 'introduction novel crossmodel regularizer  student model leverage information learnt teacher  act summary everything seen till ', 'regularizer additional benefit reducing effect catastrophic interference appears learn streaming data ', 'demonstrate efficacy streaming distribution well ability learn common latent representation across complex transfer learning scenario ']","Lifelong learning is the problem of learning multiple consecutive tasks in a sequential manner where knowledge gained from previous tasks is retained and used for future learning., It is essential towards the development of intelligent machines that can adapt to their surroundings., In this work we focus on a lifelong learning approach to generative modeling where we continuously incorporate newly observed streaming distributions into our learnt model., We do so through a student-teacher architecture which allows us to learn and preserve all the distributions seen so far without the need to retain the past data nor the past models., Through the introduction of a novel cross-model regularizer, the student model leverages the information learnt by the teacher, which acts as a summary of everything seen till now., The regularizer has the additional benefit of reducing the effect of catastrophic interference that appears when we learn over streaming data., We demonstrate its efficacy on streaming distributions as well as its ability to learn a common latent representation across a complex transfer learning scenario.
",9,5.523255813953488,19.11111111111111
497,"['Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling.', 'In this paper, we look at geometric data represented as point clouds.', 'We introduce a deep autoencoder (AE) network with excellent reconstruction quality and generalization ability.', 'The learned representations outperform the state of the art in 3D recognition tasks and enable basic shape editing applications via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation.', 'We also perform a thorough study of different generative models including GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space our AEs and, Gaussian mixture models (GMM).', 'Interestingly, GMMs trained in the latent space of our AEs produce samples of the best fidelity and diversity.\n', 'To perform our quantitative evaluation of generative models, we propose simple measures of fidelity and diversity based on optimally matching between sets point clouds.']","[0, 1, 0, 0, 0, 0, 0]","[0.19999998807907104, 0.2142857164144516, 0.06666666269302368, 0.04444443807005882, 0.12765957415103912, 0.0, 0.10256409645080566]",BJInEZsTb,"['Deep autoencoders to learn a good representation for geometric 3D point-cloud data; Generative models for point clouds.', 'Approaches to learn GAN-type generative models using PointNet architecture and latent-space GAN.']","['threedimensional geometric data offer excellent domain studying representation learning generative modeling ', 'paper  look geometric data represented point cloud ', 'introduce deep autoencoder  ae  network excellent reconstruction quality generalization ability ', 'learned representation outperform state art 3d recognition task enable basic shape editing application via simple algebraic manipulation  semantic part editing  shape analogy shape interpolation ', 'also perform thorough study different generative model including gans operating raw point cloud  significantly improved gans trained fixed latent space aes  gaussian mixture model  gmm  ', 'interestingly  gmms trained latent space aes produce sample best fidelity diversity ', 'perform quantitative evaluation generative model  propose simple measure fidelity diversity based optimally matching set point cloud ']","Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling., In this paper, we look at geometric data represented as point clouds., We introduce a deep autoencoder (AE) network with excellent reconstruction quality and generalization ability., The learned representations outperform the state of the art in 3D recognition tasks and enable basic shape editing applications via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation., We also perform a thorough study of different generative models including GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space our AEs and, Gaussian mixture models (GMM)., Interestingly, GMMs trained in the latent space of our AEs produce samples of the best fidelity and diversity.
, To perform our quantitative evaluation of generative models, we propose simple measures of fidelity and diversity based on optimally matching between sets point clouds.",14,5.919463087248322,10.642857142857142
498,"['Despite the remarkable performance of deep neural networks (DNNs) on various tasks, they are susceptible to adversarial perturbations which makes it difficult to deploy them in real-world safety-critical applications.', ""In this paper, we aim to obtain robust networks by sparsifying DNN's latent features sensitive to adversarial perturbation."", 'Specifically, we define vulnerability at the latent feature space and then propose a Bayesian framework to prioritize/prune features based on their contribution to both the original and adversarial loss.', ""We also suggest regularizing the features' vulnerability during training to improve robustness further."", 'While such network sparsification has been primarily studied in the literature for computational efficiency and regularization effect of DNNs, we confirm that it is also useful to design a defense mechanism through quantitative evaluation and qualitative analysis.', 'We validate our method, \\emph{Adversarial Neural Pruning (ANP)} on multiple benchmark datasets, which results in an improvement in test accuracy and leads to state-of-the-art robustness.', 'ANP also tackles the practical problem of obtaining sparse and robust networks at the same time, which could be crucial to ensure adversarial robustness on lightweight networks deployed to computation and memory-limited devices.']","[0, 0, 1, 0, 0, 0, 0]","[0.1702127605676651, 0.2222222238779068, 0.4000000059604645, 0.25, 0.2181818187236786, 0.1395348757505417, 0.25]",SJe4SJrFDr,"['We propose a novel method for suppressing the vulnerability of latent feature space to achieve robust and compact networks.', 'This paper proposes ""adversarial neural pruning"" method of training a pruning mask and a new vulnerability suppression loss to improve accuracy and adversarial robustness.']","['despite remarkable performance deep neural network  dnns  various task  susceptible adversarial perturbation make difficult deploy realworld safetycritical application ', 'paper  aim obtain robust network sparsifying dnn latent feature sensitive adversarial perturbation ', 'specifically  define vulnerability latent feature space propose bayesian framework prioritizeprune feature based contribution original adversarial loss ', 'also suggest regularizing feature  vulnerability training improve robustness ', 'network sparsification primarily studied literature computational efficiency regularization effect dnns  confirm also useful design defense mechanism quantitative evaluation qualitative analysis ', 'validate method  emph  adversarial neural pruning  anp   multiple benchmark datasets  result improvement test accuracy lead stateoftheart robustness ', 'anp also tackle practical problem obtaining sparse robust network time  could crucial ensure adversarial robustness lightweight network deployed computation memorylimited device ']","Despite the remarkable performance of deep neural networks (DNNs) on various tasks, they are susceptible to adversarial perturbations which makes it difficult to deploy them in real-world safety-critical applications., In this paper, we aim to obtain robust networks by sparsifying DNN's latent features sensitive to adversarial perturbation., Specifically, we define vulnerability at the latent feature space and then propose a Bayesian framework to prioritize/prune features based on their contribution to both the original and adversarial loss., We also suggest regularizing the features' vulnerability during training to improve robustness further., While such network sparsification has been primarily studied in the literature for computational efficiency and regularization effect of DNNs, we confirm that it is also useful to design a defense mechanism through quantitative evaluation and qualitative analysis., We validate our method, \emph{Adversarial Neural Pruning (ANP)} on multiple benchmark datasets, which results in an improvement in test accuracy and leads to state-of-the-art robustness., ANP also tackles the practical problem of obtaining sparse and robust networks at the same time, which could be crucial to ensure adversarial robustness on lightweight networks deployed to computation and memory-limited devices.",14,6.195652173913044,13.142857142857142
499,"['In anomaly detection (AD), one seeks to identify whether a test sample is abnormal,  given a data set of normal samples.   ', 'A recent and promising approach to AD relies on deep generative models, such as variational autoencoders (VAEs),for unsupervised learning of the normal data distribution.', 'In semi-supervised AD (SSAD), the data also includes a small sample of labeled anomalies.', 'In this work,we propose two variational methods for training VAEs for SSAD.', 'The intuitive idea in both methods is to train the encoder to separate between latent vectors for normal and outlier data.', 'We show that this idea can be derived from principled probabilistic formulations of the problem, and propose simple and effective algorithms.  ', 'Our methods can be applied to various data types, as we demonstrate on SSAD datasets ranging from natural images to astronomy and medicine, and can be combined with any VAE model architecture.', 'When comparing to state-of-the-art SSAD methods that are not specific to particular data types, we obtain marked improvement in outlier detection.']","[0, 0, 0, 0, 1, 0, 0, 0]","[0.15789473056793213, 0.09756097197532654, 0.12903225421905518, 0.1428571343421936, 0.1621621549129486, 0.15789473056793213, 0.13333332538604736, 0.1621621549129486]",Hkxp3JHtPr,"['We proposed two VAE modifications that account for negative data examples, and used them for semi-supervised anomaly detection.', 'The papers propose two methods of VAE-like approaches for semi-supervised novelty detection, MML-VAE and DP-VAE.']","['anomaly detection  ad   one seek identify whether test sample abnormal  given data set normal sample ', 'recent promising approach ad relies deep generative model  variational autoencoders  vaes   unsupervised learning normal data distribution ', 'semisupervised ad  ssad   data also includes small sample labeled anomaly ', 'work  propose two variational method training vaes ssad ', 'intuitive idea method train encoder  separate  latent vector normal outlier data ', 'show idea derived principled probabilistic formulation problem  propose simple effective algorithm ', 'method applied various data type  demonstrate ssad datasets ranging natural image astronomy medicine  combined vae model architecture ', 'comparing stateoftheart ssad method specific particular data type  obtain marked improvement outlier detection ']","In anomaly detection (AD), one seeks to identify whether a test sample is abnormal,  given a data set of normal samples.   , A recent and promising approach to AD relies on deep generative models, such as variational autoencoders (VAEs),for unsupervised learning of the normal data distribution., In semi-supervised AD (SSAD), the data also includes a small sample of labeled anomalies., In this work,we propose two variational methods for training VAEs for SSAD., The intuitive idea in both methods is to train the encoder to separate between latent vectors for normal and outlier data., We show that this idea can be derived from principled probabilistic formulations of the problem, and propose simple and effective algorithms.  , Our methods can be applied to various data types, as we demonstrate on SSAD datasets ranging from natural images to astronomy and medicine, and can be combined with any VAE model architecture., When comparing to state-of-the-art SSAD methods that are not specific to particular data types, we obtain marked improvement in outlier detection.",16,5.36144578313253,10.375
500,"['We introduce dynamic instance hardness (DIH) to facilitate the training of machine learning models.', ""DIH is a property of each training sample and is computed as the running mean of the sample's instantaneous hardness as measured over the training history."", 'We use DIH to evaluate how well a model retains knowledge about each training sample over time.', 'We find that for deep neural nets (DNNs), the DIH of a sample in relatively early training stages reflects its DIH in later stages and as a result, DIH can be effectively used to reduce the set of training samples in future epochs.', 'Specifically, during each epoch, only samples with high DIH are trained (since they are historically hard) while samples with low DIH can be safely ignored.', 'DIH is updated each epoch only for the selected samples, so it does not require additional computation.', 'Hence, using DIH during training leads to an appreciable speedup.', 'Also, since the model is focused on the historically more challenging samples, resultant models are more accurate.', 'The above, when formulated as an algorithm, can be seen as a form of curriculum learning, so we call our framework DIH curriculum learning (or DIHCL).', 'The advantages of DIHCL, compared to other curriculum learning approaches, are: (1) DIHCL does not require additional inference steps over the data not selected by DIHCL in each epoch, (2) the dynamic instance hardness, compared to static instance hardness (e.g., instantaneous loss), is more stable as it integrates information over the entire training history up to the present time.', 'Making certain mathematical assumptions, we formulate the problem of DIHCL as finding a curriculum that maximizes a multi-set function $f(\\cdot)$, and derive an approximation bound for a DIH-produced curriculum relative to the optimal curriculum.', 'Empirically, DIHCL-trained DNNs significantly outperform random mini-batch SGD and other recently developed curriculum learning methods in terms of efficiency, early-stage convergence, and final performance, and this is shown in training several state-of-the-art DNNs on 11 modern datasets.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.3448275923728943, 0.22857142984867096, 0.1249999925494194, 0.16326530277729034, 0.0, 0.0, 0.1599999964237213, 0.0, 0.1538461446762085, 0.1818181723356247, 0.1818181723356247, 0.2083333283662796]",H1lXVJStwB,"['New understanding of training dynamics and metrics of memorization hardness lead to efficient and provable curriculum learning.', 'This paper formulates DIH as a curriculum leaning problem that can more effectively utilize the data to train DNNs, and derives theory on the approximation bound.']","['introduce dynamic instance hardness  dih  facilitate training machine learning model ', 'dih property training sample computed running mean sample instantaneous hardness measured training history ', 'use dih evaluate well model retains knowledge training sample time ', 'find deep neural net  dnns   dih sample relatively early training stage reflects dih later stage result  dih effectively used reduce set training sample future epoch ', 'specifically  epoch  sample high dih trained  since historically hard  sample low dih safely ignored ', 'dih updated epoch selected sample  require additional computation ', 'hence  using dih training lead appreciable speedup ', 'also  since model focused historically challenging sample  resultant model accurate ', ' formulated algorithm  seen form curriculum learning  call framework dih curriculum learning  dihcl  ', 'advantage dihcl  compared curriculum learning approach    1  dihcl require additional inference step data selected dihcl epoch   2  dynamic instance hardness  compared static instance hardness  eg  instantaneous loss   stable integrates information entire training history present time ', 'making certain mathematical assumption  formulate problem dihcl finding curriculum maximizes multiset function  f  cdot    derive approximation bound dihproduced curriculum relative optimal curriculum ', 'empirically  dihcltrained dnns significantly outperform random minibatch sgd recently developed curriculum learning method term efficiency  earlystage convergence  final performance  shown training several stateoftheart dnns 11 modern datasets ']","We introduce dynamic instance hardness (DIH) to facilitate the training of machine learning models., DIH is a property of each training sample and is computed as the running mean of the sample's instantaneous hardness as measured over the training history., We use DIH to evaluate how well a model retains knowledge about each training sample over time., We find that for deep neural nets (DNNs), the DIH of a sample in relatively early training stages reflects its DIH in later stages and as a result, DIH can be effectively used to reduce the set of training samples in future epochs., Specifically, during each epoch, only samples with high DIH are trained (since they are historically hard) while samples with low DIH can be safely ignored., DIH is updated each epoch only for the selected samples, so it does not require additional computation., Hence, using DIH during training leads to an appreciable speedup., Also, since the model is focused on the historically more challenging samples, resultant models are more accurate., The above, when formulated as an algorithm, can be seen as a form of curriculum learning, so we call our framework DIH curriculum learning (or DIHCL)., The advantages of DIHCL, compared to other curriculum learning approaches, are: (1) DIHCL does not require additional inference steps over the data not selected by DIHCL in each epoch, (2) the dynamic instance hardness, compared to static instance hardness (e.g., instantaneous loss), is more stable as it integrates information over the entire training history up to the present time., Making certain mathematical assumptions, we formulate the problem of DIHCL as finding a curriculum that maximizes a multi-set function $f(\cdot)$, and derive an approximation bound for a DIH-produced curriculum relative to the optimal curriculum., Empirically, DIHCL-trained DNNs significantly outperform random mini-batch SGD and other recently developed curriculum learning methods in terms of efficiency, early-stage convergence, and final performance, and this is shown in training several state-of-the-art DNNs on 11 modern datasets.",35,5.3938461538461535,9.285714285714286
501,"['This paper explores many immediate connections between adaptive control and machine learning, both through common update laws as well as common concepts.', 'Adaptive control as a field has focused on mathematical rigor and guaranteed convergence.', 'The rapid advances in machine learning on the other hand have brought about a plethora of new techniques and problems for learning.', 'This paper elucidates many of the numerous common connections between both fields such that results from both may be leveraged together to solve new problems.', 'In particular, a specific problem related to higher order learning is solved through insights obtained from these intersections.']","[1, 0, 0, 0, 0]","[0.4571428596973419, 0.1428571343421936, 0.277777761220932, 0.10256409645080566, 0.060606054961681366]",HyxbV5HshN,['History of parallel developments in update laws and concepts between adaptive control and optimization in machine learning.'],"['paper explores many immediate connection adaptive control machine learning  common update law well common concept ', 'adaptive control field focused mathematical rigor guaranteed convergence ', 'rapid advance machine learning hand brought plethora new technique problem learning ', 'paper elucidates many numerous common connection field result may leveraged together solve new problem ', 'particular  specific problem related higher order learning solved insight obtained intersection ']","This paper explores many immediate connections between adaptive control and machine learning, both through common update laws as well as common concepts., Adaptive control as a field has focused on mathematical rigor and guaranteed convergence., The rapid advances in machine learning on the other hand have brought about a plethora of new techniques and problems for learning., This paper elucidates many of the numerous common connections between both fields such that results from both may be leveraged together to solve new problems., In particular, a specific problem related to higher order learning is solved through insights obtained from these intersections.",7,5.62,14.285714285714286
502,"['Recurrent convolution (RC) shares the same convolutional kernels and unrolls them multiple times, which is originally proposed to model time-space signals.', 'We suggest that RC can be viewed as a model compression strategy for deep convolutional neural networks.', 'RC reduces the redundancy across layers and is complementary to most existing model compression approaches.', ""However, the performance of an RC network can't match the performance of its corresponding standard one, i.e. with the same depth but independent convolutional kernels.  "", 'This reduces the value of RC for model compression.', 'In this paper, we propose a simple variant which improves RC networks: The batch normalization layers of an RC module are learned independently (not shared) for different unrolling steps.', 'We provide insights on why this works.', 'Experiments on CIFAR show that unrolling a convolutional layer several steps can improve the performance, thus indirectly plays a role in model compression.']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.25641024112701416, 0.2857142686843872, 0.24242423474788666, 0.04878048226237297, 0.2222222238779068, 0.1304347813129425, 0.0, 0.25]",H1fKsUQKjm,"['Recurrent convolution for model compression and a trick for training it, that is learning independent BN layres over steps.', 'The author modifies the recurrent convolution neural network (RCNN) with independent batch normalization, with the experimental results on RCNN compatible with the ResNet neural network architecture when it contains the same number of layers.']","['recurrent convolution  rc  share convolutional kernel unrolls multiple time  originally proposed model timespace signal ', 'suggest rc viewed model compression strategy deep convolutional neural network ', 'rc reduces redundancy across layer complementary existing model compression approach ', 'however  performance rc network ca nt match performance corresponding standard one  ie  depth independent convolutional kernel ', 'reduces value rc model compression ', 'paper  propose simple variant improves rc network  batch normalization layer rc module learned independently  shared  different unrolling step ', 'provide insight work ', 'experiment cifar show unrolling convolutional layer several step improve performance  thus indirectly play role model compression ']","Recurrent convolution (RC) shares the same convolutional kernels and unrolls them multiple times, which is originally proposed to model time-space signals., We suggest that RC can be viewed as a model compression strategy for deep convolutional neural networks., RC reduces the redundancy across layers and is complementary to most existing model compression approaches., However, the performance of an RC network can't match the performance of its corresponding standard one, i.e. with the same depth but independent convolutional kernels.  , This reduces the value of RC for model compression., In this paper, we propose a simple variant which improves RC networks: The batch normalization layers of an RC module are learned independently (not shared) for different unrolling steps., We provide insights on why this works., Experiments on CIFAR show that unrolling a convolutional layer several steps can improve the performance, thus indirectly plays a role in model compression.",13,5.636986301369863,10.428571428571429
503,"['The visual world is vast and varied, but its variations divide into structured and unstructured factors.', 'Structured factors, such as scale and orientation, admit clear theories and efficient representation design.', 'Unstructured factors, such as what it is that makes a cat look like a cat, are too complicated to model analytically, and so require free-form representation learning.', 'We compose structured Gaussian filters and free-form filters, optimized end-to-end, to factorize the representation for efficient yet general learning.', 'Our experiments on dynamic structure, in which the structured filters vary with the input, equal the accuracy of dynamic inference with more degrees of freedom while improving efficiency.\n\n', '(Please see https://arxiv.org/abs/1904.11487 for the full edition.)']","[0, 0, 0, 1, 0, 0]","[0.07692307233810425, 0.1666666567325592, 0.10810810327529907, 0.19999998807907104, 0.05714285373687744, 0.0]",Bkl-xjAVOV,"['Dynamic receptive fields with spatial Gaussian structure are accurate and efficient.', 'This paper proposes a structured convolution operator to model deformations of local regions of an image, which significantly reduced the number of parameters.']","['visual world vast varied  variation divide structured unstructured factor ', 'structured factor  scale orientation  admit clear theory efficient representation design ', 'unstructured factor  make cat look like cat  complicated model analytically  require freeform representation learning ', 'compose structured gaussian filter freeform filter  optimized endtoend  factorize representation efficient yet general learning ', 'experiment dynamic structure  structured filter vary input  equal accuracy dynamic inference degree freedom improving efficiency ', ' please see http  arxivorgabs190411487 full edition  ']","The visual world is vast and varied, but its variations divide into structured and unstructured factors., Structured factors, such as scale and orientation, admit clear theories and efficient representation design., Unstructured factors, such as what it is that makes a cat look like a cat, are too complicated to model analytically, and so require free-form representation learning., We compose structured Gaussian filters and free-form filters, optimized end-to-end, to factorize the representation for efficient yet general learning., Our experiments on dynamic structure, in which the structured filters vary with the input, equal the accuracy of dynamic inference with more degrees of freedom while improving efficiency.

, (Please see https://arxiv.org/abs/1904.11487 for the full edition.)",16,6.027027027027027,6.9375
504,"['It is widely known that well-designed perturbations can cause state-of-the-art machine learning classifiers to mis-label an image, with sufficiently small perturbations that are imperceptible to the human eyes.', 'However, by detecting the inconsistency between the image and wrong label, the human observer would be alerted of the attack.', 'In this paper, we aim to design attacks that not only make classifiers generate wrong labels, but also make the wrong labels imperceptible to human observers.', 'To achieve this, we propose an algorithm called LabelFool which identifies a target label similar to the ground truth label and finds a perturbation of the image for this target label.', 'We first find the target label for an input image by a probability model, then move the input in the feature space towards the target label.', 'Subjective studies on ImageNet show that in the label space, our attack is much less recognizable by human observers, while objective experimental results on ImageNet show that we maintain similar performance in the image space as well as attack rates to state-of-the-art attack algorithms.']","[0, 0, 1, 0, 0, 0]","[0.2790697515010834, 0.11428570747375488, 0.3414634168148041, 0.13636362552642822, 0.21052631735801697, 0.30188679695129395]",r1glDpNYwS,"['A trick on adversarial samples so that the mis-classified labels are imperceptible in the label space to human observers', 'A method for constructing adversarial attacks that are less detectable by humans without cost in image space by changing the target class to be similar to the original class of the image.']","['widely known welldesigned perturbation cause stateoftheart machine learning classifier mislabel image  sufficiently small perturbation imperceptible human eye ', 'however  detecting inconsistency image wrong label  human observer would alerted attack ', 'paper  aim design attack make classifier generate wrong label  also make wrong label imperceptible human observer ', 'achieve  propose algorithm called labelfool identifies target label similar ground truth label find perturbation image target label ', 'first find target label input image probability model  move input feature space towards target label ', 'subjective study imagenet show label space  attack much le recognizable human observer  objective experimental result imagenet show maintain similar performance image space well attack rate stateoftheart attack algorithm ']","It is widely known that well-designed perturbations can cause state-of-the-art machine learning classifiers to mis-label an image, with sufficiently small perturbations that are imperceptible to the human eyes., However, by detecting the inconsistency between the image and wrong label, the human observer would be alerted of the attack., In this paper, we aim to design attacks that not only make classifiers generate wrong labels, but also make the wrong labels imperceptible to human observers., To achieve this, we propose an algorithm called LabelFool which identifies a target label similar to the ground truth label and finds a perturbation of the image for this target label., We first find the target label for an input image by a probability model, then move the input in the feature space towards the target label., Subjective studies on ImageNet show that in the label space, our attack is much less recognizable by human observers, while objective experimental results on ImageNet show that we maintain similar performance in the image space as well as attack rates to state-of-the-art attack algorithms.",15,5.308571428571429,11.666666666666666
505,"['This paper presents noise type/position classification of various impact noises generated in a building which is a serious conflict issue in apartment complexes.', 'For this study, a collection of floor impact noise dataset is recorded with a single microphone.', 'Noise types/positions are selected based on a report by the Floor Management Center under Korea Environmental Corporation.', 'Using a convolutional neural networks based classifier, the impact noise signals converted to log-scaled Mel-spectrograms are classified into noise types or positions.', 'Also, our model is evaluated on a standard environmental sound dataset ESC-50 to show extensibility on environmental sound classification.\n']","[1, 0, 0, 0, 0]","[1.0, 0.277777761220932, 0.052631575614213943, 0.1428571343421936, 0.15789473056793213]",HkxzDiAcK7,"['This paper presents noise type/position classification of various impact noises generated in a building which is a serious conflict issue in apartment complexes', 'This work describes the use of convolutional neural networks in a novel application area of building noise type and noise position classification. ']","['paper present noise typeposition classification various impact noise generated building serious conflict issue apartment complex ', 'study  collection floor impact noise dataset recorded single microphone ', 'noise typespositions selected based report floor management center korea environmental corporation ', 'using convolutional neural network based classifier  impact noise signal converted logscaled melspectrograms classified noise type position ', 'also  model evaluated standard environmental sound dataset esc50 show extensibility environmental sound classification ']","This paper presents noise type/position classification of various impact noises generated in a building which is a serious conflict issue in apartment complexes., For this study, a collection of floor impact noise dataset is recorded with a single microphone., Noise types/positions are selected based on a report by the Floor Management Center under Korea Environmental Corporation., Using a convolutional neural networks based classifier, the impact noise signals converted to log-scaled Mel-spectrograms are classified into noise types or positions., Also, our model is evaluated on a standard environmental sound dataset ESC-50 to show extensibility on environmental sound classification.
",8,6.072164948453608,12.125
506,"['Recordings of neural circuits in the brain reveal extraordinary dynamical richness and high variability.', 'At the same time, dimensionality reduction techniques generally uncover low-dimensional structures underlying these dynamics.', 'What determines the dimensionality of activity in neural circuits?', 'What is the functional role of dimensionality in behavior and task learning?', 'In this work we address these questions using recurrent neural network (RNN) models.', 'We find that, depending on the dynamics of the initial network, RNNs learn to increase and reduce dimensionality in a way that matches task demands.', 'These findings shed light on fundamental dynamical mechanisms by which neural networks solve tasks with robust representations that generalize to new cases.']","[0, 0, 0, 0, 0, 1, 0]","[0.20512820780277252, 0.1538461446762085, 0.23529411852359772, 0.2702702581882477, 0.052631575614213943, 0.6938775181770325, 0.12765957415103912]",BylmV7tI8S,"['Recurrent Neural Networks learn to  increase and reduce the dimensionality of their internal representation in a way that matches the task, depending on the dynamics of the initial network.']","['recording neural circuit brain reveal extraordinary dynamical richness high variability ', 'time  dimensionality reduction technique generally uncover lowdimensional structure underlying dynamic ', 'determines dimensionality activity neural circuit ', 'functional role dimensionality behavior task learning ', 'work address question using recurrent neural network  rnn  model ', 'find  depending dynamic initial network  rnns learn increase reduce dimensionality way match task demand ', 'finding shed light fundamental dynamical mechanism neural network solve task robust representation generalize new case ']","Recordings of neural circuits in the brain reveal extraordinary dynamical richness and high variability., At the same time, dimensionality reduction techniques generally uncover low-dimensional structures underlying these dynamics., What determines the dimensionality of activity in neural circuits?, What is the functional role of dimensionality in behavior and task learning?, In this work we address these questions using recurrent neural network (RNN) models., We find that, depending on the dynamics of the initial network, RNNs learn to increase and reduce dimensionality in a way that matches task demands., These findings shed light on fundamental dynamical mechanisms by which neural networks solve tasks with robust representations that generalize to new cases.",10,6.0,10.9
507,"['Domain adaptation addresses the common problem when the target distribution generating our test data drifts from the source (training) distribution.', 'While absent assumptions, domain adaptation is impossible, strict conditions, e.g. covariate or label shift, enable principled algorithms.', 'Recently-proposed domain-adversarial approaches consist of aligning source and target encodings, often motivating this approach as minimizing two (of three) terms in a theoretical bound on target error.', 'Unfortunately, this minimization can cause arbitrary increases in the third term, e.g. they can break down under shifting label distributions.', 'We propose asymmetrically-relaxed distribution alignment, a new approach that overcomes some limitations of standard domain-adversarial algorithms.', 'Moreover, we characterize precise assumptions under which our algorithm is theoretically principled and demonstrate empirical benefits on both synthetic and real datasets.']","[0, 0, 0, 0, 1, 0]","[0.1666666567325592, 0.16326530277729034, 0.17543859779834747, 0.07843136787414551, 0.21276594698429108, 0.11538460850715637]",S1gvPPMVv4,"['Instead of strict distribution alignments in traditional deep domain adaptation objectives, which fails when target label distribution shifts, we propose to optimize a relaxed objective with new analysis, new algorithms, and experimental validation.', 'This paper suggests relaxed metrics for domain adaptation which give new theoretical bounds on the target error.']","['domain adaptation address common problem target distribution generating test data drift source  training  distribution ', 'absent assumption  domain adaptation impossible  strict condition  eg  covariate label shift  enable principled algorithm ', 'recentlyproposed domainadversarial approach consist aligning source target encoding  often motivating approach minimizing two  three  term theoretical bound target error ', 'unfortunately  minimization cause arbitrary increase third term  eg  break shifting label distribution ', 'propose asymmetricallyrelaxed distribution alignment  new approach overcomes limitation standard domainadversarial algorithm ', 'moreover  characterize precise assumption algorithm theoretically principled demonstrate empirical benefit synthetic real datasets ']","Domain adaptation addresses the common problem when the target distribution generating our test data drifts from the source (training) distribution., While absent assumptions, domain adaptation is impossible, strict conditions, e.g. covariate or label shift, enable principled algorithms., Recently-proposed domain-adversarial approaches consist of aligning source and target encodings, often motivating this approach as minimizing two (of three) terms in a theoretical bound on target error., Unfortunately, this minimization can cause arbitrary increases in the third term, e.g. they can break down under shifting label distributions., We propose asymmetrically-relaxed distribution alignment, a new approach that overcomes some limitations of standard domain-adversarial algorithms., Moreover, we characterize precise assumptions under which our algorithm is theoretically principled and demonstrate empirical benefits on both synthetic and real datasets.",15,6.745901639344262,7.176470588235294
508,"['In this paper, we explore \\textit{summary-to-article generation}: the task of generating long articles given a short summary, which provides finer-grained content control for the generated text.', 'To prevent sequence-to-sequence (seq2seq) models from degenerating into language models and better controlling the long text to be generated, we propose a hierarchical generation approach which first generates a sketch of intermediate length based on the summary and then completes the article by enriching the generated sketch.', ""To mitigate the discrepancy between the ``oracle'' sketch used during training and the noisy sketch generated during inference, we propose an end-to-end joint training framework based on multi-agent reinforcement learning."", 'For evaluation, we use text summarization corpora by reversing their inputs and outputs, and introduce a novel evaluation method that employs a summarization system to summarize the generated article and test its match with the original input summary.', 'Experiments show that our proposed hierarchical generation approach can generate a coherent and relevant article based on the given summary, yielding significant improvements upon conventional seq2seq models.']","[0, 0, 1, 0, 0]","[0.25531914830207825, 0.29032257199287415, 0.3404255211353302, 0.2181818187236786, 0.20408162474632263]",Hkl8Ia4YPH,"['we explore the task of summary-to-article generation and propose a hierarchical generation scheme together with a jointly end-to-end reinforcement learning framework to train the hierarchical model.', 'To address the issue of degeneration in summary-to-article generation, this paper proposes a hierarchical generation approach which first generates an intermediate sketch of the article and then the full article.']","['paper  explore textit  summarytoarticle generation   task generating long article given short summary  provides finergrained content control generated text ', 'prevent sequencetosequence  seq2seq  model degenerating language model better controlling long text generated  propose hierarchical generation approach first generates sketch intermediate length based summary completes article enriching generated sketch ', 'mitigate discrepancy  oracle  sketch used training noisy sketch generated inference  propose endtoend joint training framework based multiagent reinforcement learning ', 'evaluation  use text summarization corpus reversing input output  introduce novel evaluation method employ summarization system summarize generated article test match original input summary ', 'experiment show proposed hierarchical generation approach generate coherent relevant article based given summary  yielding significant improvement upon conventional seq2seq model ']","In this paper, we explore \textit{summary-to-article generation}: the task of generating long articles given a short summary, which provides finer-grained content control for the generated text., To prevent sequence-to-sequence (seq2seq) models from degenerating into language models and better controlling the long text to be generated, we propose a hierarchical generation approach which first generates a sketch of intermediate length based on the summary and then completes the article by enriching the generated sketch., To mitigate the discrepancy between the ``oracle'' sketch used during training and the noisy sketch generated during inference, we propose an end-to-end joint training framework based on multi-agent reinforcement learning., For evaluation, we use text summarization corpora by reversing their inputs and outputs, and introduce a novel evaluation method that employs a summarization system to summarize the generated article and test its match with the original input summary., Experiments show that our proposed hierarchical generation approach can generate a coherent and relevant article based on the given summary, yielding significant improvements upon conventional seq2seq models.",12,6.148809523809524,14.0
509,"['When training a deep neural network for supervised image classification, one can broadly distinguish between two types of latent features of images that will drive the classification of class Y. Following the notation of Gong et al. (2016), we can divide features broadly into the classes of', '(i) core or conditionally invariant features X^ci whose distribution P(X^ci | Y) does not change substantially across domains and', '(ii) style or orthogonal features X^orth whose distribution P(X^orth | Y) can change substantially across domains.', 'These latter orthogonal features would generally include features such as position, rotation, image quality or brightness but also more complex ones like hair color or posture for images of persons.', 'We try to guard against future adversarial domain shifts by ideally just using the conditionally invariant features for classification.', 'In contrast to previous work, we assume that the domain itself is not observed and hence a latent variable.', 'We can hence not directly see the distributional change of features across different domains. \n\n', 'We do assume, however, that we can sometimes observe a so-called identifier or ID variable.', 'We might know, for example, that two images show the same person, with ID referring to the identity of the person.', 'In data augmentation, we generate several images from the same original image, with ID referring to the relevant original image.', 'The method requires only a small fraction of images to have an ID variable.\n\n', 'We provide a causal framework for the problem by adding the ID variable to the model of Gong et al. (2016).', 'However, we are interested in settings where we cannot observe the domain directly and we treat domain as a latent variable.', 'If two or more samples share the same class and identifier, (Y, ID)=(y,i), then we treat those samples as counterfactuals under different style interventions on the orthogonal or style features.', 'Using this grouping-by-ID approach, we regularize the network to provide near constant output across samples that share the same ID by penalizing with an appropriate graph Laplacian.', 'This is shown to substantially improve performance in settings where domains change in terms of image quality, brightness, color changes, and more complex changes such as changes in movement and posture.', 'We show links to questions of interpretability, fairness and transfer learning.']","[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.13793103396892548, 0.051282044500112534, 0.0555555522441864, 0.0833333283662796, 0.41025641560554504, 0.20512819290161133, 0.17142856121063232, 0.05714285373687744, 0.25641024112701416, 0.15789473056793213, 0.17142856121063232, 0.20512819290161133, 0.21052631735801697, 0.04347825422883034, 0.08695651590824127, 0.12765957415103912, 0.19354838132858276]",HyPpD0g0Z,"['We propose counterfactual regularization to guard against adversarial domain shifts arising through shifts in the distribution of latent ""style features"" of images.', 'The paper discusses ways to guard against adversarial domain shifts with counterfactual regularization by learning a classifier that is invariant to superficial changes (or ""style"" features) in imagess.', 'This paper aims at robust image classification against adversarial domain shifts and the goal is achieved by avoiding using the changing style features.']","['training deep neural network supervised image classification  one broadly distinguish two type latent feature image drive classification class  following notation gong et al   2016   divide feature broadly class', '   core   conditionally invariant  feature xci whose distribution p  xci   change substantially across domain', ' ii   style   orthogonal  feature xorth whose distribution p  xorth   change substantially across domain ', 'latter orthogonal feature would generally include feature position  rotation  image quality brightness also complex one like hair color posture image person ', 'try guard future adversarial domain shift ideally using  conditionally invariant  feature classification ', 'contrast previous work  assume domain observed hence latent variable ', 'hence directly see distributional change feature across different domain ', 'assume  however  sometimes observe socalled identifier id variable ', 'might know  example  two image show person  id referring identity person ', 'data augmentation  generate several image original image  id referring relevant original image ', 'method requires small fraction image id variable ', 'provide causal framework problem adding id variable model gong et al   2016  ', 'however  interested setting observe domain directly treat domain latent variable ', 'two sample share class identifier    id       treat sample counterfactuals different style intervention orthogonal style feature ', 'using groupingbyid approach  regularize network provide near constant output across sample share id penalizing appropriate graph laplacian ', 'shown substantially improve performance setting domain change term image quality  brightness  color change  complex change change movement posture ', 'show link question interpretability  fairness transfer learning ']","When training a deep neural network for supervised image classification, one can broadly distinguish between two types of latent features of images that will drive the classification of class Y. Following the notation of Gong et al. (2016), we can divide features broadly into the classes of, (i) core or conditionally invariant features X^ci whose distribution P(X^ci | Y) does not change substantially across domains and, (ii) style or orthogonal features X^orth whose distribution P(X^orth | Y) can change substantially across domains., These latter orthogonal features would generally include features such as position, rotation, image quality or brightness but also more complex ones like hair color or posture for images of persons., We try to guard against future adversarial domain shifts by ideally just using the conditionally invariant features for classification., In contrast to previous work, we assume that the domain itself is not observed and hence a latent variable., We can hence not directly see the distributional change of features across different domains. 

, We do assume, however, that we can sometimes observe a so-called identifier or ID variable., We might know, for example, that two images show the same person, with ID referring to the identity of the person., In data augmentation, we generate several images from the same original image, with ID referring to the relevant original image., The method requires only a small fraction of images to have an ID variable.

, We provide a causal framework for the problem by adding the ID variable to the model of Gong et al. (2016)., However, we are interested in settings where we cannot observe the domain directly and we treat domain as a latent variable., If two or more samples share the same class and identifier, (Y, ID)=(y,i), then we treat those samples as counterfactuals under different style interventions on the orthogonal or style features., Using this grouping-by-ID approach, we regularize the network to provide near constant output across samples that share the same ID by penalizing with an appropriate graph Laplacian., This is shown to substantially improve performance in settings where domains change in terms of image quality, brightness, color changes, and more complex changes such as changes in movement and posture., We show links to questions of interpretability, fairness and transfer learning.",38,5.32,9.146341463414634
510,"['Gradient-based meta-learning algorithms require several steps of gradient descent to adapt to newly incoming tasks.', 'This process becomes more costly as the number  of  samples  increases.', '  Moreover,  the  gradient  updates  suffer  from  several sources of noise leading to a degraded performance', '.   In this work,  we propose a meta-learning algorithm equipped with the GradiEnt Component COrrections, aGECCO cell for short, which generates a multiplicative corrective low-rank matrix which (after vectorization) corrects the estimated gradients', '. GECCO contains a simple decoder-like network with learnable parameters, an attention module and a so-called context input parameter', '. The context parameter of GECCO is updated to  generate  a  low-rank  corrective  term  for  the  network  gradients', '.   As  a  result, meta-learning requires only a few of gradient updates to absorb new task (often, a single update is sufficient in the few-shot scenario', '). While previous approaches address this problem by altering the learning rates, factorising network parameters or directly learning feature corrections from features and/or gradients, GECCO is an off-the-shelf generator-like unit that performs element-wise gradient corrections without the need to observe the features and/or the gradients directly', '.  We show that our GECCO', '(i) accelerates learning,', '(ii) performs robust corrections of the gradients corrupted by a noise, and', '(iii) leads to notable improvements over existing gradient-based meta-learning algorithms.']","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.19999998807907104, 0.0, 0.12903225421905518, 0.08888888359069824, 0.060606054961681366, 0.12121211737394333, 0.20512819290161133, 0.03703703358769417, 0.0952380895614624, 0.0, 0.0714285671710968, 0.07692307233810425]",H1g7sxHKPr,"['We propose a meta-learner to adapt quickly on multiple tasks even one step in a few-shot setting.', 'This paper proposes a method to meta-learn a gradient correction module in which preconditioning is parameterized by a neural network, and builds in a two-stage gradient update process during adaptation. ']","['gradientbased metalearning algorithm require several step gradient descent adapt newly incoming task ', 'process becomes costly number sample increase ', 'moreover  gradient update suffer several source noise leading degraded performance', ' work  propose metalearning algorithm equipped gradient component correction  agecco cell short  generates multiplicative corrective lowrank matrix  vectorization  corrects estimated gradient', ' gecco contains simple decoderlike network learnable parameter  attention module socalled context input parameter', ' context parameter gecco updated generate lowrank corrective term network gradient', ' result  metalearning requires gradient update absorb new task  often  single update sufficient fewshot scenario', '  previous approach address problem altering learning rate  factorising network parameter directly learning feature correction feature andor gradient  gecco offtheshelf generatorlike unit performs elementwise gradient correction without need  observe  feature andor gradient directly', ' show gecco', '  accelerates learning ', ' ii  performs robust correction gradient corrupted noise ', ' iii  lead notable improvement existing gradientbased metalearning algorithm ']","Gradient-based meta-learning algorithms require several steps of gradient descent to adapt to newly incoming tasks., This process becomes more costly as the number  of  samples  increases.,   Moreover,  the  gradient  updates  suffer  from  several sources of noise leading to a degraded performance, .   In this work,  we propose a meta-learning algorithm equipped with the GradiEnt Component COrrections, aGECCO cell for short, which generates a multiplicative corrective low-rank matrix which (after vectorization) corrects the estimated gradients, . GECCO contains a simple decoder-like network with learnable parameters, an attention module and a so-called context input parameter, . The context parameter of GECCO is updated to  generate  a  low-rank  corrective  term  for  the  network  gradients, .   As  a  result, meta-learning requires only a few of gradient updates to absorb new task (often, a single update is sufficient in the few-shot scenario, ). While previous approaches address this problem by altering the learning rates, factorising network parameters or directly learning feature corrections from features and/or gradients, GECCO is an off-the-shelf generator-like unit that performs element-wise gradient corrections without the need to observe the features and/or the gradients directly, .  We show that our GECCO, (i) accelerates learning,, (ii) performs robust corrections of the gradients corrupted by a noise, and, (iii) leads to notable improvements over existing gradient-based meta-learning algorithms.",22,5.957943925233645,7.642857142857143
511,"['Discriminative  question  answering  models  can  overfit  to  superficial  biases  in datasets,  because their loss function saturates when any clue makes the answer likely.  ', 'We introduce generative models of the joint distribution of questions and answers, which are trained to explain the whole question, not just to answer it.', 'Our  question  answering  (QA)  model  is  implemented  by  learning  a  prior  over answers,  and  a  conditional  language  model  to  generate  the  question  given  the answerallowing scalable and interpretable many-hop reasoning as the question is generated word-by-word.  ', 'Our model achieves competitive performance with specialised discriminative models on the SQUAD and CLEVR benchmarks, indicating that it is a more general architecture for language understanding and reasoning than previous work.', 'The model greatly improves generalisation both from biased training data and to adversarial testing data, achieving a new state-of-the-art on ADVERSARIAL SQUAD.', 'We will release our code.']","[0, 1, 0, 0, 0, 0]","[0.19512194395065308, 0.3589743673801422, 0.17391303181648254, 0.3404255211353302, 0.10256409645080566, 0.0]",Bkx0RjA9tX,"['Question answering models that model the joint distribution of questions and answers can learn more than discriminative models', 'This paper proposes a generative approach to textual and visual QA, where a joint distribution over the question and answer space given the context is learned, which captures more complex relationships.', 'This paper introduces a generative model for question answering and proposes to model p(q,a|c), factorized as p(a|c) * p(q|a,c). ', 'The authors proposes a generative QA model, which optimizes jointly the distribution of questions and answering given a document/context. ']","['discriminative question answering model overfit superficial bias datasets  loss function saturates clue make answer likely ', 'introduce generative model joint distribution question answer  trained explain whole question  answer ', 'question answering  qa  model implemented learning prior answer  conditional language model generate question given answerallowing scalable interpretable manyhop reasoning question generated wordbyword ', 'model achieves competitive performance specialised discriminative model squad clevr benchmark  indicating general architecture language understanding reasoning previous work ', 'model greatly improves generalisation biased training data adversarial testing data  achieving new stateoftheart adversarial squad ', 'release code ']","Discriminative  question  answering  models  can  overfit  to  superficial  biases  in datasets,  because their loss function saturates when any clue makes the answer likely.  , We introduce generative models of the joint distribution of questions and answers, which are trained to explain the whole question, not just to answer it., Our  question  answering  (QA)  model  is  implemented  by  learning  a  prior  over answers,  and  a  conditional  language  model  to  generate  the  question  given  the answerallowing scalable and interpretable many-hop reasoning as the question is generated word-by-word.  , Our model achieves competitive performance with specialised discriminative models on the SQUAD and CLEVR benchmarks, indicating that it is a more general architecture for language understanding and reasoning than previous work., The model greatly improves generalisation both from biased training data and to adversarial testing data, achieving a new state-of-the-art on ADVERSARIAL SQUAD., We will release our code.",12,5.936619718309859,11.833333333333334
512,"['In this paper, we turn our attention to the interworking between the activation functions and the batch normalization, which is a virtually mandatory technique to train deep networks currently.', 'We propose the activation function Displaced Rectifier Linear Unit (DReLU) by conjecturing that extending the identity function of ReLU to the third quadrant enhances compatibility with batch normalization.', 'Moreover, we used statistical tests to compare the impact of using distinct activation functions (ReLU, LReLU, PReLU, ELU, and DReLU) on the learning speed and test accuracy performance of standardized VGG and Residual Networks state-of-the-art models.', 'These convolutional neural networks were trained on CIFAR-100 and CIFAR-10, the most commonly used deep learning computer vision datasets.', 'The results showed DReLU speeded up learning in all models and datasets.', 'Besides, statistical significant performance assessments (p<0.05) showed DReLU enhanced the test accuracy presented by ReLU in all scenarios.', 'Furthermore, DReLU showed better test accuracy than any other tested activation function in all experiments with one exception, in which case it presented the second best performance.', 'Therefore, this work demonstrates that it is possible to increase performance replacing ReLU by an enhanced activation function.']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.26923075318336487, 0.3921568691730499, 0.20689654350280762, 0.2222222238779068, 0.10526315122842789, 0.13333332538604736, 0.19230768084526062, 0.22727271914482117]",H1DGha1CZ,"['A new activation function called Displaced Rectifier Linear Unit is proposed. It is showed to enhance the training and inference performance of batch normalized convolutional neural networks.', 'The paper compares and suggests against the usage of batch normalization after using rectifier linear units', 'This paper proposes an activation function, called displaced ReLU, to improve the performance of CNNs that use batch normalization.']","['paper  turn attention interworking activation function batch normalization  virtually mandatory technique train deep network currently ', 'propose activation function displaced rectifier linear unit  drelu  conjecturing extending identity function relu third quadrant enhances compatibility batch normalization ', 'moreover  used statistical test compare impact using distinct activation function  relu  lrelu  prelu  elu  drelu  learning speed test accuracy performance standardized vgg residual network stateoftheart model ', 'convolutional neural network trained cifar100 cifar10  commonly used deep learning computer vision datasets ', 'result showed drelu speeded learning model datasets ', 'besides  statistical significant performance assessment  p  005  showed drelu enhanced test accuracy presented relu scenario ', 'furthermore  drelu showed better test accuracy tested activation function experiment one exception  case presented second best performance ', 'therefore  work demonstrates possible increase performance replacing relu enhanced activation function ']","In this paper, we turn our attention to the interworking between the activation functions and the batch normalization, which is a virtually mandatory technique to train deep networks currently., We propose the activation function Displaced Rectifier Linear Unit (DReLU) by conjecturing that extending the identity function of ReLU to the third quadrant enhances compatibility with batch normalization., Moreover, we used statistical tests to compare the impact of using distinct activation functions (ReLU, LReLU, PReLU, ELU, and DReLU) on the learning speed and test accuracy performance of standardized VGG and Residual Networks state-of-the-art models., These convolutional neural networks were trained on CIFAR-100 and CIFAR-10, the most commonly used deep learning computer vision datasets., The results showed DReLU speeded up learning in all models and datasets., Besides, statistical significant performance assessments (p<0.05) showed DReLU enhanced the test accuracy presented by ReLU in all scenarios., Furthermore, DReLU showed better test accuracy than any other tested activation function in all experiments with one exception, in which case it presented the second best performance., Therefore, this work demonstrates that it is possible to increase performance replacing ReLU by an enhanced activation function.",20,6.0,9.35
513,"['Encoding the input scale information explicitly into the representation learned by a convolutional neural network (CNN) is beneficial for many vision tasks especially when dealing with multiscale input signals.', 'We study, in this paper, a scale-equivariant CNN architecture with joint convolutions across the space and the scaling group, which is shown to be both sufficient and necessary to achieve scale-equivariant representations.', 'To reduce the model complexity and computational burden, we decompose the convolutional filters under two pre-fixed separable bases and truncate the expansion to low-frequency components.', 'A further benefit of the truncated filter expansion is the improved deformation robustness of the equivariant representation.', 'Numerical experiments demonstrate that the proposed scale-equivariant neural network with decomposed convolutional filters (ScDCFNet) achieves significantly improved performance in multiscale image classification and better interpretability than regular CNNs at a reduced model size.']","[0, 1, 0, 0, 0]","[0.17391303181648254, 0.2978723347187042, 0.19512194395065308, 0.1818181723356247, 0.26923075318336487]",rkgCJ64tDB,"['We construct scale-equivariant convolutional neural networks in the most general form with both computational efficiency and proved deformation robustness.', 'The authors propose a CNN architecture that is theoretically equivariant to isotropic scalings and translations by adding an extra scale-dimension to activation tensors.']","['encoding input scale information explicitly representation learned convolutional neural network  cnn  beneficial many vision task especially dealing multiscale input signal ', 'study  paper  scaleequivariant cnn architecture joint convolution across space scaling group  shown sufficient necessary achieve scaleequivariant representation ', 'reduce model complexity computational burden  decompose convolutional filter two prefixed separable base truncate expansion lowfrequency component ', 'benefit truncated filter expansion improved deformation robustness equivariant representation ', 'numerical experiment demonstrate proposed scaleequivariant neural network decomposed convolutional filter  scdcfnet  achieves significantly improved performance multiscale image classification better interpretability regular cnns reduced model size ']","Encoding the input scale information explicitly into the representation learned by a convolutional neural network (CNN) is beneficial for many vision tasks especially when dealing with multiscale input signals., We study, in this paper, a scale-equivariant CNN architecture with joint convolutions across the space and the scaling group, which is shown to be both sufficient and necessary to achieve scale-equivariant representations., To reduce the model complexity and computational burden, we decompose the convolutional filters under two pre-fixed separable bases and truncate the expansion to low-frequency components., A further benefit of the truncated filter expansion is the improved deformation robustness of the equivariant representation., Numerical experiments demonstrate that the proposed scale-equivariant neural network with decomposed convolutional filters (ScDCFNet) achieves significantly improved performance in multiscale image classification and better interpretability than regular CNNs at a reduced model size.",9,6.5588235294117645,15.11111111111111
514,"['In this paper, we diagnose deep neural networks for 3D point cloud processing to explore the utility of different network architectures.', 'We propose a number of hypotheses on the effects of specific network architectures on the representation capacity of DNNs.', 'In order to prove the hypotheses, we design five metrics to diagnose various types of DNNs from the following perspectives, information discarding, information concentration, rotation robustness, adversarial robustness, and neighborhood inconsistency.', 'We conduct comparative studies based on such metrics to verify the hypotheses, which may shed new lights on the architectural design of neural networks.', 'Experiments demonstrated the effectiveness of our method.', 'The code will be released when this paper is accepted.']","[1, 0, 0, 0, 0, 0]","[0.8500000238418579, 0.29411762952804565, 0.17391303181648254, 0.2926829159259796, 0.1538461446762085, 0.0]",rkxxKhVYwr,"['We diagnose deep neural networks for 3D point cloud processing to explore the utility of different network architectures. ', 'The paper investigates different neural network architectures for 3D point cloud processing and proposes metrics for adversarial robustness, rotational robustness, and neighborhood consistency.']","['paper  diagnose deep neural network 3d point cloud processing explore utility different network architecture ', 'propose number hypothesis effect specific network architecture representation capacity dnns ', 'order prove hypothesis  design five metric diagnose various type dnns following perspective  information discarding  information concentration  rotation robustness  adversarial robustness  neighborhood inconsistency ', 'conduct comparative study based metric verify hypothesis  may shed new light architectural design neural network ', 'experiment demonstrated effectiveness method ', 'code released paper accepted ']","In this paper, we diagnose deep neural networks for 3D point cloud processing to explore the utility of different network architectures., We propose a number of hypotheses on the effects of specific network architectures on the representation capacity of DNNs., In order to prove the hypotheses, we design five metrics to diagnose various types of DNNs from the following perspectives, information discarding, information concentration, rotation robustness, adversarial robustness, and neighborhood inconsistency., We conduct comparative studies based on such metrics to verify the hypotheses, which may shed new lights on the architectural design of neural networks., Experiments demonstrated the effectiveness of our method., The code will be released when this paper is accepted.",14,5.875,8.0
515,"['In this work we construct flexible joint distributions from low-dimensional conditional semi-implicit distributions.', 'Explicitly defining the structure of the approximation allows to make the variational lower bound tighter, resulting in more accurate inference.']","[0, 1]","[0.1904761791229248, 0.37037035822868347]",HkxStk34Kr,['Utilizing the structure of distributions improves semi-implicit variational inference'],"['work construct flexible joint distribution lowdimensional conditional semiimplicit distribution ', 'explicitly defining structure approximation allows make variational lower bound tighter  resulting accurate inference ']","In this work we construct flexible joint distributions from low-dimensional conditional semi-implicit distributions., Explicitly defining the structure of the approximation allows to make the variational lower bound tighter, resulting in more accurate inference.",3,6.909090909090909,11.0
516,"['Imitation learning from human-expert demonstrations has been shown to be greatly helpful for challenging reinforcement learning problems with sparse environment rewards.', 'However, it is very difficult to achieve similar success without relying on expert demonstrations.', ""Recent works on self-imitation learning showed that imitating the agent's own past good experience could indirectly drive exploration in some environments, but these methods often lead to sub-optimal and myopic behavior."", 'To address this issue, we argue that exploration in diverse directions by imitating diverse trajectories, instead of focusing on limited good trajectories, is more desirable for the hard-exploration tasks.', ""We propose a new method of learning a trajectory-conditioned policy to imitate diverse trajectories from the agent's own past experiences and show that such self-imitation helps avoid myopic behavior and increases the chance of finding a globally optimal solution for hard-exploration tasks, especially when there are misleading rewards."", 'Our method significantly outperforms existing self-imitation learning and count-based exploration methods on various hard-exploration tasks with local optima.', 'In particular, we report a state-of-the-art score of more than 20,000 points on Montezumas Revenge without using expert demonstrations or resetting to arbitrary states.']","[0, 0, 0, 0, 1, 0, 0]","[0.1428571343421936, 0.0, 0.05128204822540283, 0.11428570747375488, 0.23529411852359772, 0.1538461446762085, 0.0624999962747097]",Byg5KyHYwr,"['Self-imitation learning of diverse trajectories with trajectory-conditioned policy', 'This paper addresses hard exploration tasks by applying self-imitation to a diverse selection of trajectories from past experience, to drive more efficient exploration in sparse-reward problems, achieving SOTA results.']","['imitation learning humanexpert demonstration shown greatly helpful challenging reinforcement learning problem sparse environment reward ', 'however  difficult achieve similar success without relying expert demonstration ', 'recent work selfimitation learning showed imitating agent past good experience could indirectly drive exploration environment  method often lead suboptimal myopic behavior ', 'address issue  argue exploration diverse direction imitating diverse trajectory  instead focusing limited good trajectory  desirable hardexploration task ', 'propose new method learning trajectoryconditioned policy imitate diverse trajectory agent past experience show selfimitation help avoid myopic behavior increase chance finding globally optimal solution hardexploration task  especially misleading reward ', 'method significantly outperforms existing selfimitation learning countbased exploration method various hardexploration task local optimum ', 'particular  report stateoftheart score 20000 point montezuma revenge without using expert demonstration resetting arbitrary state ']","Imitation learning from human-expert demonstrations has been shown to be greatly helpful for challenging reinforcement learning problems with sparse environment rewards., However, it is very difficult to achieve similar success without relying on expert demonstrations., Recent works on self-imitation learning showed that imitating the agent's own past good experience could indirectly drive exploration in some environments, but these methods often lead to sub-optimal and myopic behavior., To address this issue, we argue that exploration in diverse directions by imitating diverse trajectories, instead of focusing on limited good trajectories, is more desirable for the hard-exploration tasks., We propose a new method of learning a trajectory-conditioned policy to imitate diverse trajectories from the agent's own past experiences and show that such self-imitation helps avoid myopic behavior and increases the chance of finding a globally optimal solution for hard-exploration tasks, especially when there are misleading rewards., Our method significantly outperforms existing self-imitation learning and count-based exploration methods on various hard-exploration tasks with local optima., In particular, we report a state-of-the-art score of more than 20,000 points on Montezumas Revenge without using expert demonstrations or resetting to arbitrary states.",14,6.324324324324325,13.214285714285714
517,"['We present a method that trains large capacity neural networks with significantly improved accuracy and lower dynamic computational cost.', 'This is achieved by gating the deep-learning architecture on a fine-grained-level.', 'Individual convolutional maps are turned on/off conditionally on features in the network.', 'To achieve this, we introduce a new residual block architecture that gates convolutional channels in a fine-grained manner.', 'We also introduce a generally applicable tool batch-shaping that matches the marginal aggregate posteriors of features in a neural network to a pre-specified prior distribution.', 'We use this novel technique to force gates to be more conditional on the data.', 'We present results on CIFAR-10 and ImageNet datasets for image classification, and Cityscapes for semantic segmentation.', 'Our results show that our method can slim down large architectures conditionally, such that the average computational cost on the data is on par with a smaller architecture, but with higher accuracy.', 'In particular, on ImageNet, our ResNet50 and ResNet34 gated networks obtain 74.60% and 72.55% top-1 accuracy compared to the 69.76% accuracy of the baseline ResNet18 model, for similar complexity.', 'We also show that the resulting networks automatically learn to use more features for difficult examples and fewer features for simple examples.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.8888888955116272, 0.0, 0.0, 0.05882352590560913, 0.09999999403953552, 0.0, 0.06451612710952759, 0.31111109256744385, 0.1304347813129425, 0.1666666567325592]",Bke89JBtvB,"['A method that trains large capacity neural networks with significantly improved accuracy and lower dynamic computational cost', 'A method to train a network with large capacity, only parts of which are used at inference time dependent on input, using fine-grained conditional selection and a new method of regularization, ""batch shaping.""']","['present method train large capacity neural network significantly improved accuracy lower dynamic computational cost ', 'achieved gating deeplearning architecture finegrainedlevel ', 'individual convolutional map turned onoff conditionally feature network ', 'achieve  introduce new residual block architecture gate convolutional channel finegrained manner ', 'also introduce generally applicable tool batchshaping match marginal aggregate posterior feature neural network prespecified prior distribution ', 'use novel technique force gate conditional data ', 'present result cifar10 imagenet datasets image classification  cityscape semantic segmentation ', 'result show method slim large architecture conditionally  average computational cost data par smaller architecture  higher accuracy ', 'particular  imagenet  resnet50 resnet34 gated network obtain 7460  7255  top1 accuracy compared 6976  accuracy baseline resnet18 model  similar complexity ', 'also show resulting network automatically learn use feature difficult example fewer feature simple example ']","We present a method that trains large capacity neural networks with significantly improved accuracy and lower dynamic computational cost., This is achieved by gating the deep-learning architecture on a fine-grained-level., Individual convolutional maps are turned on/off conditionally on features in the network., To achieve this, we introduce a new residual block architecture that gates convolutional channels in a fine-grained manner., We also introduce a generally applicable tool batch-shaping that matches the marginal aggregate posteriors of features in a neural network to a pre-specified prior distribution., We use this novel technique to force gates to be more conditional on the data., We present results on CIFAR-10 and ImageNet datasets for image classification, and Cityscapes for semantic segmentation., Our results show that our method can slim down large architectures conditionally, such that the average computational cost on the data is on par with a smaller architecture, but with higher accuracy., In particular, on ImageNet, our ResNet50 and ResNet34 gated networks obtain 74.60% and 72.55% top-1 accuracy compared to the 69.76% accuracy of the baseline ResNet18 model, for similar complexity., We also show that the resulting networks automatically learn to use more features for difficult examples and fewer features for simple examples.",17,5.773869346733668,11.705882352941176
518,"['With a view to bridging the gap between deep learning and symbolic AI, we present a novel end-to-end neural network architecture that learns to form propositional representations with an explicitly relational structure from raw pixel data.', 'In order to evaluate and analyse the architecture, we introduce a family of simple visual relational reasoning tasks of varying complexity.', 'We show that the proposed architecture, when pre-trained on a curriculum of such tasks, learns to generate reusable representations that better facilitate subsequent learning on previously unseen tasks when compared to a number of baseline architectures.', 'The workings of a successfully trained model are visualised to shed some light on how the architecture functions.']","[0, 1, 0, 0]","[0.35087719559669495, 0.41860464215278625, 0.30188679695129395, 0.24390242993831635]",S1l6ITVKPS,"['We present an end-to-end differentiable architecture that learns to map pixels to predicates, and evaluate it on a suite of simple relational reasoning tasks', 'A network architecture based on the multi-head self-attention module to learn a new form of relational representations, which improves data efficiency and generalization ability on curriculum learning.']","['view bridging gap deep learning symbolic ai  present novel endtoend neural network architecture learns form propositional representation explicitly relational structure raw pixel data ', 'order evaluate analyse architecture  introduce family simple visual relational reasoning task varying complexity ', 'show proposed architecture  pretrained curriculum task  learns generate reusable representation better facilitate subsequent learning previously unseen task compared number baseline architecture ', 'working successfully trained model visualised shed light architecture function ']","With a view to bridging the gap between deep learning and symbolic AI, we present a novel end-to-end neural network architecture that learns to form propositional representations with an explicitly relational structure from raw pixel data., In order to evaluate and analyse the architecture, we introduce a family of simple visual relational reasoning tasks of varying complexity., We show that the proposed architecture, when pre-trained on a curriculum of such tasks, learns to generate reusable representations that better facilitate subsequent learning on previously unseen tasks when compared to a number of baseline architectures., The workings of a successfully trained model are visualised to shed some light on how the architecture functions.",8,5.711711711711712,13.875
519,"['In natural language inference, the semantics of some words do not affect the inference.', 'Such information is considered superficial and brings overfitting.', 'How can we represent and discard such superficial information?', 'In this paper, we use first order logic (FOL) - a classic technique from meaning representation language  to explain what information is superficial for a given sentence pair.', 'Such explanation also suggests two inductive biases according to its properties.', 'We proposed a neural network-based approach that utilizes the two inductive biases.', 'We obtain substantial improvements over extensive experiments.']","[0, 0, 0, 1, 0, 0, 0]","[0.277777761220932, 0.19354838132858276, 0.1249999925494194, 0.31372547149658203, 0.05882352590560913, 0.17142856121063232, 0.06666666269302368]",HkxQzlHFPr,"['We use neural networks to project superficial information out for natural language inference by defining and identifying the superficial information from the perspective of first-order logic.', 'This paper tries to reduce superficial information in natural language inference to prevent overfitting, and introduces a graph neural network to model relation between premise and hypothesis. ', 'An approach to treat natural language inference using first-order logic and to infuse NLI models with logical information to be more robust at inference.']","['natural language inference  semantics word affect inference ', 'information considered superficial brings overfitting ', 'represent discard superficial information ', 'paper  use first order logic  fol   classic technique meaning representation language  explain information superficial given sentence pair ', 'explanation also suggests two inductive bias according property ', 'proposed neural networkbased approach utilizes two inductive bias ', 'obtain substantial improvement extensive experiment ']","In natural language inference, the semantics of some words do not affect the inference., Such information is considered superficial and brings overfitting., How can we represent and discard such superficial information?, In this paper, we use first order logic (FOL) - a classic technique from meaning representation language  to explain what information is superficial for a given sentence pair., Such explanation also suggests two inductive biases according to its properties., We proposed a neural network-based approach that utilizes the two inductive biases., We obtain substantial improvements over extensive experiments.",9,5.9,10.0
520,"['We propose an approach to training machine learning models that are fair in the sense that their performance is invariant under certain perturbations to the features.', 'For example, the performance of a resume screening system should be invariant under changes to the name of the applicant.', 'We formalize this intuitive notion of fairness by connecting it to the original  notion of individual fairness put forth by Dwork et al and show that the proposed approach achieves this notion of fairness.', 'We also demonstrate the effectiveness of the approach on two machine learning tasks that are susceptible to gender and racial biases.']","[1, 0, 0, 0]","[0.1249999925494194, 0.0, 0.0, 0.0]",B1gdkxHFDH,"['Algorithm for training individually fair classifier using adversarial robustness', 'This paper proposes a new definition of algorithmic fairness and an algorithm to provably find an ML model that satisfies the fairness contraint.']","['propose approach training machine learning model fair sense performance invariant certain perturbation feature ', 'example  performance resume screening system invariant change name applicant ', 'formalize intuitive notion fairness connecting original notion individual fairness put forth dwork et al show proposed approach achieves notion fairness ', 'also demonstrate effectiveness approach two machine learning task susceptible gender racial bias ']","We propose an approach to training machine learning models that are fair in the sense that their performance is invariant under certain perturbations to the features., For example, the performance of a resume screening system should be invariant under changes to the name of the applicant., We formalize this intuitive notion of fairness by connecting it to the original  notion of individual fairness put forth by Dwork et al and show that the proposed approach achieves this notion of fairness., We also demonstrate the effectiveness of the approach on two machine learning tasks that are susceptible to gender and racial biases.",5,5.207920792079208,20.2
521,"['In this paper, we propose a Seed-Augment-Train/Transfer (SAT) framework that contains a synthetic seed image dataset generation procedure for languages with different numeral systems using freely available open font file datasets.', 'This seed dataset of images is then augmented to create a purely synthetic training dataset, which is in turn used to train a deep neural network and test on held-out real world handwritten digits dataset spanning five Indic scripts, Kannada, Tamil, Gujarati, Malayalam, and Devanagari.', 'We showcase the efficacy of this approach both qualitatively, by training a Boundary-seeking GAN (BGAN) that generates realistic digit images in the five languages, and also qualitatively by testing a CNN trained on the synthetic data on the real-world datasets.', 'This establishes not only an interesting nexus between the font-datasets-world and transfer learning but also provides a recipe for universal-digit classification in any script.']","[0, 0, 0, 1]","[0.04651162400841713, 0.11320754140615463, 0.08510638028383255, 0.21621620655059814]",Bkgzr8LKOV,"['Is seeding and augmentation all you need for classifying digits in any language?', 'This paper presents new datasets for five languages and proposes a new framework (SAT) for font image datasets generation for universal digit classification.']","['paper  propose seedaugmenttraintransfer  sat  framework contains synthetic seed image dataset generation procedure language different numeral system using freely available open font file datasets ', 'seed dataset image augmented create purely synthetic training dataset  turn used train deep neural network test heldout real world handwritten digit dataset spanning five indic script  kannada  tamil  gujarati  malayalam  devanagari ', 'showcase efficacy approach qualitatively  training boundaryseeking gan  bgan  generates realistic digit image five language  also qualitatively testing cnn trained synthetic data realworld datasets ', 'establishes interesting nexus fontdatasetsworld transfer learning also provides recipe universaldigit classification script ']","In this paper, we propose a Seed-Augment-Train/Transfer (SAT) framework that contains a synthetic seed image dataset generation procedure for languages with different numeral systems using freely available open font file datasets., This seed dataset of images is then augmented to create a purely synthetic training dataset, which is in turn used to train a deep neural network and test on held-out real world handwritten digits dataset spanning five Indic scripts, Kannada, Tamil, Gujarati, Malayalam, and Devanagari., We showcase the efficacy of this approach both qualitatively, by training a Boundary-seeking GAN (BGAN) that generates realistic digit images in the five languages, and also qualitatively by testing a CNN trained on the synthetic data on the real-world datasets., This establishes not only an interesting nexus between the font-datasets-world and transfer learning but also provides a recipe for universal-digit classification in any script.",13,5.785714285714286,10.76923076923077
522,"['An important research direction in machine learning has centered around developing meta-learning algorithms to tackle few-shot learning.', 'An especially successful algorithm has been Model Agnostic Meta-Learning (MAML), a method that consists of two optimization loops, with the outer loop finding a meta-initialization, from which the inner loop can efficiently learn new tasks.', ""Despite MAML's popularity, a fundamental open question remains -- is the effectiveness of MAML due to the meta-initialization being primed for rapid learning (large, efficient changes in the representations) or due to feature reuse,  with the meta initialization already containing high quality features?"", 'We investigate this question, via ablation studies and analysis of the latent representations, finding that feature reuse is the dominant factor.', 'This leads to the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we remove the inner loop for all but the (task-specific) head of the underlying neural network.', ""ANIL matches MAML's performance on benchmark few-shot image classification and RL and offers computational improvements over MAML."", 'We further study the precise contributions of the head and body of the network, showing that performance on the test tasks is entirely determined by the quality of the learned features, and we can remove even the head of the network (the NIL algorithm).', 'We conclude with a discussion of the rapid learning vs feature reuse question for meta-learning algorithms more broadly.']","[0, 0, 0, 0, 1, 0, 0, 0]","[0.0, 0.28125, 0.19999998807907104, 0.19230768084526062, 0.37288135290145874, 0.1249999925494194, 0.21875, 0.2800000011920929]",rkgMkCEtPB,"['The success of MAML relies on feature reuse from the meta-initialization, which also yields a natural simplification of the algorithm, with the inner loop removed for the network body, as well as other insights on the head and body.', 'The paper finds that feature reuse is the dominant factor in the success of MAML, and propose new algorithms which spend much less computation than MAML.']","['important research direction machine learning centered around developing metalearning algorithm tackle fewshot learning ', 'especially successful algorithm model agnostic metalearning  maml   method consists two optimization loop  outer loop finding metainitialization  inner loop efficiently learn new task ', 'despite maml popularity  fundamental open question remains  effectiveness maml due metainitialization primed rapid learning  large  efficient change representation  due feature reuse  meta initialization already containing high quality feature ', 'investigate question  via ablation study analysis latent representation  finding feature reuse dominant factor ', 'lead anil  almost inner loop  algorithm  simplification maml remove inner loop  taskspecific  head underlying neural network ', 'anil match maml performance benchmark fewshot image classification rl offer computational improvement maml ', 'study precise contribution head body network  showing performance test task entirely determined quality learned feature  remove even head network  nil algorithm  ', 'conclude discussion rapid learning v feature reuse question metalearning algorithm broadly ']","An important research direction in machine learning has centered around developing meta-learning algorithms to tackle few-shot learning., An especially successful algorithm has been Model Agnostic Meta-Learning (MAML), a method that consists of two optimization loops, with the outer loop finding a meta-initialization, from which the inner loop can efficiently learn new tasks., Despite MAML's popularity, a fundamental open question remains -- is the effectiveness of MAML due to the meta-initialization being primed for rapid learning (large, efficient changes in the representations) or due to feature reuse,  with the meta initialization already containing high quality features?, We investigate this question, via ablation studies and analysis of the latent representations, finding that feature reuse is the dominant factor., This leads to the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we remove the inner loop for all but the (task-specific) head of the underlying neural network., ANIL matches MAML's performance on benchmark few-shot image classification and RL and offers computational improvements over MAML., We further study the precise contributions of the head and body of the network, showing that performance on the test tasks is entirely determined by the quality of the learned features, and we can remove even the head of the network (the NIL algorithm)., We conclude with a discussion of the rapid learning vs feature reuse question for meta-learning algorithms more broadly.",19,5.668141592920354,11.894736842105264
523,"['Model training remains a dominant financial cost and time investment in machine learning applications.', 'Developing and debugging models often involve iterative training, further exacerbating this issue.', 'With growing interest in increasingly complex models, there is a need for techniques that help to reduce overall training effort.', 'While incremental training can save substantial time and cost by training an existing model on a small subset of data, little work has explored policies for determining when incremental training provides adequate model performance versus full retraining.', 'We provide a method-agnostic algorithm for deciding when to incrementally train versus fully train.', 'We call this setting of non-deterministic full- or incremental training ``Mixed Setting Training"".', 'Upon evaluation in slot-filling tasks, we find that this algorithm provides a bounded error, avoids catastrophic forgetting, and results in a significant speedup over a policy of always fully training.']","[0, 0, 0, 0, 1, 0, 0]","[0.1621621549129486, 0.05714285373687744, 0.1860465109348297, 0.25, 0.7222222089767456, 0.1111111044883728, 0.4399999976158142]",rJg4GgHKPB,"['We provide a method-agnostic algorithm for deciding when to incrementally train versus fully train and it provides a significant speedup over fully training and avoids catastrophic forgetting', 'This paper proposes an approach for deciding when to incrementally vs. fully retrain a model in the setting of iterative model development in slot filling tasks.']","['model training remains dominant financial cost time investment machine learning application ', 'developing debugging model often involve iterative training  exacerbating issue ', 'growing interest increasingly complex model  need technique help reduce overall training effort ', 'incremental training save substantial time cost training existing model small subset data  little work explored policy determining incremental training provides adequate model performance versus full retraining ', 'provide methodagnostic algorithm deciding incrementally train versus fully train ', 'call setting nondeterministic full incremental training  mixed setting training  ', 'upon evaluation slotfilling task  find algorithm provides bounded error  avoids catastrophic forgetting  result significant speedup policy always fully training ']","Model training remains a dominant financial cost and time investment in machine learning applications., Developing and debugging models often involve iterative training, further exacerbating this issue., With growing interest in increasingly complex models, there is a need for techniques that help to reduce overall training effort., While incremental training can save substantial time and cost by training an existing model on a small subset of data, little work has explored policies for determining when incremental training provides adequate model performance versus full retraining., We provide a method-agnostic algorithm for deciding when to incrementally train versus fully train., We call this setting of non-deterministic full- or incremental training ``Mixed Setting Training""., Upon evaluation in slot-filling tasks, we find that this algorithm provides a bounded error, avoids catastrophic forgetting, and results in a significant speedup over a policy of always fully training.",13,6.014285714285714,10.76923076923077
524,"['Neural networks have succeeded in many reasoning tasks.', 'Empirically, these tasks require specialized network structures, e.g., Graph Neural Networks (GNNs) perform well on many such tasks, while less structured networks fail.', 'Theoretically, there is limited understanding of why and when a network structure generalizes better than other equally expressive ones.', 'We develop a framework to characterize which reasoning tasks a network can learn well, by studying how well its structure aligns with the algorithmic structure of the relevant reasoning procedure.', 'We formally define algorithmic alignment and derive a sample complexity bound that decreases with better alignment.', 'This framework explains the empirical success of popular reasoning models and suggests their limitations.', 'We unify seemingly different reasoning tasks, such as intuitive physics, visual question answering, and shortest paths, via the lens of a powerful algorithmic paradigm, dynamic programming (DP).', 'We show that GNNs can learn DP and thus solve these tasks.', 'On several reasoning tasks, our theory aligns with empirical results.']","[0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.17391303181648254, 0.14999999105930328, 0.11764705181121826, 0.6341463327407837, 0.13333332538604736, 0.13793103396892548, 0.1428571343421936, 0.29629629850387573, 0.07999999821186066]",rJxbJeHFPS,"['We develop a theoretical framework to characterize which reasoning tasks a neural network can learn well.', 'The paper proposes a measure of classes of algorithmic alignment that measure how ""close"" neural networks are to known algorithms, proving the link between several classes of known algorithms and neural network architectures.']","['neural network succeeded many reasoning task ', 'empirically  task require specialized network structure  eg  graph neural network  gnns  perform well many task  le structured network fail ', 'theoretically  limited understanding network structure generalizes better equally expressive one ', 'develop framework characterize reasoning task network learn well  studying well structure aligns algorithmic structure relevant reasoning procedure ', 'formally define algorithmic alignment derive sample complexity bound decrease better alignment ', 'framework explains empirical success popular reasoning model suggests limitation ', 'unify seemingly different reasoning task  intuitive physic  visual question answering  shortest path  via lens powerful algorithmic paradigm  dynamic programming  dp  ', 'show gnns learn dp thus solve task ', 'several reasoning task  theory aligns empirical result ']","Neural networks have succeeded in many reasoning tasks., Empirically, these tasks require specialized network structures, e.g., Graph Neural Networks (GNNs) perform well on many such tasks, while less structured networks fail., Theoretically, there is limited understanding of why and when a network structure generalizes better than other equally expressive ones., We develop a framework to characterize which reasoning tasks a network can learn well, by studying how well its structure aligns with the algorithmic structure of the relevant reasoning procedure., We formally define algorithmic alignment and derive a sample complexity bound that decreases with better alignment., This framework explains the empirical success of popular reasoning models and suggests their limitations., We unify seemingly different reasoning tasks, such as intuitive physics, visual question answering, and shortest paths, via the lens of a powerful algorithmic paradigm, dynamic programming (DP)., We show that GNNs can learn DP and thus solve these tasks., On several reasoning tasks, our theory aligns with empirical results.",21,5.880503144654088,7.571428571428571
525,"['Cell-cell interactions have an integral role in tumorigenesis as they are critical in governing immune responses.', 'As such, investigating specific cell-cell interactions has the potential to not only expand upon the understanding of tumorigenesis, but also guide clinical management of patient responses to cancer immunotherapies.', 'A recent imaging technique for exploring cell-cell interactions, multiplexed ion beam imaging by time-of-flight (MIBI-TOF), allows for cells to be quantified in 36 different protein markers at sub-cellular resolutions in situ as high resolution multiplexed images.', 'To explore the MIBI images, we propose a GAN for multiplexed data with protein specific attention.', 'By conditioning image generation on cell types, sizes, and neighborhoods through semantic segmentation maps, we are able to observe how these factors affect cell-cell interactions simultaneously in different protein channels.', 'Furthermore, we design a set of metrics and offer the first insights towards cell spatial orientations, cell protein expressions, and cell neighborhoods.', 'Our model, cell-cell interaction GAN (CCIGAN), outperforms or matches existing image synthesis methods on all conventional measures and significantly outperforms on biologically motivated metrics.', 'To our knowledge, we are the first to systematically model multiple cellular protein behaviors and interactions under simulated conditions through image synthesis.']","[0, 0, 0, 1, 0, 0, 0, 0]","[0.10810810327529907, 0.0833333283662796, 0.14814814925193787, 0.31578946113586426, 0.1538461446762085, 0.04878048226237297, 0.1818181723356247, 0.13636362552642822]",Byg9AR4YDB,"['We explore cell-cell interactions across tumor environment contexts observed in highly multiplexed images, by image synthesis using a novel attention GAN architecture.', ""A new method to model the data generated by multiplexed ion beam imaging by time-of-flight (MIBI-TOF) by learning the many-to-many mapping between cell types and protein markers' expression levels.""]","['cellcell interaction integral role tumorigenesis critical governing immune response ', ' investigating specific cellcell interaction potential expand upon understanding tumorigenesis  also guide clinical management patient response cancer immunotherapy ', 'recent imaging technique exploring cellcell interaction  multiplexed ion beam imaging timeofflight  mibitof   allows cell quantified 36 different protein marker subcellular resolution situ high resolution multiplexed image ', 'explore mibi image  propose gan multiplexed data protein specific attention ', 'conditioning image generation cell type  size  neighborhood semantic segmentation map  able observe factor affect cellcell interaction simultaneously different protein channel ', 'furthermore  design set metric offer first insight towards cell spatial orientation  cell protein expression  cell neighborhood ', 'model  cellcell interaction gan  ccigan   outperforms match existing image synthesis method conventional measure significantly outperforms biologically motivated metric ', 'knowledge  first systematically model multiple cellular protein behavior interaction simulated condition image synthesis ']","Cell-cell interactions have an integral role in tumorigenesis as they are critical in governing immune responses., As such, investigating specific cell-cell interactions has the potential to not only expand upon the understanding of tumorigenesis, but also guide clinical management of patient responses to cancer immunotherapies., A recent imaging technique for exploring cell-cell interactions, multiplexed ion beam imaging by time-of-flight (MIBI-TOF), allows for cells to be quantified in 36 different protein markers at sub-cellular resolutions in situ as high resolution multiplexed images., To explore the MIBI images, we propose a GAN for multiplexed data with protein specific attention., By conditioning image generation on cell types, sizes, and neighborhoods through semantic segmentation maps, we are able to observe how these factors affect cell-cell interactions simultaneously in different protein channels., Furthermore, we design a set of metrics and offer the first insights towards cell spatial orientations, cell protein expressions, and cell neighborhoods., Our model, cell-cell interaction GAN (CCIGAN), outperforms or matches existing image synthesis methods on all conventional measures and significantly outperforms on biologically motivated metrics., To our knowledge, we are the first to systematically model multiple cellular protein behaviors and interactions under simulated conditions through image synthesis.",22,6.287179487179487,8.863636363636363
526,"['Machine learning models for question-answering (QA), where given a question and a passage, the learner must select some span in the passage as an answer, are known to be brittle.', 'By inserting a single nuisance sentence into the passage, an adversary can fool the model into selecting the wrong span.', 'A promising new approach for QA decomposes the task into two stages:', '(i) select relevant sentences from the passage; and', '(ii) select a span among those sentences.', 'Intuitively, if the sentence selector excludes the offending sentence, then the downstream span selector will be robust.', 'While recent work has hinted at the potential robustness of two-stage QA, these methods have never, to our knowledge, been explicitly combined with adversarial training.', 'This paper offers a thorough empirical investigation of adversarial robustness, demonstrating that although the two-stage approach lags behind single-stage span selection, adversarial training improves its performance significantly, leading to an improvement of over 22 points in F1 score over the adversarially-trained single-stage model.']","[0, 0, 0, 0, 0, 0, 0, 1]","[0.1818181723356247, 0.22727271914482117, 0.10256409645080566, 0.0, 0.11764705926179886, 0.19512194395065308, 0.1538461446762085, 0.307692289352417]",SJeB-KQHnm,"['A two-stage approach consisting of sentence selection followed by span selection can be made more robust to adversarial attacks in comparison to a single-stage model trained on full context.', 'This paper investigates an existing model and finds that a two-stage trained QA method is not more robust to adversarial attacks compared to other methods.']","['machine learning model questionanswering  qa   given question passage  learner must select span passage answer  known brittle ', 'inserting single nuisance sentence passage  adversary fool model selecting wrong span ', 'promising new approach qa decomposes task two stage ', '  select relevant sentence passage ', ' ii  select span among sentence ', 'intuitively  sentence selector excludes offending sentence  downstream span selector robust ', 'recent work hinted potential robustness twostage qa  method never  knowledge  explicitly combined adversarial training ', 'paper offer thorough empirical investigation adversarial robustness  demonstrating although twostage approach lag behind singlestage span selection  adversarial training improves performance significantly  leading improvement 22 point f1 score adversariallytrained singlestage model ']","Machine learning models for question-answering (QA), where given a question and a passage, the learner must select some span in the passage as an answer, are known to be brittle., By inserting a single nuisance sentence into the passage, an adversary can fool the model into selecting the wrong span., A promising new approach for QA decomposes the task into two stages:, (i) select relevant sentences from the passage; and, (ii) select a span among those sentences., Intuitively, if the sentence selector excludes the offending sentence, then the downstream span selector will be robust., While recent work has hinted at the potential robustness of two-stage QA, these methods have never, to our knowledge, been explicitly combined with adversarial training., This paper offers a thorough empirical investigation of adversarial robustness, demonstrating that although the two-stage approach lags behind single-stage span selection, adversarial training improves its performance significantly, leading to an improvement of over 22 points in F1 score over the adversarially-trained single-stage model.",20,5.679012345679013,8.1
527,"['The aim of this study is to introduce a formal framework for analysis and synthesis of driver assistance systems.', 'It applies formal methods to the verification of a stochastic human driver model built using the cognitive architecture ACT-R, and then bootstraps safety in semi-autonomous vehicles through the design of provably correct Advanced Driver Assistance Systems.', 'The main contributions include the integration of probabilistic ACT-R models in the formal analysis of semi-autonomous systems and an abstraction technique that enables a finite representation of a large dimensional, continuous system in the form of a Markov model.', 'The effectiveness of the method is illustrated in several case studies under various conditions.']","[0, 1, 0, 0]","[0.29411762952804565, 0.3265306055545807, 0.1702127605676651, 0.06666666269302368]",H1luEtWjTE,['Verification of a human driver model based on a cognitive architecture and synthesis of a correct-by-construction ADAS from it.'],"['aim study introduce formal framework analysis synthesis driver assistance system ', 'applies formal method verification stochastic human driver model built using cognitive architecture actr  bootstrap safety semiautonomous vehicle design provably correct advanced driver assistance system ', 'main contribution include integration probabilistic actr model formal analysis semiautonomous system abstraction technique enables finite representation large dimensional  continuous system form markov model ', 'effectiveness method illustrated several case study various condition ']","The aim of this study is to introduce a formal framework for analysis and synthesis of driver assistance systems., It applies formal methods to the verification of a stochastic human driver model built using the cognitive architecture ACT-R, and then bootstraps safety in semi-autonomous vehicles through the design of provably correct Advanced Driver Assistance Systems., The main contributions include the integration of probabilistic ACT-R models in the formal analysis of semi-autonomous systems and an abstraction technique that enables a finite representation of a large dimensional, continuous system in the form of a Markov model., The effectiveness of the method is illustrated in several case studies under various conditions.",6,5.777777777777778,18.0
528,"['In contrast to the older writing system of the 19th century, modern Hawaiian orthography employs characters for long vowels and glottal stops.', 'These extra characters account for about one-third of the phonemes in Hawaiian, so including them makes a big difference to reading comprehension and pronunciation.', 'However, transliterating between older and newer texts is a laborious task when performed manually.', 'We introduce two related methods to help solve this transliteration problem automatically, given that there were not enough data to train an end-to-end deep learning model.', 'One approach is implemented, end-to-end, using finite state transducers (FSTs).', 'The other is a hybrid deep learning approach which approximately composes an FST with a recurrent neural network (RNN).', 'We find that the hybrid approach outperforms the end-to-end FST by partitioning the original problem into one part that can be modelled by hand, using an FST, and into another part, which is easily solved by an RNN trained on the available data.']","[0, 0, 0, 0, 0, 1, 0]","[0.1904761791229248, 0.17777776718139648, 0.11428570747375488, 0.17391303181648254, 0.12903225421905518, 0.307692289352417, 0.178571417927742]",rkgj0tNfom,"['A novel, hybrid deep learning approach provides the best solution to a limited-data problem (which is important to the conservation of the Hawaiian language)']","['contrast older writing system 19th century  modern hawaiian orthography employ character long vowel glottal stop ', 'extra character account onethird phoneme hawaiian  including make big difference reading comprehension pronunciation ', 'however  transliterating older newer text laborious task performed manually ', 'introduce two related method help solve transliteration problem automatically  given enough data train endtoend deep learning model ', 'one approach implemented  endtoend  using finite state transducer  fsts  ', 'hybrid deep learning approach approximately composes fst recurrent neural network  rnn  ', 'find hybrid approach outperforms endtoend fst partitioning original problem one part modelled hand  using fst  another part  easily solved rnn trained available data ']","In contrast to the older writing system of the 19th century, modern Hawaiian orthography employs characters for long vowels and glottal stops., These extra characters account for about one-third of the phonemes in Hawaiian, so including them makes a big difference to reading comprehension and pronunciation., However, transliterating between older and newer texts is a laborious task when performed manually., We introduce two related methods to help solve this transliteration problem automatically, given that there were not enough data to train an end-to-end deep learning model., One approach is implemented, end-to-end, using finite state transducers (FSTs)., The other is a hybrid deep learning approach which approximately composes an FST with a recurrent neural network (RNN)., We find that the hybrid approach outperforms the end-to-end FST by partitioning the original problem into one part that can be modelled by hand, using an FST, and into another part, which is easily solved by an RNN trained on the available data.",16,5.443037974683544,9.875
529,"['In many real-world settings, a learning model must perform few-shot classification: learn to classify examples from unseen classes using only a few labeled examples per class.\n', 'Additionally, to be safely deployed, it should have the ability to detect out-of-distribution inputs: examples that do not belong to any of the classes.\n', 'While both few-shot classification and out-of-distribution detection are popular topics,\ntheir combination has not been studied.', 'In this work, we propose tasks for out-of-distribution detection in the few-shot setting and establish benchmark datasets, based on four popular few-shot classification datasets.  ', 'Then, we propose two new methods for this task and investigate their performance.\n', 'In sum, we establish baseline out-of-distribution detection results using standard metrics on new benchmark datasets and show improved results with our proposed methods.']","[0, 0, 0, 0, 0, 1]","[0.045454539358615875, 0.04878048226237297, 0.22857142984867096, 0.2790697515010834, 0.060606054961681366, 0.39024388790130615]",BygNAa4YPH,"['We quantitatively study out-of-distribution detection in few-shot setting, establish baseline results with ProtoNet, MAML, ABML, and improved upon them.', 'The paper proposes two new confidence scores which are more suitable for out-of-distribution detection of few-shot classification and shows that a distance metric-based approach improves performance.']","['many realworld setting  learning model must perform fewshot classification  learn classify example unseen class using labeled example per class ', 'additionally  safely deployed  ability detect outofdistribution input  example belong class ', 'fewshot classification outofdistribution detection popular topic  combination studied ', 'work  propose task outofdistribution detection fewshot setting establish benchmark datasets  based four popular fewshot classification datasets ', ' propose two new method task investigate performance ', 'sum  establish baseline outofdistribution detection result using standard metric new benchmark datasets show improved result proposed method ']","In many real-world settings, a learning model must perform few-shot classification: learn to classify examples from unseen classes using only a few labeled examples per class.
, Additionally, to be safely deployed, it should have the ability to detect out-of-distribution inputs: examples that do not belong to any of the classes.
, While both few-shot classification and out-of-distribution detection are popular topics,
their combination has not been studied., In this work, we propose tasks for out-of-distribution detection in the few-shot setting and establish benchmark datasets, based on four popular few-shot classification datasets.  , Then, we propose two new methods for this task and investigate their performance.
, In sum, we establish baseline out-of-distribution detection results using standard metrics on new benchmark datasets and show improved results with our proposed methods.",13,6.0,9.692307692307692
530,"['While modern  generative  models are able to synthesize high-fidelity, visually appealing images, successfully generating examples that are useful for recognition tasks remains an elusive goal.', 'To this end, our key insight is that the examples should be synthesized to recover classifier decision boundaries that would be learned from a large amount of real examples.', ""More concretely, we treat a classifier trained on synthetic examples as ''student'' and a classifier trained on real examples as ''teacher''."", 'By introducing knowledge distillation into a meta-learning framework, we encourage the generative model to produce examples in a way that enables the student classifier to mimic the behavior of the teacher.', 'To mitigate the potential gap between student and teacher classifiers, we further propose to distill the knowledge in a progressive manner, either by gradually strengthening the teacher or weakening the student.', 'We demonstrate the use of our model-agnostic distillation approach to deal with data scarcity, significantly improving few-shot learning performance on miniImageNet and ImageNet1K benchmarks.']","[1, 0, 0, 0, 0, 0]","[0.307692289352417, 0.04878048226237297, 0.0, 0.19512194395065308, 0.09756097197532654, 0.10256409645080566]",ByxV2kBYwB,"['This paper introduces progressive knowledge distillation for learning generative models that are recognition task oriented', 'This paper demonstrates easy-to-hard curriculum learning to train a generative model to improve few-shot classification.']","['modern generative model able synthesize highfidelity  visually appealing image  successfully generating example useful recognition task remains elusive goal ', 'end  key insight example synthesized recover classifier decision boundary would learned large amount real example ', 'concretely  treat classifier trained synthetic example  student  classifier trained real example  teacher  ', 'introducing knowledge distillation metalearning framework  encourage generative model produce example way enables student classifier mimic behavior teacher ', 'mitigate potential gap student teacher classifier  propose distill knowledge progressive manner  either gradually strengthening teacher weakening student ', 'demonstrate use modelagnostic distillation approach deal data scarcity  significantly improving fewshot learning performance miniimagenet imagenet1k benchmark ']","While modern  generative  models are able to synthesize high-fidelity, visually appealing images, successfully generating examples that are useful for recognition tasks remains an elusive goal., To this end, our key insight is that the examples should be synthesized to recover classifier decision boundaries that would be learned from a large amount of real examples., More concretely, we treat a classifier trained on synthetic examples as ''student'' and a classifier trained on real examples as ''teacher''., By introducing knowledge distillation into a meta-learning framework, we encourage the generative model to produce examples in a way that enables the student classifier to mimic the behavior of the teacher., To mitigate the potential gap between student and teacher classifiers, we further propose to distill the knowledge in a progressive manner, either by gradually strengthening the teacher or weakening the student., We demonstrate the use of our model-agnostic distillation approach to deal with data scarcity, significantly improving few-shot learning performance on miniImageNet and ImageNet1K benchmarks.",14,5.900621118012422,11.5
531,"['Deep neural networks provide state-of-the-art performance for many applications of interest.', 'Unfortunately they are known to be vulnerable to adversarial examples, formed by applying small but malicious perturbations to the original inputs.', 'Moreover, the perturbations can transfer across models: adversarial examples generated for a specific model will often mislead other unseen models.', 'Consequently  the adversary can leverage it to attack against the deployed black-box systems. \n', 'In this work, we demonstrate that the adversarial perturbation can be decomposed into two components: model-specific and data-dependent one, and it is the latter that mainly contributes to the transferability.', 'Motivated by this understanding, we propose to craft adversarial examples by utilizing the noise reduced gradient (NRG) which approximates the data-dependent component.', 'Experiments on various classification models trained on ImageNet demonstrates that the new approach enhances the transferability dramatically.', 'We also find that low-capacity models have more powerful attack capability than high-capacity counterparts, under the condition that they have comparable test performance.  ', 'These insights give rise to a principled manner to construct adversarial examples with high success rates and could potentially provide us guidance for designing effective defense approaches against black-box attacks.']","[0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.14814814925193787, 0.17142856121063232, 0.277777761220932, 0.06896550953388214, 0.1428571343421936, 0.3333333432674408, 0.19354838132858276, 0.10526315122842789, 0.17777776718139648]",ryvxcPeAb,"['We propose a new method for enhancing the transferability of adversarial examples by using the noise-reduced gradient.', 'This paper postulates that an adversarial perturbation consists of a model-specific and data-specific component, and that amplification of the latter is best suited for adversarial attacks.', 'This paper focuses on enhancing the transferability of adversarial examples from one model to another model.']","['deep neural network provide stateoftheart performance many application interest ', 'unfortunately known vulnerable adversarial example  formed applying small malicious perturbation original input ', 'moreover  perturbation transfer across model  adversarial example generated specific model often mislead unseen model ', 'consequently adversary leverage attack deployed blackbox system ', 'work  demonstrate adversarial perturbation decomposed two component  modelspecific datadependent one  latter mainly contributes transferability ', 'motivated understanding  propose craft adversarial example utilizing noise reduced gradient  nrg  approximates datadependent component ', 'experiment various classification model trained imagenet demonstrates new approach enhances transferability dramatically ', 'also find lowcapacity model powerful attack capability highcapacity counterpart  condition comparable test performance ', 'insight give rise principled manner construct adversarial example high success rate could potentially provide u guidance designing effective defense approach blackbox attack ']","Deep neural networks provide state-of-the-art performance for many applications of interest., Unfortunately they are known to be vulnerable to adversarial examples, formed by applying small but malicious perturbations to the original inputs., Moreover, the perturbations can transfer across models: adversarial examples generated for a specific model will often mislead other unseen models., Consequently  the adversary can leverage it to attack against the deployed black-box systems. 
, In this work, we demonstrate that the adversarial perturbation can be decomposed into two components: model-specific and data-dependent one, and it is the latter that mainly contributes to the transferability., Motivated by this understanding, we propose to craft adversarial examples by utilizing the noise reduced gradient (NRG) which approximates the data-dependent component., Experiments on various classification models trained on ImageNet demonstrates that the new approach enhances the transferability dramatically., We also find that low-capacity models have more powerful attack capability than high-capacity counterparts, under the condition that they have comparable test performance.  , These insights give rise to a principled manner to construct adversarial examples with high success rates and could potentially provide us guidance for designing effective defense approaches against black-box attacks.",15,6.422459893048129,12.466666666666667
532,"['We present the iterative two-pass decomposition flow to accelerate existing convolutional neural networks (CNNs).  ', 'The proposed rank selection algorithm can effectively determine the proper ranks of the target convolutional layers for the low rank approximation.', 'Our two-pass CP-decomposition helps prevent from the instability problem.', 'The iterative flow makes the decomposition of the deeper networks systematic.', 'The experiment results shows that VGG16 can be accelerated with a 6.2x measured speedup while the accuracy drop remains only 1.2%.\n']","[1, 0, 0, 0, 0]","[0.9032257795333862, 0.1764705777168274, 0.1599999964237213, 0.38461539149284363, 0.04999999701976776]",BkBCjzp7G,"['We present the iterative two-pass CP decomposition flow to effectively accelerate existing convolutional neural networks (CNNs).', 'The paper proposes a novel workflow for acceleration and compression of CNNs and also proposes a way to determine the target rank of each layer given the target overall acceleration. ', 'This paper addresses the problem of learning a low rank tensor filter operation for filtering layers in deep neural networks (DNNs). ']","['present iterative twopass decomposition flow accelerate existing convolutional neural network  cnns  ', 'proposed rank selection algorithm effectively determine proper rank target convolutional layer low rank approximation ', 'twopass cpdecomposition help prevent instability problem ', 'iterative flow make decomposition deeper network systematic ', 'experiment result show vgg16 accelerated 62x measured speedup accuracy drop remains 12  ']","We present the iterative two-pass decomposition flow to accelerate existing convolutional neural networks (CNNs).  , The proposed rank selection algorithm can effectively determine the proper ranks of the target convolutional layers for the low rank approximation., Our two-pass CP-decomposition helps prevent from the instability problem., The iterative flow makes the decomposition of the deeper networks systematic., The experiment results shows that VGG16 can be accelerated with a 6.2x measured speedup while the accuracy drop remains only 1.2%.
",5,6.171052631578948,15.2
533,"['We introduce LiPopt, a polynomial optimization framework for computing increasingly tighter upper bound on the Lipschitz constant of neural networks.', 'The underlying optimization problems boil down to either linear (LP) or semidefinite (SDP) programming.', 'We show how to use the sparse connectivity of a network, to significantly reduce the complexity of computation.', 'This is specially useful for convolutional as well as pruned neural networks.', 'We conduct experiments on networks with random weights as well as networks trained on MNIST, showing that in the particular case of the $\\ell_\\infty$-Lipschitz constant, our approach yields superior estimates as compared to other baselines available in the literature.\n']","[1, 0, 0, 0, 0]","[0.4000000059604645, 0.0, 0.1599999964237213, 0.0, 0.1395348757505417]",rJe4_xSFDB,"['LP-based upper bounds on the Lipschitz constant of Neural Networks', 'The authors study the problem of estimating the Lipschitz constant of a deep neural network with ELO activation function, formulating it as a polynomial optimisation problem.']","['introduce lipopt  polynomial optimization framework computing increasingly tighter upper bound lipschitz constant neural network ', 'underlying optimization problem boil either linear  lp  semidefinite  sdp  programming ', 'show use sparse connectivity network  significantly reduce complexity computation ', 'specially useful convolutional well pruned neural network ', 'conduct experiment network random weight well network trained mnist  showing particular case  ellinfty  lipschitz constant  approach yield superior estimate compared baseline available literature ']","We introduce LiPopt, a polynomial optimization framework for computing increasingly tighter upper bound on the Lipschitz constant of neural networks., The underlying optimization problems boil down to either linear (LP) or semidefinite (SDP) programming., We show how to use the sparse connectivity of a network, to significantly reduce the complexity of computation., This is specially useful for convolutional as well as pruned neural networks., We conduct experiments on networks with random weights as well as networks trained on MNIST, showing that in the particular case of the $\ell_\infty$-Lipschitz constant, our approach yields superior estimates as compared to other baselines available in the literature.
",9,5.883495145631068,11.444444444444445
534,"['Although few-shot learning research has advanced rapidly with the help of meta-learning, its practical usefulness is still limited because most of the researches assumed that all meta-training and meta-testing examples came from a single domain.', 'We propose a simple but effective way for few-shot classification in which a task distribution spans multiple domains including previously unseen ones during meta-training.\n', 'The key idea is to build a pool of embedding models which have their own metric spaces and to learn to select the best one for a particular task through multi-domain meta-learning.', 'This simplifies task-specific adaptation over a complex task distribution as a simple selection problem rather than modifying the model with a number of parameters at meta-testing time.', 'Inspired by common multi-task learning techniques, we let all models in the pool share a base network and add a separate modulator to each model to refine the base network in its own way.', 'This architecture allows the pool to maintain representational diversity and each model to have domain-invariant representation as well. \n', 'Experiments show that our selection scheme outperforms other few-shot classification algorithms when target tasks could come from many different domains.', 'They also reveal that aggregating outputs from all constituent models is effective for tasks from unseen domains showing the effectiveness of our framework.']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.12903225421905518, 0.3396226465702057, 0.20689654350280762, 0.3333333134651184, 0.24561403691768646, 0.12765957415103912, 0.16326530277729034, 0.07843136787414551]",S1xjJpNYvB,"['We address multi-domain few-shot classification by building multiple models to represent this complex task distribution in a collective way and simplifying task-specific adaptation as a selection problem from these pre-trained models.', 'This paper tackles few-shot classification with many different domains by building a pool of embedding models to capture domain-invariant and domain-specific features without a significant increase in the number of parameters.']","['although fewshot learning research advanced rapidly help metalearning  practical usefulness still limited research assumed metatraining metatesting example came single domain ', 'propose simple effective way fewshot classification task distribution span multiple domain including previously unseen one metatraining ', 'key idea build pool embedding model metric space learn select best one particular task multidomain metalearning ', 'simplifies taskspecific adaptation complex task distribution simple selection problem rather modifying model number parameter metatesting time ', 'inspired common multitask learning technique  let model pool share base network add separate modulator model refine base network way ', 'architecture allows pool maintain representational diversity model domaininvariant representation well ', 'experiment show selection scheme outperforms fewshot classification algorithm target task could come many different domain ', 'also reveal aggregating output constituent model effective task unseen domain showing effectiveness framework ']","Although few-shot learning research has advanced rapidly with the help of meta-learning, its practical usefulness is still limited because most of the researches assumed that all meta-training and meta-testing examples came from a single domain., We propose a simple but effective way for few-shot classification in which a task distribution spans multiple domains including previously unseen ones during meta-training.
, The key idea is to build a pool of embedding models which have their own metric spaces and to learn to select the best one for a particular task through multi-domain meta-learning., This simplifies task-specific adaptation over a complex task distribution as a simple selection problem rather than modifying the model with a number of parameters at meta-testing time., Inspired by common multi-task learning techniques, we let all models in the pool share a base network and add a separate modulator to each model to refine the base network in its own way., This architecture allows the pool to maintain representational diversity and each model to have domain-invariant representation as well. 
, Experiments show that our selection scheme outperforms other few-shot classification algorithms when target tasks could come from many different domains., They also reveal that aggregating outputs from all constituent models is effective for tasks from unseen domains showing the effectiveness of our framework.",10,5.666666666666667,21.3
535,"['Still in 2019, many scanned documents come into businesses in non-digital format.', 'Text to be extracted from real world documents is often nestled inside rich formatting, such as tabular structures or forms with fill-in-the-blank boxes or underlines whose ink often touches or even strikes through the ink of the text itself.', 'Such ink artifacts can severely interfere with the performance of recognition algorithms or other downstream processing tasks.', 'In this work, we propose DeepErase, a neural preprocessor to erase ink artifacts from text images.', 'We devise a method to programmatically augment text images with real artifacts, and use them to train a segmentation network in an weakly supervised manner.', 'In additional to high segmentation accuracy, we show that our cleansed images achieve a significant boost in downstream recognition accuracy by popular OCR software such as Tesseract 4.0.', 'We test DeepErase on out-of-distribution datasets (NIST SDB) of scanned IRS tax return forms and achieve double-digit improvements in recognition accuracy over baseline for both printed and handwritten text.']","[0, 0, 1, 0, 0, 0, 0]","[0.0, 0.07999999821186066, 0.1818181723356247, 0.1249999925494194, 0.0, 0.0, 0.045454539358615875]",SJgRf659Ur,"['Neural-based removal of document ink artifacts (underlines, smudges, etc.) using no manually annotated training data']","['still 2019  many scanned document come business nondigital format ', 'text extracted real world document often nestled inside rich formatting  tabular structure form fillintheblank box underline whose ink often touch even strike ink text ', 'ink artifact severely interfere performance recognition algorithm downstream processing task ', 'work  propose deeperase  neural preprocessor erase ink artifact text image ', 'devise method programmatically augment text image real artifact  use train segmentation network weakly supervised manner ', 'additional high segmentation accuracy  show cleansed image achieve significant boost downstream recognition accuracy popular ocr software tesseract 40 ', 'test deeperase outofdistribution datasets  nist sdb  scanned irs tax return form achieve doubledigit improvement recognition accuracy baseline printed handwritten text ']","Still in 2019, many scanned documents come into businesses in non-digital format., Text to be extracted from real world documents is often nestled inside rich formatting, such as tabular structures or forms with fill-in-the-blank boxes or underlines whose ink often touches or even strikes through the ink of the text itself., Such ink artifacts can severely interfere with the performance of recognition algorithms or other downstream processing tasks., In this work, we propose DeepErase, a neural preprocessor to erase ink artifacts from text images., We devise a method to programmatically augment text images with real artifacts, and use them to train a segmentation network in an weakly supervised manner., In additional to high segmentation accuracy, we show that our cleansed images achieve a significant boost in downstream recognition accuracy by popular OCR software such as Tesseract 4.0., We test DeepErase on out-of-distribution datasets (NIST SDB) of scanned IRS tax return forms and achieve double-digit improvements in recognition accuracy over baseline for both printed and handwritten text.",13,5.614457831325301,12.76923076923077
536,"['Black-box adversarial attacks require a large number of attempts before finding successful adversarial examples that are visually indistinguishable from the original input.', 'Current approaches relying on substitute model training, gradient estimation or genetic algorithms often require an excessive number of queries.', 'Therefore, they are not suitable for real-world systems where the maximum query number is limited due to cost.', 'We propose a query-efficient black-box attack which uses Bayesian optimisation in combination with Bayesian model selection to optimise over the adversarial perturbation and the optimal degree of search space dimension reduction.', 'We demonstrate empirically that our method can achieve comparable success rates with 2-5 times fewer queries compared to previous state-of-the-art black-box attacks.']","[0, 0, 0, 1, 0]","[0.15686273574829102, 0.08163265138864517, 0.0833333283662796, 0.9830508232116699, 0.1538461446762085]",Hkem-lrtvH,"['We propose a query-efficient black-box attack which uses Bayesian optimisation in combination with Bayesian model selection to optimise over the adversarial perturbation and the optimal degree of search space dimension reduction. ', 'The authors propose to use Bayesian optimization with a GP surrogate for adversarial image generation, by exploiting additive structure and using Bayesian model selection to determine an optimal dimensionality reduction.']","['blackbox adversarial attack require large number attempt finding successful adversarial example visually indistinguishable original input ', 'current approach relying substitute model training  gradient estimation genetic algorithm often require excessive number query ', 'therefore  suitable realworld system maximum query number limited due cost ', 'propose queryefficient blackbox attack us bayesian optimisation combination bayesian model selection optimise adversarial perturbation optimal degree search space dimension reduction ', 'demonstrate empirically method achieve comparable success rate 25 time fewer query compared previous stateoftheart blackbox attack ']","Black-box adversarial attacks require a large number of attempts before finding successful adversarial examples that are visually indistinguishable from the original input., Current approaches relying on substitute model training, gradient estimation or genetic algorithms often require an excessive number of queries., Therefore, they are not suitable for real-world systems where the maximum query number is limited due to cost., We propose a query-efficient black-box attack which uses Bayesian optimisation in combination with Bayesian model selection to optimise over the adversarial perturbation and the optimal degree of search space dimension reduction., We demonstrate empirically that our method can achieve comparable success rates with 2-5 times fewer queries compared to previous state-of-the-art black-box attacks.",7,6.348214285714286,16.0
537,"['Learning multimodal representations is a fundamentally complex research problem due to the presence of multiple heterogeneous sources of information.', 'Although the presence of multiple modalities provides additional valuable information, there are two key challenges to address when learning from multimodal data:', '1) models must learn the complex intra-modal and cross-modal interactions for prediction and', '2) models must be robust to unexpected missing or noisy modalities during testing.', 'In this paper, we propose to optimize for a joint generative-discriminative objective across multimodal data and labels.', 'We introduce a model that factorizes representations into two sets of independent factors: multimodal discriminative and modality-specific generative factors.', 'Multimodal discriminative factors are shared across all modalities and contain joint multimodal features required for discriminative tasks such as sentiment prediction.', 'Modality-specific generative factors are unique for each modality and contain the information required for generating data.', 'Experimental results show that our model is able to learn meaningful multimodal representations that achieve state-of-the-art or competitive performance on six multimodal datasets.', 'Our model demonstrates flexible generative capabilities by conditioning on independent factors and can reconstruct missing modalities without significantly impacting performance.', 'Lastly, we interpret our factorized representations to understand the interactions that influence multimodal learning.']","[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]","[0.24242423474788666, 0.1621621549129486, 0.14814814925193787, 0.0714285671710968, 0.3125, 0.4117647111415863, 0.17142856121063232, 0.13333332538604736, 0.3333333432674408, 0.11428570747375488, 0.3448275923728943]",rygqqsA9KX,"['We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.', ""This paper presents 'Multimodal Factorization model' that factorizes representations into shared multimodal discriminative factors and modality specific generative factors. ""]","['learning multimodal representation fundamentally complex research problem due presence multiple heterogeneous source information ', 'although presence multiple modality provides additional valuable information  two key challenge address learning multimodal data ', '1  model must learn complex intramodal crossmodal interaction prediction', '2  model must robust unexpected missing noisy modality testing ', 'paper  propose optimize joint generativediscriminative objective across multimodal data label ', 'introduce model factorizes representation two set independent factor  multimodal discriminative modalityspecific generative factor ', 'multimodal discriminative factor shared across modality contain joint multimodal feature required discriminative task sentiment prediction ', 'modalityspecific generative factor unique modality contain information required generating data ', 'experimental result show model able learn meaningful multimodal representation achieve stateoftheart competitive performance six multimodal datasets ', 'model demonstrates flexible generative capability conditioning independent factor reconstruct missing modality without significantly impacting performance ', 'lastly  interpret factorized representation understand interaction influence multimodal learning ']","Learning multimodal representations is a fundamentally complex research problem due to the presence of multiple heterogeneous sources of information., Although the presence of multiple modalities provides additional valuable information, there are two key challenges to address when learning from multimodal data:, 1) models must learn the complex intra-modal and cross-modal interactions for prediction and, 2) models must be robust to unexpected missing or noisy modalities during testing., In this paper, we propose to optimize for a joint generative-discriminative objective across multimodal data and labels., We introduce a model that factorizes representations into two sets of independent factors: multimodal discriminative and modality-specific generative factors., Multimodal discriminative factors are shared across all modalities and contain joint multimodal features required for discriminative tasks such as sentiment prediction., Modality-specific generative factors are unique for each modality and contain the information required for generating data., Experimental results show that our model is able to learn meaningful multimodal representations that achieve state-of-the-art or competitive performance on six multimodal datasets., Our model demonstrates flexible generative capabilities by conditioning on independent factors and can reconstruct missing modalities without significantly impacting performance., Lastly, we interpret our factorized representations to understand the interactions that influence multimodal learning.",14,6.807106598984771,14.071428571428571
538,"['The successful application of flexible, general learning algorithms to real-world robotics applications is often limited by their poor data-efficiency.', 'To address the challenge, domains with more than one dominant task of interest encourage the sharing of information across tasks to limit required experiment time.', 'To this end, we investigate compositional inductive biases in the form of hierarchical policies as a mechanism for knowledge transfer across tasks in reinforcement learning (RL).', 'We demonstrate that this type of hierarchy enables positive transfer while mitigating negative interference.', 'Furthermore, we demonstrate the benefits of additional incentives to efficiently decompose task solutions.', 'Our experiments show that these incentives are naturally given in multitask learning and can be easily introduced for single objectives.', 'We design an RL algorithm that enables stable and fast learning of structured policies and the effective reuse of both behavior components and transition data across tasks in an off-policy setting.', 'Finally, we evaluate our algorithm in simulated environments as well as physical robot experiments and  demonstrate substantial improvements in data data-efficiency over competitive baselines.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.0416666604578495, 0.11538460850715637, 0.25925925374031067, 0.1395348757505417, 0.0952380895614624, 0.20408162474632263, 0.2142857164144516, 0.23529411852359772]",H1lTRJBtwB,"['We develop a hierarchical, actor-critic algorithm for compositional transfer by sharing policy components and demonstrate component specialization and related direct benefits in multitask domains as well as its adaptation for single tasks.', 'A combination of different learning techniques for acquiring structure and learning with asymmetric data, used to train an HRL policy.', ""The authors introduce a hierarchical policy structure for use in both single task and multitask reinforcement learning, and assess the structure's usefulness on complex robotic tasks.""]","['successful application flexible  general learning algorithm realworld robotics application often limited poor dataefficiency ', 'address challenge  domain one dominant task interest encourage sharing information across task limit required experiment time ', 'end  investigate compositional inductive bias form hierarchical policy mechanism knowledge transfer across task reinforcement learning  rl  ', 'demonstrate type hierarchy enables positive transfer mitigating negative interference ', 'furthermore  demonstrate benefit additional incentive efficiently decompose task solution ', 'experiment show incentive naturally given multitask learning easily introduced single objective ', 'design rl algorithm enables stable fast learning structured policy effective reuse behavior component transition data across task offpolicy setting ', 'finally  evaluate algorithm simulated environment well physical robot experiment demonstrate substantial improvement data dataefficiency competitive baseline ']","The successful application of flexible, general learning algorithms to real-world robotics applications is often limited by their poor data-efficiency., To address the challenge, domains with more than one dominant task of interest encourage the sharing of information across tasks to limit required experiment time., To this end, we investigate compositional inductive biases in the form of hierarchical policies as a mechanism for knowledge transfer across tasks in reinforcement learning (RL)., We demonstrate that this type of hierarchy enables positive transfer while mitigating negative interference., Furthermore, we demonstrate the benefits of additional incentives to efficiently decompose task solutions., Our experiments show that these incentives are naturally given in multitask learning and can be easily introduced for single objectives., We design an RL algorithm that enables stable and fast learning of structured policies and the effective reuse of both behavior components and transition data across tasks in an off-policy setting., Finally, we evaluate our algorithm in simulated environments as well as physical robot experiments and  demonstrate substantial improvements in data data-efficiency over competitive baselines.",13,6.1686046511627906,13.23076923076923
539,"['In this paper, we study the representational power of deep neural networks (DNN) that belong to the family of piecewise-linear (PWL) functions, based on PWL activation units such as rectifier or maxout.', 'We investigate the complexity of such networks by studying the number of linear regions of the PWL function.', 'Typically, a PWL function from a DNN can be seen as a large family of linear functions acting on millions of such regions.', 'We directly build upon the work of Montufar et al. (2014), Montufar (2017), and Raghu et al. (2017) by refining the upper and lower bounds on the number of linear regions for rectified and maxout networks.', 'In addition to achieving tighter bounds, we also develop a novel method to perform exact numeration or counting of the number of linear regions with a mixed-integer linear formulation that maps the input space to output.', 'We use this new capability to visualize how the number of linear regions change while training DNNs.  ']","[0, 0, 0, 1, 0, 0]","[0.17777776718139648, 0.48275861144065857, 0.17142856121063232, 0.5116279125213623, 0.2222222238779068, 0.3636363446712494]",Sy-tszZRZ,"['We empirically count the number of linear regions of rectifier networks and refine upper and lower bounds.', 'This paper presents improved bounds for counting the number of linear regions in ReLU networks.']","['paper  study representational power deep neural network  dnn  belong family piecewiselinear  pwl  function  based pwl activation unit rectifier maxout ', 'investigate complexity network studying number linear region pwl function ', 'typically  pwl function dnn seen large family linear function acting million region ', 'directly build upon work montufar et al   2014   montufar  2017   raghu et al   2017  refining upper lower bound number linear region rectified maxout network ', 'addition achieving tighter bound  also develop novel method perform exact numeration counting number linear region mixedinteger linear formulation map input space output ', 'use new capability visualize number linear region change training dnns ']","In this paper, we study the representational power of deep neural networks (DNN) that belong to the family of piecewise-linear (PWL) functions, based on PWL activation units such as rectifier or maxout., We investigate the complexity of such networks by studying the number of linear regions of the PWL function., Typically, a PWL function from a DNN can be seen as a large family of linear functions acting on millions of such regions., We directly build upon the work of Montufar et al. (2014), Montufar (2017), and Raghu et al. (2017) by refining the upper and lower bounds on the number of linear regions for rectified and maxout networks., In addition to achieving tighter bounds, we also develop a novel method to perform exact numeration or counting of the number of linear regions with a mixed-integer linear formulation that maps the input space to output., We use this new capability to visualize how the number of linear regions change while training DNNs.  ",12,4.919753086419753,11.571428571428571
540,"['Convolutional neural networks memorize part of their training data, which is why strategies such as data augmentation and drop-out are employed to mitigate over- fitting.', 'This paper considers the related question of membership inference, where the goal is to determine if an image was used during training.', 'We con- sider membership tests over either ensembles of samples or individual samples.\n', 'First, we show how to detect if a dataset was used to train a model, and in particular whether some validation images were used at train time.', 'Then, we introduce a new approach to infer membership when a few of the top layers are not available or have been fine-tuned, and show that lower layers still carry information about the training samples.', 'To support our findings, we conduct large-scale experiments on Imagenet and subsets of YFCC-100M with modern architectures such as VGG and Resnet.\n']","[0, 0, 0, 0, 1, 0]","[0.1249999925494194, 0.1818181723356247, 0.1666666567325592, 0.17391303181648254, 0.290909081697464, 0.17777776718139648]",B1lwSsC5KX,"['We analyze the memorization properties by a convnet of the training set and propose several use-cases where we can extract some information about the training set. ', 'Illuminates the generalization/memorization properties of large and deep ConvNets and tries to develop procedures related to identifying whether an input to a trained ConvNet has actually been used to train the network.']","['convolutional neural network memorize part training data  strategy data augmentation dropout employed mitigate fitting ', 'paper considers related question  membership inference   goal determine image used training ', 'con sider membership test either ensemble sample individual sample ', 'first  show detect dataset used train model  particular whether validation image used train time ', ' introduce new approach infer membership top layer available finetuned  show lower layer still carry information training sample ', 'support finding  conduct largescale experiment imagenet subset yfcc100m modern architecture vgg resnet ']","Convolutional neural networks memorize part of their training data, which is why strategies such as data augmentation and drop-out are employed to mitigate over- fitting., This paper considers the related question of membership inference, where the goal is to determine if an image was used during training., We con- sider membership tests over either ensembles of samples or individual samples.
, First, we show how to detect if a dataset was used to train a model, and in particular whether some validation images were used at train time., Then, we introduce a new approach to infer membership when a few of the top layers are not available or have been fine-tuned, and show that lower layers still carry information about the training samples., To support our findings, we conduct large-scale experiments on Imagenet and subsets of YFCC-100M with modern architectures such as VGG and Resnet.
",13,5.138888888888889,11.076923076923077
541,"['While Generative Adversarial Networks (GANs) have empirically produced impressive results on learning complex real-world distributions, recent works have shown that they suffer from lack of diversity or mode collapse.', 'The theoretical work of Arora et al. (2017a) suggests a dilemma about GANs statistical properties: powerful discriminators cause overfitting, whereas weak discriminators cannot detect mode collapse.\n', 'By contrast, we show in this paper that GANs can in principle learn distributions in Wasserstein distance (or KL-divergence in many cases) with polynomial sample complexity, if the discriminator class has strong distinguishing power against the particular generator class (instead of against all possible generators).', 'For various generator classes such as mixture of Gaussians, exponential families, and invertible and injective neural networks generators, we design corresponding discriminators (which are often neural nets of specific architectures) such that the Integral Probability Metric (IPM) induced by the discriminators can provably approximate the Wasserstein distance and/or KL-divergence.', 'This implies that if the training is successful, then the learned distribution is close to the true distribution in Wasserstein distance or KL divergence, and thus cannot drop modes.', 'Our preliminary experiments show that on synthetic datasets the test IPM is well correlated with KL divergence or the Wasserstein distance, indicating that the lack of diversity in GANs may be caused by the sub-optimality in optimization instead of statistical inefficiency.']","[0, 0, 1, 0, 0, 0]","[0.0, 0.0, 0.5666666626930237, 0.1269841194152832, 0.21739129722118378, 0.1428571343421936]",rJfW5oA5KQ,"['GANs can in principle learn distributions sample-efficiently, if the discriminator class is compact and has strong distinguishing power against the particular generator class.', 'Proposes the notion of restricted approximability, and provides a sample complexity bound, polynomial in the dimension, which is useful in investigating lack of diversity in GANs.', 'Analyzes that the Integral Probability Metric can be a good approximation of Wasserstein distance under some mild assumptions.']","['generative adversarial network  gans  empirically produced impressive result learning complex realworld distribution  recent work shown suffer lack diversity mode collapse ', 'theoretical work arora et al   2017a  suggests dilemma gans  statistical property  powerful discriminator cause overfitting  whereas weak discriminator detect mode collapse ', 'contrast  show paper gans principle learn distribution wasserstein distance  kldivergence many case  polynomial sample complexity  discriminator class strong distinguishing power particular generator class  instead possible generator  ', 'various generator class mixture gaussians  exponential family  invertible injective neural network generator  design corresponding discriminator  often neural net specific architecture  integral probability metric  ipm  induced discriminator provably approximate wasserstein distance andor kldivergence ', 'implies training successful  learned distribution close true distribution wasserstein distance kl divergence  thus drop mode ', 'preliminary experiment show synthetic datasets test ipm well correlated kl divergence wasserstein distance  indicating lack diversity gans may caused suboptimality optimization instead statistical inefficiency ']","While Generative Adversarial Networks (GANs) have empirically produced impressive results on learning complex real-world distributions, recent works have shown that they suffer from lack of diversity or mode collapse., The theoretical work of Arora et al. (2017a) suggests a dilemma about GANs statistical properties: powerful discriminators cause overfitting, whereas weak discriminators cannot detect mode collapse.
, By contrast, we show in this paper that GANs can in principle learn distributions in Wasserstein distance (or KL-divergence in many cases) with polynomial sample complexity, if the discriminator class has strong distinguishing power against the particular generator class (instead of against all possible generators)., For various generator classes such as mixture of Gaussians, exponential families, and invertible and injective neural networks generators, we design corresponding discriminators (which are often neural nets of specific architectures) such that the Integral Probability Metric (IPM) induced by the discriminators can provably approximate the Wasserstein distance and/or KL-divergence., This implies that if the training is successful, then the learned distribution is close to the true distribution in Wasserstein distance or KL divergence, and thus cannot drop modes., Our preliminary experiments show that on synthetic datasets the test IPM is well correlated with KL divergence or the Wasserstein distance, indicating that the lack of diversity in GANs may be caused by the sub-optimality in optimization instead of statistical inefficiency.",16,6.159817351598173,12.882352941176471
542,"['Understanding the optimization trajectory is critical to understand training of deep neural networks.', 'We show how the hyperparameters of stochastic gradient descent influence the covariance of the gradients (K) and the Hessian of the training loss (H) along this trajectory.', 'Based on a theoretical model, we predict that using a high learning rate or a small batch size in the early phase of training leads SGD to regions of the parameter space with (1) reduced spectral norm of K, and (2) improved conditioning of K and H. We show that the point on the trajectory after which these effects hold, which we refer to as the break-even point, is reached early during training.', 'We demonstrate these effects empirically for a range of deep neural networks applied to multiple different tasks.', 'Finally, we apply our analysis to networks with batch normalization (BN) layers and find that it is necessary to use a high learning rate to achieve loss smoothing effects attributed previously to BN alone.']","[1, 0, 0, 0, 0]","[0.4848484694957733, 0.19512194395065308, 0.21052631735801697, 0.2702702581882477, 0.07843136787414551]",r1g87C4KwB,"['In the early phase of training of deep neural networks there exists a ""break-even point"" which determines properties of the entire optimization trajectory.', 'This work analyzes the optimization of deep neural networks by considering how the batch size and step-size hyper-parameters modify learning trajectories.']","['understanding optimization trajectory critical understand training deep neural network ', 'show hyperparameters stochastic gradient descent influence covariance gradient  k  hessian training loss  h  along trajectory ', 'based theoretical model  predict using high learning rate small batch size early phase training lead sgd region parameter space  1  reduced spectral norm k   2  improved conditioning k h show point trajectory effect hold  refer breakeven point  reached early training ', 'demonstrate effect empirically range deep neural network applied multiple different task ', 'finally  apply analysis network batch normalization  bn  layer find necessary use high learning rate achieve loss smoothing effect attributed previously bn alone ']","Understanding the optimization trajectory is critical to understand training of deep neural networks., We show how the hyperparameters of stochastic gradient descent influence the covariance of the gradients (K) and the Hessian of the training loss (H) along this trajectory., Based on a theoretical model, we predict that using a high learning rate or a small batch size in the early phase of training leads SGD to regions of the parameter space with (1) reduced spectral norm of K, and (2) improved conditioning of K and H. We show that the point on the trajectory after which these effects hold, which we refer to as the break-even point, is reached early during training., We demonstrate these effects empirically for a range of deep neural networks applied to multiple different tasks., Finally, we apply our analysis to networks with batch normalization (BN) layers and find that it is necessary to use a high learning rate to achieve loss smoothing effects attributed previously to BN alone.",10,5.036585365853658,16.4
543,"['Graph Convolution Network (GCN) has been recognized as one of the most effective graph models for semi-supervised learning, but it extracts merely the first-order or few-order neighborhood information through information propagation, which suffers performance drop-off for deeper structure.', 'Existing approaches that deal with the higher-order neighbors tend to take advantage of adjacency matrix power.', 'In this paper, we assume a seemly trivial condition that the higher-order neighborhood information may be similar to that of the first-order neighbors.', 'Accordingly, we present an unsupervised approach to describe such similarities and learn the weight matrices of higher-order neighbors automatically through Lasso that minimizes the feature loss between the first-order and higher-order neighbors, based on which we formulate the new convolutional filter for GCN to learn the better node representations.', 'Our model, called higher-order weighted GCN (HWGCN), has achieved the state-of-the-art results on a number of node classification tasks over Cora, Citeseer and Pubmed datasets.']","[0, 0, 1, 0, 0]","[0.11764705181121826, 0.1249999925494194, 0.21621620655059814, 0.2142857164144516, 0.09756097197532654]",HylwpaNKPB,"['We propose HWGCN to mix the relevant neighborhood information at different orders to better learn node representations.', 'The authors propose a variant of GCN, HWGCN, to consider convolution beyond 1-step neighbors, which is comparable to state-of-the-art methods.']","['graph convolution network  gcn  recognized one effective graph model semisupervised learning  extract merely firstorder feworder neighborhood information information propagation  suffers performance dropoff deeper structure ', 'existing approach deal higherorder neighbor tend take advantage adjacency matrix power ', 'paper  assume seemly trivial condition higherorder neighborhood information may similar firstorder neighbor ', 'accordingly  present unsupervised approach describe similarity learn weight matrix higherorder neighbor automatically lasso minimizes feature loss firstorder higherorder neighbor  based formulate new convolutional filter gcn learn better node representation ', 'model  called higherorder weighted gcn  hwgcn   achieved stateoftheart result number node classification task cora  citeseer pubmed datasets ']","Graph Convolution Network (GCN) has been recognized as one of the most effective graph models for semi-supervised learning, but it extracts merely the first-order or few-order neighborhood information through information propagation, which suffers performance drop-off for deeper structure., Existing approaches that deal with the higher-order neighbors tend to take advantage of adjacency matrix power., In this paper, we assume a seemly trivial condition that the higher-order neighborhood information may be similar to that of the first-order neighbors., Accordingly, we present an unsupervised approach to describe such similarities and learn the weight matrices of higher-order neighbors automatically through Lasso that minimizes the feature loss between the first-order and higher-order neighbors, based on which we formulate the new convolutional filter for GCN to learn the better node representations., Our model, called higher-order weighted GCN (HWGCN), has achieved the state-of-the-art results on a number of node classification tasks over Cora, Citeseer and Pubmed datasets.",13,6.139072847682119,11.615384615384615
544,"['The performance of deep neural networks is often attributed to their automated, task-related feature construction.', 'It remains an open question, though, why this leads to solutions with good generalization, even in cases where the number of parameters is larger than the number of samples.', 'Back in the 90s, Hochreiter and Schmidhuber observed that flatness of the loss surface around a local minimum correlates with low generalization error.', 'For several flatness measures, this correlation has been empirically validated.', 'However, it has recently been shown that existing measures of flatness cannot theoretically be related to generalization: if a network uses ReLU activations, the network function can be reparameterized without changing its output in such a way that flatness is changed almost arbitrarily.', 'This paper proposes a natural modification of existing flatness measures that results in invariance to reparameterization.', 'The proposed measures imply a robustness of the network to changes in the input and the hidden layers.', 'Connecting this feature robustness to generalization leads to a generalized definition of the representativeness of data.', 'With this, the generalization error of a model trained on representative data can be bounded by its feature robustness which depends on our novel flatness measure.']","[0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.31111109256744385, 0.178571417927742, 0.38461539149284363, 0.04999999701976776, 0.1764705777168274, 0.17391303181648254, 0.260869562625885, 0.3181818127632141, 0.3636363446712494]",rJxFpp4Fvr,"['We introduce a novel measure of flatness at local minima of the loss surface of deep neural networks which is invariant with respect to layer-wise reparameterizations and we connect flatness to feature robustness and generalization.', ""The authors propose a notion of feature robustness which is invariant with respect to rescaling the weight and discuss the notion's relationship to generalization."", 'This paper defines a notion of feature-robustness and combines it with epsilon representativeness of a function to describe a connection between flatness of minima and generalization in deep neural networks.']","['performance deep neural network often attributed automated  taskrelated feature construction ', 'remains open question  though  lead solution good generalization  even case number parameter larger number sample ', 'back 90  hochreiter schmidhuber observed flatness loss surface around local minimum correlate low generalization error ', 'several flatness measure  correlation empirically validated ', 'however  recently shown existing measure flatness theoretically related generalization  network us relu activation  network function reparameterized without changing output way flatness changed almost arbitrarily ', 'paper proposes natural modification existing flatness measure result invariance reparameterization ', 'proposed measure imply robustness network change input hidden layer ', 'connecting feature robustness generalization lead generalized definition representativeness data ', ' generalization error model trained representative data bounded feature robustness depends novel flatness measure ']","The performance of deep neural networks is often attributed to their automated, task-related feature construction., It remains an open question, though, why this leads to solutions with good generalization, even in cases where the number of parameters is larger than the number of samples., Back in the 90s, Hochreiter and Schmidhuber observed that flatness of the loss surface around a local minimum correlates with low generalization error., For several flatness measures, this correlation has been empirically validated., However, it has recently been shown that existing measures of flatness cannot theoretically be related to generalization: if a network uses ReLU activations, the network function can be reparameterized without changing its output in such a way that flatness is changed almost arbitrarily., This paper proposes a natural modification of existing flatness measures that results in invariance to reparameterization., The proposed measures imply a robustness of the network to changes in the input and the hidden layers., Connecting this feature robustness to generalization leads to a generalized definition of the representativeness of data., With this, the generalization error of a model trained on representative data can be bounded by its feature robustness which depends on our novel flatness measure.",18,5.698979591836735,10.88888888888889
545,"['Bayesian methods have been successfully applied to sparsify weights of neural networks and to remove structure units from the networks, e.', 'g.', 'neurons.', 'We apply and further develop this approach for gated recurrent architectures.', 'Specifically, in addition to sparsification of individual weights and neurons, we propose to sparsify preactivations of gates and information flow in LSTM.', 'It makes some gates and information flow components constant, speeds up forward pass and improves compression.', 'Moreover, the resulting structure of gate sparsity is interpretable and depends on the task.']","[0, 0, 1, 0, 0, 0, 0]","[0.25, 0.12903225421905518, 0.5789473652839661, 0.22857142984867096, 0.24242423474788666]",ByMQgZHYoX,"['We propose to sparsify preactivations of gates and information flow in LSTM to make them constant and boost the neuron sparsity level', 'This paper proposed a sparsification method for recurrent neural networks by eliminating neurons with zero preactivations to obtain compact networks.']","['bayesian method successfully applied sparsify weight neural network remove structure unit network  e ', 'g ', 'neuron ', 'apply develop approach gated recurrent architecture ', 'specifically  addition sparsification individual weight neuron  propose sparsify preactivations gate information flow lstm ', 'make gate information flow component constant  speed forward pas improves compression ', 'moreover  resulting structure gate sparsity interpretable depends task ']","Bayesian methods have been successfully applied to sparsify weights of neural networks and to remove structure units from the networks, e., g., neurons., We apply and further develop this approach for gated recurrent architectures., Specifically, in addition to sparsification of individual weights and neurons, we propose to sparsify preactivations of gates and information flow in LSTM., It makes some gates and information flow components constant, speeds up forward pass and improves compression., Moreover, the resulting structure of gate sparsity is interpretable and depends on the task.",12,5.790697674418604,7.166666666666667
546,"['Improving the accuracy of numerical methods remains a central challenge in many disciplines and is especially important for nonlinear simulation problems.', 'A representative example of such problems is fluid flow, which has been thoroughly studied to arrive at efficient simulations of complex flow phenomena.', 'This paper presents a data-driven approach that learns to improve the accuracy of numerical solvers.', 'The proposed method utilizes an advanced numerical scheme with a fine simulation resolution to acquire reference data.', 'We, then, employ a neural network that infers a correction to move a coarse thus quickly obtainable result closer to the reference data.', 'We provide insights into the targeted learning problem with different learning approaches: fully supervised learning methods with a naive and an optimized data acquisition as well as an unsupervised learning method with a differentiable Navier-Stokes solver.', 'While our approach is very general and applicable to arbitrary partial differential equation models, we specifically highlight gains in accuracy for fluid flow simulations.']","[0, 0, 1, 0, 0, 0, 0]","[0.060606054961681366, 0.05882352590560913, 0.29629629850387573, 0.13793103396892548, 0.25, 0.09999999403953552, 0.277777761220932]",rketraEtPr,"['We introduce a neural network approach to assist partial differential equation solvers.', 'The authors aim at improving the accuracy of numerical solvers by training a neural network on simulated reference data which corrects the numerical solver.']","['improving accuracy numerical method remains central challenge many discipline especially important nonlinear simulation problem ', 'representative example problem fluid flow  thoroughly studied arrive efficient simulation complex flow phenomenon ', 'paper present datadriven approach learns improve accuracy numerical solver ', 'proposed method utilizes advanced numerical scheme fine simulation resolution acquire reference data ', '  employ neural network infers correction move coarse thus quickly obtainable result closer reference data ', 'provide insight targeted learning problem different learning approach  fully supervised learning method naive optimized data acquisition well unsupervised learning method differentiable navierstokes solver ', 'approach general applicable arbitrary partial differential equation model  specifically highlight gain accuracy fluid flow simulation ']","Improving the accuracy of numerical methods remains a central challenge in many disciplines and is especially important for nonlinear simulation problems., A representative example of such problems is fluid flow, which has been thoroughly studied to arrive at efficient simulations of complex flow phenomena., This paper presents a data-driven approach that learns to improve the accuracy of numerical solvers., The proposed method utilizes an advanced numerical scheme with a fine simulation resolution to acquire reference data., We, then, employ a neural network that infers a correction to move a coarse thus quickly obtainable result closer to the reference data., We provide insights into the targeted learning problem with different learning approaches: fully supervised learning methods with a naive and an optimized data acquisition as well as an unsupervised learning method with a differentiable Navier-Stokes solver., While our approach is very general and applicable to arbitrary partial differential equation models, we specifically highlight gains in accuracy for fluid flow simulations.",11,5.8742138364779874,14.454545454545455
547,"['A patients health information is generally fragmented across silos.', 'Though it is technically feasible to unite data for analysis in a manner that underpins a rapid learning healthcare system, privacy concerns and regulatory barriers limit data centralization.', 'Machine learning can be conducted in a federated manner on patient datasets with the same set of variables, but separated across sites of care.', 'But federated learning cannot handle the situation where different data types for a given\n', 'patient are separated vertically across different organizations.', 'We call methods that enable machine learning model training on data separated by two or more degrees confederated machine learning.', 'We built and evaluated a confederated machine\nlearning', 'model to stratify the risk of accidental falls among the elderly.']","[0, 0, 0, 0, 0, 0, 1, 0]","[0.0, 0.25, 0.1621621549129486, 0.2142857164144516, 0.1904761791229248, 0.3030303120613098, 0.3636363446712494, 0.0833333283662796]",Hye00pVtPS,"['a confederated learning method that train model from horizontally and vertically separated medical data ', 'A ""confederated"" machine learning method that learns across divides in medical data separated both horizontally and vertically.']","['patient  health information generally fragmented across silo ', 'though technically feasible unite data analysis manner underpins rapid learning healthcare system  privacy concern regulatory barrier limit data centralization ', 'machine learning conducted federated manner patient datasets set variable  separated across site care ', 'federated learning handle situation different data type given', 'patient separated vertically across different organization ', 'call method enable machine learning model training data separated two degree  confederated machine learning  ', 'built evaluated confederated machine learning', 'model stratify risk accidental fall among elderly ']","A patients health information is generally fragmented across silos., Though it is technically feasible to unite data for analysis in a manner that underpins a rapid learning healthcare system, privacy concerns and regulatory barriers limit data centralization., Machine learning can be conducted in a federated manner on patient datasets with the same set of variables, but separated across sites of care., But federated learning cannot handle the situation where different data types for a given
, patient are separated vertically across different organizations., We call methods that enable machine learning model training on data separated by two or more degrees confederated machine learning., We built and evaluated a confederated machine
learning, model to stratify the risk of accidental falls among the elderly.",10,5.7190082644628095,12.1
548,"['Existing neural networks are vulnerable to ""adversarial examples""---created by adding maliciously designed small perturbations in inputs to induce a misclassification by the networks.', 'The most investigated defense strategy is adversarial training which augments training data with adversarial examples.', 'However, applying single-step adversaries in adversarial training does not support the robustness of the networks, instead, they will even make the networks to be overfitted.', 'In contrast to the single-step, multi-step training results in the state-of-the-art performance on MNIST and CIFAR10, yet it needs a massive amount of time.', 'Therefore, we propose a method, Stochastic Quantized Activation (SQA) that solves overfitting problems in single-step adversarial training and fastly achieves the robustness comparable to the multi-step.', 'SQA attenuates the adversarial effects by providing random selectivity to activation functions and allows the network to learn robustness with only single-step training.', 'Throughout the experiment, our method demonstrates the state-of-the-art robustness against one of the strongest white-box attacks as PGD training, but with much less computational cost.', 'Finally, we visualize the learning process of the network with SQA to handle strong adversaries, which is different from existing methods.']","[0, 0, 0, 0, 1, 0, 0, 0]","[0.1428571343421936, 0.11428570747375488, 0.2666666507720947, 0.2666666507720947, 0.7659574151039124, 0.2790697515010834, 0.08888888359069824, 0.0952380895614624]",ryxeB30cYX,"['This paper proposes Stochastic Quantized Activation that solves overfitting problems in FGSM adversarial training and fastly achieves the robustness comparable to multi-step training.', 'The paper proposes a model to improve adversarial training by introducing random perturbations in the activations of one of the hidden layers']","['existing neural network vulnerable  adversarial example   created adding maliciously designed small perturbation input induce misclassification network ', 'investigated defense strategy adversarial training augments training data adversarial example ', 'however  applying singlestep adversary adversarial training support robustness network  instead  even make network overfitted ', 'contrast singlestep  multistep training result stateoftheart performance mnist cifar10  yet need massive amount time ', 'therefore  propose method  stochastic quantized activation  sqa  solves overfitting problem singlestep adversarial training fastly achieves robustness comparable multistep ', 'sqa attenuates adversarial effect providing random selectivity activation function allows network learn robustness singlestep training ', 'throughout experiment  method demonstrates stateoftheart robustness one strongest whitebox attack pgd training  much le computational cost ', 'finally  visualize learning process network sqa handle strong adversary  different existing method ']","Existing neural networks are vulnerable to ""adversarial examples""---created by adding maliciously designed small perturbations in inputs to induce a misclassification by the networks., The most investigated defense strategy is adversarial training which augments training data with adversarial examples., However, applying single-step adversaries in adversarial training does not support the robustness of the networks, instead, they will even make the networks to be overfitted., In contrast to the single-step, multi-step training results in the state-of-the-art performance on MNIST and CIFAR10, yet it needs a massive amount of time., Therefore, we propose a method, Stochastic Quantized Activation (SQA) that solves overfitting problems in single-step adversarial training and fastly achieves the robustness comparable to the multi-step., SQA attenuates the adversarial effects by providing random selectivity to activation functions and allows the network to learn robustness with only single-step training., Throughout the experiment, our method demonstrates the state-of-the-art robustness against one of the strongest white-box attacks as PGD training, but with much less computational cost., Finally, we visualize the learning process of the network with SQA to handle strong adversaries, which is different from existing methods.",19,6.269230769230769,9.578947368421053
549,"['Neural activity is highly variable in response to repeated stimuli.', 'We used an open dataset, the Allen Brain Observatory, to quantify the distribution of responses to repeated natural movie presentations.', 'A large fraction of responses are best fit by log-normal distributions or Gaussian mixtures with two components.', 'These distributions are similar to those from units in deep neural networks with dropout.', 'Using a separate set of electrophysiological recordings, we constructed a population coupling model as a control for state-dependent activity fluctuations and found that the model residuals also show non-Gaussian distributions.', 'We then analyzed responses across trials from multiple sections of different movie clips and observed that the noise in cortex aligns better with in-clip versus out-of-clip stimulus variations.', 'We argue that noise is useful for generalization when it moves along representations of different exemplars in-class, similar to the structure of cortical noise.']","[0, 0, 0, 0, 0, 0, 1]","[0.06451612710952759, 0.1538461446762085, 0.10526315122842789, 0.05714285373687744, 0.1249999925494194, 0.3265306055545807, 0.41860464215278625]",S1gc4XF8Lr,['We study the structure of noise in the brain and find it may help generalization by moving representations along in-class stimulus variations.'],"['neural activity highly variable response repeated stimulus ', 'used open dataset  allen brain observatory  quantify distribution response repeated natural movie presentation ', 'large fraction response best fit lognormal distribution gaussian mixture two component ', 'distribution similar unit deep neural network dropout ', 'using separate set electrophysiological recording  constructed population coupling model control statedependent activity fluctuation found model residual also show nongaussian distribution ', 'analyzed response across trial multiple section different movie clip observed noise cortex aligns better inclip versus outofclip stimulus variation ', 'argue noise useful generalization move along representation different exemplar inclass  similar structure cortical noise ']","Neural activity is highly variable in response to repeated stimuli., We used an open dataset, the Allen Brain Observatory, to quantify the distribution of responses to repeated natural movie presentations., A large fraction of responses are best fit by log-normal distributions or Gaussian mixtures with two components., These distributions are similar to those from units in deep neural networks with dropout., Using a separate set of electrophysiological recordings, we constructed a population coupling model as a control for state-dependent activity fluctuations and found that the model residuals also show non-Gaussian distributions., We then analyzed responses across trials from multiple sections of different movie clips and observed that the noise in cortex aligns better with in-clip versus out-of-clip stimulus variations., We argue that noise is useful for generalization when it moves along representations of different exemplars in-class, similar to the structure of cortical noise.",11,5.909090909090909,13.0
550,"['Unsupervised domain adaptation has received significant attention in recent years.', 'Most of existing works tackle the closed-set scenario, assuming that the source and target domains share the exactly same categories.', 'In practice, nevertheless, a target domain often contains samples of classes unseen in source domain (i.e., unknown class).', 'The extension of domain adaptation from closed-set to such open-set situation is not trivial since the target samples in unknown class are not expected to align with the source.', 'In this paper, we address this problem by augmenting the state-of-the-art domain adaptation technique, Self-Ensembling, with category-agnostic clusters in target domain.', 'Specifically, we present Self-Ensembling with Category-agnostic Clusters (SE-CC) --- a novel architecture that steers domain adaptation with the additional guidance of category-agnostic clusters that are specific to target domain.', 'These clustering information provides domain-specific visual cues, facilitating the generalization of Self-Ensembling for both closed-set and open-set scenarios.', 'Technically, clustering is firstly performed over all the unlabeled target samples to obtain the category-agnostic clusters, which reveal the underlying data space structure peculiar to target domain.', 'A clustering branch is capitalized on to ensure that the learnt representation preserves such underlying structure by matching the estimated assignment distribution over clusters to the inherent cluster distribution for each target sample.', 'Furthermore, SE-CC enhances the learnt representation with mutual information maximization.', 'Extensive experiments are conducted on Office and VisDA datasets for both open-set and closed-set domain adaptation, and superior results are reported when comparing to the state-of-the-art approaches.']","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]","[0.13793103396892548, 0.10810810327529907, 0.21052631735801697, 0.2222222238779068, 0.15789473056793213, 0.31111109256744385, 0.3243243098258972, 0.0476190410554409, 0.0416666604578495, 0.06896550953388214, 0.2790697515010834]",Bkgv71rtwr,"['We present a new design, i.e., Self-Ensembling with Category-agnostic Clusters, for both closed-set and open-set domain adaptation.', 'A new approach to open set domain adaptation, where the source domain categories are contained in the target domain categories in order to filter out outlier categories and enable adaptation within the shared classes.']","['unsupervised domain adaptation received significant attention recent year ', 'existing work tackle closedset scenario  assuming source target domain share exactly category ', 'practice  nevertheless  target domain often contains sample class unseen source domain  ie  unknown class  ', 'extension domain adaptation closedset openset situation trivial since target sample unknown class expected align source ', 'paper  address problem augmenting stateoftheart domain adaptation technique  selfensembling  categoryagnostic cluster target domain ', 'specifically  present selfensembling categoryagnostic cluster  secc    novel architecture steer domain adaptation additional guidance categoryagnostic cluster specific target domain ', 'clustering information provides domainspecific visual cue  facilitating generalization selfensembling closedset openset scenario ', 'technically  clustering firstly performed unlabeled target sample obtain categoryagnostic cluster  reveal underlying data space structure peculiar target domain ', 'clustering branch capitalized ensure learnt representation preserve underlying structure matching estimated assignment distribution cluster inherent cluster distribution target sample ', 'furthermore  secc enhances learnt representation mutual information maximization ', 'extensive experiment conducted office visda datasets openset closedset domain adaptation  superior result reported comparing stateoftheart approach ']","Unsupervised domain adaptation has received significant attention in recent years., Most of existing works tackle the closed-set scenario, assuming that the source and target domains share the exactly same categories., In practice, nevertheless, a target domain often contains samples of classes unseen in source domain (i.e., unknown class)., The extension of domain adaptation from closed-set to such open-set situation is not trivial since the target samples in unknown class are not expected to align with the source., In this paper, we address this problem by augmenting the state-of-the-art domain adaptation technique, Self-Ensembling, with category-agnostic clusters in target domain., Specifically, we present Self-Ensembling with Category-agnostic Clusters (SE-CC) --- a novel architecture that steers domain adaptation with the additional guidance of category-agnostic clusters that are specific to target domain., These clustering information provides domain-specific visual cues, facilitating the generalization of Self-Ensembling for both closed-set and open-set scenarios., Technically, clustering is firstly performed over all the unlabeled target samples to obtain the category-agnostic clusters, which reveal the underlying data space structure peculiar to target domain., A clustering branch is capitalized on to ensure that the learnt representation preserves such underlying structure by matching the estimated assignment distribution over clusters to the inherent cluster distribution for each target sample., Furthermore, SE-CC enhances the learnt representation with mutual information maximization., Extensive experiments are conducted on Office and VisDA datasets for both open-set and closed-set domain adaptation, and superior results are reported when comparing to the state-of-the-art approaches.",24,6.454545454545454,10.083333333333334
551,"['We present Spectral Inference Networks, a framework for learning eigenfunctions of linear operators by stochastic optimization.', 'Spectral Inference Networks generalize Slow Feature Analysis to generic symmetric operators, and are closely related to Variational Monte Carlo methods from computational physics.', 'As such, they can be a powerful tool for unsupervised representation learning from video or graph-structured data.', 'We cast training Spectral Inference Networks as a bilevel optimization problem, which allows for online learning of multiple eigenfunctions.', 'We show results of training Spectral Inference Networks on problems in quantum mechanics and feature learning for videos on synthetic datasets.', 'Our results demonstrate that Spectral Inference Networks accurately recover eigenfunctions of linear operators and can discover interpretable representations from video in a fully unsupervised manner.']","[1, 0, 0, 0, 0, 0]","[0.3589743673801422, 0.08888888359069824, 0.19999998807907104, 0.2380952388048172, 0.2790697515010834, 0.25]",SJzqpj09YQ,"['We show how to learn spectral decompositions of linear operators with deep learning, and use it for unsupervised learning without a generative model.', 'The authors propose to use a deep learning framework to solve the computation of the largest eigenvectors.', 'This paper presents a framework to learn eigenfunctions via a stochastic process and proposes to tackle the challenge of computing eigenfunctions in a large-scale context by approximating then using a two-phase stochastic optimization process.']","['present spectral inference network  framework learning eigenfunctions linear operator stochastic optimization ', 'spectral inference network generalize slow feature analysis generic symmetric operator  closely related variational monte carlo method computational physic ', ' powerful tool unsupervised representation learning video graphstructured data ', 'cast training spectral inference network bilevel optimization problem  allows online learning multiple eigenfunctions ', 'show result training spectral inference network problem quantum mechanic feature learning video synthetic datasets ', 'result demonstrate spectral inference network accurately recover eigenfunctions linear operator discover interpretable representation video fully unsupervised manner ']","We present Spectral Inference Networks, a framework for learning eigenfunctions of linear operators by stochastic optimization., Spectral Inference Networks generalize Slow Feature Analysis to generic symmetric operators, and are closely related to Variational Monte Carlo methods from computational physics., As such, they can be a powerful tool for unsupervised representation learning from video or graph-structured data., We cast training Spectral Inference Networks as a bilevel optimization problem, which allows for online learning of multiple eigenfunctions., We show results of training Spectral Inference Networks on problems in quantum mechanics and feature learning for videos on synthetic datasets., Our results demonstrate that Spectral Inference Networks accurately recover eigenfunctions of linear operators and can discover interpretable representations from video in a fully unsupervised manner.",10,6.479338842975206,12.1
552,"['The Tensor-Train factorization (TTF) is an efficient way to compress large weight matrices of fully-connected layers and recurrent layers in recurrent neural networks (RNNs).', 'However, high Tensor-Train ranks for all the core tensors of parameters need to be element-wise fixed, which results in an unnecessary redundancy of model parameters.', 'This work applies Riemannian stochastic gradient descent (RSGD) to train core tensors of parameters in the Riemannian Manifold before finding vectors of lower Tensor-Train ranks for parameters.', 'The paper first presents the RSGD algorithm with a convergence analysis and then tests it on more advanced Tensor-Train RNNs such as bi-directional GRU/LSTM and Encoder-Decoder RNNs with a Tensor-Train attention model.', 'The experiments on digit recognition and machine translation tasks suggest the effectiveness of the RSGD algorithm for Tensor-Train RNNs.']","[0, 0, 1, 0, 0]","[0.10810810327529907, 0.31578946113586426, 0.3589743673801422, 0.2380952388048172, 0.3030303120613098]",B1fPYj0qt7,"['Applying the Riemannian SGD (RSGD) algorithm for training Tensor-Train RNNs to further reduce model parameters.', 'The paper proposes to use Riemannian stochastic gradient algorithm for low-rank tensor train learning in deep networks.', 'Proposes an algorithm for optimizing neural networks parametrized by Tensor Train decomposition based on the Riemannian optimization and rank adaptation, and designs a bidirectional TT LSTM architecture.']","['tensortrain factorization  ttf  efficient way compress large weight matrix fullyconnected layer recurrent layer recurrent neural network  rnns  ', 'however  high tensortrain rank core tensor parameter need elementwise fixed  result unnecessary redundancy model parameter ', 'work applies riemannian stochastic gradient descent  rsgd  train core tensor parameter riemannian manifold finding vector lower tensortrain rank parameter ', 'paper first present rsgd algorithm convergence analysis test advanced tensortrain rnns bidirectional grulstm encoderdecoder rnns tensortrain attention model ', 'experiment digit recognition machine translation task suggest effectiveness rsgd algorithm tensortrain rnns ']","The Tensor-Train factorization (TTF) is an efficient way to compress large weight matrices of fully-connected layers and recurrent layers in recurrent neural networks (RNNs)., However, high Tensor-Train ranks for all the core tensors of parameters need to be element-wise fixed, which results in an unnecessary redundancy of model parameters., This work applies Riemannian stochastic gradient descent (RSGD) to train core tensors of parameters in the Riemannian Manifold before finding vectors of lower Tensor-Train ranks for parameters., The paper first presents the RSGD algorithm with a convergence analysis and then tests it on more advanced Tensor-Train RNNs such as bi-directional GRU/LSTM and Encoder-Decoder RNNs with a Tensor-Train attention model., The experiments on digit recognition and machine translation tasks suggest the effectiveness of the RSGD algorithm for Tensor-Train RNNs.",7,6.015748031496063,18.142857142857142
553,"['In this paper, we consider the problem of learning control policies that optimize areward function while satisfying constraints due to considerations of safety, fairness, or other costs.', 'We propose a new algorithm - Projection Based ConstrainedPolicy Optimization (PCPO), an iterative method for optimizing policies in a two-step process - the first step performs an unconstrained update while the secondstep reconciles the constraint violation by projection the policy back onto the constraint set.', 'We theoretically analyze PCPO and provide a lower bound on rewardimprovement, as well as an upper bound on constraint violation for each policy update.', 'We further characterize the convergence of PCPO with projection basedon two different metrics - L2 norm and Kullback-Leibler divergence.', 'Our empirical results over several control tasks demonstrate that our algorithm achievessuperior performance, averaging more than 3.5 times less constraint violation andaround 15% higher reward compared to state-of-the-art methods.']","[0, 0, 0, 1, 0]","[0.20408162474632263, 0.23333333432674408, 0.1818181723356247, 0.2380952388048172, 0.11320754140615463]",rke3TJrtPS,"['We propose a new algorithm that learns constraint-satisfying policies, and provide theoretical analysis and empirical demonstration in the context of reinforcement learning with constraints.', 'This paper introduces a constrained policy optimization algorithm using a two-step optimization process, where policies that do not satisfy the constraint can be projected back into the constraint set.']","['paper  consider problem learning control policy optimize areward function satisfying constraint due consideration safety  fairness  cost ', 'propose new algorithm  projection based constrainedpolicy optimization  pcpo   iterative method optimizing policy twostep process  first step performs unconstrained update secondstep reconciles constraint violation projection policy back onto constraint set ', 'theoretically analyze pcpo provide lower bound rewardimprovement  well upper bound constraint violation policy update ', 'characterize convergence pcpo projection basedon two different metric  l2 norm kullbackleibler divergence ', 'empirical result several control task demonstrate algorithm achievessuperior performance  averaging 35 time le constraint violation andaround 15  higher reward compared stateoftheart method ']","In this paper, we consider the problem of learning control policies that optimize areward function while satisfying constraints due to considerations of safety, fairness, or other costs., We propose a new algorithm - Projection Based ConstrainedPolicy Optimization (PCPO), an iterative method for optimizing policies in a two-step process - the first step performs an unconstrained update while the secondstep reconciles the constraint violation by projection the policy back onto the constraint set., We theoretically analyze PCPO and provide a lower bound on rewardimprovement, as well as an upper bound on constraint violation for each policy update., We further characterize the convergence of PCPO with projection basedon two different metrics - L2 norm and Kullback-Leibler divergence., Our empirical results over several control tasks demonstrate that our algorithm achievessuperior performance, averaging more than 3.5 times less constraint violation andaround 15% higher reward compared to state-of-the-art methods.",11,6.048611111111111,13.090909090909092
554,"['Deep networks face challenges of ensuring their robustness against inputs that cannot be effectively represented by information learned from training data.', 'We attribute this vulnerability to the limitations inherent to activation-based representation.', 'To complement the learned information from activation-based representation, we propose utilizing a gradient-based representation that explicitly focuses on missing information.', 'In addition, we propose a directional constraint on the gradients as an objective during training to improve the characterization of missing information.', 'To validate the effectiveness of the proposed approach, we compare the anomaly detection performance of gradient-based and activation-based representations.', 'We show that the gradient-based representation outperforms the activation-based representation by 0.093 in CIFAR-10 and 0.361 in CURE-TSR datasets in terms of AUROC averaged over all classes.', 'Also, we propose an anomaly detection algorithm that uses the gradient-based representation, denoted as GradCon, and validate its performance on three benchmarking datasets.', 'The proposed method outperforms the majority of the state-of-the-art algorithms in CIFAR-10, MNIST, and fMNIST datasets with an average AUROC of 0.664, 0.973, and 0.934, respectively.']","[0, 0, 1, 0, 0, 0, 0, 0]","[0.22857142984867096, 0.1666666567325592, 0.42424240708351135, 0.17142856121063232, 0.06666666269302368, 0.21052631735801697, 0.1621621549129486, 0.0]",SJxFWRVKDr,"['We propose a gradient-based representation for characterizing information that deep networks have not learned.', 'The authors present creating representations based on gradients with respect to the weights to supplement information missing from the training dataset for deep networks.']","['deep network face challenge ensuring robustness input effectively represented information learned training data ', 'attribute vulnerability limitation inherent activationbased representation ', 'complement learned information activationbased representation  propose utilizing gradientbased representation explicitly focus missing information ', 'addition  propose directional constraint gradient objective training improve characterization missing information ', 'validate effectiveness proposed approach  compare anomaly detection performance gradientbased activationbased representation ', 'show gradientbased representation outperforms activationbased representation 0093 cifar10 0361 curetsr datasets term auroc averaged class ', 'also  propose anomaly detection algorithm us gradientbased representation  denoted gradcon  validate performance three benchmarking datasets ', 'proposed method outperforms majority stateoftheart algorithm cifar10  mnist  fmnist datasets average auroc 0664  0973  0934  respectively ']","Deep networks face challenges of ensuring their robustness against inputs that cannot be effectively represented by information learned from training data., We attribute this vulnerability to the limitations inherent to activation-based representation., To complement the learned information from activation-based representation, we propose utilizing a gradient-based representation that explicitly focuses on missing information., In addition, we propose a directional constraint on the gradients as an objective during training to improve the characterization of missing information., To validate the effectiveness of the proposed approach, we compare the anomaly detection performance of gradient-based and activation-based representations., We show that the gradient-based representation outperforms the activation-based representation by 0.093 in CIFAR-10 and 0.361 in CURE-TSR datasets in terms of AUROC averaged over all classes., Also, we propose an anomaly detection algorithm that uses the gradient-based representation, denoted as GradCon, and validate its performance on three benchmarking datasets., The proposed method outperforms the majority of the state-of-the-art algorithms in CIFAR-10, MNIST, and fMNIST datasets with an average AUROC of 0.664, 0.973, and 0.934, respectively.",19,6.568047337278107,8.894736842105264
555,"['Medical images may contain various types of artifacts with different patterns and mixtures, which depend on many factors such as scan setting, machine condition, patients characteristics, surrounding environment, etc.', 'However, existing deep learning based artifact reduction methods are restricted by their training set with specific predetermined artifact type and pattern.', 'As such, they have limited clinical adoption.', 'In this paper, we introduce a Zero-Shot medical image Artifact Reduction (ZSAR) framework, which leverages the power of deep learning but without using general pre-trained networks or any clean image reference.', 'Specifically, we utilize the low internal visual entropy of an image and train a light-weight image-specific artifact reduction network to reduce artifacts in an image at test-time.', 'We use Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) as vehicles to show that ZSAR can reduce artifacts better than state-of-the-art both qualitatively and quantitatively, while using shorter execution time.', 'To the best of our knowledge, this is the first deep learning framework that reduces artifacts in medical images without using a priori training set.']","[0, 0, 0, 1, 0, 0, 0]","[0.0714285671710968, 0.08510638028383255, 0.0, 0.8771929740905762, 0.1538461446762085, 0.07017543166875839, 0.31372547149658203]",H1xjh6EYvS,"['We introduce a Zero-Shot medical image Artifact Reduction framework, which leverages the power of deep learning but without using general pre-trained networks or any clean image reference. ']","['medical image may contain various type artifact different pattern mixture  depend many factor scan setting  machine condition  patient  characteristic  surrounding environment  etc ', 'however  existing deep learning based artifact reduction method restricted training set specific predetermined artifact type pattern ', ' limited clinical adoption ', 'paper  introduce  zeroshot  medical image artifact reduction  zsar  framework  leverage power deep learning without using general pretrained network clean image reference ', 'specifically  utilize low internal visual entropy image train lightweight imagespecific artifact reduction network reduce artifact image testtime ', 'use computed tomography  ct  magnetic resonance imaging  mri  vehicle show zsar reduce artifact better stateoftheart qualitatively quantitatively  using shorter execution time ', 'best knowledge  first deep learning framework reduces artifact medical image without using priori training set ']","Medical images may contain various types of artifacts with different patterns and mixtures, which depend on many factors such as scan setting, machine condition, patients characteristics, surrounding environment, etc., However, existing deep learning based artifact reduction methods are restricted by their training set with specific predetermined artifact type and pattern., As such, they have limited clinical adoption., In this paper, we introduce a Zero-Shot medical image Artifact Reduction (ZSAR) framework, which leverages the power of deep learning but without using general pre-trained networks or any clean image reference., Specifically, we utilize the low internal visual entropy of an image and train a light-weight image-specific artifact reduction network to reduce artifacts in an image at test-time., We use Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) as vehicles to show that ZSAR can reduce artifacts better than state-of-the-art both qualitatively and quantitatively, while using shorter execution time., To the best of our knowledge, this is the first deep learning framework that reduces artifacts in medical images without using a priori training set.",19,5.894736842105263,9.0
556,"['Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks.', 'For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image.', 'In this work we adapt the information bottleneck concept for attribution.', 'By adding noise to intermediate feature maps we restrict the flow of information and can quantify (in bits) how much information image regions provide.', 'We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings.', ""The methods information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision.""]","[0, 0, 1, 0, 0, 0]","[0.08695651590824127, 0.1428571343421936, 0.42105263471603394, 0.12903225421905518, 0.05882352590560913, 0.1621621549129486]",S1xWh1rYwB,"['We apply the informational bottleneck concept to attribution.', 'The paper proposes a novel perturbation-based method for computing attribution/saliency maps for deep neural network based image classifiers, by injecting crafted noise into an early layer of the network.']","['attribution method provide insight decisionmaking machine learning model like artificial neural network ', 'given input sample  assign relevance score individual input variable  pixel image ', 'work adapt information bottleneck concept attribution ', 'adding noise intermediate feature map restrict flow information quantify  bit  much information image region provide ', 'compare method ten baseline using three different metric vgg16 resnet50  find method outperform baseline five six setting ', 'method  informationtheoretic foundation provides absolute frame reference attribution value  bit  guarantee region scored close zero necessary network decision ']","Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks., For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image., In this work we adapt the information bottleneck concept for attribution., By adding noise to intermediate feature maps we restrict the flow of information and can quantify (in bits) how much information image regions provide., We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings., The methods information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision.",9,5.557251908396947,14.555555555555555
557,"['Recurrent Neural Networks (RNNs) are used in state-of-the-art models in domains such as speech recognition, machine translation, and language modelling.', 'Sparsity is a technique to reduce compute and memory requirements of deep learning models.', 'Sparse RNNs are easier to deploy on devices and high-end server processors.', 'Even though sparse operations need less compute and memory relative to their dense counterparts, the speed-up observed by using sparse operations is less than expected on different hardware platforms.', 'In order to address this issue, we investigate two different approaches to induce block sparsity in RNNs: pruning blocks of weights in a layer and using group lasso regularization with pruning to create blocks of weights with zeros.', 'Using these techniques, we can create block-sparse RNNs with sparsity ranging from 80% to 90% with a small loss in accuracy.', 'This technique allows us to reduce the model size by roughly 10x.', 'Additionally, we can prune a larger dense network to recover this loss in accuracy while maintaining high block sparsity and reducing the overall parameter count.', 'Our technique works with a variety of block sizes up to 32x32.', 'Block-sparse RNNs eliminate overheads related to data storage and irregular memory accesses while increasing hardware efficiency compared to unstructured sparsity.\n']","[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.0, 0.05882352590560913, 0.1875, 0.260869562625885, 0.1599999964237213, 0.19999998807907104, 0.1249999925494194, 0.2222222238779068, 0.1249999925494194, 0.19999998807907104]",HJaDJZ-0W,"['We show the RNNs can be pruned to induce block sparsity which improves speedup for sparse operations on existing hardware', 'The authors propose a block sparsity pruning approach to compress RNNs, using group LASSO to promote sparsity and to prune, but with a very specialized schedule as to the pruning and pruning weight.']","['recurrent neural network  rnns  used stateoftheart model domain speech recognition  machine translation  language modelling ', 'sparsity technique reduce compute memory requirement deep learning model ', 'sparse rnns easier deploy device highend server processor ', 'even though sparse operation need le compute memory relative dense counterpart  speedup observed using sparse operation le expected different hardware platform ', 'order address issue  investigate two different approach induce block sparsity rnns  pruning block weight layer using group lasso regularization pruning create block weight zero ', 'using technique  create blocksparse rnns sparsity ranging 80  90  small loss accuracy ', 'technique allows u reduce model size roughly 10x ', 'additionally  prune larger dense network recover loss accuracy maintaining high block sparsity reducing overall parameter count ', 'technique work variety block size 32x32 ', 'blocksparse rnns eliminate overhead related data storage irregular memory access increasing hardware efficiency compared unstructured sparsity ']","Recurrent Neural Networks (RNNs) are used in state-of-the-art models in domains such as speech recognition, machine translation, and language modelling., Sparsity is a technique to reduce compute and memory requirements of deep learning models., Sparse RNNs are easier to deploy on devices and high-end server processors., Even though sparse operations need less compute and memory relative to their dense counterparts, the speed-up observed by using sparse operations is less than expected on different hardware platforms., In order to address this issue, we investigate two different approaches to induce block sparsity in RNNs: pruning blocks of weights in a layer and using group lasso regularization with pruning to create blocks of weights with zeros., Using these techniques, we can create block-sparse RNNs with sparsity ranging from 80% to 90% with a small loss in accuracy., This technique allows us to reduce the model size by roughly 10x., Additionally, we can prune a larger dense network to recover this loss in accuracy while maintaining high block sparsity and reducing the overall parameter count., Our technique works with a variety of block sizes up to 32x32., Block-sparse RNNs eliminate overheads related to data storage and irregular memory accesses while increasing hardware efficiency compared to unstructured sparsity.
",16,5.54679802955665,12.6875
558,"['Value iteration networks are an approximation of the value iteration (VI) algorithm implemented with convolutional neural networks to make VI fully differentiable.', 'In this work, we study these networks in the context of robot motion planning, with a focus on applications to planetary rovers.', 'The key challenging task in learning-based motion planning is to learn a transformation from terrain observations to a suitable navigation reward function.', 'In order to deal with complex terrain observations and policy learning, we propose a value iteration recurrence, referred to as the soft value iteration network (SVIN).', 'SVIN is designed to produce more effective training gradients through the value iteration network.', 'It relies on a soft policy model, where the policy is represented with a probability distribution over all possible actions, rather than a deterministic policy that returns only the best action.', 'We demonstrate the effectiveness of the proposed method in robot motion planning scenarios.', 'In particular, we study the application of SVIN to very challenging problems in planetary rover navigation and present early training results on data gathered by the  Curiosity rover that is currently operating on Mars.']","[1, 0, 0, 0, 0, 0, 0, 0]","[0.29411762952804565, 0.2222222238779068, 0.11764705181121826, 0.2702702581882477, 0.2142857164144516, 0.04999999701976776, 0.1538461446762085, 0.13333332538604736]",Sktm4zWRb,"['We propose an improvement to value iteration networks, with applications to planetary rover path planning.', 'This paper learns a reward function based on expert trajectories using a Value Iteration Module to make the planning step differentiable']","['value iteration network approximation value iteration  vi  algorithm implemented convolutional neural network make vi fully differentiable ', 'work  study network context robot motion planning  focus application planetary rover ', 'key challenging task learningbased motion planning learn transformation terrain observation suitable navigation reward function ', 'order deal complex terrain observation policy learning  propose value iteration recurrence  referred soft value iteration network  svin  ', 'svin designed produce effective training gradient value iteration network ', 'relies soft policy model  policy represented probability distribution possible action  rather deterministic policy return best action ', 'demonstrate effectiveness proposed method robot motion planning scenario ', 'particular  study application svin challenging problem planetary rover navigation present early training result data gathered curiosity rover currently operating mar ']","Value iteration networks are an approximation of the value iteration (VI) algorithm implemented with convolutional neural networks to make VI fully differentiable., In this work, we study these networks in the context of robot motion planning, with a focus on applications to planetary rovers., The key challenging task in learning-based motion planning is to learn a transformation from terrain observations to a suitable navigation reward function., In order to deal with complex terrain observations and policy learning, we propose a value iteration recurrence, referred to as the soft value iteration network (SVIN)., SVIN is designed to produce more effective training gradients through the value iteration network., It relies on a soft policy model, where the policy is represented with a probability distribution over all possible actions, rather than a deterministic policy that returns only the best action., We demonstrate the effectiveness of the proposed method in robot motion planning scenarios., In particular, we study the application of SVIN to very challenging problems in planetary rover navigation and present early training results on data gathered by the  Curiosity rover that is currently operating on Mars.",15,5.608695652173913,12.266666666666667
559,"['Transformer networks have lead to important progress in language modeling and machine translation.', 'These models include two consecutive modules, a feed-forward layer and a self-attention layer.', 'The latter allows the network to capture long term dependencies and are often regarded as the key ingredient in the success of Transformers.', 'Building upon this intuition, we propose a new model that solely consists of attention layers.', 'More precisely, we augment the self-attention layers with persistent memory vectors that play a similar role as the feed-forward layer.', 'Thanks to these vectors, we can remove the feed-forward layer without degrading the performance of a transformer.', 'Our evaluation shows the benefits brought by our model on standard character and word level language modeling benchmarks.']","[0, 1, 0, 0, 0, 0, 0]","[0.23076923191547394, 0.3333333432674408, 0.11764705181121826, 0.2142857164144516, 0.25, 0.20689654350280762, 0.06451612710952759]",HklJdaNYPH,"['A novel attention layer that combines self-attention and feed-forward sublayers of Transformer networks.', 'This paper proposes a modification to the Transformer model by incorporating attention over ""persistent"" memory vectors into the self-attention layer, resulting in performance on par with existing models while using fewer parameters.']","['transformer network lead important progress language modeling machine translation ', 'model include two consecutive module  feedforward layer selfattention layer ', 'latter allows network capture long term dependency often regarded key ingredient success transformer ', 'building upon intuition  propose new model solely consists attention layer ', 'precisely  augment selfattention layer persistent memory vector play similar role feedforward layer ', 'thanks vector  remove feedforward layer without degrading performance transformer ', 'evaluation show benefit brought model standard character word level language modeling benchmark ']","Transformer networks have lead to important progress in language modeling and machine translation., These models include two consecutive modules, a feed-forward layer and a self-attention layer., The latter allows the network to capture long term dependencies and are often regarded as the key ingredient in the success of Transformers., Building upon this intuition, we propose a new model that solely consists of attention layers., More precisely, we augment the self-attention layers with persistent memory vectors that play a similar role as the feed-forward layer., Thanks to these vectors, we can remove the feed-forward layer without degrading the performance of a transformer., Our evaluation shows the benefits brought by our model on standard character and word level language modeling benchmarks.",11,5.705882352941177,10.818181818181818
560,"['This work views neural networks as data generating systems and applies anomalous pattern detection techniques on that data in order to detect when a network is processing a group of anomalous inputs.  ', 'Detecting anomalies is a critical component for multiple machine learning problems including detecting the presence of adversarial noise added to inputs.', 'More broadly, this work is a step towards giving neural networks the ability to detect groups of out-of-distribution samples.  ', 'This work introduces ``Subset Scanning methods from the anomalous pattern detection domain to the task of detecting anomalous inputs to neural networks.  ', 'Subset Scanning allows us to answer the question: ""``Which subset of inputs have larger-than-expected activations at which subset of nodes?', '""  Framing the adversarial detection problem this way allows us to identify systematic patterns in the activation space that span multiple adversarially noised images.  ', 'Such images are ``""weird together"".  ', 'Leveraging this common anomalous pattern, we show increased detection power as the proportion of noised images increases in a test set.   ', 'Detection power and accuracy results are provided for targeted adversarial noise added to CIFAR-10 images on a 20-layer ResNet using the Basic Iterative Method attack.']","[1, 0, 0, 0, 0, 0, 0, 0, 0]","[0.37288135290145874, 0.1599999964237213, 0.20408162474632263, 0.16326530277729034, 0.21276594698429108, 0.15094339847564697, 0.11428571492433548, 0.23529411852359772, 0.18518517911434174]",Skld1aVtPB,"['We efficiently find a subset of images that have higher than expected activations for some subset of nodes.  These images appear more anomalous and easier to detect when viewed as a group. ', 'The paper proposed a scheme to detect the presence of anomalous inputs based on a ""subset scanning"" approach to detect anomalous activations in the deep learning network.']","['work view neural network data generating system applies anomalous pattern detection technique data order detect network processing group anomalous input ', 'detecting anomaly critical component multiple machine learning problem including detecting presence adversarial noise added input ', 'broadly  work step towards giving neural network ability detect group outofdistribution sample ', 'work introduces  subset scanning method anomalous pattern detection domain task detecting anomalous input neural network ', 'subset scanning allows u answer question    subset input largerthanexpected activation subset node ', ' framing adversarial detection problem way allows u identify systematic pattern activation space span multiple adversarially noised image ', 'image   weird together  ', 'leveraging common anomalous pattern  show increased detection power proportion noised image increase test set ', 'detection power accuracy result provided targeted adversarial noise added cifar10 image 20layer resnet using basic iterative method attack ']","This work views neural networks as data generating systems and applies anomalous pattern detection techniques on that data in order to detect when a network is processing a group of anomalous inputs.  , Detecting anomalies is a critical component for multiple machine learning problems including detecting the presence of adversarial noise added to inputs., More broadly, this work is a step towards giving neural networks the ability to detect groups of out-of-distribution samples.  , This work introduces ``Subset Scanning methods from the anomalous pattern detection domain to the task of detecting anomalous inputs to neural networks.  , Subset Scanning allows us to answer the question: ""``Which subset of inputs have larger-than-expected activations at which subset of nodes?, ""  Framing the adversarial detection problem this way allows us to identify systematic patterns in the activation space that span multiple adversarially noised images.  , Such images are ``""weird together"".  , Leveraging this common anomalous pattern, we show increased detection power as the proportion of noised images increases in a test set.   , Detection power and accuracy results are provided for targeted adversarial noise added to CIFAR-10 images on a 20-layer ResNet using the Basic Iterative Method attack.",11,5.761904761904762,17.181818181818183
561,"['Stability is a fundamental property of dynamical systems, yet to this date it has had little bearing on the practice of recurrent neural networks.', 'In this work, we conduct a thorough investigation of stable recurrent models.', 'Theoretically, we prove stable recurrent neural networks are well approximated by feed-forward networks for the purpose of both inference and training by gradient descent.', 'Empirically, we demonstrate stable recurrent models often perform as well as their unstable counterparts on benchmark sequence tasks.', 'Taken together, these findings shed light on the effective power of recurrent networks and suggest much of sequence learning happens, or can be made to happen, in the stable regime.', 'Moreover, our results help to explain why in many cases practitioners succeed in replacing recurrent models by feed-forward models.\n']","[0, 0, 0, 1, 0, 0]","[0.1463414579629898, 0.13333332538604736, 0.3499999940395355, 0.514285683631897, 0.260869562625885, 0.2222222238779068]",Hygxb2CqKm,"['Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.', 'Studies the stability of RNNs and investigation of spectral normalization to sequential predictions.']","['stability fundamental property dynamical system  yet date little bearing practice recurrent neural network ', 'work  conduct thorough investigation stable recurrent model ', 'theoretically  prove stable recurrent neural network well approximated feedforward network purpose inference training gradient descent ', 'empirically  demonstrate stable recurrent model often perform well unstable counterpart benchmark sequence task ', 'taken together  finding shed light effective power recurrent network suggest much sequence learning happens  made happen  stable regime ', 'moreover  result help explain many case practitioner succeed replacing recurrent model feedforward model ']","Stability is a fundamental property of dynamical systems, yet to this date it has had little bearing on the practice of recurrent neural networks., In this work, we conduct a thorough investigation of stable recurrent models., Theoretically, we prove stable recurrent neural networks are well approximated by feed-forward networks for the purpose of both inference and training by gradient descent., Empirically, we demonstrate stable recurrent models often perform as well as their unstable counterparts on benchmark sequence tasks., Taken together, these findings shed light on the effective power of recurrent networks and suggest much of sequence learning happens, or can be made to happen, in the stable regime., Moreover, our results help to explain why in many cases practitioners succeed in replacing recurrent models by feed-forward models.
",14,5.590551181102362,9.071428571428571
562,"['Weight-sharing plays a significant role in the success of many deep neural networks, by increasing memory efficiency and incorporating useful inductive priors about the problem into the network.', 'But understanding how weight-sharing can be used effectively in general is a topic that has not been studied extensively.', 'Chen et al. (2015) proposed HashedNets, which augments a multi-layer perceptron with a hash table, as a method for neural network compression.', 'We generalize this method into a framework (ArbNets) that allows for efficient arbitrary weight-sharing, and use it to study the role of weight-sharing in neural networks.', 'We show that common neural networks can be expressed as ArbNets with different hash functions.', 'We also present two novel hash functions, the Dirichlet hash and the Neighborhood hash, and use them to demonstrate experimentally that balanced and deterministic weight-sharing helps with the performance of a neural network.']","[0, 0, 0, 0, 0, 1]","[0.3333333432674408, 0.1463414579629898, 0.1904761791229248, 0.375, 0.21621620655059814, 0.5199999809265137]",SJD8YjCpW,"['Studied the role of weight sharing in neural networks using hash functions, found that a balanced and deterministic hash function helps network performance.', 'Proposing ArbNets to study weight sharing in a more systematic way by defining the weight sharing function as a hash function.']","['weightsharing play significant role success many deep neural network  increasing memory efficiency incorporating useful inductive prior problem network ', 'understanding weightsharing used effectively general topic studied extensively ', 'chen et al   2015  proposed hashednets  augments multilayer perceptron hash table  method neural network compression ', 'generalize method framework  arbnets  allows efficient arbitrary weightsharing  use study role weightsharing neural network ', 'show common neural network expressed arbnets different hash function ', 'also present two novel hash function  dirichlet hash neighborhood hash  use demonstrate experimentally balanced deterministic weightsharing help performance neural network ']","Weight-sharing plays a significant role in the success of many deep neural networks, by increasing memory efficiency and incorporating useful inductive priors about the problem into the network., But understanding how weight-sharing can be used effectively in general is a topic that has not been studied extensively., Chen et al. (2015) proposed HashedNets, which augments a multi-layer perceptron with a hash table, as a method for neural network compression., We generalize this method into a framework (ArbNets) that allows for efficient arbitrary weight-sharing, and use it to study the role of weight-sharing in neural networks., We show that common neural networks can be expressed as ArbNets with different hash functions., We also present two novel hash functions, the Dirichlet hash and the Neighborhood hash, and use them to demonstrate experimentally that balanced and deterministic weight-sharing helps with the performance of a neural network.",12,5.6223776223776225,11.0
563,"['We introduce Neural Markov Logic Networks (NMLNs), a statistical relational learning system that borrows ideas from Markov logic.', 'Like Markov Logic Networks (MLNs), NMLNs are an exponential-family model for modelling distributions over possible worlds, but unlike MLNs, they do not rely on explicitly specified first-order logic rules.', 'Instead, NMLNs learn an implicit representation of such rules as a neural network that acts as a potential function on fragments of the relational structure.', 'Interestingly, any MLN can be represented as an NMLN.', 'Similarly to recently proposed Neural theorem provers (NTPs) (Rocktaschel at al. 2017), NMLNs can exploit embeddings of constants but, unlike NTPs, NMLNs work well also in their absence.', 'This is extremely important for predicting in settings other than the transductive one.', 'We showcase the potential of NMLNs on knowledge-base completion tasks and on generation of molecular (graph) data.']","[1, 0, 0, 0, 0, 0, 0]","[0.6499999761581421, 0.19230768084526062, 0.4888888895511627, 0.1249999925494194, 0.03999999538064003, 0.0, 0.10526315122842789]",SkeGvaEtPr,"[' We introduce a statistical relational learning system that borrows ideas from Markov logic but learns an implicit representation of rules as a neural network.', 'The paper provides an extension to Markov Logic Networks by removing their dependency on pre-defined first-order logic rules to model more domains in knowledge-base completion tasks.']","['introduce neural markov logic network  nmlns   statistical relational learning system borrows idea markov logic ', 'like markov logic network  mlns   nmlns exponentialfamily model modelling distribution possible world  unlike mlns  rely explicitly specified firstorder logic rule ', 'instead  nmlns learn implicit representation rule neural network act potential function fragment relational structure ', 'interestingly  mln represented nmln ', 'similarly recently proposed neural theorem provers  ntps   rocktaschel al  2017   nmlns exploit embeddings constant  unlike ntps  nmlns work well also absence ', 'extremely important predicting setting transductive one ', 'showcase potential nmlns knowledgebase completion task generation molecular  graph  data ']","We introduce Neural Markov Logic Networks (NMLNs), a statistical relational learning system that borrows ideas from Markov logic., Like Markov Logic Networks (MLNs), NMLNs are an exponential-family model for modelling distributions over possible worlds, but unlike MLNs, they do not rely on explicitly specified first-order logic rules., Instead, NMLNs learn an implicit representation of such rules as a neural network that acts as a potential function on fragments of the relational structure., Interestingly, any MLN can be represented as an NMLN., Similarly to recently proposed Neural theorem provers (NTPs) (Rocktaschel at al. 2017), NMLNs can exploit embeddings of constants but, unlike NTPs, NMLNs work well also in their absence., This is extremely important for predicting in settings other than the transductive one., We showcase the potential of NMLNs on knowledge-base completion tasks and on generation of molecular (graph) data.",16,5.683453237410072,8.176470588235293
564,"['Using variational Bayes neural networks, we develop an algorithm capable of accumulating knowledge into a prior from multiple different tasks.', 'This results in a rich prior capable of few-shot learning on new tasks.', 'The posterior can go beyond the mean field approximation and yields good uncertainty on the performed experiments.', 'Analysis on toy tasks show that it can learn from significantly different tasks while finding similarities among them.', 'Experiments on Mini-Imagenet reach state of the art with 74.5% accuracy on 5 shot learning.', 'Finally, we provide two new benchmarks, each showing a failure mode of existing meta learning algorithms such as MAML and prototypical Networks.']","[1, 0, 0, 0, 0, 0]","[0.29411762952804565, 0.2222222238779068, 0.0, 0.06451612710952759, 0.06896550953388214, 0.0555555522441864]",S1eEmn05tQ,"['A scalable method for learning an expressive prior over neural networks across multiple tasks.', 'The paper presents a method for training a probabilistic model for Multitasks Transfer Learning by introducing a latent variable per task to capture the commonality in the task instances.', 'The work proposes a variational approach to meta-learning that employs latent variables corresponding to task-specific datasets.', 'Aims to learn a prior over neural networks for multiple tasks. ']","['using variational bayes neural network  develop algorithm capable accumulating knowledge prior multiple different task ', 'result rich prior capable fewshot learning new task ', 'posterior go beyond mean field approximation yield good uncertainty performed experiment ', 'analysis toy task show learn significantly different task finding similarity among ', 'experiment miniimagenet reach state art 745  accuracy 5 shot learning ', 'finally  provide two new benchmark  showing failure mode existing meta learning algorithm maml prototypical network ']","Using variational Bayes neural networks, we develop an algorithm capable of accumulating knowledge into a prior from multiple different tasks., This results in a rich prior capable of few-shot learning on new tasks., The posterior can go beyond the mean field approximation and yields good uncertainty on the performed experiments., Analysis on toy tasks show that it can learn from significantly different tasks while finding similarities among them., Experiments on Mini-Imagenet reach state of the art with 74.5% accuracy on 5 shot learning., Finally, we provide two new benchmarks, each showing a failure mode of existing meta learning algorithms such as MAML and prototypical Networks.",9,5.504761904761905,11.666666666666666
565,"['Sequential data often originates from diverse environments.', 'Across them exist both shared regularities and environment specifics.', 'To learn robust cross-environment descriptions of sequences we introduce disentangled state space models (DSSM).', 'In the latent space of DSSM environment-invariant state dynamics is explicitly disentangled from environment-specific information governing that dynamics.', 'We empirically show that such separation enables robust prediction, sequence manipulation and environment characterization.', 'We also propose an unsupervised VAE-based training procedure to learn DSSM as Bayesian filters.', 'In our experiments, we demonstrate state-of-the-art performance in controlled generation and prediction of bouncing ball video sequences across varying gravitational influences.']","[1, 0, 0, 0, 0, 0, 0]","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]",HklaEUUtON,"['DISENTANGLED STATE SPACE MODELS', 'The paper presents a generative state space model using a global latent variable E to capture environment-specific information.']","['sequential data often originates diverse environment ', 'across exist shared regularity environment specific ', 'learn robust crossenvironment description sequence introduce disentangled state space model  dssm  ', 'latent space dssm environmentinvariant state dynamic explicitly disentangled environmentspecific information governing dynamic ', 'empirically show separation enables robust prediction  sequence manipulation environment characterization ', 'also propose unsupervised vaebased training procedure learn dssm bayesian filter ', 'experiment  demonstrate stateoftheart performance controlled generation prediction bouncing ball video sequence across varying gravitational influence ']","Sequential data often originates from diverse environments., Across them exist both shared regularities and environment specifics., To learn robust cross-environment descriptions of sequences we introduce disentangled state space models (DSSM)., In the latent space of DSSM environment-invariant state dynamics is explicitly disentangled from environment-specific information governing that dynamics., We empirically show that such separation enables robust prediction, sequence manipulation and environment characterization., We also propose an unsupervised VAE-based training procedure to learn DSSM as Bayesian filters., In our experiments, we demonstrate state-of-the-art performance in controlled generation and prediction of bouncing ball video sequences across varying gravitational influences.",9,7.185567010309279,10.777777777777779
566,"['In this work, we approach one-shot and few-shot learning problems as methods for finding good prototypes for each class, where these prototypes are generalizable to new data samples and classes.', 'We propose a metric learner that learns a Bregman divergence by learning its underlying convex function.', 'Bregman divergences are a good candidate for this framework given they are the only class of divergences with the property that the best representative of a set of points is given by its mean.', 'We propose a flexible extension to prototypical networks to enable joint learning of the embedding and the divergence, while preserving computational efficiency.', 'Our preliminary results are comparable with the prior work on the Omniglot and Mini-ImageNet datasets, two standard benchmarks for one-shot and few-shot learning.', 'We argue that our model can be used for other tasks that involve metric learning or tasks that require approximate convexity such as structured prediction and data completion.']","[0, 1, 0, 0, 0, 0]","[0.1818181723356247, 0.2857142686843872, 0.125, 0.07692307233810425, 0.2222222238779068, 0.12903225421905518]",r1gFV9Sj2N,['Bregman divergence learning for few-shot learning. '],"['work  approach oneshot fewshot learning problem method finding good prototype class  prototype generalizable new data sample class ', 'propose metric learner learns bregman divergence learning underlying convex function ', 'bregman divergence good candidate framework given class divergence property best representative set point given mean ', 'propose flexible extension prototypical network enable joint learning embedding divergence  preserving computational efficiency ', 'preliminary result comparable prior work omniglot miniimagenet datasets  two standard benchmark oneshot fewshot learning ', 'argue model used task involve metric learning task require approximate convexity structured prediction data completion ']","In this work, we approach one-shot and few-shot learning problems as methods for finding good prototypes for each class, where these prototypes are generalizable to new data samples and classes., We propose a metric learner that learns a Bregman divergence by learning its underlying convex function., Bregman divergences are a good candidate for this framework given they are the only class of divergences with the property that the best representative of a set of points is given by its mean., We propose a flexible extension to prototypical networks to enable joint learning of the embedding and the divergence, while preserving computational efficiency., Our preliminary results are comparable with the prior work on the Omniglot and Mini-ImageNet datasets, two standard benchmarks for one-shot and few-shot learning., We argue that our model can be used for other tasks that involve metric learning or tasks that require approximate convexity such as structured prediction and data completion.",10,5.470588235294118,15.3
567,"['Motivated by the flexibility of biological neural networks whose connectivity structure changes significantly during their lifetime,we introduce the Unrestricted Recursive Network (URN) and demonstrate that it can exhibit similar flexibility during training via gradient descent.', 'We show empirically that many of the different neural network structures commonly used in practice today (including fully connected, locally connected and residual networks of differ-ent depths and widths) can emerge dynamically from the same URN.These different structures can be derived using gradient descent on a single general loss function where the structure of the data and the relative strengths of various regulator terms determine the structure of the emergent network.', 'We show that this loss function and the regulators arise naturally when considering the symmetries of the network as well as the geometric properties of the input data.']","[1, 0, 0]","[0.27586206793785095, 0.2222222238779068, 0.25]",rJl_7mtULB,['We introduce a network framework which can modify its structure during training and show that it can converge to various ML network archetypes such as MLPs and LCNs. '],"['motivated flexibility biological neural network whose connectivity structure change significantly lifetime  introduce unrestricted recursive network  urn  demonstrate exhibit similar flexibility training via gradient descent ', 'show empirically many different neural network structure commonly used practice today  including fully connected  locally connected residual network different depth width  emerge dynamically urnthese different structure derived using gradient descent single general loss function structure data relative strength various regulator term determine structure emergent network ', 'show loss function regulator arise naturally considering symmetry network well geometric property input data ']","Motivated by the flexibility of biological neural networks whose connectivity structure changes significantly during their lifetime,we introduce the Unrestricted Recursive Network (URN) and demonstrate that it can exhibit similar flexibility during training via gradient descent., We show empirically that many of the different neural network structures commonly used in practice today (including fully connected, locally connected and residual networks of differ-ent depths and widths) can emerge dynamically from the same URN.These different structures can be derived using gradient descent on a single general loss function where the structure of the data and the relative strengths of various regulator terms determine the structure of the emergent network., We show that this loss function and the regulators arise naturally when considering the symmetries of the network as well as the geometric properties of the input data.",4,5.932835820895522,33.5
568,"['We present CROSSGRAD , a method to use multi-domain training data to learn a classifier that generalizes to new domains.', 'CROSSGRAD does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain.', 'Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training.', 'In contrast, CROSSGRAD is free to use domain signals for predicting labels, if it can prevent overfitting on training domains.', 'We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances.', 'CROSSGRAD jointly trains a label and a domain classifier on examples perturbed by loss gradients of each others objectives.', 'This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions.', 'Empirical evaluation on three different applications where this setting is natural establishes that', '\n (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and \n', '(2) data augmentation is a more stable and accurate method than domain adversarial training.']","[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]","[0.19999998807907104, 0.06666666269302368, 0.07407406717538834, 0.060606054961681366, 0.1666666567325592, 0.25806450843811035, 0.12903225421905518, 0.0, 0.2142857164144516, 0.5185185074806213]",r1Dx7fbCW,"['Domain guided augmentation of data provides a robust and stable method of domain generalization', 'This paper proposes a domain generalization approach by domain-dependent data augmentation', 'The authors introduce the CrossGrad method, which trains both a label classification task and a domain classification task.']","['present crossgrad  method use multidomain training data learn classifier generalizes new domain ', 'crossgrad need adaptation phase via labeled unlabeled data  domain feature new domain ', 'existing domain adaptation method attempt erase domain signal using technique like domain adversarial training ', 'contrast  crossgrad free use domain signal predicting label  prevent overfitting training domain ', 'conceptualize task bayesian setting  sampling step implemented data augmentation  based domainguided perturbation input instance ', 'crossgrad jointly train label domain classifier example perturbed loss gradient  objective ', 'enables u directly perturb input  without separating remixing domain signal making various distributional assumption ', 'empirical evaluation three different application setting natural establishes', ' 1  domainguided perturbation provides consistently better generalization unseen domain  compared generic instance perturbation method ', ' 2  data augmentation stable accurate method domain adversarial training ']","We present CROSSGRAD , a method to use multi-domain training data to learn a classifier that generalizes to new domains., CROSSGRAD does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain., Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training., In contrast, CROSSGRAD is free to use domain signals for predicting labels, if it can prevent overfitting on training domains., We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances., CROSSGRAD jointly trains a label and a domain classifier on examples perturbed by loss gradients of each others objectives., This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions., Empirical evaluation on three different applications where this setting is natural establishes that, 
 (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and 
, (2) data augmentation is a more stable and accurate method than domain adversarial training.",19,5.944444444444445,9.473684210526315
569,"['We present sketch-rnn, a recurrent neural network able to construct stroke-based drawings of common objects.', 'The model is trained on a dataset of human-drawn images representing many different classes.', 'We outline a framework for conditional and unconditional sketch generation, and describe new robust training methods for generating coherent sketch drawings in a vector format.']","[0, 0, 1]","[0.1875, 0.19354838132858276, 0.2631579041481018]",Hy6GHpkCW,"['We investigate alternative to traditional pixel image modelling approaches, and propose a generative model for vector images.', 'This paper introduces a neural network architecture for generating sketch drawings inspired by the variational autoencoder.']","['present sketchrnn  recurrent neural network able construct strokebased drawing common object ', 'model trained dataset humandrawn image representing many different class ', 'outline framework conditional unconditional sketch generation  describe new robust training method generating coherent sketch drawing vector format ']","We present sketch-rnn, a recurrent neural network able to construct stroke-based drawings of common objects., The model is trained on a dataset of human-drawn images representing many different classes., We outline a framework for conditional and unconditional sketch generation, and describe new robust training methods for generating coherent sketch drawings in a vector format.",5,5.981481481481482,10.8
570,"['Wilson et al. (2017) showed that, when the stepsize schedule is properly designed, stochastic gradient generalizes better than ADAM (Kingma & Ba, 2014).', 'In light of recent work on hypergradient methods (Baydin et al., 2018), we revisit these claims to see if such methods close the gap between the most popular optimizers.', 'As a byproduct, we analyze the true benefit of these hypergradient methods compared to more classical schedules, such as the fixed decay of Wilson et al. (2017).', 'In particular, we observe they are of marginal help since their performance varies significantly when tuning their hyperparameters.', 'Finally, as robustness is a critical quality of an optimizer, we provide a sensitivity analysis of these gradient based optimizers to assess how challenging their tuning is.']","[0, 0, 0, 0, 1]","[0.1818181723356247, 0.19999998807907104, 0.21052631735801697, 0.0, 0.25]",rJgSV3AqKQ,"['We provide a study trying to see how the recent online learning rate adaptation extends the conclusion made by Wilson et al. 2018 about adaptive gradient methods, along with comparison and sensitivity analysis.', 'Reports the results of testing several stepsize adjustment related methods including vanilla SGD, SGD with Neserov momentum, and ADAM and compares those methods with hypergradient and without. ']","['wilson et al   2017  showed  stepsize schedule properly designed  stochastic gradient generalizes better adam  kingma  ba  2014  ', 'light recent work hypergradient method  baydin et al  2018   revisit claim see method close gap popular optimizers ', 'byproduct  analyze true benefit hypergradient method compared classical schedule  fixed decay wilson et al   2017  ', 'particular  observe marginal help since performance varies significantly tuning hyperparameters ', 'finally  robustness critical quality optimizer  provide sensitivity analysis gradient based optimizers ass challenging tuning ']","Wilson et al. (2017) showed that, when the stepsize schedule is properly designed, stochastic gradient generalizes better than ADAM (Kingma & Ba, 2014)., In light of recent work on hypergradient methods (Baydin et al., 2018), we revisit these claims to see if such methods close the gap between the most popular optimizers., As a byproduct, we analyze the true benefit of these hypergradient methods compared to more classical schedules, such as the fixed decay of Wilson et al. (2017)., In particular, we observe they are of marginal help since their performance varies significantly when tuning their hyperparameters., Finally, as robustness is a critical quality of an optimizer, we provide a sensitivity analysis of these gradient based optimizers to assess how challenging their tuning is.",15,5.298387096774194,7.294117647058823
571,"['Despite an ever growing literature on reinforcement learning algorithms and applications, much less is known about their statistical inference.', 'In this paper, we investigate the large-sample behaviors of the Q-value estimates with closed-form characterizations of the asymptotic variances.', 'This allows us to efficiently construct confidence regions for Q-value and optimal value functions, and to develop policies to minimize their estimation errors.', 'This also leads to a policy exploration strategy that relies on estimating the relative discrepancies among the Q estimates.', 'Numerical experiments show superior performances of our exploration strategy than other benchmark approaches.']","[0, 0, 0, 1, 0]","[0.1428571343421936, 0.3589743673801422, 0.09302324801683426, 0.5853658318519592, 0.1666666567325592]",rygw7aNYDS,"['We investigate the large-sample behaviors of the Q-value estimates and proposed an efficient exploration strategy that relies on estimating the relative discrepancies among the Q estimates. ', 'This paper presents a pure-exploration algorithm for reinforcement learning based on an asymptotic analysis of Q-values and their convergence to central limit distribution, outperforming benchmark exploration algorithms.']","['despite ever growing literature reinforcement learning algorithm application  much le known statistical inference ', 'paper  investigate largesample behavior qvalue estimate closedform characterization asymptotic variance ', 'allows u efficiently construct confidence region qvalue optimal value function  develop policy minimize estimation error ', 'also lead policy exploration strategy relies estimating relative discrepancy among q estimate ', 'numerical experiment show superior performance exploration strategy benchmark approach ']","Despite an ever growing literature on reinforcement learning algorithms and applications, much less is known about their statistical inference., In this paper, we investigate the large-sample behaviors of the Q-value estimates with closed-form characterizations of the asymptotic variances., This allows us to efficiently construct confidence regions for Q-value and optimal value functions, and to develop policies to minimize their estimation errors., This also leads to a policy exploration strategy that relies on estimating the relative discrepancies among the Q estimates., Numerical experiments show superior performances of our exploration strategy than other benchmark approaches.",8,6.344086021505376,11.625
572,"['We perform completely unsupervised one-sided image to image translation between a source domain $X$ and a target domain $Y$ such that we preserve relevant underlying shared semantics (e.g., class, size, shape, etc). \n', 'In particular, we are interested in a more difficult case than those typically addressed in the literature, where the source and target are ``far"" enough that reconstruction-style or pixel-wise approaches fail.\n', 'We argue that transferring (i.e., \\emph{translating}) said relevant information should involve both discarding source domain-specific information while incorporate target domain-specific information, the latter of which we model with a noisy prior distribution. \n', 'In order to avoid the degenerate case where the generated samples are only explained by the prior distribution, we propose to minimize an estimate of the mutual information between the generated sample and the sample from the prior distribution.', 'We discover that the architectural choices are an important factor to consider in order to preserve the shared semantic between $X$ and $Y$. \n', 'We show state of the art results on the MNIST to SVHN task for unsupervised image to image translation.']","[1, 0, 0, 0, 0, 0]","[0.3396226465702057, 0.23999999463558197, 0.29629629850387573, 0.3199999928474426, 0.2790697515010834, 0.2702702581882477]",B1GIQhCcYm,"['We train an image to image translation network that take as input the source image and a sample from a prior distribution to generate a sample from the target distribution', 'This paper formalizes the problem of unsupervised translation and proposes an augmented GAN framework which uses the mutual information to avoid the degenerate case', 'This paper formulates the problem of unsupervised one-to-many image translation and addresses the problem by minimizing the mutual information. ']","['perform completely unsupervised onesided image image translation source domain  x  target domain   preserve relevant underlying shared semantics  eg  class  size  shape  etc  ', 'particular  interested difficult case typically addressed literature  source target  far  enough reconstructionstyle pixelwise approach fail ', 'argue transferring  ie  emph  translating   said relevant information involve discarding source domainspecific information incorporate target domainspecific information  latter model noisy prior distribution ', 'order avoid degenerate case generated sample explained prior distribution  propose minimize estimate mutual information generated sample sample prior distribution ', 'discover architectural choice important factor consider order preserve shared semantic  x    ', 'show state art result mnist svhn task unsupervised image image translation ']","We perform completely unsupervised one-sided image to image translation between a source domain $X$ and a target domain $Y$ such that we preserve relevant underlying shared semantics (e.g., class, size, shape, etc). 
, In particular, we are interested in a more difficult case than those typically addressed in the literature, where the source and target are ``far"" enough that reconstruction-style or pixel-wise approaches fail.
, We argue that transferring (i.e., \emph{translating}) said relevant information should involve both discarding source domain-specific information while incorporate target domain-specific information, the latter of which we model with a noisy prior distribution. 
, In order to avoid the degenerate case where the generated samples are only explained by the prior distribution, we propose to minimize an estimate of the mutual information between the generated sample and the sample from the prior distribution., We discover that the architectural choices are an important factor to consider in order to preserve the shared semantic between $X$ and $Y$. 
, We show state of the art results on the MNIST to SVHN task for unsupervised image to image translation.",15,5.653409090909091,11.733333333333333
573,"['Identifying salient points in images is a crucial component for visual odometry, Structure-from-Motion or SLAM algorithms.', 'Recently, several learned keypoint methods have demonstrated compelling performance on challenging benchmarks.  ', 'However, generating consistent and accurate training data for interest-point detection in natural images still remains challenging, especially for human annotators.', 'We introduce IO-Net (i.e. InlierOutlierNet), a novel proxy task for the self-supervision of keypoint detection, description and matching.', 'By making the sampling of inlier-outlier sets from point-pair correspondences fully differentiable within the keypoint learning framework, we show that are able to simultaneously self-supervise keypoint description and improve keypoint matching.', 'Second, we introduce KeyPointNet, a keypoint-network architecture that is especially amenable to robust keypoint detection and description.', 'We design the network to allow local keypoint aggregation to avoid artifacts due to spatial discretizations commonly used for this task, and we improve fine-grained keypoint descriptor performance by taking advantage of efficient sub-pixel convolutions to upsample the descriptor feature-maps to a higher operating resolution.', 'Through extensive experiments and ablative analysis, we show that the proposed self-supervised keypoint learning method greatly improves the quality of feature matching and homography estimation on challenging benchmarks over the state-of-the-art.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.07407406717538834, 0.0, 0.0, 0.13333332538604736, 0.10256409645080566, 0.1428571343421936, 0.12244897335767746, 0.0]",Skx82ySYPH,"['Learning to extract distinguishable keypoints from a proxy task, outlier rejection.', 'This paper is devoted to the self-supervised learning of local features using Neural Guided RANSAC as an additional auxillary loss provider for improving descriptor interpolation.']","['identifying salient point image crucial component visual odometry  structurefrommotion slam algorithm ', 'recently  several learned keypoint method demonstrated compelling performance challenging benchmark ', 'however  generating consistent accurate training data interestpoint detection natural image still remains challenging  especially human annotator ', 'introduce ionet  ie  inlieroutliernet   novel proxy task selfsupervision keypoint detection  description matching ', 'making sampling inlieroutlier set pointpair correspondence fully differentiable within keypoint learning framework  show able simultaneously selfsupervise keypoint description improve keypoint matching ', 'second  introduce keypointnet  keypointnetwork architecture especially amenable robust keypoint detection description ', 'design network allow local keypoint aggregation avoid artifact due spatial discretizations commonly used task  improve finegrained keypoint descriptor performance taking advantage efficient subpixel convolution upsample descriptor featuremaps higher operating resolution ', 'extensive experiment ablative analysis  show proposed selfsupervised keypoint learning method greatly improves quality feature matching homography estimation challenging benchmark stateoftheart ']","Identifying salient points in images is a crucial component for visual odometry, Structure-from-Motion or SLAM algorithms., Recently, several learned keypoint methods have demonstrated compelling performance on challenging benchmarks.  , However, generating consistent and accurate training data for interest-point detection in natural images still remains challenging, especially for human annotators., We introduce IO-Net (i.e. InlierOutlierNet), a novel proxy task for the self-supervision of keypoint detection, description and matching., By making the sampling of inlier-outlier sets from point-pair correspondences fully differentiable within the keypoint learning framework, we show that are able to simultaneously self-supervise keypoint description and improve keypoint matching., Second, we introduce KeyPointNet, a keypoint-network architecture that is especially amenable to robust keypoint detection and description., We design the network to allow local keypoint aggregation to avoid artifacts due to spatial discretizations commonly used for this task, and we improve fine-grained keypoint descriptor performance by taking advantage of efficient sub-pixel convolutions to upsample the descriptor feature-maps to a higher operating resolution., Through extensive experiments and ablative analysis, we show that the proposed self-supervised keypoint learning method greatly improves the quality of feature matching and homography estimation on challenging benchmarks over the state-of-the-art.",19,6.826315789473684,9.5
574,"['We study the role of intrinsic motivation as an exploration bias for reinforcement learning in sparse-reward synergistic tasks, which are tasks where multiple agents must work together to achieve a goal they could not individually.', 'Our key idea is that a good guiding principle for intrinsic motivation in synergistic tasks is to take actions which affect the world in ways that would not be achieved if the agents were acting on their own.', 'Thus, we propose to incentivize agents to take (joint) actions whose effects cannot be predicted via a composition of the predicted effect for each individual agent.', 'We study two instantiations of this idea, one based on the true states encountered, and another based on a dynamics model trained concurrently with the policy.', 'While the former is simpler, the latter has the benefit of being analytically differentiable with respect to the action taken.', 'We validate our approach in robotic bimanual manipulation tasks with sparse rewards; we find that our approach yields more efficient learning than both', '1) training with only the sparse reward and', '2) using the typical surprise-based formulation of intrinsic motivation, which does not bias toward synergistic behavior.', 'Videos are available on the project webpage: https://sites.google.com/view/iclr2020-synergistic.']","[0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.5352112650871277, 0.5714285373687744, 0.23333333432674408, 0.1355932205915451, 0.15094339847564697, 0.10526315122842789, 0.045454543083906174, 0.26923075318336487, 0.043478257954120636]",SJleNCNtDH,"['We propose a formulation of intrinsic motivation that is suitable as an exploration bias in multi-agent sparse-reward synergistic tasks, by encouraging agents to affect the world in ways that would not be achieved if they were acting individually.', 'The paper focuses on using intrinsic motivation to improve the exploration process of reinforcement learning agents in tasks that require multi-agent to achieve.']","['study role intrinsic motivation exploration bias reinforcement learning sparsereward synergistic task  task multiple agent must work together achieve goal could individually ', 'key idea good guiding principle intrinsic motivation synergistic task take action affect world way would achieved agent acting ', 'thus  propose incentivize agent take  joint  action whose effect predicted via composition predicted effect individual agent ', 'study two instantiation idea  one based true state encountered  another based dynamic model trained concurrently policy ', 'former simpler  latter benefit analytically differentiable respect action taken ', 'validate approach robotic bimanual manipulation task sparse reward  find approach yield efficient learning', '1  training sparse reward', '2  using typical surprisebased formulation intrinsic motivation  bias toward synergistic behavior ', 'video available project webpage  http  sitesgooglecomviewiclr2020synergistic ']","We study the role of intrinsic motivation as an exploration bias for reinforcement learning in sparse-reward synergistic tasks, which are tasks where multiple agents must work together to achieve a goal they could not individually., Our key idea is that a good guiding principle for intrinsic motivation in synergistic tasks is to take actions which affect the world in ways that would not be achieved if the agents were acting on their own., Thus, we propose to incentivize agents to take (joint) actions whose effects cannot be predicted via a composition of the predicted effect for each individual agent., We study two instantiations of this idea, one based on the true states encountered, and another based on a dynamics model trained concurrently with the policy., While the former is simpler, the latter has the benefit of being analytically differentiable with respect to the action taken., We validate our approach in robotic bimanual manipulation tasks with sparse rewards; we find that our approach yields more efficient learning than both, 1) training with only the sparse reward and, 2) using the typical surprise-based formulation of intrinsic motivation, which does not bias toward synergistic behavior., Videos are available on the project webpage: https://sites.google.com/view/iclr2020-synergistic.",15,5.515,13.333333333333334
575,"['A general graph-structured neural network architecture operates on graphs through two core components: (1) complex enough message functions; (2) a fixed information aggregation process.', 'In this paper, we present the Policy Message Passing algorithm, which takes a probabilistic perspective and reformulates the whole information aggregation as stochastic sequential processes.', 'The algorithm works on a much larger search space, utilizes reasoning history to perform inference, and is robust to noisy edges.', 'We apply our algorithm to multiple complex graph reasoning and prediction tasks and show that our algorithm consistently outperforms state-of-the-art graph-structured models by a significant margin.']","[0, 0, 0, 1]","[0.17142856121063232, 0.05714285373687744, 0.06451612710952759, 0.23529411852359772]",rklxF0NtDr,"['An probabilistic inference algorithm driven by neural network for graph-structured models', 'This paper introduces policy message passing, a graph neural network with an inference mechanism that assigns messages to edges in a recurrent fashion, indicating competitive performance on visual reasoning tasks.']","['general graphstructured neural network architecture operates graph two core component   1  complex enough message function   2  fixed information aggregation process ', 'paper  present policy message passing algorithm  take probabilistic perspective reformulates whole information aggregation stochastic sequential process ', 'algorithm work much larger search space  utilizes reasoning history perform inference  robust noisy edge ', 'apply algorithm multiple complex graph reasoning prediction task show algorithm consistently outperforms stateoftheart graphstructured model significant margin ']","A general graph-structured neural network architecture operates on graphs through two core components: (1) complex enough message functions; (2) a fixed information aggregation process., In this paper, we present the Policy Message Passing algorithm, which takes a probabilistic perspective and reformulates the whole information aggregation as stochastic sequential processes., The algorithm works on a much larger search space, utilizes reasoning history to perform inference, and is robust to noisy edges., We apply our algorithm to multiple complex graph reasoning and prediction tasks and show that our algorithm consistently outperforms state-of-the-art graph-structured models by a significant margin.",8,6.3125,12.0
576,"['Deep multitask networks, in which one neural network produces multiple predictive outputs, are more scalable and often better regularized than their single-task counterparts.', 'Such advantages can potentially lead to gains in both speed and performance, but multitask networks are also difficult to train without finding the right balance between tasks.', 'We present a novel gradient normalization (GradNorm) technique which automatically balances the multitask loss function by directly tuning the gradients to equalize task training rates.', 'We show that for various network architectures, for both regression and classification tasks, and on both synthetic and real datasets, GradNorm improves accuracy and reduces overfitting over single networks, static baselines, and other adaptive multitask loss balancing techniques.', 'GradNorm also matches or surpasses the performance of exhaustive grid search methods, despite only involving a single asymmetry hyperparameter $\\alpha$.', 'Thus, what was once a tedious search process which incurred exponentially more compute for each task added can now be accomplished within a few training runs, irrespective of the number of tasks.', 'Ultimately, we hope to demonstrate that gradient manipulation affords us great control over the training dynamics of multitask networks and may be one of the keys to unlocking the potential of multitask learning.']","[0, 0, 1, 0, 0, 0, 0]","[0.12765957415103912, 0.11999999731779099, 0.375, 0.2857142686843872, 0.09090908616781235, 0.07407406717538834, 0.07843136787414551]",H1bM1fZCW,"['We show how you can boost performance in a multitask network by tuning an adaptive multitask loss function that is learned through directly balancing network gradients.', 'This work proposes a dynamic weight update scheme that updates weights for different task losses during training time by making use of the loss ratios of different tasks.']","['deep multitask network  one neural network produce multiple predictive output  scalable often better regularized singletask counterpart ', 'advantage potentially lead gain speed performance  multitask network also difficult train without finding right balance task ', 'present novel gradient normalization  gradnorm  technique automatically balance multitask loss function directly tuning gradient equalize task training rate ', 'show various network architecture  regression classification task  synthetic real datasets  gradnorm improves accuracy reduces overfitting single network  static baseline  adaptive multitask loss balancing technique ', 'gradnorm also match surpasses performance exhaustive grid search method  despite involving single asymmetry hyperparameter  alpha  ', 'thus  tedious search process incurred exponentially compute task added accomplished within training run  irrespective number task ', 'ultimately  hope demonstrate gradient manipulation affords u great control training dynamic multitask network may one key unlocking potential multitask learning ']","Deep multitask networks, in which one neural network produces multiple predictive outputs, are more scalable and often better regularized than their single-task counterparts., Such advantages can potentially lead to gains in both speed and performance, but multitask networks are also difficult to train without finding the right balance between tasks., We present a novel gradient normalization (GradNorm) technique which automatically balances the multitask loss function by directly tuning the gradients to equalize task training rates., We show that for various network architectures, for both regression and classification tasks, and on both synthetic and real datasets, GradNorm improves accuracy and reduces overfitting over single networks, static baselines, and other adaptive multitask loss balancing techniques., GradNorm also matches or surpasses the performance of exhaustive grid search methods, despite only involving a single asymmetry hyperparameter $\alpha$., Thus, what was once a tedious search process which incurred exponentially more compute for each task added can now be accomplished within a few training runs, irrespective of the number of tasks., Ultimately, we hope to demonstrate that gradient manipulation affords us great control over the training dynamics of multitask networks and may be one of the keys to unlocking the potential of multitask learning.",19,5.91919191919192,10.421052631578947
577,"['Image segmentation aims at grouping pixels that belong to the same object or region.', 'At the heart of image segmentation lies the problem of determining whether a pixel is inside or outside a region, which we denote as the ""insideness"" problem.', 'Many Deep Neural Networks (DNNs) variants excel in segmentation benchmarks, but regarding insideness, they have not been well visualized or understood: What representations do DNNs use to address the long-range relationships of insideness?', 'How do architectural choices affect the learning of these representations?', 'In this paper, we take the reductionist approach by analyzing DNNs solving the insideness problem in isolation, i.e. determining the inside of closed (Jordan) curves.', 'We demonstrate analytically that state-of-the-art feed-forward and recurrent architectures can implement solutions of the insideness problem for any given curve.', 'Yet, only recurrent networks could  learn these general solutions when the training enforced a specific ""routine"" capable of breaking down the long-range relationships.', 'Our results highlights the need for new training strategies that decompose the learning into appropriate stages, and that lead to the general class of solutions necessary for DNNs to understand insideness.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.10526315122842789, 0.260869562625885, 0.17543859779834747, 0.11764705181121826, 0.2083333283662796, 0.40909090638160706, 0.3913043439388275, 0.23999999463558197]",ryevtyHtPr,"['DNNs for image segmentation can implement solutions for the insideness problem but only some recurrent nets could learn them with a specific type of supervision.', 'This paper introduces insideness to study semantic segmentation in deep learning era, and the results can help models generalize better.']","['image segmentation aim grouping pixel belong object region ', 'heart image segmentation lie problem determining whether pixel inside outside region  denote  insideness  problem ', 'many deep neural network  dnns  variant excel segmentation benchmark  regarding insideness  well visualized understood  representation dnns use address longrange relationship insideness ', 'architectural choice affect learning representation ', 'paper  take reductionist approach analyzing dnns solving insideness problem isolation  ie  determining inside closed  jordan  curve ', 'demonstrate analytically stateoftheart feedforward recurrent architecture implement solution insideness problem given curve ', 'yet  recurrent network could learn general solution training enforced specific  routine  capable breaking longrange relationship ', 'result highlight need new training strategy decompose learning appropriate stage  lead general class solution necessary dnns understand insideness ']","Image segmentation aims at grouping pixels that belong to the same object or region., At the heart of image segmentation lies the problem of determining whether a pixel is inside or outside a region, which we denote as the ""insideness"" problem., Many Deep Neural Networks (DNNs) variants excel in segmentation benchmarks, but regarding insideness, they have not been well visualized or understood: What representations do DNNs use to address the long-range relationships of insideness?, How do architectural choices affect the learning of these representations?, In this paper, we take the reductionist approach by analyzing DNNs solving the insideness problem in isolation, i.e. determining the inside of closed (Jordan) curves., We demonstrate analytically that state-of-the-art feed-forward and recurrent architectures can implement solutions of the insideness problem for any given curve., Yet, only recurrent networks could  learn these general solutions when the training enforced a specific ""routine"" capable of breaking down the long-range relationships., Our results highlights the need for new training strategies that decompose the learning into appropriate stages, and that lead to the general class of solutions necessary for DNNs to understand insideness.",15,5.85792349726776,11.4375
578,"['We address the challenging problem of deep representation learning--the efficient adaption of a pre-trained deep network to different tasks.', 'Specifically, we propose to explore gradient-based features.', 'These features are gradients of the model parameters with respect to a task-specific loss given an input sample.', 'Our key innovation is the design of a linear model that incorporates both gradient features and the activation of the network.', 'We show that our model provides a local linear approximation to a underlying deep model, and discuss important theoretical insight.', 'Moreover, we present an efficient algorithm for the training and inference of our model without computing the actual gradients.', 'Our method is evaluated across a number of representation learning tasks on several datasets and using different network architectures.', 'We demonstrate strong results in all settings.', 'And our results are well-aligned with our theoretical insight.']","[0, 0, 1, 0, 0, 0, 0, 0, 0]","[0.25641024112701416, 0.13793103396892548, 0.4000000059604645, 0.4000000059604645, 0.3414634168148041, 0.29999998211860657, 0.1463414579629898, 0.0, 0.0]",BkeoaeHKDS,"['Given a pre-trained model, we explored the per-sample gradients of the model parameters relative to a task-specific loss, and constructed a linear model that combines gradients of model parameters and the activation of the model.', 'This paper proposes to use the gradients of specific layers of convolutional networks as features in a linearized model for transfer learning and fast adaptation.']","['address challenging problem deep representation learning  efficient adaption pretrained deep network different task ', 'specifically  propose explore gradientbased feature ', 'feature gradient model parameter respect taskspecific loss given input sample ', 'key innovation design linear model incorporates gradient feature activation network ', 'show model provides local linear approximation underlying deep model  discus important theoretical insight ', 'moreover  present efficient algorithm training inference model without computing actual gradient ', 'method evaluated across number representation learning task several datasets using different network architecture ', 'demonstrate strong result setting ', 'result wellaligned theoretical insight ']","We address the challenging problem of deep representation learning--the efficient adaption of a pre-trained deep network to different tasks., Specifically, we propose to explore gradient-based features., These features are gradients of the model parameters with respect to a task-specific loss given an input sample., Our key innovation is the design of a linear model that incorporates both gradient features and the activation of the network., We show that our model provides a local linear approximation to a underlying deep model, and discuss important theoretical insight., Moreover, we present an efficient algorithm for the training and inference of our model without computing the actual gradients., Our method is evaluated across a number of representation learning tasks on several datasets and using different network architectures., We demonstrate strong results in all settings., And our results are well-aligned with our theoretical insight.",12,5.798561151079137,11.583333333333334
579,"['Recovering 3D geometry shape, albedo and lighting from a single image has wide applications in many areas, which is also a typical ill-posed problem.', 'In order to eliminate the ambiguity, face prior knowledge like linear 3D morphable models (3DMM) learned from limited scan data are often adopted to the reconstruction process.', 'However, methods based on linear parametric models cannot generalize well for facial images in the wild with various ages, ethnicity, expressions, poses, and lightings.', 'Recent methods aim to learn a nonlinear parametric model using convolutional neural networks (CNN) to regress the face shape and texture directly.', 'However, the models were only trained on a dataset that is generated from a linear 3DMM.', 'Moreover, the identity and expression representations are entangled in these models, which hurdles many facial editing applications.', 'In this paper, we train our model with adversarial loss in a semi-supervised manner on hybrid batches of unlabeled and labeled face images to exploit the value of large amounts of unlabeled face images from unconstrained photo collections.', 'A novel center loss is introduced to make sure that different facial images from the same person have the same identity shape and albedo.', 'Besides, our proposed model disentangles identity, expression, pose, and lighting representations, which improves the overall reconstruction performance and facilitates facial editing applications, e.g., expression transfer.', 'Comprehensive experiments demonstrate that our model produces high-quality reconstruction compared to state-of-the-art methods and is robust to various expression, pose, and lighting conditions.\n']","[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]","[0.11320754140615463, 0.1818181723356247, 0.2222222238779068, 0.19607841968536377, 0.13333332538604736, 0.12765957415103912, 0.8888888955116272, 0.23076923191547394, 0.178571417927742, 0.19230768084526062]",H1lK5kBKvr,"['We train our face reconstruction model with adversarial loss in semi-supervised manner on hybrid batches of unlabeled and labeled face images to exploit the value of large amounts of unlabeled face images from unconstrained photo collections.', 'This paper proposes a semi-supervised and adversarial training process to exact nonlinear disentangled representations from a face image with loss functions, achieving state-of-the-art performance in face reconstruction.']","['recovering 3d geometry shape  albedo lighting single image wide application many area  also typical illposed problem ', 'order eliminate ambiguity  face prior knowledge like linear 3d morphable model  3dmm  learned limited scan data often adopted reconstruction process ', 'however  method based linear parametric model generalize well facial image wild various age  ethnicity  expression  pose  lighting ', 'recent method aim learn nonlinear parametric model using convolutional neural network  cnn  regress face shape texture directly ', 'however  model trained dataset generated linear 3dmm ', 'moreover  identity expression representation entangled model  hurdle many facial editing application ', 'paper  train model adversarial loss semisupervised manner hybrid batch unlabeled labeled face image exploit value large amount unlabeled face image unconstrained photo collection ', 'novel center loss introduced make sure different facial image person identity shape albedo ', 'besides  proposed model disentangles identity  expression  pose  lighting representation  improves overall reconstruction performance facilitates facial editing application  eg  expression transfer ', 'comprehensive experiment demonstrate model produce highquality reconstruction compared stateoftheart method robust various expression  pose  lighting condition ']","Recovering 3D geometry shape, albedo and lighting from a single image has wide applications in many areas, which is also a typical ill-posed problem., In order to eliminate the ambiguity, face prior knowledge like linear 3D morphable models (3DMM) learned from limited scan data are often adopted to the reconstruction process., However, methods based on linear parametric models cannot generalize well for facial images in the wild with various ages, ethnicity, expressions, poses, and lightings., Recent methods aim to learn a nonlinear parametric model using convolutional neural networks (CNN) to regress the face shape and texture directly., However, the models were only trained on a dataset that is generated from a linear 3DMM., Moreover, the identity and expression representations are entangled in these models, which hurdles many facial editing applications., In this paper, we train our model with adversarial loss in a semi-supervised manner on hybrid batches of unlabeled and labeled face images to exploit the value of large amounts of unlabeled face images from unconstrained photo collections., A novel center loss is introduced to make sure that different facial images from the same person have the same identity shape and albedo., Besides, our proposed model disentangles identity, expression, pose, and lighting representations, which improves the overall reconstruction performance and facilitates facial editing applications, e.g., expression transfer., Comprehensive experiments demonstrate that our model produces high-quality reconstruction compared to state-of-the-art methods and is robust to various expression, pose, and lighting conditions.
",31,5.841666666666667,7.741935483870968
580,"['Human conversations naturally evolve around related entities and connected concepts, while may also shift from topic to topic.', 'This paper presents ConceptFlow, which leverages commonsense knowledge graphs to explicitly model such conversation flows for better conversation response generation.', 'ConceptFlow grounds the conversation inputs to the latent concept space and represents the potential conversation flow as a concept flow along the commonsense relations.', 'The concept is guided by a graph attention mechanism that models the possibility of the conversation evolving towards different concepts.', 'The conversation response is then decoded using the encodings of both utterance texts and concept flows, integrating the learned conversation structure in the concept space.', 'Our experiments on Reddit conversations demonstrate the advantage of ConceptFlow over previous commonsense aware dialog models and fine-tuned GPT-2 models, while using much fewer parameters but with explicit modeling of conversation structures.']","[0, 1, 0, 0, 0, 0]","[0.0, 0.555555522441864, 0.2857142686843872, 0.277777761220932, 0.15789473056793213, 0.2083333283662796]",B1lOzpVtDB,"['This paper presents ConceptFlow that explicitly models the conversation flow in commonsense knowledge graph for better conversation generation.', 'The paper proposes a system for generating a single-turn response to a posted utterance in an open-domain dialog setting using the diffiusion into the neighbors of the grounded concepts.']","['human conversation naturally evolve around related entity connected concept  may also shift topic topic ', 'paper present conceptflow  leverage commonsense knowledge graph explicitly model conversation flow better conversation response generation ', 'conceptflow ground conversation input latent concept space represents potential conversation flow concept flow along commonsense relation ', 'concept guided graph attention mechanism model possibility conversation evolving towards different concept ', 'conversation response decoded using encoding utterance text concept flow  integrating learned conversation structure concept space ', 'experiment reddit conversation demonstrate advantage conceptflow previous commonsense aware dialog model finetuned gpt2 model  using much fewer parameter explicit modeling conversation structure ']","Human conversations naturally evolve around related entities and connected concepts, while may also shift from topic to topic., This paper presents ConceptFlow, which leverages commonsense knowledge graphs to explicitly model such conversation flows for better conversation response generation., ConceptFlow grounds the conversation inputs to the latent concept space and represents the potential conversation flow as a concept flow along the commonsense relations., The concept is guided by a graph attention mechanism that models the possibility of the conversation evolving towards different concepts., The conversation response is then decoded using the encodings of both utterance texts and concept flows, integrating the learned conversation structure in the concept space., Our experiments on Reddit conversations demonstrate the advantage of ConceptFlow over previous commonsense aware dialog models and fine-tuned GPT-2 models, while using much fewer parameters but with explicit modeling of conversation structures.",10,6.316546762589928,13.9
581,"['Biological neural networks face homeostatic and resource constraints that restrict the allowed configurations of connection weights.', 'If a constraint is tight it defines a very small solution space, and the size of these constraint spaces determines their potential overlap with the solutions for computational tasks.', ""We study the geometry of the solution spaces for constraints on neurons' total synaptic weight and on individual synaptic weights, characterizing the connection degrees (numbers of partners) that maximize the size of these solution spaces."", ""We then hypothesize that the size of constraints' solution spaces could serve as a cost function governing neural circuit development."", 'We develop analytical approximations and bounds for the model evidence of the maximum entropy degree distributions under these cost functions.', 'We test these on a published electron microscopic connectome of an associative learning center in the fly brain, finding evidence for a developmental progression in circuit structure.']","[0, 0, 0, 1, 0, 0]","[0.2857142686843872, 0.23076923191547394, 0.38461539149284363, 0.6521739363670349, 0.2666666507720947, 0.2745097875595093]",SyeWE7tU8H,"['We examine the hypothesis that the entropy of solution spaces for constraints on synaptic weights (the ""flexibility"" of the constraint) could serve as a cost function for neural circuit development.']","['biological neural network face homeostatic resource constraint restrict allowed configuration connection weight ', 'constraint tight defines small solution space  size constraint space determines potential overlap solution computational task ', 'study geometry solution space constraint neuron  total synaptic weight individual synaptic weight  characterizing connection degree  number partner  maximize size solution space ', 'hypothesize size constraint  solution space could serve cost function governing neural circuit development ', 'develop analytical approximation bound model evidence maximum entropy degree distribution cost function ', 'test published electron microscopic connectome associative learning center fly brain  finding evidence developmental progression circuit structure ']","Biological neural networks face homeostatic and resource constraints that restrict the allowed configurations of connection weights., If a constraint is tight it defines a very small solution space, and the size of these constraint spaces determines their potential overlap with the solutions for computational tasks., We study the geometry of the solution spaces for constraints on neurons' total synaptic weight and on individual synaptic weights, characterizing the connection degrees (numbers of partners) that maximize the size of these solution spaces., We then hypothesize that the size of constraints' solution spaces could serve as a cost function governing neural circuit development., We develop analytical approximations and bounds for the model evidence of the maximum entropy degree distributions under these cost functions., We test these on a published electron microscopic connectome of an associative learning center in the fly brain, finding evidence for a developmental progression in circuit structure.",9,5.91156462585034,16.333333333333332
582,"['In  this  preliminary  work,  we  study  the  generalization  properties  of  infinite  ensembles  of infinitely-wide neural networks.  ', 'Amazingly, this model family admits tractable calculations for many information-theoretic quantities.  ', 'We report analytical and empirical investigations in the search for signals that correlate with generalization.']","[1, 0, 0]","[0.25, 0.1428571343421936, 0.0]",rJgv9J3NKH,['Infinite ensembles of infinitely wide neural networks are an interesting model family from an information theoretic perspective.'],"['preliminary work  study generalization property infinite ensemble infinitelywide neural network ', 'amazingly  model family admits tractable calculation many informationtheoretic quantity ', 'report analytical empirical investigation search signal correlate generalization ']","In  this  preliminary  work,  we  study  the  generalization  properties  of  infinite  ensembles  of infinitely-wide neural networks.  , Amazingly, this model family admits tractable calculations for many information-theoretic quantities.  , We report analytical and empirical investigations in the search for signals that correlate with generalization.",5,6.976190476190476,8.4
583,"['Learning multilingual representations of text has proven a successful method for many cross-lingual transfer learning tasks.', 'There are two main paradigms for learning such representations: (1) alignment, which maps different independently trained monolingual representations into a shared space, and (2) joint training, which directly learns unified multilingual representations using monolingual and cross-lingual objectives jointly.', 'In this paper, we first conduct direct comparisons of representations learned using both of these methods across diverse cross-lingual tasks.', 'Our empirical results reveal a set of pros and cons for both methods, and show that the relative performance of alignment versus joint training is task-dependent.', 'Stemming from this analysis, we propose a simple and novel framework that combines these two previously mutually-exclusive approaches.', 'Extensive experiments on various tasks demonstrate that our proposed framework alleviates limitations of both approaches, and outperforms existing methods on the MUSE bilingual lexicon induction (BLI) benchmark.', 'We further show that our proposed framework can generalize to contextualized representations and achieves state-of-the-art results on the CoNLL cross-lingual NER benchmark.']","[0, 0, 0, 0, 1, 0, 0]","[0.1538461446762085, 0.21052631735801697, 0.2380952388048172, 0.25531914830207825, 0.2926829159259796, 0.16326530277729034, 0.17777776718139648]",S1l-C0NtwS,"['We conduct a comparative study of cross-lingual alignment vs joint training methods and unify these two previously exclusive paradigms in a new framework. ', 'This paper compares approaches to bilingual lexicon induction and shows which method performs better on lexicon, induction, and NER and MT tasks.']","['learning multilingual representation text proven successful method many crosslingual transfer learning task ', 'two main paradigm learning representation   1  alignment  map different independently trained monolingual representation shared space   2  joint training  directly learns unified multilingual representation using monolingual crosslingual objective jointly ', 'paper  first conduct direct comparison representation learned using method across diverse crosslingual task ', 'empirical result reveal set pro con method  show relative performance alignment versus joint training taskdependent ', 'stemming analysis  propose simple novel framework combine two previously mutuallyexclusive approach ', 'extensive experiment various task demonstrate proposed framework alleviates limitation approach  outperforms existing method muse bilingual lexicon induction  bli  benchmark ', 'show proposed framework generalize contextualized representation achieves stateoftheart result conll crosslingual ner benchmark ']","Learning multilingual representations of text has proven a successful method for many cross-lingual transfer learning tasks., There are two main paradigms for learning such representations: (1) alignment, which maps different independently trained monolingual representations into a shared space, and (2) joint training, which directly learns unified multilingual representations using monolingual and cross-lingual objectives jointly., In this paper, we first conduct direct comparisons of representations learned using both of these methods across diverse cross-lingual tasks., Our empirical results reveal a set of pros and cons for both methods, and show that the relative performance of alignment versus joint training is task-dependent., Stemming from this analysis, we propose a simple and novel framework that combines these two previously mutually-exclusive approaches., Extensive experiments on various tasks demonstrate that our proposed framework alleviates limitations of both approaches, and outperforms existing methods on the MUSE bilingual lexicon induction (BLI) benchmark., We further show that our proposed framework can generalize to contextualized representations and achieves state-of-the-art results on the CoNLL cross-lingual NER benchmark.",14,6.502994011976048,11.928571428571429
584,"['Large number of weights in deep neural networks make the models difficult to be deployed in low memory environments such as, mobile phones, IOT edge devices as well as ""inferencing as a service"" environments on the cloud. \n', 'Prior work has considered reduction in the size of the models, through compression techniques like weight pruning, filter pruning, etc. or through low-rank decomposition of the convolution layers.\n\n', 'In this paper, we demonstrate the use of multiple techniques to achieve not only higher model compression but also reduce the compute resources required during inferencing.', 'We do filter pruning followed by low-rank decomposition using Tucker decomposition for model compression.\n\n', 'We show that our approach achieves upto 57\\% higher model compression when compared to either Tucker Decomposition or Filter pruning alone  at similar accuracy for GoogleNet.', 'Also, it reduces the Flops by upto 48\\% thereby making the inferencing faster.']","[0, 0, 1, 0, 0, 0]","[0.15686273574829102, 0.2857142686843872, 0.3720930218696594, 0.1249999925494194, 0.13636362552642822, 0.06666666269302368]",SJeBwn2usm,"['Combining orthogonal model compression techniques to get significant reduction in model size and number of flops required during inferencing.', 'This paper proposes combining Tucker Decomposition with Filter pruning.']","['large number weight deep neural network make model difficult deployed low memory environment  mobile phone  iot edge device well  inferencing service  environment cloud ', 'prior work considered reduction size model  compression technique like weight pruning  filter pruning  etc  lowrank decomposition convolution layer ', 'paper  demonstrate use multiple technique achieve higher model compression also reduce compute resource required inferencing ', 'filter pruning followed lowrank decomposition using tucker decomposition model compression ', 'show approach achieves upto 57  higher model compression compared either tucker decomposition filter pruning alone similar accuracy googlenet ', 'also  reduces flop upto 48  thereby making inferencing faster ']","Large number of weights in deep neural networks make the models difficult to be deployed in low memory environments such as, mobile phones, IOT edge devices as well as ""inferencing as a service"" environments on the cloud. 
, Prior work has considered reduction in the size of the models, through compression techniques like weight pruning, filter pruning, etc. or through low-rank decomposition of the convolution layers.

, In this paper, we demonstrate the use of multiple techniques to achieve not only higher model compression but also reduce the compute resources required during inferencing., We do filter pruning followed by low-rank decomposition using Tucker decomposition for model compression.

, We show that our approach achieves upto 57\% higher model compression when compared to either Tucker Decomposition or Filter pruning alone  at similar accuracy for GoogleNet., Also, it reduces the Flops by upto 48\% thereby making the inferencing faster.",13,5.555555555555555,10.285714285714286
585,"['We review the limitations of BLEU and ROUGE -- the most popular metrics used to assess reference summaries against hypothesis summaries, and introduce JAUNE:  a set of criteria for what a good metric should behave like and propose concrete ways to use recent Transformers-based Language Models to assess reference summaries against hypothesis summaries.\n\n']",[1],[0.27586206793785095],r1gx60NKPS,"['Introduces JAUNE: a methodology to replace BLEU and ROUGE score with multidimensional, model-based evaluators for assessing summaries', 'This paper proposes a new JAUNE metric for the evaluation of machine translation and text summarization systems, showing that their model corresponds better to ground truth similarity labels than BLEU.']",['review limitation bleu rouge  popular metric used ass reference summary hypothesis summary  introduce jaune  set criterion good metric behave like propose concrete way use recent transformersbased language model ass reference summary hypothesis summary '],"We review the limitations of BLEU and ROUGE -- the most popular metrics used to assess reference summaries against hypothesis summaries, and introduce JAUNE:  a set of criteria for what a good metric should behave like and propose concrete ways to use recent Transformers-based Language Models to assess reference summaries against hypothesis summaries.

",2,5.6415094339622645,26.5
586,"['This paper presents a new Graph Neural Network (GNN) type using feature-wise linear modulation (FiLM).', ""Many standard GNN variants propagate information along the edges of a graph by computing ``messages'' based only on the representation of the source of each edge."", 'In GNN-FiLM, the representation of the target node of an edge is additionally used to compute a transformation that can be applied to all incoming messages, allowing feature-wise modulation of the passed information.\n\n', 'Results of experiments comparing different GNN architectures on three tasks from the literature are presented, based on re-implementations of baseline methods.', 'Hyperparameters for all methods were found using extensive search, yielding somewhat surprising results: differences between baseline models are smaller than reported in the literature.', 'Nonetheless, GNN-FiLM outperforms baseline methods on a regression task on molecular graphs and performs competitively on other tasks.\n']","[0, 0, 0, 0, 1, 0]","[0.06896550953388214, 0.0555555522441864, 0.0, 0.12121211737394333, 0.31578946113586426, 0.0]",HJe4Cp4KwH,"['new GNN formalism + extensive experiments; showing differences between GGNN/GCN/GAT are smaller than thought', 'The paper proposes a new Graph Neural Network architecture that uses Feature-wise Linear Modulation to condition the source-to-target node message-passing based on the target node representation.']","['paper present new graph neural network  gnn  type using featurewise linear modulation  film  ', 'many standard gnn variant propagate information along edge graph computing  message  based representation source edge ', 'gnnfilm  representation target node edge additionally used compute transformation applied incoming message  allowing featurewise modulation passed information ', 'result experiment comparing different gnn architecture three task literature presented  based reimplementations baseline method ', 'hyperparameters method found using extensive search  yielding somewhat surprising result  difference baseline model smaller reported literature ', 'nonetheless  gnnfilm outperforms baseline method regression task molecular graph performs competitively task ']","This paper presents a new Graph Neural Network (GNN) type using feature-wise linear modulation (FiLM)., Many standard GNN variants propagate information along the edges of a graph by computing ``messages'' based only on the representation of the source of each edge., In GNN-FiLM, the representation of the target node of an edge is additionally used to compute a transformation that can be applied to all incoming messages, allowing feature-wise modulation of the passed information.

, Results of experiments comparing different GNN architectures on three tasks from the literature are presented, based on re-implementations of baseline methods., Hyperparameters for all methods were found using extensive search, yielding somewhat surprising results: differences between baseline models are smaller than reported in the literature., Nonetheless, GNN-FiLM outperforms baseline methods on a regression task on molecular graphs and performs competitively on other tasks.
",11,6.0,12.454545454545455
587,"['To deal simultaneously with both, the attributed network embedding and clustering, we propose a new model.', 'It exploits both content and structure information, capitalising on their simultaneous use.', 'The proposed model relies on the approximation of the relaxed continuous embedding solution by the true discrete clustering one.', 'Thereby, we show that incorporating an embedding representation provides simpler and more interpretable solutions.', 'Experiment results demonstrate that the proposed algorithm performs better, in terms of clustering and embedding, than the state-of-art algorithms, including deep learning methods devoted to similar tasks for attributed network datasets with different proprieties.']","[1, 0, 0, 0, 0]","[0.375, 0.1428571343421936, 0.12121211737394333, 0.13333332538604736, 0.20408162474632263]",B1gL904FwH,"['This paper propose a novel matrix decomposition framework for simultaneous attributed network data embedding and clustering.', 'This paper proposes an algorithm to perform jointly attribute network embedding and clustering together.']","['deal simultaneously  attributed network embedding clustering  propose new model ', 'exploit content structure information  capitalising simultaneous use ', 'proposed model relies approximation relaxed continuous embedding solution true discrete clustering one ', 'thereby  show incorporating embedding representation provides simpler interpretable solution ', 'experiment result demonstrate proposed algorithm performs better  term clustering embedding  stateofart algorithm  including deep learning method devoted similar task attributed network datasets different propriety ']","To deal simultaneously with both, the attributed network embedding and clustering, we propose a new model., It exploits both content and structure information, capitalising on their simultaneous use., The proposed model relies on the approximation of the relaxed continuous embedding solution by the true discrete clustering one., Thereby, we show that incorporating an embedding representation provides simpler and more interpretable solutions., Experiment results demonstrate that the proposed algorithm performs better, in terms of clustering and embedding, than the state-of-art algorithms, including deep learning methods devoted to similar tasks for attributed network datasets with different proprieties.",12,6.378947368421053,7.916666666666667
588,"['We propose a learned image-guided rendering technique that combines the benefits of image-based rendering and GAN-based image synthesis.', 'The goal of our method is to generate photo-realistic re-renderings of reconstructed objects for virtual and augmented reality applications (e.g., virtual showrooms, virtual tours and sightseeing, the digital inspection of historical artifacts).', 'A core component of our work is the handling of view-dependent effects.', 'Specifically, we directly train an object-specific deep neural network to synthesize the view-dependent appearance of an object.\n', 'As input data we are using an RGB video of the object.', 'This video is used to reconstruct a proxy geometry of the object via multi-view stereo.', 'Based on this 3D proxy, the appearance of a captured view can be warped into a new target view as in classical image-based rendering.', 'This warping assumes diffuse surfaces, in case of view-dependent effects, such as specular highlights, it leads to artifacts.', 'To this end, we propose EffectsNet, a deep neural network that predicts view-dependent effects.', 'Based on these estimations, we are able to convert observed images to diffuse images.', 'These diffuse images can be projected into other views.', 'In the target view, our pipeline reinserts the new view-dependent effects.', 'To composite multiple reprojected images to a final output, we learn a composition network that outputs photo-realistic results.', ""Using this image-guided approach, the network does not have to allocate capacity on ``remembering'' object appearance, instead it learns how to combine the appearance of captured images."", 'We demonstrate the effectiveness of our approach both qualitatively and quantitatively on synthetic as well as on real data.']","[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0.8947368264198303, 0.11999999731779099, 0.25, 0.15789473056793213, 0.12121211737394333, 0.1666666567325592, 0.23255813121795654, 0.10256409645080566, 0.2857142686843872, 0.0, 0.0, 0.19354838132858276, 0.10526315122842789, 0.1304347813129425, 0.21052631735801697]",Hyg9anEFPS,"['We propose a learned image-guided rendering technique that combines the benefits of image-based rendering and GAN-based image synthesis while considering view-dependent effects.', 'This submission proposes a method to handle view-dependent effects in neural rendering, which improves the robustness of existing neural rendering methods.']","['propose learned imageguided rendering technique combine benefit imagebased rendering ganbased image synthesis ', 'goal method generate photorealistic rerenderings reconstructed object virtual augmented reality application  eg  virtual showroom  virtual tour sightseeing  digital inspection historical artifact  ', 'core component work handling viewdependent effect ', 'specifically  directly train objectspecific deep neural network synthesize viewdependent appearance object ', 'input data using rgb video object ', 'video used reconstruct proxy geometry object via multiview stereo ', 'based 3d proxy  appearance captured view warped new target view classical imagebased rendering ', 'warping assumes diffuse surface  case viewdependent effect  specular highlight  lead artifact ', 'end  propose effectsnet  deep neural network predicts viewdependent effect ', 'based estimation  able convert observed image diffuse image ', 'diffuse image projected view ', 'target view  pipeline reinserts new viewdependent effect ', 'composite multiple reprojected image final output  learn composition network output photorealistic result ', 'using imageguided approach  network allocate capacity  remembering  object appearance  instead learns combine appearance captured image ', 'demonstrate effectiveness approach qualitatively quantitatively synthetic well real data ']","We propose a learned image-guided rendering technique that combines the benefits of image-based rendering and GAN-based image synthesis., The goal of our method is to generate photo-realistic re-renderings of reconstructed objects for virtual and augmented reality applications (e.g., virtual showrooms, virtual tours and sightseeing, the digital inspection of historical artifacts)., A core component of our work is the handling of view-dependent effects., Specifically, we directly train an object-specific deep neural network to synthesize the view-dependent appearance of an object.
, As input data we are using an RGB video of the object., This video is used to reconstruct a proxy geometry of the object via multi-view stereo., Based on this 3D proxy, the appearance of a captured view can be warped into a new target view as in classical image-based rendering., This warping assumes diffuse surfaces, in case of view-dependent effects, such as specular highlights, it leads to artifacts., To this end, we propose EffectsNet, a deep neural network that predicts view-dependent effects., Based on these estimations, we are able to convert observed images to diffuse images., These diffuse images can be projected into other views., In the target view, our pipeline reinserts the new view-dependent effects., To composite multiple reprojected images to a final output, we learn a composition network that outputs photo-realistic results., Using this image-guided approach, the network does not have to allocate capacity on ``remembering'' object appearance, instead it learns how to combine the appearance of captured images., We demonstrate the effectiveness of our approach both qualitatively and quantitatively on synthetic as well as on real data.",30,5.638461538461539,8.666666666666666
589,"['We evaluate the distribution learning capabilities of generative adversarial networks by testing them on synthetic datasets.', 'The datasets include common distributions of points in $R^n$ space and images containing polygons of various shapes and sizes.', 'We find that by and large GANs fail to faithfully recreate point datasets which contain discontinous support or sharp bends with noise.', 'Additionally, on image datasets, we find that GANs do not seem to learn to count the number of objects of the same kind in an image.', 'We also highlight the apparent tension between generalization and learning in GANs.']","[1, 0, 0, 0, 0]","[0.27272728085517883, 0.08695651590824127, 0.1428571343421936, 0.1428571343421936, 0.1111111044883728]",Syeehk2ca4,['GANs are evaluated on synthetic datasets'],"['evaluate distribution learning capability generative adversarial network testing synthetic datasets ', 'datasets include common distribution point  rn  space image containing polygon various shape size ', 'find large gans fail faithfully recreate point datasets contain discontinous support sharp bend noise ', 'additionally  image datasets  find gans seem learn count number object kind image ', 'also highlight apparent tension generalization learning gans ']","We evaluate the distribution learning capabilities of generative adversarial networks by testing them on synthetic datasets., The datasets include common distributions of points in $R^n$ space and images containing polygons of various shapes and sizes., We find that by and large GANs fail to faithfully recreate point datasets which contain discontinous support or sharp bends with noise., Additionally, on image datasets, we find that GANs do not seem to learn to count the number of objects of the same kind in an image., We also highlight the apparent tension between generalization and learning in GANs.",7,5.347368421052631,13.571428571428571
590,"['This paper proposes a new approach for step size adaptation in gradient methods.', 'The proposed method called step size optimization (SSO) formulates the step size adaptation as an optimization problem which minimizes the loss function with respect to the step size for the given model parameters and gradients.', 'Then, the step size is optimized based on alternating direction method of multipliers (ADMM).', 'SSO does not require the second-order information or any probabilistic models for adapting the step size, so it is efficient and easy to implement.', 'Furthermore, we also introduce stochastic SSO for stochastic learning environments.', 'In the experiments, we integrated SSO to vanilla SGD and Adam, and they outperformed state-of-the-art adaptive gradient methods including RMSProp, Adam, L4-Adam, and AdaBound on extensive benchmark datasets.']","[1, 0, 0, 0, 0, 0]","[0.4444444477558136, 0.39024388790130615, 0.2857142686843872, 0.2702702581882477, 0.08695651590824127, 0.20512820780277252]",Sygg3JHtwB,"['We propose an efficient and effective step size adaptation method for the gradient methods.', 'A new step size adaptation in first-order gradient methods that establishes a new optimization problem with the first-order expansion of the loss function and regularization, where step size is treated as variable.']","['paper proposes new approach step size adaptation gradient method ', 'proposed method called step size optimization  sso  formulates step size adaptation optimization problem minimizes loss function respect step size given model parameter gradient ', ' step size optimized based alternating direction method multiplier  admm  ', 'sso require secondorder information probabilistic model adapting step size  efficient easy implement ', 'furthermore  also introduce stochastic sso stochastic learning environment ', 'experiment  integrated sso vanilla sgd adam  outperformed stateoftheart adaptive gradient method including rmsprop  adam  l4adam  adabound extensive benchmark datasets ']","This paper proposes a new approach for step size adaptation in gradient methods., The proposed method called step size optimization (SSO) formulates the step size adaptation as an optimization problem which minimizes the loss function with respect to the step size for the given model parameters and gradients., Then, the step size is optimized based on alternating direction method of multipliers (ADMM)., SSO does not require the second-order information or any probabilistic models for adapting the step size, so it is efficient and easy to implement., Furthermore, we also introduce stochastic SSO for stochastic learning environments., In the experiments, we integrated SSO to vanilla SGD and Adam, and they outperformed state-of-the-art adaptive gradient methods including RMSProp, Adam, L4-Adam, and AdaBound on extensive benchmark datasets.",14,5.741935483870968,8.857142857142858
591,"['Despite the fact that generative models are extremely successful in practice, the theory underlying this phenomenon is only starting to catch up with practice.', 'In this work we address the question of the universality of generative models: is it true that neural networks can approximate any data manifold arbitrarily well?', 'We provide a positive answer to this question and show that under mild assumptions on the activation function one can always find a feedforward neural network that maps the latent space onto a set located within the specified Hausdorff distance from the desired data manifold.', 'We also prove similar theorems for the case of multiclass generative models and cycle generative models, trained to map samples from one manifold to another and vice versa.']","[0, 1, 0, 0]","[0.0952380895614624, 0.1860465109348297, 0.17241378128528595, 0.13636362552642822]",rJlJF1SYPB,"['We shot that a wide class of manifolds can be generated by ReLU and sigmoid networks with arbitrary precision.', 'This paper provides certain basic guarantees on when manifolds can be written as the image of a map approximated by a neural net, and stitches together theorems from manifold geometry and standard universal approximation results.', 'This paper theoretically shows that neural-network-based generative models can approximate data manifolds, and proves that under mild assumptions neural networks can map a latent space onto a set close to the given data manifold within a small Hausdorff distance.']","['despite fact generative model extremely successful practice  theory underlying phenomenon starting catch practice ', 'work address question universality generative model  true neural network approximate data manifold arbitrarily well ', 'provide positive answer question show mild assumption activation function one always find feedforward neural network map latent space onto set located within specified hausdorff distance desired data manifold ', 'also prove similar theorem case multiclass generative model cycle generative model  trained map sample one manifold another vice versa ']","Despite the fact that generative models are extremely successful in practice, the theory underlying this phenomenon is only starting to catch up with practice., In this work we address the question of the universality of generative models: is it true that neural networks can approximate any data manifold arbitrarily well?, We provide a positive answer to this question and show that under mild assumptions on the activation function one can always find a feedforward neural network that maps the latent space onto a set located within the specified Hausdorff distance from the desired data manifold., We also prove similar theorems for the case of multiclass generative models and cycle generative models, trained to map samples from one manifold to another and vice versa.",6,5.2682926829268295,20.5
592,"['Model-based reinforcement learning (RL) is considered to be a promising approach to reduce the sample complexity that hinders model-free RL.', 'However, the theoretical understanding of such methods has been rather limited.', 'This paper introduces a novel algorithmic framework for designing and analyzing model-based RL algorithms with theoretical guarantees.', 'We design a meta-algorithm with a theoretical guarantee of monotone improvement to a local maximum of the expected reward.', 'The meta-algorithm iteratively builds a lower bound of the expected reward based on the estimated dynamical model and sample trajectories, and then maximizes the lower bound jointly over the policy and the model.', 'The framework extends the optimism-in-face-of-uncertainty principle to non-linear dynamical models in a way that requires no explicit uncertainty quantification.', 'Instantiating our framework with simplification gives a  variant of model-based RL algorithms Stochastic Lower Bounds Optimization (SLBO).', 'Experiments demonstrate that SLBO achieves the state-of-the-art performance when only 1M or fewer samples are permitted on a range of continuous control benchmark tasks.']","[0, 0, 0, 0, 0, 0, 0, 1]","[0.09090908616781235, 0.0555555522441864, 0.2857142686843872, 0.19512194395065308, 0.08163265138864517, 0.0, 0.1428571343421936, 0.40816324949264526]",BJe1E2R5KX,"['We design model-based reinforcement learning algorithms with theoretical guarantees and achieve state-of-the-art results on Mujuco benchmark tasks when one million or fewer samples are permitted.', 'The paper proposed a framework to design model-based RL algorithms based on OFU that achieves SOTA performance on MuJoCo tasks.']","['modelbased reinforcement learning  rl  considered promising approach reduce sample complexity hinders modelfree rl ', 'however  theoretical understanding method rather limited ', 'paper introduces novel algorithmic framework designing analyzing modelbased rl algorithm theoretical guarantee ', 'design metaalgorithm theoretical guarantee monotone improvement local maximum expected reward ', 'metaalgorithm iteratively build lower bound expected reward based estimated dynamical model sample trajectory  maximizes lower bound jointly policy model ', 'framework extends optimisminfaceofuncertainty principle nonlinear dynamical model way requires explicit uncertainty quantification ', 'instantiating framework simplification give variant modelbased rl algorithm stochastic lower bound optimization  slbo  ', 'experiment demonstrate slbo achieves stateoftheart performance 1m fewer sample permitted range continuous control benchmark task ']","Model-based reinforcement learning (RL) is considered to be a promising approach to reduce the sample complexity that hinders model-free RL., However, the theoretical understanding of such methods has been rather limited., This paper introduces a novel algorithmic framework for designing and analyzing model-based RL algorithms with theoretical guarantees., We design a meta-algorithm with a theoretical guarantee of monotone improvement to a local maximum of the expected reward., The meta-algorithm iteratively builds a lower bound of the expected reward based on the estimated dynamical model and sample trajectories, and then maximizes the lower bound jointly over the policy and the model., The framework extends the optimism-in-face-of-uncertainty principle to non-linear dynamical models in a way that requires no explicit uncertainty quantification., Instantiating our framework with simplification gives a  variant of model-based RL algorithms Stochastic Lower Bounds Optimization (SLBO)., Experiments demonstrate that SLBO achieves the state-of-the-art performance when only 1M or fewer samples are permitted on a range of continuous control benchmark tasks.",10,6.25,16.0
593,"['We study the use of knowledge distillation to compress the U-net architecture.', 'We show that, while standard distillation is not sufficient to reliably train a compressed U-net, introducing other regularization methods, such as batch normalization and class re-weighting, in knowledge distillation significantly improves the training process.', 'This allows us to compress a U-net by over 1000x, i.e., to 0.1% of its original number of parameters, at a negligible decrease in performance.']","[1, 0, 0]","[0.5833333134651184, 0.17391304671764374, 0.2631579041481018]",HJxHWxewim,"['We present additional techniques to use knowledge distillation to compress U-net by over 1000x.', 'The authors introduced a modified distillation strategy to compress a U-net architecture by over 1000x while retaining an accuracy close to the original U-net.']","['study use knowledge distillation compress unet architecture ', 'show  standard distillation sufficient reliably train compressed unet  introducing regularization method  batch normalization class reweighting  knowledge distillation significantly improves training process ', 'allows u compress unet 1000x  ie  01  original number parameter  negligible decrease performance ']","We study the use of knowledge distillation to compress the U-net architecture., We show that, while standard distillation is not sufficient to reliably train a compressed U-net, introducing other regularization methods, such as batch normalization and class re-weighting, in knowledge distillation significantly improves the training process., This allows us to compress a U-net by over 1000x, i.e., to 0.1% of its original number of parameters, at a negligible decrease in performance.",10,5.732394366197183,7.1
594,"['Learning neural networks with gradient descent over a long sequence of tasks is problematic as their fine-tuning to new tasks overwrites the network weights that are important for previous tasks.', 'This leads to a poor performance on old tasks  a phenomenon framed as catastrophic forgetting.  ', 'While early approaches use task rehearsal and growing networks that both limit the scalability of the task sequence orthogonal approaches build on regularization.  ', 'Based on the Fisher information matrix (FIM) changes to parameters that are relevant to old tasks are penalized, which forces the task to be mapped into the available remaining capacity of the network.', 'This requires to calculate the Hessian around a mode, which makes learning tractable.', 'In this paper, we introduce Hessian-free curvature estimates as an alternative method to actually calculating the Hessian.  ', 'In contrast to previous work, we exploit the fact that most regions in the loss surface are flat and hence only calculate a Hessian-vector-product around the surface that is relevant for the current task.', 'Our experiments show that on a variety of well-known task sequences we either significantly outperform or are en par with previous work.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.04878048226237297, 0.27586206793785095, 0.0, 0.04999999701976776, 0.1538461446762085, 0.32258063554763794, 0.0476190447807312, 0.0]",H1ls_eSKPH,"['This paper provides an approach to address catastrophic forgetting via Hessian-free curvature estimates', ""The paper proposes an approximate Laplace's method in neural network training in the continual learning setting with a low space complexity.""]","['learning neural network gradient descent long sequence task problematic finetuning new task overwrites network weight important previous task ', 'lead poor performance old task  phenomenon framed catastrophic forgetting ', 'early approach use task rehearsal growing network limit scalability task sequence orthogonal approach build regularization ', 'based fisher information matrix  fim  change parameter relevant old task penalized  force task mapped available remaining capacity network ', 'requires calculate hessian around mode  make learning tractable ', 'paper  introduce hessianfree curvature estimate alternative method actually calculating hessian ', 'contrast previous work  exploit fact region loss surface flat hence calculate hessianvectorproduct around surface relevant current task ', 'experiment show variety wellknown task sequence either significantly outperform en par previous work ']","Learning neural networks with gradient descent over a long sequence of tasks is problematic as their fine-tuning to new tasks overwrites the network weights that are important for previous tasks., This leads to a poor performance on old tasks  a phenomenon framed as catastrophic forgetting.  , While early approaches use task rehearsal and growing networks that both limit the scalability of the task sequence orthogonal approaches build on regularization.  , Based on the Fisher information matrix (FIM) changes to parameters that are relevant to old tasks are penalized, which forces the task to be mapped into the available remaining capacity of the network., This requires to calculate the Hessian around a mode, which makes learning tractable., In this paper, we introduce Hessian-free curvature estimates as an alternative method to actually calculating the Hessian.  , In contrast to previous work, we exploit the fact that most regions in the loss surface are flat and hence only calculate a Hessian-vector-product around the surface that is relevant for the current task., Our experiments show that on a variety of well-known task sequences we either significantly outperform or are en par with previous work.",12,5.404255319148936,15.666666666666666
595,"['There has been recent interest in improving performance of simple models for multiple reasons such as interpretability, robust learning from small data, deployment in memory constrained settings as well as environmental considerations.', 'In this paper, we propose a novel method SRatio that can utilize information from high performing complex models (viz. deep neural networks, boosted trees, random forests) to reweight a training dataset for a potentially low performing simple model such as a decision tree or a shallow network enhancing its performance.', ""Our method also leverages the per sample hardness estimate of the simple model which is not the case with the prior works which primarily consider the complex model's confidences/predictions and is thus conceptually novel."", 'Moreover, we generalize and formalize the concept of attaching probes to intermediate layers of a neural network, which was one of the main ideas in previous work \\citep{profweight}, to other commonly used classifiers and incorporate this into our method.', 'The benefit of these contributions is witnessed in the experiments where on 6 UCI datasets and CIFAR-10 we outperform competitors in a majority (16 out of 27) of the cases and tie for best performance in the remaining cases.', ""In fact, in a couple of cases, we even approach the complex model's performance."", 'We also conduct further experiments to validate assertions and intuitively understand why our method works.', 'Theoretically, we motivate our approach by showing that the weighted loss minimized by simple models using our weighting upper bounds the loss of the complex model.']","[0, 1, 0, 0, 0, 0, 0, 0]","[0.14999999105930328, 0.25, 0.1538461446762085, 0.08888888359069824, 0.0952380895614624, 0.23999999463558197, 0.07692307233810425, 0.25]",HyxQbaEYPr,"['Method to improve simple models performance given a (accurate) complex model.', 'The paper proposes a means of improving the predictions of a low-capacity model which shows benefits over existing approaches.']","['recent interest improving performance simple model multiple reason interpretability  robust learning small data  deployment memory constrained setting well environmental consideration ', 'paper  propose novel method sratio utilize information high performing complex model  viz  deep neural network  boosted tree  random forest  reweight training dataset potentially low performing simple model decision tree shallow network enhancing performance ', 'method also leverage per sample hardness estimate simple model case prior work primarily consider complex model confidencespredictions thus conceptually novel ', 'moreover  generalize formalize concept attaching probe intermediate layer neural network  one main idea previous work citep  profweight   commonly used classifier incorporate method ', 'benefit contribution witnessed experiment 6 uci datasets cifar10 outperform competitor majority  16 27  case tie best performance remaining case ', 'fact  couple case  even approach complex model performance ', 'also conduct experiment validate assertion intuitively understand method work ', 'theoretically  motivate approach showing weighted loss minimized simple model using weighting upper bound loss complex model ']","There has been recent interest in improving performance of simple models for multiple reasons such as interpretability, robust learning from small data, deployment in memory constrained settings as well as environmental considerations., In this paper, we propose a novel method SRatio that can utilize information from high performing complex models (viz. deep neural networks, boosted trees, random forests) to reweight a training dataset for a potentially low performing simple model such as a decision tree or a shallow network enhancing its performance., Our method also leverages the per sample hardness estimate of the simple model which is not the case with the prior works which primarily consider the complex model's confidences/predictions and is thus conceptually novel., Moreover, we generalize and formalize the concept of attaching probes to intermediate layers of a neural network, which was one of the main ideas in previous work \citep{profweight}, to other commonly used classifiers and incorporate this into our method., The benefit of these contributions is witnessed in the experiments where on 6 UCI datasets and CIFAR-10 we outperform competitors in a majority (16 out of 27) of the cases and tie for best performance in the remaining cases., In fact, in a couple of cases, we even approach the complex model's performance., We also conduct further experiments to validate assertions and intuitively understand why our method works., Theoretically, we motivate our approach by showing that the weighted loss minimized by simple models using our weighting upper bounds the loss of the complex model.",19,5.4417670682730925,12.45
596,"['We propose a principled method for kernel learning, which relies on a Fourier-analytic characterization of translation-invariant or rotation-invariant kernels.', 'Our method produces a sequence of feature maps, iteratively refining the SVM margin.', 'We provide rigorous guarantees for optimality and generalization, interpreting our algorithm as online equilibrium-finding dynamics in a certain two-player min-max game.', 'Evaluations on synthetic and real-world datasets demonstrate scalability and consistent improvements over related random features-based methods.']","[1, 0, 0, 0]","[0.24390242993831635, 0.0555555522441864, 0.1818181723356247, 0.052631575614213943]",Hk8XMWgRb,"['A simple and practical algorithm for learning a margin-maximizing translation-invariant or spherically symmetric kernel from training data, using tools from Fourier analysis and regret minimization.', 'The paper proposes to learn a custom translation or rotation invariant kernal in the Fourier representation to maximize the margin of SVM.', 'The authors propose an interesting algorithm for learning the l1-SVM and the Fourier represented kernel together', 'The authors consider learning directly Fourier representations of shift/translation invariant kernels for machine learning applications with the alignment of the kernel to data as the objective function to optimize.']","['propose principled method kernel learning  relies fourieranalytic characterization translationinvariant rotationinvariant kernel ', 'method produce sequence feature map  iteratively refining svm margin ', 'provide rigorous guarantee optimality generalization  interpreting algorithm online equilibriumfinding dynamic certain twoplayer minmax game ', 'evaluation synthetic realworld datasets demonstrate scalability consistent improvement related random featuresbased method ']","We propose a principled method for kernel learning, which relies on a Fourier-analytic characterization of translation-invariant or rotation-invariant kernels., Our method produces a sequence of feature maps, iteratively refining the SVM margin., We provide rigorous guarantees for optimality and generalization, interpreting our algorithm as online equilibrium-finding dynamics in a certain two-player min-max game., Evaluations on synthetic and real-world datasets demonstrate scalability and consistent improvements over related random features-based methods.",7,7.072463768115942,9.857142857142858
597,"['We elaborate on using importance sampling for causal reasoning, in particular for counterfactual inference.', 'We show how this can be implemented natively in probabilistic programming.', 'By considering the structure of the counterfactual query, one can significantly optimise the inference process.', 'We also consider design choices to enable further optimisations.', 'We introduce MultiVerse, a probabilistic programming prototype engine for approximate causal reasoning.', 'We provide experimental results and compare with Pyro, an existing probabilistic programming framework with some of causal reasoning tools.']","[1, 0, 0, 0, 0, 0]","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]",S1xFcknVFS,"['Probabilistic Programming that Natively Supports Causal, Counterfactual Inference']","['elaborate using importance sampling causal reasoning  particular counterfactual inference ', 'show implemented natively probabilistic programming ', 'considering structure counterfactual query  one significantly optimise inference process ', 'also consider design choice enable optimisation ', 'introduce multiverse  probabilistic programming prototype engine approximate causal reasoning ', 'provide experimental result compare pyro  existing probabilistic programming framework causal reasoning tool ']","We elaborate on using importance sampling for causal reasoning, in particular for counterfactual inference., We show how this can be implemented natively in probabilistic programming., By considering the structure of the counterfactual query, one can significantly optimise the inference process., We also consider design choices to enable further optimisations., We introduce MultiVerse, a probabilistic programming prototype engine for approximate causal reasoning., We provide experimental results and compare with Pyro, an existing probabilistic programming framework with some of causal reasoning tools.",10,6.5,8.0
598,"['We consider the problem of representing collective behavior of large populations and predicting the evolution of a population distribution over a discrete state space.', 'A discrete time mean field game (MFG) is motivated as an interpretable model founded on game theory for understanding the aggregate effect of individual actions and predicting the temporal evolution of population distributions.', 'We achieve a synthesis of MFG and Markov decision processes (MDP) by showing that a special MFG is reducible to an MDP.', 'This enables us to broaden the scope of mean field game theory and infer MFG models of large real-world systems via deep inverse reinforcement learning.', 'Our method learns both the reward function and forward dynamics of an MFG from real data, and we report the first empirical test of a mean field game model of a real-world social media population.']","[0, 0, 1, 0, 0]","[0.31578946113586426, 0.3333333432674408, 0.42105263471603394, 0.380952388048172, 0.375]",HktK4BeCZ,"['Inference of a mean field game (MFG) model of large population behavior via a synthesis of MFG and Markov decision processes.', 'The authors deal with inference in models of collective behavior by using inverse reinforcement learning to learn the reward functions of agents in the model.']","['consider problem representing collective behavior large population predicting evolution population distribution discrete state space ', 'discrete time mean field game  mfg  motivated interpretable model founded game theory understanding aggregate effect individual action predicting temporal evolution population distribution ', 'achieve synthesis mfg markov decision process  mdp  showing special mfg reducible mdp ', 'enables u broaden scope mean field game theory infer mfg model large realworld system via deep inverse reinforcement learning ', 'method learns reward function forward dynamic mfg real data  report first empirical test mean field game model realworld social medium population ']","We consider the problem of representing collective behavior of large populations and predicting the evolution of a population distribution over a discrete state space., A discrete time mean field game (MFG) is motivated as an interpretable model founded on game theory for understanding the aggregate effect of individual actions and predicting the temporal evolution of population distributions., We achieve a synthesis of MFG and Markov decision processes (MDP) by showing that a special MFG is reducible to an MDP., This enables us to broaden the scope of mean field game theory and infer MFG models of large real-world systems via deep inverse reinforcement learning., Our method learns both the reward function and forward dynamics of an MFG from real data, and we report the first empirical test of a mean field game model of a real-world social media population.",6,5.223021582733813,23.166666666666668
599,"['We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  ', 'When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  ', 'Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way.', 'We present a hierarchical framework that can effectively learn such sequential generative models.  ', 'Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime.', 'In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods.', 'We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.']","[1, 0, 0, 0, 0, 0, 0]","[0.2857142686843872, 0.0952380895614624, 0.0, 0.17142856121063232, 0.09756097197532654, 0.19999998807907104, 0.09756097197532654]",rkxw-hAcFQ,"['We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.', 'Proposes multi-agent sequential generative models.', 'The paper proposes training generative models that produce multi-agent trajectories using heuristic functions that label variables that would otherwise be latent in training data']","['study problem training sequential generative model capturing coordinated multiagent trajectory behavior  offensive basketball gameplay ', 'modeling setting  often beneficial design hierarchical model capture longterm coordination using intermediate variable ', 'furthermore  intermediate variable capture interesting highlevel behavioral semantics interpretable manipulable way ', 'present hierarchical framework effectively learn sequential generative model ', 'approach inspired recent work leveraging programmatically produced weak label  extend spatiotemporal regime ', 'addition synthetic setting  show instantiate framework effectively model complex interaction basketball player generate realistic multiagent trajectory basketball gameplay long time period ', 'validate approach using quantitative qualitative evaluation  including user study comparison conducted professional sport analyst ']","We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  , When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  , Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way., We present a hierarchical framework that can effectively learn such sequential generative models.  , Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime., In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods., We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.",13,6.673758865248227,10.846153846153847
600,"['Many automated machine learning methods, such as those for hyperparameter and neural architecture optimization, are computationally expensive because they involve training many different model configurations.', 'In this work, we present a new method that saves computational budget by terminating poor configurations early on in the training.', 'In contrast to existing methods, we consider this task as a ranking and transfer learning problem.', 'We qualitatively show that by optimizing a pairwise ranking loss and leveraging learning curves from other data sets, our model is able to effectively rank learning curves without having to observe many or very long learning curves.', 'We further demonstrate that our method can be used to accelerate a neural architecture search by a factor of up to 100 without a significant performance degradation of the discovered architecture.', 'In further experiments we analyze the quality of ranking, the influence of different model components as well as the predictive behavior of the model.']","[0, 0, 0, 1, 0, 0]","[0.145454540848732, 0.15686273574829102, 0.21739129722118378, 0.32258063554763794, 0.1071428507566452, 0.12765957415103912]",BJxAHgSYDB,"['Learn to rank learning curves in order to stop unpromising training jobs early. Novelty: use of pairwise ranking loss to directly model the probability of improving and transfer learning across data sets to reduce required training data.', 'The paper proposes a method to rank learning curves of neural networks that can model learning curves across different datasets, achieving higher speed-ups on image classification tasks.']","['many automated machine learning method  hyperparameter neural architecture optimization  computationally expensive involve training many different model configuration ', 'work  present new method save computational budget terminating poor configuration early training ', 'contrast existing method  consider task ranking transfer learning problem ', 'qualitatively show optimizing pairwise ranking loss leveraging learning curve data set  model able effectively rank learning curve without observe many long learning curve ', 'demonstrate method used accelerate neural architecture search factor 100 without significant performance degradation discovered architecture ', 'experiment analyze quality ranking  influence different model component well predictive behavior model ']","Many automated machine learning methods, such as those for hyperparameter and neural architecture optimization, are computationally expensive because they involve training many different model configurations., In this work, we present a new method that saves computational budget by terminating poor configurations early on in the training., In contrast to existing methods, we consider this task as a ranking and transfer learning problem., We qualitatively show that by optimizing a pairwise ranking loss and leveraging learning curves from other data sets, our model is able to effectively rank learning curves without having to observe many or very long learning curves., We further demonstrate that our method can be used to accelerate a neural architecture search by a factor of up to 100 without a significant performance degradation of the discovered architecture., In further experiments we analyze the quality of ranking, the influence of different model components as well as the predictive behavior of the model.",12,5.584415584415584,12.833333333333334
601,"['Continual learning is the problem of learning new tasks or knowledge while protecting old knowledge and ideally generalizing from old experience to learn new tasks faster.', 'Neural networks trained by stochastic gradient descent often degrade on old tasks when trained successively on new tasks with different data distributions.', 'This phenomenon, referred to as catastrophic forgetting, is considered a major hurdle to learning with non-stationary data or sequences of new tasks, and prevents networks from continually accumulating knowledge and skills.', 'We examine this issue in the context of reinforcement learning, in a setting where an agent is exposed to tasks in a sequence.', 'Unlike most other work, we do not provide an explicit indication to the model of task boundaries, which is the most general circumstance for a learning agent exposed to continuous experience.', 'While various methods to counteract catastrophic forgetting have recently been proposed, we explore a straightforward, general, and seemingly overlooked solution - that of using experience replay buffers for all past events - with a mixture of on- and off-policy learning, leveraging behavioral cloning.', 'We show that this strategy can still learn new tasks quickly yet can substantially reduce catastrophic forgetting in both Atari and DMLab domains, even matching the performance of methods that require task identities.', 'When buffer storage is constrained, we confirm that a simple mechanism for randomly discarding data allows a limited size buffer to perform almost as well as an unbounded one.']","[0, 0, 0, 0, 0, 1, 0, 0]","[0.20408162474632263, 0.12765957415103912, 0.28070175647735596, 0.2083333283662796, 0.1428571343421936, 0.35820895433425903, 0.3050847351551056, 0.07407406717538834]",S1g2V3Cct7,"['We show that, in continual learning settings, catastrophic forgetting can be avoided by applying off-policy RL to a mixture of new and replay experience, with a behavioral cloning loss.', 'Proposes a particular variant of experience replay with behavior cloning as a method for continual learning.']","['continual learning problem learning new task knowledge protecting old knowledge ideally generalizing old experience learn new task faster ', 'neural network trained stochastic gradient descent often degrade old task trained successively new task different data distribution ', 'phenomenon  referred catastrophic forgetting  considered major hurdle learning nonstationary data sequence new task  prevents network continually accumulating knowledge skill ', 'examine issue context reinforcement learning  setting agent exposed task sequence ', 'unlike work  provide explicit indication model task boundary  general circumstance learning agent exposed continuous experience ', 'various method counteract catastrophic forgetting recently proposed  explore straightforward  general  seemingly overlooked solution  using experience replay buffer past event  mixture offpolicy learning  leveraging behavioral cloning ', 'show strategy still learn new task quickly yet substantially reduce catastrophic forgetting atari dmlab domain  even matching performance method require task identity ', 'buffer storage constrained  confirm simple mechanism randomly discarding data allows limited size buffer perform almost well unbounded one ']","Continual learning is the problem of learning new tasks or knowledge while protecting old knowledge and ideally generalizing from old experience to learn new tasks faster., Neural networks trained by stochastic gradient descent often degrade on old tasks when trained successively on new tasks with different data distributions., This phenomenon, referred to as catastrophic forgetting, is considered a major hurdle to learning with non-stationary data or sequences of new tasks, and prevents networks from continually accumulating knowledge and skills., We examine this issue in the context of reinforcement learning, in a setting where an agent is exposed to tasks in a sequence., Unlike most other work, we do not provide an explicit indication to the model of task boundaries, which is the most general circumstance for a learning agent exposed to continuous experience., While various methods to counteract catastrophic forgetting have recently been proposed, we explore a straightforward, general, and seemingly overlooked solution - that of using experience replay buffers for all past events - with a mixture of on- and off-policy learning, leveraging behavioral cloning., We show that this strategy can still learn new tasks quickly yet can substantially reduce catastrophic forgetting in both Atari and DMLab domains, even matching the performance of methods that require task identities., When buffer storage is constrained, we confirm that a simple mechanism for randomly discarding data allows a limited size buffer to perform almost as well as an unbounded one.",20,5.542016806722689,11.9
602,"['We present a method which learns to integrate temporal information, from a learned dynamics model, with ambiguous visual information, from a learned vision model, in the context of interacting agents.', 'Our method is based on a graph-structured variational recurrent neural network, which is trained end-to-end to infer the current state of the (partially observed) world, as well as to forecast future states.', 'We show that our method outperforms various baselines on two sports datasets, one based on real basketball trajectories, and one generated by a soccer game engine.']","[1, 0, 0]","[0.7906976938247681, 0.25531914830207825, 0.1860465109348297]",r1xdH3CcKX,"['We present a method which learns to integrate temporal information and ambiguous visual information in the context of interacting agents.', 'The authors propose Graph VRNN which models the interaction of multiple agents by deploying a VRNN for each agent', 'This paper presents a graph neural network based architecture that is trained to locate and model the interactions of agents in an environment directly from pixels and show advantage of model for tracking tasks and forecasting agent locations.']","['present method learns integrate temporal information  learned dynamic model  ambiguous visual information  learned vision model  context interacting agent ', 'method based graphstructured variational recurrent neural network  trained endtoend infer current state  partially observed  world  well forecast future state ', 'show method outperforms various baseline two sport datasets  one based real basketball trajectory  one generated soccer game engine ']","We present a method which learns to integrate temporal information, from a learned dynamics model, with ambiguous visual information, from a learned vision model, in the context of interacting agents., Our method is based on a graph-structured variational recurrent neural network, which is trained end-to-end to infer the current state of the (partially observed) world, as well as to forecast future states., We show that our method outperforms various baselines on two sports datasets, one based on real basketball trajectories, and one generated by a soccer game engine.",11,5.420454545454546,8.0
603,"['In this paper we study the problem of learning the weights of a deep convolutional neural network.', 'We consider a network where convolutions are carried out over non-overlapping patches with a single kernel in each layer.', 'We develop an algorithm for simultaneously learning all the kernels from the training data.', 'Our approach dubbed Deep Tensor Decomposition (DeepTD) is based on a rank-1 tensor decomposition.', 'We theoretically investigate DeepTD under a realizable model for the training data where the inputs are chosen i.i.d. from a Gaussian distribution and the labels are generated according to planted convolutional kernels.', 'We show that DeepTD is data-efficient and provably works as soon as the sample size exceeds the total number of convolutional weights in the network.', 'Our numerical experiments demonstrate the effectiveness of DeepTD and verify our theoretical findings.']","[1, 0, 0, 0, 0, 0, 0]","[0.3589743673801422, 0.2380952388048172, 0.10810810327529907, 0.15789473056793213, 0.15094339847564697, 0.260869562625885, 0.05405404791235924]",BJlhEs09YQ,"['We consider a simplified deep convolutional neural network model. We show that all layers of this network can be approximately learned with a proper application of tensor decomposition.', 'Provides theoretical guarantees for learning deep convolutional neural networks using rank-one tensor decomposition.', 'This paper proposes a learning method for a restricted case of deep convolutional networks, where the layers are limited to the non-overlapping case and have only one output channel per layer', 'Analyzes the problem of learning a very special class of CNNs: each layers consists of a single filter, applied to non-overlapping patches of the input.']","['paper study problem learning weight deep convolutional neural network ', 'consider network convolution carried nonoverlapping patch single kernel layer ', 'develop algorithm simultaneously learning kernel training data ', 'approach dubbed deep tensor decomposition  deeptd  based rank1 tensor decomposition ', 'theoretically investigate deeptd realizable model training data input chosen iid  gaussian distribution label generated according planted convolutional kernel ', 'show deeptd dataefficient provably work soon sample size exceeds total number convolutional weight network ', 'numerical experiment demonstrate effectiveness deeptd verify theoretical finding ']","In this paper we study the problem of learning the weights of a deep convolutional neural network., We consider a network where convolutions are carried out over non-overlapping patches with a single kernel in each layer., We develop an algorithm for simultaneously learning all the kernels from the training data., Our approach dubbed Deep Tensor Decomposition (DeepTD) is based on a rank-1 tensor decomposition., We theoretically investigate DeepTD under a realizable model for the training data where the inputs are chosen i.i.d. from a Gaussian distribution and the labels are generated according to planted convolutional kernels., We show that DeepTD is data-efficient and provably works as soon as the sample size exceeds the total number of convolutional weights in the network., Our numerical experiments demonstrate the effectiveness of DeepTD and verify our theoretical findings.",7,5.597014925373134,16.75
604,"['Neural network pruning techniques can reduce the parameter counts of trained networks by over 90%, decreasing storage requirements and improving computational performance of inference without compromising accuracy.', 'However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance.\n\n', 'We find that a standard pruning technique naturally uncovers subnetworks whose initializations made them capable of training effectively.', 'Based on these results, we articulate the ""lottery ticket hypothesis:"" dense, randomly-initialized, feed-forward networks contain subnetworks (""winning tickets"") that - when trained in isolation - reach test accuracy comparable to the original network in a similar number of iterations.', 'The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective.\n\n', 'We present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations.', 'We consistently find winning tickets that are less than 10-20% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10.', 'Above this size, the winning tickets that we find learn faster than the original network and reach higher test accuracy.']","[0, 0, 0, 0, 1, 0, 0, 0]","[0.1463414579629898, 0.1538461446762085, 0.12121211737394333, 0.11764705181121826, 0.2857142686843872, 0.10526315122842789, 0.10810810327529907, 0.11764705181121826]",rJl-b3RcF7,"['Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training', 'Shows that there exists sparse subnetworks that can be trained from scratch with good generalization performance and proposes a unpruned, randomly initialized NNs contain subnetworks that can be trained from scratch with similar generalization accuracy.', 'The paper examines the hypothesis that randomly initialized neural networks contain sub-networks that converge equally fast or faster and can reach the same or better classification accuracy']","['neural network pruning technique reduce parameter count trained network 90   decreasing storage requirement improving computational performance inference without compromising accuracy ', 'however  contemporary experience sparse architecture produced pruning difficult train start  would similarly improve training performance ', 'find standard pruning technique naturally uncovers subnetworks whose initialization made capable training effectively ', 'based result  articulate  lottery ticket hypothesis   dense  randomlyinitialized  feedforward network contain subnetworks   winning ticket    trained isolation  reach test accuracy comparable original network similar number iteration ', 'winning ticket find initialization lottery  connection initial weight make training particularly effective ', 'present algorithm identify winning ticket series experiment support lottery ticket hypothesis importance fortuitous initialization ', 'consistently find winning ticket le 1020  size several fullyconnected convolutional feedforward architecture mnist cifar10 ', 'size  winning ticket find learn faster original network reach higher test accuracy ']","Neural network pruning techniques can reduce the parameter counts of trained networks by over 90%, decreasing storage requirements and improving computational performance of inference without compromising accuracy., However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance.

, We find that a standard pruning technique naturally uncovers subnetworks whose initializations made them capable of training effectively., Based on these results, we articulate the ""lottery ticket hypothesis:"" dense, randomly-initialized, feed-forward networks contain subnetworks (""winning tickets"") that - when trained in isolation - reach test accuracy comparable to the original network in a similar number of iterations., The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective.

, We present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations., We consistently find winning tickets that are less than 10-20% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10., Above this size, the winning tickets that we find learn faster than the original network and reach higher test accuracy.",15,6.207070707070707,13.2
605,"['We investigate the difficulties of training sparse neural networks and make new observations about optimization dynamics and the energy landscape within the sparse regime.', 'Recent work of \\citep{Gale2019, Liu2018} has shown that sparse ResNet-50 architectures trained on ImageNet-2012 dataset converge to solutions that are significantly worse than those found by pruning.', ""We show that, despite the failure of optimizers, there is a linear path with a monotonically decreasing objective from the initialization to the ``good'' solution."", ""Additionally, our attempts to find a decreasing objective path from ``bad'' solutions to the ``good'' ones in the sparse subspace fail."", 'However, if we allow the path to traverse the dense subspace, then we consistently find a path between two solutions.', 'These findings suggest traversing extra dimensions may be needed to escape stationary points found in the sparse subspace.']","[1, 0, 0, 0, 0, 0]","[0.41025641560554504, 0.13333332538604736, 0.09756097197532654, 0.15789473056793213, 0.1111111044883728, 0.1621621549129486]",SyeyPEH23N,['In this paper we highlight  the difficulty of training sparse neural networks by doing interpolation experiments in the energy landscape '],"['investigate difficulty training sparse neural network make new observation optimization dynamic energy landscape within sparse regime ', 'recent work citep  gale2019  liu2018  shown sparse resnet50 architecture trained imagenet2012 dataset converge solution significantly worse found pruning ', 'show  despite failure optimizers  linear path monotonically decreasing objective initialization  good  solution ', 'additionally  attempt find decreasing objective path  bad  solution  good  one sparse subspace fail ', 'however  allow path traverse dense subspace  consistently find path two solution ', 'finding suggest traversing extra dimension may needed escape stationary point found sparse subspace ']","We investigate the difficulties of training sparse neural networks and make new observations about optimization dynamics and the energy landscape within the sparse regime., Recent work of \citep{Gale2019, Liu2018} has shown that sparse ResNet-50 architectures trained on ImageNet-2012 dataset converge to solutions that are significantly worse than those found by pruning., We show that, despite the failure of optimizers, there is a linear path with a monotonically decreasing objective from the initialization to the ``good'' solution., Additionally, our attempts to find a decreasing objective path from ``bad'' solutions to the ``good'' ones in the sparse subspace fail., However, if we allow the path to traverse the dense subspace, then we consistently find a path between two solutions., These findings suggest traversing extra dimensions may be needed to escape stationary points found in the sparse subspace.",12,5.718518518518518,11.25
606,"['Neural network training depends on the structure of the underlying loss landscape, i.e. local minima, saddle points, flat plateaus, and loss barriers.', 'In relation to the structure of the landscape, we study the permutation symmetry of neurons in each layer of a deep neural network, which gives rise not only to multiple equivalent global minima of the loss function but also to critical points in between partner minima.', ""In a network of $d-1$ hidden layers with $n_k$ neurons in layers $k = 1, \\ldots, d$, we construct continuous paths between equivalent global minima that lead through a `permutation point' where the input and output weight vectors of two neurons in the same hidden layer $k$ collide and interchange."", 'We show that such permutation points are critical points which lie inside high-dimensional subspaces of equal loss, contributing to the global flatness of the landscape.', 'We also find that a permutation point for the exchange of neurons $i$ and $j$ transits into a flat high-dimensional plateau that enables all $n_k!$', 'permutations of neurons in a given layer $k$ at the same loss value. Moreover', ', we introduce higher-order permutation points by exploiting the hierarchical structure in the loss landscapes of neural networks, and find that the number of $K$-th order permutation points is much larger than the (already huge) number of equivalent global minima -- at least by a polynomial factor of order $K$. In two', 'tasks, we demonstrate numerically with our path finding method that continuous paths between partner minima exist: first, in a toy network with a single hidden layer on a function approximation task and, second, in a multilayer network on the MNIST task. Our geometric', 'approach yields a lower bound on the number of critical points generated by weight-space symmetries and provides a simple intuitive link between previous theoretical results and numerical observations.']","[0, 1, 0, 0, 0, 0, 0, 0, 0]","[0.21052631735801697, 0.2641509473323822, 0.1355932205915451, 0.20512819290161133, 0.19999998807907104, 0.12903225421905518, 0.20689654350280762, 0.07692307233810425, 0.1395348757505417]",rkxmPgrKwB,"['Weight-space symmetry in neural network landscapes gives rise to numerous number of saddles and flat high-dimensional subspaces.', 'The paper presented a low-loss method for studying the loss function with respect to parameters in a neural network from the perspective of weight-space symmetry.']","['neural network training depends structure underlying loss landscape  ie  local minimum  saddle point  flat plateau  loss barrier ', 'relation structure landscape  study permutation symmetry neuron layer deep neural network  give rise multiple equivalent global minimum loss function also critical point partner minimum ', 'network  d1  hidden layer  nk  neuron layer  k  1  ldots    construct continuous path equivalent global minimum lead  permutation point  input output weight vector two neuron hidden layer  k  collide interchange ', 'show permutation point critical point lie inside highdimensional subspace equal loss  contributing global flatness landscape ', 'also find permutation point exchange neuron    j  transit flat highdimensional plateau enables  nk  ', 'permutation neuron given layer  k  loss value  moreover', ' introduce higherorder permutation point exploiting hierarchical structure loss landscape neural network  find number  k  th order permutation point much larger  already huge  number equivalent global minimum  least polynomial factor order  k   two', 'task  demonstrate numerically path finding method continuous path partner minimum exist  first  toy network single hidden layer function approximation task  second  multilayer network mnist task  geometric', 'approach yield lower bound number critical point generated weightspace symmetry provides simple intuitive link previous theoretical result numerical observation ']","Neural network training depends on the structure of the underlying loss landscape, i.e. local minima, saddle points, flat plateaus, and loss barriers., In relation to the structure of the landscape, we study the permutation symmetry of neurons in each layer of a deep neural network, which gives rise not only to multiple equivalent global minima of the loss function but also to critical points in between partner minima., In a network of $d-1$ hidden layers with $n_k$ neurons in layers $k = 1, \ldots, d$, we construct continuous paths between equivalent global minima that lead through a `permutation point' where the input and output weight vectors of two neurons in the same hidden layer $k$ collide and interchange., We show that such permutation points are critical points which lie inside high-dimensional subspaces of equal loss, contributing to the global flatness of the landscape., We also find that a permutation point for the exchange of neurons $i$ and $j$ transits into a flat high-dimensional plateau that enables all $n_k!$, permutations of neurons in a given layer $k$ at the same loss value. Moreover, , we introduce higher-order permutation points by exploiting the hierarchical structure in the loss landscapes of neural networks, and find that the number of $K$-th order permutation points is much larger than the (already huge) number of equivalent global minima -- at least by a polynomial factor of order $K$. In two, tasks, we demonstrate numerically with our path finding method that continuous paths between partner minima exist: first, in a toy network with a single hidden layer on a function approximation task and, second, in a multilayer network on the MNIST task. Our geometric, approach yields a lower bound on the number of critical points generated by weight-space symmetries and provides a simple intuitive link between previous theoretical results and numerical observations.",25,5.223684210526316,10.857142857142858
607,"['The training of stochastic neural network models with binary ($\\pm1$) weights and activations via continuous surrogate networks is investigated.', 'We derive, using mean field theory, a set of scalar equations describing how input signals propagate through surrogate networks.', 'The equations reveal that depending on the choice of surrogate model, the networks may or may not exhibit an order to chaos transition, and the presence of depth scales that limit the maximum trainable depth.', 'Specifically, in solving the equations for edge of chaos conditions, we show that surrogates derived using the Gaussian local reparameterisation trick have no critical initialisation, whereas a deterministic surrogates based on analytic Gaussian integration do.', 'The theory is applied to a range of binary neuron and weight design choices, such as different neuron noise models, allowing the categorisation of algorithms in terms of their behaviour at initialisation.', 'Moreover, we predict theoretically and confirm numerically, that common weight initialization schemes used in standard continuous networks, when applied to the mean values of the stochastic binary weights, yield poor training performance.', 'This study shows that, contrary to common intuition, the means of the stochastic binary weights should be initialised close to close to $\\pm 1$ for deeper networks to be trainable.']","[0, 0, 0, 0, 1, 0, 0]","[0.1666666567325592, 0.0555555522441864, 0.13333332538604736, 0.16326530277729034, 0.21739129722118378, 0.2083333283662796, 0.1463414579629898]",rylmoxrFDH,"['signal propagation theory applied to continuous surrogates of binary nets;  counter intuitive initialisation; reparameterisation trick not helpful', 'The authors investigate the training dynamics of binary neural networks when using continuous surrogates, study what properties networks should have at initialization to best train, and provide concrete advice about stochastic weights at initialization.', 'An in-depth exploration of stochastic binary networks, continuous surrogates, and their training dynamics, with insights on how to initialize weights for best performance.']","['training stochastic neural network model binary   pm1   weight activation via continuous surrogate network investigated ', 'derive  using mean field theory  set scalar equation describing input signal propagate surrogate network ', 'equation reveal depending choice surrogate model  network may may exhibit order chaos transition  presence depth scale limit maximum trainable depth ', 'specifically  solving equation edge chaos condition  show surrogate derived using gaussian local reparameterisation trick critical initialisation  whereas deterministic surrogate based analytic gaussian integration ', 'theory applied range binary neuron weight design choice  different neuron noise model  allowing categorisation algorithm term behaviour initialisation ', 'moreover  predict theoretically confirm numerically  common weight initialization scheme used standard continuous network  applied mean value stochastic binary weight  yield poor training performance ', 'study show  contrary common intuition  mean stochastic binary weight initialised close close  pm 1  deeper network trainable ']","The training of stochastic neural network models with binary ($\pm1$) weights and activations via continuous surrogate networks is investigated., We derive, using mean field theory, a set of scalar equations describing how input signals propagate through surrogate networks., The equations reveal that depending on the choice of surrogate model, the networks may or may not exhibit an order to chaos transition, and the presence of depth scales that limit the maximum trainable depth., Specifically, in solving the equations for edge of chaos conditions, we show that surrogates derived using the Gaussian local reparameterisation trick have no critical initialisation, whereas a deterministic surrogates based on analytic Gaussian integration do., The theory is applied to a range of binary neuron and weight design choices, such as different neuron noise models, allowing the categorisation of algorithms in terms of their behaviour at initialisation., Moreover, we predict theoretically and confirm numerically, that common weight initialization schemes used in standard continuous networks, when applied to the mean values of the stochastic binary weights, yield poor training performance., This study shows that, contrary to common intuition, the means of the stochastic binary weights should be initialised close to close to $\pm 1$ for deeper networks to be trainable.",22,5.707920792079208,9.181818181818182
608,"['Semantic dependency parsing, which aims to find rich bi-lexical relationships, allows words to have multiple dependency heads, resulting in graph-structured representations.', 'We propose an approach to semi-supervised learning of semantic dependency parsers based on the CRF autoencoder framework.', 'Our encoder is a discriminative neural semantic dependency parser that predicts the latent parse graph of the input sentence.', 'Our decoder is a generative neural model that reconstructs the input sentence conditioned on the latent parse graph.', 'Our model is arc-factored and therefore parsing and learning are both tractable.', 'Experiments show our model achieves significant and consistent improvement over the supervised baseline.']","[0, 1, 0, 0, 0, 0]","[0.1111111044883728, 1.0, 0.22857142984867096, 0.11764705181121826, 0.0714285671710968, 0.06666666269302368]",BklS6ANFDH,"['We propose an approach to semi-supervised learning of semantic dependency parsers based on the CRF autoencoder framework.', 'This paper focuses on semi-supervised semantic dependency parsing using the CRF-autoencoder to train the model in a semi-supervised style, indicating effectiveness on low resource labeled data tasks.']","['semantic dependency parsing  aim find rich bilexical relationship  allows word multiple dependency head  resulting graphstructured representation ', 'propose approach semisupervised learning semantic dependency parser based crf autoencoder framework ', 'encoder discriminative neural semantic dependency parser predicts latent parse graph input sentence ', 'decoder generative neural model reconstructs input sentence conditioned latent parse graph ', 'model arcfactored therefore parsing learning tractable ', 'experiment show model achieves significant consistent improvement supervised baseline ']","Semantic dependency parsing, which aims to find rich bi-lexical relationships, allows words to have multiple dependency heads, resulting in graph-structured representations., We propose an approach to semi-supervised learning of semantic dependency parsers based on the CRF autoencoder framework., Our encoder is a discriminative neural semantic dependency parser that predicts the latent parse graph of the input sentence., Our decoder is a generative neural model that reconstructs the input sentence conditioned on the latent parse graph., Our model is arc-factored and therefore parsing and learning are both tractable., Experiments show our model achieves significant and consistent improvement over the supervised baseline.",9,6.22,11.11111111111111
609,"['For sequence models with large word-level vocabularies, a majority of network parameters lie in the input and output layers.', 'In this work, we describe a new method, DeFINE, for learning deep word-level representations efficiently.', 'Our architecture uses a hierarchical structure with novel skip-connections which allows for the use of low dimensional input and output layers, reducing total parameters and training time while delivering similar or better performance versus existing methods.', 'DeFINE can be incorporated easily in new or existing sequence models.', 'Compared to state-of-the-art methods including adaptive input representations, this technique results in a 6% to 20% drop in perplexity.', 'On WikiText-103, DeFINE reduces total parameters of Transformer-XL by half with minimal impact on performance.', 'On the Penn Treebank, DeFINE improves AWD-LSTM by 4 points with a 17% reduction in parameters,  achieving comparable performance to state-of-the-art methods with fewer parameters.', 'For machine translation, DeFINE improves a Transformer model by 2% while simultaneously reducing total parameters by 26%']","[0, 0, 0, 0, 0, 0, 1, 0]","[0.1621621549129486, 0.1818181723356247, 0.15094339847564697, 0.13793103396892548, 0.11428570747375488, 0.12121211737394333, 0.1904761791229248, 0.11764705181121826]",rJeXS04FPH,"['DeFINE uses a deep, hierarchical, sparse network with new skip connections to learn better word embeddings efficiently. ', 'This paper describes a new method for learning deep word-level representations efficiently by using a hierarchical structure with skip-connections for the use of low dimensional input and output layers.']","['sequence model large wordlevel vocabulary  majority network parameter lie input output layer ', 'work  describe new method  define  learning deep wordlevel representation efficiently ', 'architecture us hierarchical structure novel skipconnections allows use low dimensional input output layer  reducing total parameter training time delivering similar better performance versus existing method ', 'define incorporated easily new existing sequence model ', 'compared stateoftheart method including adaptive input representation  technique result 6  20  drop perplexity ', 'wikitext103  define reduces total parameter transformerxl half minimal impact performance ', 'penn treebank  define improves awdlstm 4 point 17  reduction parameter  achieving comparable performance stateoftheart method fewer parameter ', 'machine translation  define improves transformer model 2  simultaneously reducing total parameter 26 ']","For sequence models with large word-level vocabularies, a majority of network parameters lie in the input and output layers., In this work, we describe a new method, DeFINE, for learning deep word-level representations efficiently., Our architecture uses a hierarchical structure with novel skip-connections which allows for the use of low dimensional input and output layers, reducing total parameters and training time while delivering similar or better performance versus existing methods., DeFINE can be incorporated easily in new or existing sequence models., Compared to state-of-the-art methods including adaptive input representations, this technique results in a 6% to 20% drop in perplexity., On WikiText-103, DeFINE reduces total parameters of Transformer-XL by half with minimal impact on performance., On the Penn Treebank, DeFINE improves AWD-LSTM by 4 points with a 17% reduction in parameters,  achieving comparable performance to state-of-the-art methods with fewer parameters., For machine translation, DeFINE improves a Transformer model by 2% while simultaneously reducing total parameters by 26%",18,6.0,8.722222222222221
610,"['In this paper, we present a reproduction of the paper of Bertinetto et al. [2019] ""Meta-learning with differentiable closed-form solvers"" as part of the ICLR 2019 Reproducibility Challenge.', 'In successfully reproducing the most crucial part of the paper, we reach a performance that is comparable with or superior to the original paper on two benchmarks for several settings.', 'We evaluate new baseline results, using a new dataset presented in the paper.', 'Yet, we also provide multiple remarks and recommendations about reproducibility and comparability.  ', 'After we brought our reproducibility work to the authors attention, they have updated the original paper on which this work is based and released code as well.', 'Our contributions mainly consist in reproducing the most important results of their original paper, in giving insight in the reproducibility and in providing a first open-source implementation.']","[0, 1, 0, 0, 0, 0]","[0.19607841968536377, 0.29629629850387573, 0.15789473056793213, 0.10526315122842789, 0.11764705181121826, 0.16326530277729034]",BJx0N2I6IN,['We successfully reproduce and give remarks on the comparison with baselines of a meta-learning approach for few-shot classification that works by backpropagating through the solution of a closed-form solver.'],"['paper  present reproduction paper bertinetto et al   2019   metalearning differentiable closedform solver  part iclr 2019 reproducibility challenge ', 'successfully reproducing crucial part paper  reach performance comparable superior original paper two benchmark several setting ', 'evaluate new baseline result  using new dataset presented paper ', 'yet  also provide multiple remark recommendation reproducibility comparability ', 'brought reproducibility work author  attention  updated original paper work based released code well ', 'contribution mainly consist reproducing important result original paper  giving insight reproducibility providing first opensource implementation ']","In this paper, we present a reproduction of the paper of Bertinetto et al. [2019] ""Meta-learning with differentiable closed-form solvers"" as part of the ICLR 2019 Reproducibility Challenge., In successfully reproducing the most crucial part of the paper, we reach a performance that is comparable with or superior to the original paper on two benchmarks for several settings., We evaluate new baseline results, using a new dataset presented in the paper., Yet, we also provide multiple remarks and recommendations about reproducibility and comparability.  , After we brought our reproducibility work to the authors attention, they have updated the original paper on which this work is based and released code as well., Our contributions mainly consist in reproducing the most important results of their original paper, in giving insight in the reproducibility and in providing a first open-source implementation.",12,5.576642335766423,10.538461538461538
611,"['Network pruning has emerged as a powerful technique for reducing the size of deep neural networks.', 'Pruning uncovers high-performance subnetworks by taking a trained dense network and gradually removing unimportant connections.', 'Recently, alternative techniques have emerged for training sparse networks directly without having to train a large dense model beforehand, thereby achieving small memory footprints during both training and inference.These techniques are based on dynamic reallocation of non-zero parameters during training.', 'Thus, they are in effect executing a training-time search for the optimal subnetwork.', 'We investigate a most recent one of these techniques and conduct additional experiments to elucidate its behavior in training sparse deep convolutional networks.', 'Dynamic parameter reallocation converges early during training to a highly trainable subnetwork.', 'We show that neither the structure, nor the initialization of the discovered high-performance subnetwork is sufficient to explain its good performance.', 'Rather, it is the dynamics of parameter reallocation that are responsible for successful learning.', 'Dynamic parameter reallocation thus improves the trainability of deep convolutional networks, playing a similar role as overparameterization, without incurring the memory and computational cost of the latter.']","[0, 0, 0, 0, 0, 0, 0, 0, 1]","[0.09999999403953552, 0.10256409645080566, 0.13114753365516663, 0.10810810327529907, 0.1702127605676651, 0.1111111044883728, 0.09302324801683426, 0.21052631735801697, 0.25]",BygIWTMdjX,"['Dynamic parameter-reallocation enables the successful direct training of compact sparse networks, and it plays an indispensable role even when we know the optimal sparse network a-priori']","['network pruning emerged powerful technique reducing size deep neural network ', 'pruning uncovers highperformance subnetworks taking trained dense network gradually removing unimportant connection ', 'recently  alternative technique emerged training sparse network directly without train large dense model beforehand  thereby achieving small memory footprint training inferencethese technique based dynamic reallocation nonzero parameter training ', 'thus  effect executing trainingtime search optimal subnetwork ', 'investigate recent one technique conduct additional experiment elucidate behavior training sparse deep convolutional network ', 'dynamic parameter reallocation converges early training highly trainable subnetwork ', 'show neither structure  initialization discovered highperformance subnetwork sufficient explain good performance ', 'rather  dynamic parameter reallocation responsible successful learning ', 'dynamic parameter reallocation thus improves trainability deep convolutional network  playing similar role overparameterization  without incurring memory computational cost latter ']","Network pruning has emerged as a powerful technique for reducing the size of deep neural networks., Pruning uncovers high-performance subnetworks by taking a trained dense network and gradually removing unimportant connections., Recently, alternative techniques have emerged for training sparse networks directly without having to train a large dense model beforehand, thereby achieving small memory footprints during both training and inference.These techniques are based on dynamic reallocation of non-zero parameters during training., Thus, they are in effect executing a training-time search for the optimal subnetwork., We investigate a most recent one of these techniques and conduct additional experiments to elucidate its behavior in training sparse deep convolutional networks., Dynamic parameter reallocation converges early during training to a highly trainable subnetwork., We show that neither the structure, nor the initialization of the discovered high-performance subnetwork is sufficient to explain its good performance., Rather, it is the dynamics of parameter reallocation that are responsible for successful learning., Dynamic parameter reallocation thus improves the trainability of deep convolutional networks, playing a similar role as overparameterization, without incurring the memory and computational cost of the latter.",16,6.3646408839779,11.3125
612,"['n this paper we present a thrust in three directions of visual development us- ing supervised and semi-supervised techniques.', 'The first is an implementation of semi-supervised object detection and recognition using the principles of Soft At- tention and Generative Adversarial Networks (GANs).', 'The second and the third are supervised networks that learn basic concepts of spatial locality and quantity respectively using Convolutional Neural Networks (CNNs).', 'The three thrusts to- gether are based on the approach of Experiential Robot Learning, introduced in previous publication.', 'While the results are unripe for implementation, we believe they constitute a stepping stone towards autonomous development of robotic vi- sual modules.']","[0, 0, 0, 0, 1]","[0.0624999962747097, 0.05882352590560913, 0.05714285373687744, 0.12903225421905518, 0.17142856121063232]",H1BHbmWCZ,"['3 thrusts serving as stepping stones for robot experiential learning of vision module', 'Investigates is performance of existing image classifiers and object detectors. ']","['n paper present thrust three direction visual development u ing supervised semisupervised technique ', 'first implementation semisupervised object detection recognition using principle soft tention generative adversarial network  gans  ', 'second third supervised network learn basic concept spatial locality quantity respectively using convolutional neural network  cnns  ', 'three thrust gether based approach experiential robot learning  introduced previous publication ', 'result unripe implementation  believe constitute stepping stone towards autonomous development robotic vi sual module ']","n this paper we present a thrust in three directions of visual development us- ing supervised and semi-supervised techniques., The first is an implementation of semi-supervised object detection and recognition using the principles of Soft At- tention and Generative Adversarial Networks (GANs)., The second and the third are supervised networks that learn basic concepts of spatial locality and quantity respectively using Convolutional Neural Networks (CNNs)., The three thrusts to- gether are based on the approach of Experiential Robot Learning, introduced in previous publication., While the results are unripe for implementation, we believe they constitute a stepping stone towards autonomous development of robotic vi- sual modules.",7,5.980952380952381,15.0
613,"['Characterization of the representations learned in intermediate layers of deep networks can provide valuable insight into the nature of a task and can guide the development of well-tailored learning strategies.', 'Here we study convolutional neural network-based acoustic models in the context of automatic speech recognition.', 'Adapting a method proposed by Yosinski et al. [2014], we measure the transferability of each layer between German and English to assess the their language-specifity.', 'We observe three distinct regions of transferability: (1) the first two layers are entirely transferable between languages, (2) layers 28 are also highly transferable but we find evidence of some language specificity, (3) the subsequent fully connected layers are more language specific but can be successfully finetuned to the target language.', 'To further probe the effect of weight freezing, we performed follow-up experiments using freeze-training [Raghu et al., 2017].', ""Our results are consistent with the observation that CCNs converge 'bottom up' during training and demonstrate the benefit of freeze training, especially for transfer learning.""]","[0, 0, 0, 1, 0, 0]","[0.12765957415103912, 0.21052631735801697, 0.12765957415103912, 0.2539682388305664, 0.0952380895614624, 0.21276594698429108]",HkgPMupoj7,"['All but the first two layers of our CNNs based acoustic models demonstrated some degree of language-specificity but freeze training enabled successful transfer between languages.', ""The paper measures the transferability of features for each layer in CNN-based acoustic models across languages, concluding that AMs trained with 'the freeze training' technique outperformed other transferred models.""]","['characterization representation learned intermediate layer deep network provide valuable insight nature task guide development welltailored learning strategy ', 'study convolutional neural networkbased acoustic model context automatic speech recognition ', 'adapting method proposed yosinski et al   2014   measure transferability layer german english ass languagespecifity ', 'observe three distinct region transferability   1  first two layer entirely transferable language   2  layer 28 also highly transferable find evidence language specificity   3  subsequent fully connected layer language specific successfully finetuned target language ', 'probe effect weight freezing  performed followup experiment using freezetraining  raghu et al  2017  ', 'result consistent observation ccns converge bottom  training demonstrate benefit freeze training  especially transfer learning ']","Characterization of the representations learned in intermediate layers of deep networks can provide valuable insight into the nature of a task and can guide the development of well-tailored learning strategies., Here we study convolutional neural network-based acoustic models in the context of automatic speech recognition., Adapting a method proposed by Yosinski et al. [2014], we measure the transferability of each layer between German and English to assess the their language-specifity., We observe three distinct regions of transferability: (1) the first two layers are entirely transferable between languages, (2) layers 28 are also highly transferable but we find evidence of some language specificity, (3) the subsequent fully connected layers are more language specific but can be successfully finetuned to the target language., To further probe the effect of weight freezing, we performed follow-up experiments using freeze-training [Raghu et al., 2017]., Our results are consistent with the observation that CCNs converge 'bottom up' during training and demonstrate the benefit of freeze training, especially for transfer learning.",12,5.914634146341464,12.615384615384615
614,"['Policy gradients methods often achieve better performance when the change in policy is limited to a small Kullback-Leibler divergence.', 'We derive policy gradients where the change in policy is limited to a small Wasserstein distance (or trust region).', 'This is done in the discrete and continuous multi-armed bandit settings with entropy regularisation.', 'We show that in the small steps limit with respect to the Wasserstein distance $W_2$, policy dynamics are governed by the heat equation, following the Jordan-Kinderlehrer-Otto result.', 'This means that policies undergo diffusion and advection, concentrating near actions with high reward.', 'This helps elucidate the nature of convergence in the probability matching setup, and provides justification for empirical practices such as Gaussian policy priors and additive gradient noise.']","[0, 0, 0, 1, 0, 0]","[0.13793103396892548, 0.1428571343421936, 0.1666666567325592, 0.1764705777168274, 0.0833333283662796, 0.17142856121063232]",rk3mjYRp-,"['Linking Wasserstein-trust region entropic policy gradients, and the heat equation.', 'The paper explores the connections between reinforcement learning and the theory of quadratic optimal transport', 'The authors studied policy gradient with change of policies limited by a trust region of Wasserstein distance in the multi-armed bandit setting, showing that in the small steps limit, the policy dynamics are governed by the heat equation (Fokker-Planck equation).']","['policy gradient method often achieve better performance change policy limited small kullbackleibler divergence ', 'derive policy gradient change policy limited small wasserstein distance  trust region  ', 'done discrete continuous multiarmed bandit setting entropy regularisation ', 'show small step limit respect wasserstein distance  w2   policy dynamic governed heat equation  following jordankinderlehrerotto result ', 'mean policy undergo diffusion advection  concentrating near action high reward ', 'help elucidate nature convergence probability matching setup  provides justification empirical practice gaussian policy prior additive gradient noise ']","Policy gradients methods often achieve better performance when the change in policy is limited to a small Kullback-Leibler divergence., We derive policy gradients where the change in policy is limited to a small Wasserstein distance (or trust region)., This is done in the discrete and continuous multi-armed bandit settings with entropy regularisation., We show that in the small steps limit with respect to the Wasserstein distance $W_2$, policy dynamics are governed by the heat equation, following the Jordan-Kinderlehrer-Otto result., This means that policies undergo diffusion and advection, concentrating near actions with high reward., This helps elucidate the nature of convergence in the probability matching setup, and provides justification for empirical practices such as Gaussian policy priors and additive gradient noise.",10,5.9,12.0
615,"['The softmax function is widely used to train deep neural networks for multi-class classification.', 'Despite its outstanding performance in classification tasks, the features derived from the supervision of softmax are usually sub-optimal in some scenarios where Euclidean distances apply in feature spaces.', 'To address this issue, we propose a new loss, dubbed the isotropic loss, in the sense that the overall distribution of data points is regularized to approach the isotropic normal one.', 'Combined with the vanilla softmax, we formalize a novel criterion called the isotropic softmax, or isomax for short, for supervised learning of deep neural networks.', 'By virtue of the isomax, the intra-class features are penalized by the isotropic loss while inter-class distances are well kept by the original softmax loss.', 'Moreover, the isomax loss does not require any additional modifications to the network, mini-batches or the training process.', 'Extensive experiments on classification and clustering are performed to demonstrate the superiority and robustness of the isomax loss.']","[0, 0, 1, 0, 0, 0, 0]","[0.2222222238779068, 0.12765957415103912, 0.25, 0.1818181723356247, 0.19512194395065308, 0.0, 0.10526315122842789]",rkgINf1G1m,['The discriminative capability of softmax for learning feature vectors of objects is effectively enhanced by virture of isotropic normalization on global distribution of data points.'],"['softmax function widely used train deep neural network multiclass classification ', 'despite outstanding performance classification task  feature derived supervision softmax usually suboptimal scenario euclidean distance apply feature space ', 'address issue  propose new loss  dubbed isotropic loss  sense overall distribution data point regularized approach isotropic normal one ', 'combined vanilla softmax  formalize novel criterion called isotropic softmax  isomax short  supervised learning deep neural network ', 'virtue isomax  intraclass feature penalized isotropic loss interclass distance well kept original softmax loss ', 'moreover  isomax loss require additional modification network  minibatches training process ', 'extensive experiment classification clustering performed demonstrate superiority robustness isomax loss ']","The softmax function is widely used to train deep neural networks for multi-class classification., Despite its outstanding performance in classification tasks, the features derived from the supervision of softmax are usually sub-optimal in some scenarios where Euclidean distances apply in feature spaces., To address this issue, we propose a new loss, dubbed the isotropic loss, in the sense that the overall distribution of data points is regularized to approach the isotropic normal one., Combined with the vanilla softmax, we formalize a novel criterion called the isotropic softmax, or isomax for short, for supervised learning of deep neural networks., By virtue of the isomax, the intra-class features are penalized by the isotropic loss while inter-class distances are well kept by the original softmax loss., Moreover, the isomax loss does not require any additional modifications to the network, mini-batches or the training process., Extensive experiments on classification and clustering are performed to demonstrate the superiority and robustness of the isomax loss.",17,5.6918238993710695,9.352941176470589
616,"['A fundamental question in reinforcement learning is whether model-free algorithms are sample efficient.', 'Recently,  Jin et al. (2018) proposed a Q-learning algorithm with UCB exploration policy, and proved it has nearly optimal regret bound for finite-horizon episodic MDP.', 'In this paper, we adapt Q-learning with UCB-exploration bonus to infinite-horizon MDP with discounted rewards \\emph{without} accessing a generative model.', 'We show that the \\textit{sample complexity of exploration} of our algorithm is bounded by $\\tilde{O}({\\frac{SA}{\\epsilon^2(1-\\gamma)^7}})$.', 'This improves the previously best known result of $\\tilde{O}({\\frac{SA}{\\epsilon^4(1-\\gamma)^8}})$ in this setting achieved by delayed Q-learning (Strehlet al., 2006),, and matches the lower bound in terms of $\\epsilon$ as well as $S$ and $A$ up to logarithmic factors.']","[0, 0, 1, 0, 0]","[0.0, 0.2083333283662796, 0.6190476417541504, 0.10810810327529907, 0.31578946113586426]",BkglSTNFDB,"['We adapt Q-learning with UCB-exploration bonus to infinite-horizon MDP with discounted rewards without accessing a generative model, and improves the previously best known result.', 'This paper considered a Q-learning algorithm with UCB exploration policy for infinite-horizon MDP.']","['fundamental question reinforcement learning whether modelfree algorithm sample efficient ', 'recently  jin et al   2018  proposed qlearning algorithm ucb exploration policy  proved nearly optimal regret bound finitehorizon episodic mdp ', 'paper  adapt qlearning ucbexploration bonus infinitehorizon mdp discounted reward emph  without  accessing generative model ', 'show textit  sample complexity exploration  algorithm bounded  tilde     frac  sa   epsilon2  1gamma  7     ', 'improves previously best known result  tilde     frac  sa   epsilon4  1gamma  8     setting achieved delayed qlearning  strehlet al  2006    match lower bound term  epsilon  well     logarithmic factor ']","A fundamental question in reinforcement learning is whether model-free algorithms are sample efficient., Recently,  Jin et al. (2018) proposed a Q-learning algorithm with UCB exploration policy, and proved it has nearly optimal regret bound for finite-horizon episodic MDP., In this paper, we adapt Q-learning with UCB-exploration bonus to infinite-horizon MDP with discounted rewards \emph{without} accessing a generative model., We show that the \textit{sample complexity of exploration} of our algorithm is bounded by $\tilde{O}({\frac{SA}{\epsilon^2(1-\gamma)^7}})$., This improves the previously best known result of $\tilde{O}({\frac{SA}{\epsilon^4(1-\gamma)^8}})$ in this setting achieved by delayed Q-learning (Strehlet al., 2006),, and matches the lower bound in terms of $\epsilon$ as well as $S$ and $A$ up to logarithmic factors.",10,6.495495495495495,10.090909090909092
617,"[""Backpropagation is driving today's artificial neural networks (ANNs)."", 'However, despite extensive research, it remains unclear if the brain implements this algorithm.', 'Among neuroscientists, reinforcement learning (RL) algorithms are often seen as a realistic alternative: neurons can randomly introduce change, and use unspecific feedback signals to observe their effect on the cost and thus approximate their gradient.', 'However, the convergence rate of such learning scales poorly with the number of involved neurons.', 'Here we propose a hybrid learning approach.', 'Each neuron uses an RL-type strategy to learn how to approximate the gradients that backpropagation would provide.', 'We provide proof that our approach converges to the true gradient for certain classes of networks.', 'In both feedforward and convolutional networks, we empirically show that our approach learns to approximate the gradient, and can match the performance of gradient-based learning.', 'Learning feedback weights provides a biologically plausible mechanism of achieving good performance, without the need for precise, pre-specified learning rules.']","[0, 0, 0, 0, 0, 0, 0, 1, 0]","[0.1666666567325592, 0.0, 0.16326530277729034, 0.0, 0.0, 0.1249999925494194, 0.1249999925494194, 0.20512819290161133, 0.1111111044883728]",ByeUBANtvB,"['Perturbations can be used to train feedback weights to learn in fully connected and convolutional neural networks', 'This paper proposes a method that addresses the ""weight transport"" problem by estimating the weights for the backward pass using a noise-based estimator ']","['backpropagation driving today artificial neural network  anns  ', 'however  despite extensive research  remains unclear brain implement algorithm ', 'among neuroscientist  reinforcement learning  rl  algorithm often seen realistic alternative  neuron randomly introduce change  use unspecific feedback signal observe effect cost thus approximate gradient ', 'however  convergence rate learning scale poorly number involved neuron ', 'propose hybrid learning approach ', 'neuron us rltype strategy learn approximate gradient backpropagation would provide ', 'provide proof approach converges true gradient certain class network ', 'feedforward convolutional network  empirically show approach learns approximate gradient  match performance gradientbased learning ', 'learning feedback weight provides biologically plausible mechanism achieving good performance  without need precise  prespecified learning rule ']","Backpropagation is driving today's artificial neural networks (ANNs)., However, despite extensive research, it remains unclear if the brain implements this algorithm., Among neuroscientists, reinforcement learning (RL) algorithms are often seen as a realistic alternative: neurons can randomly introduce change, and use unspecific feedback signals to observe their effect on the cost and thus approximate their gradient., However, the convergence rate of such learning scales poorly with the number of involved neurons., Here we propose a hybrid learning approach., Each neuron uses an RL-type strategy to learn how to approximate the gradients that backpropagation would provide., We provide proof that our approach converges to the true gradient for certain classes of networks., In both feedforward and convolutional networks, we empirically show that our approach learns to approximate the gradient, and can match the performance of gradient-based learning., Learning feedback weights provides a biologically plausible mechanism of achieving good performance, without the need for precise, pre-specified learning rules.",18,6.096153846153846,8.666666666666666
618,"['This paper proposes and demonstrates a surprising pattern in the training of neural networks: there is a one to one relation between the values of any pair of losses (such as cross entropy, mean squared error, 0/1 error etc.) evaluated for a model arising at (any point of) a training run.', 'This pattern is universal in the sense that this one to one relationship is identical across architectures (such as VGG, Resnet, Densenet etc.), algorithms (SGD and SGD with momentum) and training loss functions (cross entropy and mean squared error).']","[1, 0]","[0.18666666746139526, 0.17910447716712952]",H1e2wNB3hV,"['We identify some universal patterns (i.e., holding across architectures) in the behavior of different surrogate losses (CE, MSE, 0-1 loss) while training neural networks and present supporting empirical evidence.']","['paper proposes demonstrates surprising pattern training neural network  one one relation value pair loss  cross entropy  mean squared error  01 error etc   evaluated model arising  point  training run ', 'pattern universal sense one one relationship identical across architecture  vgg  resnet  densenet etc    algorithm  sgd sgd momentum  training loss function  cross entropy mean squared error  ']","This paper proposes and demonstrates a surprising pattern in the training of neural networks: there is a one to one relation between the values of any pair of losses (such as cross entropy, mean squared error, 0/1 error etc.) evaluated for a model arising at (any point of) a training run., This pattern is universal in the sense that this one to one relationship is identical across architectures (such as VGG, Resnet, Densenet etc.), algorithms (SGD and SGD with momentum) and training loss functions (cross entropy and mean squared error).",7,4.966666666666667,11.25
